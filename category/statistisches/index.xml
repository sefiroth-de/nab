<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistisches | Norman&#39;s Academic Blog</title>
    <link>https://sefiroth.net/nab/category/statistisches/</link>
      <atom:link href="https://sefiroth.net/nab/category/statistisches/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistisches</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>de-de</language><copyright>© in 2017-2021 by Norman Markgraf</copyright><lastBuildDate>Sun, 27 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://sefiroth.net/nab/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Statistisches</title>
      <link>https://sefiroth.net/nab/category/statistisches/</link>
    </image>
    
    <item>
      <title>Datenjudo für Fragebögen </title>
      <link>https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Ab und zu bekomme ich die Frage, wie man einen Fragebogen mit Likert-Scalen-Items auswerten kann.&lt;/p&gt;
&lt;p&gt;Dazu kann etwas gezieltes Datenjudo helfen. Wir schauen uns das folgende generierte Mini-Beispiel an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)  # Basis Paket
library(tibble)  # Eine modernere Variante der data.frames!
set.seed(2009)   # Reproduzierbarkeit

N &amp;lt;- 25  # Anzahl der Testzeileneinträge in den &amp;quot;testdaten&amp;quot;!

# Wir wollen eine Likert-Scale 
minLikert &amp;lt;- 1  # bis
maxLikert &amp;lt;- 6  # erstellen.

# Für den Zufallszahlengenerator:
maxRnd &amp;lt;- maxLikert + 0.99

# Zum späteren Umrechnen der inversen Items:
maxInvItem &amp;lt;- maxLikert + 1

# Wir bauen uns eine Testumfrage mit zwei Itemserien 
# (AS1-AS6 und BS1-BS6) und N Beobachtungen.
# Die Items AS3, AS4  und BS1 und BS5 sind dabei 
# inverse Items, welche später umgerechnet werden:
testdaten &amp;lt;- tibble(
    ID = 1:N,
    # AS1-AS6 bilden ein Itemset:
    AS1 = trunc(runif(N, min = minLikert, max = maxLikert)),
    AS2 = trunc(runif(N, min = minLikert, max = maxLikert)),
    AS3 = trunc(runif(N, min = minLikert, max = maxLikert)),
    AS4 = trunc(runif(N, min = minLikert, max = maxLikert)),
    AS5 = trunc(runif(N, min = minLikert, max = maxLikert)),
    AS6 = trunc(runif(N, min = minLikert, max = maxLikert)),
    # BS1-BS5 bilden ein Itemset:
    BS1 = trunc(runif(N, min = minLikert, max = maxLikert)),
    BS2 = trunc(runif(N, min = minLikert, max = maxLikert)),
    BS3 = trunc(runif(N, min = minLikert, max = maxLikert)),
    BS4 = trunc(runif(N, min = minLikert, max = maxLikert)),
    BS5 = trunc(runif(N, min = minLikert, max = maxLikert)),
    # Geschlecht als sex mit (1 für Frauen und 2 für Männer)
    sex = trunc(runif(N, min = 1, max = 2.99))
)

# Orinal testdaten einmal ausgeben:
head(testdaten)
#&amp;gt; # A tibble: 6 x 13
#&amp;gt;      ID   AS1   AS2   AS3   AS4   AS5   AS6   BS1   BS2   BS3   BS4   BS5   sex
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1     1     1     1     5     4     2     1     1     5     5     1     3     1
#&amp;gt; 2     2     4     4     1     5     2     2     1     2     2     3     1     2
#&amp;gt; 3     3     4     1     5     2     4     2     1     1     3     2     4     2
#&amp;gt; 4     4     1     3     3     4     4     2     4     1     5     1     2     1
#&amp;gt; 5     5     3     2     2     2     1     5     1     3     4     5     4     2
#&amp;gt; 6     6     1     1     1     3     3     5     3     4     3     1     2     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Spalten AS3, AS4 und BS1, BS5 waren inverse Items, die wir noch umrechnen müssen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Inverse Item umrechnen:
testdaten %&amp;gt;%
    mutate(
        AS3 = maxInvItem - AS3,
        AS4 = maxInvItem - AS4,
        BS1 = maxInvItem - BS1,
        BS5 = maxInvItem - BS5
    ) -&amp;gt; testdaten_korrigiert 

# Die Daten mit den umgerechnetern inversen Items:
head(testdaten_korrigiert)
#&amp;gt; # A tibble: 6 x 13
#&amp;gt;      ID   AS1   AS2   AS3   AS4   AS5   AS6   BS1   BS2   BS3   BS4   BS5   sex
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1     1     1     1     2     3     2     1     6     5     5     1     4     1
#&amp;gt; 2     2     4     4     6     2     2     2     6     2     2     3     6     2
#&amp;gt; 3     3     4     1     2     5     4     2     6     1     3     2     3     2
#&amp;gt; 4     4     1     3     4     3     4     2     3     1     5     1     5     1
#&amp;gt; 5     5     3     2     5     5     1     5     6     3     4     5     3     2
#&amp;gt; 6     6     1     1     6     4     3     5     4     4     3     1     5     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die jeweiligen Itemsets werden nun zur einem Wert (Gesamtscore)
zusammengefasst, in dem wir jeweils den Mittelwert von &lt;code&gt;AS1&lt;/code&gt;-&lt;code&gt;AS6&lt;/code&gt;
und &lt;code&gt;BS1&lt;/code&gt;-&lt;code&gt;BS5&lt;/code&gt; bildenund in &lt;code&gt;AS&lt;/code&gt; bzw. &lt;code&gt;BS&lt;/code&gt; speichern:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir fassen nun die AS1-AS6 und die BS1-BS5 zusammen 
# und bilden die jeweiligen Mittelwerte:
testdaten_korrigiert %&amp;gt;%
    group_by(ID, sex) %&amp;gt;%  # Damit wird für jede Zeile die Zusammenfassung gemacht!
    summarise(
        AS = mean(c(AS1, AS2, AS3, AS4, AS5, AS6)),
        BS = mean(c(BS1, BS2, BS3, BS4, BS5))
    ) -&amp;gt; testdaten_sum

# Ausgabe der Mittelwerte der AS und BS
head(testdaten_sum)
#&amp;gt; # A tibble: 6 x 4
#&amp;gt; # Groups:   ID [6]
#&amp;gt;      ID   sex    AS    BS
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1     1     1  1.67   4.2
#&amp;gt; 2     2     2  3.33   3.8
#&amp;gt; 3     3     2  3      3  
#&amp;gt; 4     4     1  2.83   3  
#&amp;gt; 5     5     2  3.5    4.2
#&amp;gt; 6     6     1  3.33   3.4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Datentabelle &lt;code&gt;testdaten_sum&lt;/code&gt; enthält nun die Spalten &lt;code&gt;AS&lt;/code&gt; und &lt;code&gt;BS&lt;/code&gt; mit den entsprechenden Mittelwerten der einzelnen Items &lt;code&gt;AS1&lt;/code&gt;-&lt;code&gt;AS6&lt;/code&gt; sowieso &lt;code&gt;BS1&lt;/code&gt;- &lt;code&gt;BS5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Wir wollen nun die Ergebnisse als Boxplots anzeigen lassen. Dafür benennen wir die Geschlechter von 1,2 auf “Frau”, “Mann” um:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testdaten_sum %&amp;gt;%
    mutate(sex = factor(sex, levels = c(1, 2),
                             labels = c(&amp;quot;Frau&amp;quot;, &amp;quot;Mann&amp;quot;))
    ) -&amp;gt; testdaten_sex &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun können wir die Boxplots erstellen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Darstellung der Ergebnisse als Boxplot AS ~ sex:
gf_boxplot(AS ~ sex, data = testdaten_sex) %&amp;gt;%
    gf_labs(
        title = &amp;quot;Boxplot von AS nach Geschlechtern&amp;quot;,
        x = &amp;quot;Geschlechter&amp;quot;,
        y = &amp;quot;Item AS&amp;quot;
    ) %&amp;gt;%
  gf_refine(
    scale_y_continuous(
      breaks = 1:6, 
      label = 1:6,
      limits = c(2.5, 4.5)  # Gibt den Bereich von 2.5 bis 4.5 aus!
    )  
  )

# Darstellung der Ergebnisse als Boxplot BS ~ sex:
gf_boxplot(BS ~ sex, data = testdaten_sex) %&amp;gt;%
    gf_labs(
        title = &amp;quot;Boxplot von BS nach Geschlechtern&amp;quot;,
        x = &amp;quot;Geschlechter&amp;quot;,
        y = &amp;quot;Item BS&amp;quot;
    ) %&amp;gt;%
  gf_refine(
    scale_y_continuous(
      breaks = 1:6, 
      label = 1:6,
      limits = c(1, 6)  # GIbt den ganzen Bereich von 1 bis 6 aus!
    )  
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Kennzahlen dazu erhalten wir mit &lt;code&gt;favstats&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(AS ~ sex, data = testdaten_sex)[1:6]
#&amp;gt;    sex      min    Q1   median       Q3      max
#&amp;gt; 1 Frau 1.666667 2.625 3.333333 3.666667 4.000000
#&amp;gt; 2 Mann 3.000000 3.000 3.333333 3.500000 3.833333
favstats(BS ~ sex, data = testdaten_sex)[1:6]
#&amp;gt;    sex min  Q1 median  Q3 max
#&amp;gt; 1 Frau 2.6 3.2    3.6 4.0 4.2
#&amp;gt; 2 Mann 2.2 2.8    3.0 3.8 4.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Voilà!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dinge die man in zwei Dimensionen machen kann - Multiple lineare Regression</title>
      <link>https://sefiroth.net/nab/post/dinge-die-man-in-zwei-dimensionen-machen-kann-multiple-lineare-regression/</link>
      <pubDate>Thu, 24 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/dinge-die-man-in-zwei-dimensionen-machen-kann-multiple-lineare-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/dinge-die-man-in-zwei-dimensionen-machen-kann-multiple-lineare-regression/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Wir wollen den Fall unterschen bei dem wir mit zwei statistischen Variabeln (&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;) eine dritte Variable (&lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt;) mittels einer multiplen linearen Regression modellieren.&lt;/p&gt;
&lt;p&gt;Es seien die Datenpunkte &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1, z_1), \dots, (x_n, y_n, z_n)\)&lt;/span&gt; gegeben und wir wollen eine lineare Funktion &lt;span class=&#34;math inline&#34;&gt;\(g(x,y)\)&lt;/span&gt; finden, so dass&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
z_i = g(x_i,y_i)+ \epsilon_i =\beta_0 + \beta_1 \cdot x_i + \beta_2 \cdot y_i + \epsilon_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt und der Abweichungsterm &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_i\)&lt;/span&gt; möglichst klein ist.&lt;/p&gt;
&lt;p&gt;Auf Grundlage unserer Datenpunkt wollen wir die Koeffizienten so schätzen, dass die Summe der quadratische Abweichungen minimal ist.
&lt;span class=&#34;math display&#34;&gt;\[
  QS = QS(\hat\beta_0, \hat\beta_1, \hat\beta_2) 
  = \sum\limits_{i=1}^n (z_i - \hat\beta_0 - \hat\beta_1 \cdot x_i - \hat\beta_2 \cdot y_i )^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Das führt zu der folgenden, notwendigen Bedingen (für stationäre Punkte):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\nabla QS(\hat\beta_0, \hat\beta_1, \hat\beta_2) = \begin{pmatrix} 0\\ 0\\ 0\end{pmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Im einzelnen heißt das:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{\partial}{\partial \hat\beta_0} QS(\hat\beta_0, \hat\beta_1, \hat\beta_2) &amp;amp;= -2 \cdot\sum\limits_{i=1}^n \left(z_i - \hat\beta_0 - \hat\beta_1 \cdot x_i - \hat\beta_2 \cdot y_i \right) \\
&amp;amp;= -2 \cdot n \cdot \left(\bar{z} - \hat\beta_0 - \hat\beta_1 \cdot\bar{x} - \hat\beta_2 \cdot\bar{y} \right) \\
\\
\frac{\partial}{\partial \hat\beta_1} QS(\hat\beta_0, \hat\beta_1, \hat\beta_2) &amp;amp;= -2 \cdot \sum\limits_{i=1}^n \left( z_i\cdot x_i - \hat\beta_0 \cdot x_i - \hat\beta_1 \cdot x_i\cdot x_i - \hat\beta_2 \cdot y_i\cdot x_i \right) \\
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n  z_i\cdot x_i -  \hat\beta_0 \cdot n \cdot \bar{x}- \hat\beta_1 \cdot \sum\limits_{i=1}^n x_i^2 - \hat\beta_2 \cdot \sum\limits_{i=1}^n y_i\cdot x_i \right) \\
\\
\frac{\partial}{\partial \hat\beta_2} QS(\hat\beta_0, \hat\beta_1, \hat\beta_2) &amp;amp;= -2 \cdot \sum\limits_{i=1}^n \left( z_i\cdot y_i - \hat\beta_0 \cdot y_i - \hat\beta_1 \cdot x_i\cdot y_i - \hat\beta_2 \cdot y_i\cdot y_i \right) \\
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n  z_i\cdot y_i -  \hat\beta_0 \cdot n \cdot \bar{y}- \hat\beta_1 \cdot \sum\limits_{i=1}^n x_i\cdot y_i - \hat\beta_2 \cdot \sum\limits_{i=1}^n y_i^2 \right) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir setzen die 1. Gleichung gleich Null und stellen nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
  \hat\beta_0 = \bar{z}  - \hat\beta_1 \cdot \bar{x} - \hat\beta_2 \cdot \bar{y}
\]&lt;/span&gt;
Nun ersetzen wir &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; in den verbleibenden Gleichungen durch &lt;span class=&#34;math inline&#34;&gt;\(z_i - \hat\beta_1 \cdot x_i - \hat\beta_2 \cdot y_i\)&lt;/span&gt; und nutzen den Verschiebesatz:
&lt;!--
% &amp;= -2 \cdot \left(\sum\limits_{i=1}^n  z_i\cdot x_i - n \cdot \bar{z}\cdot \bar{x} + \hat\beta_1 \cdot n \cdot \bar{x}^2 + \hat\beta_2 \cdot n \cdot \bar{y}\cdot \bar{x}- \hat\beta_1 \cdot \sum\limits_{i=1}^n x_i^2 - \hat\beta_2 \cdot \sum\limits_{i=1}^n y_i\cdot x_i \right) \\
--&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\frac{\partial}{\partial \hat\beta_1} QS
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n  z_i\cdot x_i - (\bar{z}  - \hat\beta_1 \cdot \bar{x} - \hat\beta_2 \cdot \bar{y}) \cdot n \cdot \bar{x}- \hat\beta_1 \cdot \sum\limits_{i=1}^n x_i^2 - \hat\beta_2 \cdot \sum\limits_{i=1}^n y_i\cdot x_i \right) \\
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n (z_i-\bar{z})(x_i - \bar{x}) - \hat\beta_1 \cdot \sum\limits_{i=1}^n (x_i -\bar{x})^2 - \hat\beta_2 \cdot \sum\limits_{i=1}^n (y_i-\bar{y})(x_i- \bar{x}) \right) \\
\\
\frac{\partial}{\partial \hat\beta_2} QS 
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n  z_i\cdot y_i - (\bar{z}  - \hat\beta_1 \cdot \bar{x} - \hat\beta_2 \cdot \bar{y}) \cdot n \cdot \bar{y}- \hat\beta_1 \cdot \sum\limits_{i=1}^n x_i\cdot y_i - \hat\beta_2 \cdot \sum\limits_{i=1}^n y_i^2 \right) \\
&amp;amp;= -2 \cdot \left(\sum\limits_{i=1}^n (z_i-\bar{z})(y_i - \bar{y}) - \hat\beta_2 \cdot \sum\limits_{i=1}^n (y_i -\bar{y})^2 - \hat\beta_1 \cdot \sum\limits_{i=1}^n (y_i-\bar{y})(x_i- \bar{x}) \right) \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir setzen die beiden Gleichungen nun gleich Null und formen nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_2\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \hat\beta_1 
  &amp;amp;= \frac{\sum\limits_{i=1}^n (z_i-\bar{z})(x_i - \bar{x}) - \hat\beta_2 \cdot \sum\limits_{i=1}^n (y_i-\bar{y})(x_i- \bar{x})}{\sum\limits_{i=1}^n (x_i -\bar{x})^2} \\
  \\
  \hat\beta_2 
  &amp;amp;= \frac{\sum\limits_{i=1}^n (z_i-\bar{z})(y_i - \bar{y}) - \hat\beta_1 \cdot \sum\limits_{i=1}^n (y_i-\bar{y})(x_i- \bar{x})}{\sum\limits_{i=1}^n (y_i -\bar{y})^2}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Durch Erweiterung von Zähler nun Nenner mit &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n-1}\)&lt;/span&gt; erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \hat\beta_1 
  &amp;amp;= \frac{\frac{1}{n-1}\cdot\sum\limits_{i=1}^n (z_i-\bar{z})(x_i - \bar{x}) - \hat\beta_2 \cdot \frac{1}{n-1}\cdot\sum\limits_{i=1}^n (y_i-\bar{y})(x_i- \bar{x})}{\frac{1}{n-1}\cdot\sum\limits_{i=1}^n (x_i -\bar{x})^2} \\
  &amp;amp;= \frac{s_{x,z}-\hat\beta_2\cdot s_{x,y}}{s^2_{x}} = \frac{s_{x,z}}{s^2_x}-\hat\beta_2 \frac{s_{x,y}}{s^2_{x}} \\
  \\
  \hat\beta_2 
  &amp;amp;= \frac{\frac{1}{n-1}\cdot\sum\limits_{i=1}^n (z_i-\bar{z})(y_i - \bar{y}) - \hat\beta_1 \cdot \frac{1}{n-1}\cdot\sum\limits_{i=1}^n (y_i-\bar{y})(x_i - \bar{x})}{\frac{1}{n-1}\cdot\sum\limits_{i=1}^n (y_i -\bar{y})^2} \\
  &amp;amp;= \frac{s_{y,z}-\hat\beta_1\cdot s_{x,y}}{s^2_{y}} = \frac{s_{y,z}}{s^2_y}-\hat\beta_1 \frac{s_{x,y}}{s^2_{y}} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;wir setzen nun die erste in die zweite Gleichung ein und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\hat\beta_2 
  &amp;amp;= \frac{s_{y,z}}{s^2_y} - \left(\frac{s_{x,z}}{s^2_x}-\hat\beta_2 \frac{s_{x,y}}{s^2_{x}}\right) \frac{s_{x,y}}{s^2_{y}} \\
  &amp;amp;= \frac{s_{y,z}}{s^2_y} - \frac{s_{x,z}}{s^2_x}\frac{s_{x,y}}{s^2_{y}} + \hat\beta_2 \frac{s_{x,y}}{s^2_{x}}\frac{s_{x,y}}{s^2_{y}} \\
  &amp;amp;= \frac{\frac{s_{y,z}}{s^2_y} - \frac{s_{x,z}}{s^2_x}\frac{s_{x,y}}{s^2_{y}}}{1-\frac{s_{x,y}}{s^2_{x}}\frac{s_{x,y}}{s^2_{y}}} \\
  &amp;amp;= \frac{\frac{s_{y,z}\cdot s^2_x - s_{x,z} s_{x,y}}{s^2_x\cdot s^2_y}}{\frac{s^2_x s^2_y-(s_{x,y})^2}{s^2_x \cdot s^2_y}}
  = \frac{s_{y,z}\cdot s^2_x - s_{x,z} s_{x,y}}{s^2_x s^2_y-(s_{x,y})^2}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Und damit weiter:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\hat\beta_1  
  &amp;amp;= \frac{s_{x,z}}{s^2_x}-\hat\beta_2 \frac{s_{x,y}}{s^2_{x}} \\
  &amp;amp;= \frac{s_{x,z}}{s^2_x} - \frac{s_{y,z}\cdot s^2_x - s_{x,z} s_{x,y}}{s^2_x s^2_y-(s_{x,y})^2} \frac{s_{x,y}}{s^2_{x}} \\
  &amp;amp;= \frac{s_{x,z} (s^2_x s^2_y - (s_{x,y})^2) - s_{y,z}s_{x,y}s^2_x + s_{x,z}s_{x,y}s_{x,y}}{s^2_x (s^2_x s^2_y - (s_{x,y})^2)} \\
    &amp;amp;= \frac{s_{x,z}s^2_x s^2_y - s_{x,z}(s_{x,y})^2 - s_{y,z}s_{x,y}s^2_x + s_{x,z}(s_{x,y})^2}{s^2_x s^2_x s^2_y- s^2_x(s_{x,y})^2} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)

mtcars %&amp;gt;%
  select(mpg, hp, wt) -&amp;gt; dt

# Von R berechnete Koeffizienten:
coef(lm(mpg ~ hp + wt, data = dt))
#&amp;gt; (Intercept)          hp          wt 
#&amp;gt; 37.22727012 -0.03177295 -3.87783074

mean_x = mean( ~ hp, data = dt)
mean_y = mean( ~ wt, data = dt)
mean_z = mean( ~ mpg, data = dt)

s_xy &amp;lt;- cov(hp ~ wt, data = dt)
s_xz &amp;lt;- cov(hp ~ mpg, data = dt)
s_yz &amp;lt;- cov(wt ~ mpg, data = dt)

var_x &amp;lt;- var(~ hp, data = dt)
var_y &amp;lt;- var(~ wt, data = dt)

b1 &amp;lt;- (s_xz*var_x*var_y - s_xz*(s_xy)**2 - s_yz*s_xy*var_x + s_xz*s_xy**2) / (var_x*var_x*var_y - var_x*s_xy**2)
b2 &amp;lt;- (s_yz*var_x - s_xz*s_xy) / (var_x * var_y- s_xy*s_xy)
b0 &amp;lt;- mean_z - b1 * mean_x - b2 * mean_y

# Koeffizienten zur Ausgabe aufbereiten:
my_coef &amp;lt;- c(b0, b1, b2)
names(my_coef) &amp;lt;- c(&amp;quot;(Intercept)&amp;quot;, &amp;quot;hp&amp;quot;, &amp;quot;wt&amp;quot;)

# Von Hand berechnete Koeffizienten:
my_coef
#&amp;gt; (Intercept)          hp          wt 
#&amp;gt; 37.22727012 -0.03177295 -3.87783074&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;was-passiert-wenn-wir-alle-datenpunkte-studentisieren&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Was passiert, wenn wir alle Datenpunkte studentisieren?&lt;/h2&gt;
&lt;p&gt;Wir rechnen um in:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
x_i^{\text{stud}} = \frac{x_i-\bar{x}}{s_x}; \quad y_i^{\text{stud}} = \frac{y_i-\bar{y}}{s_y}; \quad z_i^{\text{stud}} = \frac{z_i-\bar{z}}{s_z}
\]&lt;/span&gt;
Damit ist
&lt;span class=&#34;math display&#34;&gt;\[
\bar{x_i}^\text{stud} = 0; \quad \bar{y_i}^\text{stud} = 0;\quad \bar{z_i}^\text{stud} = 0
\]&lt;/span&gt;
und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
s_{{x_i}^\text{stud}} = 1; \quad s_{{y_i}^\text{stud}} = 1;\quad s_{{z_i}^\text{stud}} = 1
\]&lt;/span&gt;
Zur Vereinfachung lassen wir die Kennzeichnung “stud” weg.
Damit ist dann:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\hat\beta_0
  &amp;amp;= 0\\
\\
\hat\beta_1
  &amp;amp;= \frac{s_{x,z} \cdot s^2_x \cdot s^2_y - s_{x,z} \cdot (s_{x,y})^2 - s_{y,z} \cdot s_{x,y}s^2_x + s_{x,z} \cdot (s_{x,y})^2}{s^2_x \cdot s^2_x s^2_y- s^2_x \cdot (s_{x,y})^2} \\ 
  &amp;amp;= \frac{s_{x,z} \cdot 1 \cdot 1 -  s_{x,z} \cdot (s_{x,y})^2 - s_{y,z} \cdot s_{x,y} \cdot 1 + s_{x,z} \cdot (s_{x,y})^2}{1 \cdot 1 \cdot 1 - 1 \cdot (s_{x,y})^2}\\
  &amp;amp;= \frac{s_{x,z} -  s_{x,z} \cdot (s_{x,y})^2 - s_{y,z} \cdot s_{x,y} + s_{x,z} \cdot (s_{x,y})^2}{1 - (s_{x,y})^2} \\
  &amp;amp;= \frac{s_{x,z} - s_{y,z} \cdot s_{x,y} }{1 - (s_{x,y})^2} \\
\\
\hat\beta_2
  &amp;amp;= \frac{s_{y,z} \cdot s^2_x - s_{x,z} \cdot s_{x,y}}{s^2_x \cdot s^2_y - (s_{x,y})^2} \\ 
  &amp;amp;= \frac{s_{y,z} \cdot 1 - s_{x,z} \cdot s_{x,y}}{1 \cdot 1 - (s_{x,y})^2} \\
  &amp;amp;= \frac{s_{y,z} - s_{x,z} \cdot s_{x,y}}{1 - (s_{x,y})^2} \\
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir schauen uns ein paar Fälle genauer an:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Fall: &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; sind unabhängig.&lt;/strong&gt; Dann ist &lt;span class=&#34;math inline&#34;&gt;\(s_{x,y}=0\)&lt;/span&gt; und wir erhalten &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1=s_{x,z}\in[-1;1]\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_2=s_{y,z}\in[-1;1]\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fall: &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; sind abhängig.&lt;/strong&gt; Dann ist &lt;span class=&#34;math inline&#34;&gt;\(|s_{x,y}|=1\)&lt;/span&gt; und es gibt keine Lösung für &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fall: &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt; |s_{x,y}| &amp;lt; 1\)&lt;/span&gt;.&lt;/strong&gt; …&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Interaktionseffekte leichter interpretieren durch Transformationen</title>
      <link>https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;einleitung&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Einleitung&lt;/h3&gt;
&lt;p&gt;Bei einer multiplen linearen Regression kann man den Einfluss einer unabhägigen Variable auf das Verhalten einer anderen unabhägigen Variable in Bezug auf die abhägige Variable mit modellieren.&lt;/p&gt;
&lt;p&gt;Wir wollen das einmal an dem Beispiel der folgenden Datentabelle &lt;a href=&#34;https://vincentarelbundock.github.io/Rdatasets/doc/AER/TeachingRatings.html&#34;&gt;&lt;em&gt;Impact of Beauty on Instructor’s Teaching Ratings&lt;/em&gt;&lt;/a&gt; und der Fragestellung in wie weit das Alter und das Geschlecht einen Einfluss auf das Evaluationsergebnis haben.&lt;/p&gt;
&lt;p&gt;Dazu stellen laden wir die Daten aus dem Internet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
url &amp;lt;- paste0(&amp;quot;https://vincentarelbundock.github.io/Rdatasets/csv/AER/&amp;quot;,
              &amp;quot;TeachingRatings.csv&amp;quot;)
teacherratings &amp;lt;- read.csv(url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und betrachten das Streudiagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(eval ~ age, color = ~gender, data = teacherratings)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-lineares-modell&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein lineares Modell&lt;/h3&gt;
&lt;p&gt;Ein klassisches lineares Modell sieht wie folgt aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erglm &amp;lt;- lm(eval ~ age + gender + age:gender, data = teacherratings)
coef(erglm)
#&amp;gt;    (Intercept)            age     gendermale age:gendermale 
#&amp;gt;     4.49018892    -0.01306572    -0.32104348     0.01109285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doch was bedeuten diese Werte konkret:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;(Intercept) = 4.4901889: Gibt das (theoretische) Evaluationsergebnis für einer Frau im Alter von 0 Jahren an.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age = -0.0130657: Gibt an, um wie viele Punkte im Schnitt sich eine Frau pro Lebensjahr mehr verändert. (Da der Wert negativ ist, also verschlechtert.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;gendermale = -0.3210435: Gibt an, um wie viel sich das Startwert bei 0 Jahren verändert, wenn es ein Mann gewesen wäre. Wir kommen damit auf einen Startwert bei 0 Jahren für Männer von 4.1691454&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age:gendermale = 0.0110928: Gibt an um wie viel sich die Steigung ändert, wenn statt einer Frau ein Mann betrachtet wird. Statt einer Änderung um -0.0130657 bei Frauen beträgt sie bei Männern &lt;span class=&#34;math inline&#34;&gt;\(-0.0130657-0.0110928 = -0.0019729\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_female = c(coef(erglm)[1], coef(erglm)[2])
coef_male = c(
  coef(erglm)[1] + coef(erglm)[3],
  coef(erglm)[2] + coef(erglm)[4]
)
gf_point(eval ~ age, color = ~gender, data = teacherratings) %&amp;gt;%
  gf_coefline(coef = coef_female, color = ~&amp;quot;female&amp;quot;) %&amp;gt;%
  gf_coefline(coef = coef_male, color = ~&amp;quot;male&amp;quot;) 
  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können so die folgenden Modellgleichungen aufstellen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Für Frauen:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \widehat{eval}_{\text{female}} 
  &amp;amp; = 4.4901889 - 0.0130657 \cdot age \\
  &amp;amp;\approx 4.49 - 0.013 \cdot age
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Für Männer:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\widehat{eval}_{\text{male}} 
  &amp;amp;= 4.1691454 - 0.0019729 \cdot age\\
  &amp;amp;\approx 4.169 - 0.002 \cdot age
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;besserer-blick-durch-gute-transformation-der-daten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Besserer Blick durch gute Transformation der Daten&lt;/h3&gt;
&lt;p&gt;Spannender wäre es aber, wenn die y-Achenabschnitte nicht so weit ausserhalb unseres Betrachungsbereichs (29; 73) liegen würde.&lt;/p&gt;
&lt;p&gt;Wir zentrieren daher einmal unsere Altersangaben mit der Transformation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[age_i^\text{center} =  age_i - \overline{age}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Mittelwert bestimmen und speichern:
mean_age = mean( ~ age, data = teacherratings)

# Transformation durchführen:
teacherratings %&amp;gt;%
  mutate(
    age_center = age - mean_age
  ) -&amp;gt; teacherratings

# Das Ergebnis kurz zusammenfassen:
df_stats(~ age + age_center, min, mean, sd, max, 
         data = teacherratings)
#&amp;gt;     response       min         mean       sd      max
#&amp;gt; 1        age  29.00000 4.836501e+01 9.802742 73.00000
#&amp;gt; 2 age_center -19.36501 3.514033e-15 9.802742 24.63499&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das der Mittelwert bei den zentrierten Daten nicht exakt Null ist liegt an den numerischen Besonderheiten des Rechners. Kurz: Computer können gar nicht richitg rechnen und haben daher hier einen kleinen Rundungsfehler!&lt;/p&gt;
&lt;p&gt;Betrachten wir die gerundeten Werte, so ergibt sich das folgende, etwas übersichtlichere Bild:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir bauen uns gerundete Funktionen:
round_digits &amp;lt;- 3  # Anzahl der Nachkommastellen

mean_r &amp;lt;- function(x) round(mean(x), round_digits)
sd_r &amp;lt;- function(x) round(sd(x), round_digits)
min_r &amp;lt;- function(x) round(min(x), round_digits)
max_r &amp;lt;- function(x) round(max(x), round_digits)

# Wir benutzen nun die gerundeten Werte:
df_stats(~ age + age_center, min_r, mean_r, sd_r, max_r, 
         data = teacherratings)
#&amp;gt;     response   min_r mean_r  sd_r  max_r
#&amp;gt; 1        age  29.000 48.365 9.803 73.000
#&amp;gt; 2 age_center -19.365  0.000 9.803 24.635&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Im Mittel sind unsere Lehrer:innen also &lt;span class=&#34;math inline&#34;&gt;\(48.365\)&lt;/span&gt; alt, die Jüngsten mit 29 etwa &lt;span class=&#34;math inline&#34;&gt;\(19.365\)&lt;/span&gt; jünger und die Ältesten mit 73 etwa &lt;span class=&#34;math inline&#34;&gt;\(24.635\)&lt;/span&gt; älter als der Altersdurchschnitt.&lt;/p&gt;
&lt;p&gt;Ein Blick auf die Koeffizenten des linearen Modells bzgl. der zentrierten Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erglm_c &amp;lt;- lm(eval ~ age_center + gender + age_center:gender, 
              data = teacherratings)
coef(erglm_c)
#&amp;gt;           (Intercept)            age_center            gendermale 
#&amp;gt;            3.85826543           -0.01306572            0.21546232 
#&amp;gt; age_center:gendermale 
#&amp;gt;            0.01109285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das dazu passende Streudiagramm mit den Regressionsgeraden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_c_female = c(coef(erglm_c)[1], coef(erglm_c)[2])
coef_c_male = c(
  coef(erglm_c)[1] + coef(erglm_c)[3],
  coef(erglm_c)[2] + coef(erglm_c)[4]
)
gf_point(eval ~ age_center, color = ~gender, 
         data = teacherratings) %&amp;gt;%
  gf_coefline(coef = coef_c_female, color = ~&amp;quot;female&amp;quot;) %&amp;gt;%
  gf_coefline(coef = coef_c_male, color = ~&amp;quot;male&amp;quot;) 
  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Was bedeuten nun diese Werte konkret:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;(Intercept) = 3.8582654: Gibt das Evaluationsergebnis für einer Frau mit Durchschnittsalter (48) an.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age = -0.0130657: Gibt an, um wie viele Punkte im Schnitt sich eine Frau pro Lebensjahr mehr verändert.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;gendermale = -0.3210435: Gibt an, um wie viel sich das Evaluationsergebnis eines Mannes im Durchschnittsalter ändert gegenüber dem einer Frau. Für das Durchschnittalter liegen Männer im Schnitt bei 4.0737278&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age:gendermale = 0.0110928: Gibt an, um wie viel sich die Steigung ändert, wenn statt einer Frau ein Mann betrachtet wird. Statt einer Änderung um -0.0130657 bei Frauen beträgt sie bei Männern &lt;span class=&#34;math inline&#34;&gt;\(-0.0130657-0.0110928 = -0.0019729\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wir können daher die folgenden Modellgleichungen aufstellen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Für Frauen:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \widehat{eval}_{\text{female}} 
  &amp;amp; = 3.8582654 - 0.0130657 \cdot (age - 48.3650108) \\
  &amp;amp;\approx 3.858 - 0.013 \cdot (age - 48.365) 
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Für Männer:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\widehat{eval}_{\text{male}} 
  &amp;amp;= 4.0737278 - 0.0019729 \cdot (age - 48.3650108) \\
  &amp;amp;\approx 4.074 - 0.002 \cdot (age - 48.365)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;zur-interpretation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zur Interpretation&lt;/h3&gt;
&lt;p&gt;Im durchschnittlichen Alter ist das erwartete Evaluationsergebnis bei Frauen (&lt;span class=&#34;math inline&#34;&gt;\(3.8582654\)&lt;/span&gt;) um rund &lt;span class=&#34;math inline&#34;&gt;\(0.215\)&lt;/span&gt; Punkte schlechter als bei Männern (&lt;span class=&#34;math inline&#34;&gt;\(4.0737278\)&lt;/span&gt;).
Mit jedem Lebensjahr sinkt dabei in beiden Fällen, also sowohl bei Frauen als auch bei Männern, das Evaluationsergbnis.
Bei den Frauen aber mit ca. &lt;span class=&#34;math inline&#34;&gt;\(-0.013\)&lt;/span&gt; deutlich stärker als mit ca. &lt;span class=&#34;math inline&#34;&gt;\(-0.002\)&lt;/span&gt; bei den Männern .&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fazit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Eine gute Transformation einiger Daten kann, dank der angepassten
Modellgleichungen, die Interpretation der Ergebnisse deutlich
vereinfachen!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nachtrag-und-danksagung&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nachtrag und Danksagung&lt;/h2&gt;
&lt;p&gt;Die Idee zu diesem Blog-Post verdanke ich dem Blog von &lt;em&gt;Prof. Dr. Sebastian Sauer&lt;/em&gt;. Hier der Link zum Orginal-Blog: &lt;a href=&#34;https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/&#34;&gt;https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Danke auch für die kritische Durchsicht und die hilfreichen Anmerkungen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reproduzierbarkeitsinformationen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproduzierbarkeitsinformationen&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt; 
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt; 
#&amp;gt; Package version:
#&amp;gt;   mosaic_1.8.3 xfun_0.24&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Regression mit studentisierten Daten</title>
      <link>https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Bei einer einfachen linearen Regression versuchen wir zu vorgegebenen Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1), \cdots (x_n, y_n)\)&lt;/span&gt; die Parameter einer
möglichst passenden Gerade &lt;span class=&#34;math inline&#34;&gt;\(g(x)=\beta_0 + \beta_1 \cdot x\)&lt;/span&gt; zu schätzen.&lt;/p&gt;
&lt;p&gt;Die Schätzung des y-Achsenabschnitts &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und der Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; erfolgt dabei algebraisch exakt mittels:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0 = \bar{y} - \hat\beta_1 \cdot \bar{x} \quad\text{und}\quad \hat\beta_1 = \frac{s_x}{s_y}\cdot r_{x,y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dabei sind &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt; die Mittelwerte und &lt;span class=&#34;math inline&#34;&gt;\(s_x\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(s_y\)&lt;/span&gt; die Standardabweichungen der Datenpunkte &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;; darüberhinaus ist &lt;span class=&#34;math inline&#34;&gt;\(r_{x,y}\)&lt;/span&gt; der Korrelationskoeffizient der Datenpunkte.&lt;/p&gt;
&lt;p&gt;Beim studentisieren werden die Datenpunkte bzgl. des Mittelwertes zentriert und bzgl der Standardabweichung normiert:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_i^{\text{stud}} = \frac{x_i-\bar{x}}{s_x} \quad\text{bzw.}\quad y_i^{\text{stud}} = \frac{y_i-\bar{y}}{s_y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Was passiert nun durch eine solche Studentisierung (oft auch z-Transformation genannt) mit den geschätzen Parametern?&lt;/p&gt;
&lt;p&gt;Die Mittelwerte &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}^{stud}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}^{stud}\)&lt;/span&gt; werden zu Null. Die Standardabweichungen &lt;span class=&#34;math inline&#34;&gt;\(s_{x^{stud}}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(s_{y^stud}\)&lt;/span&gt; werden zur Eins:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{x}^{stud}=0=\bar{y}^{stud} \qquad s_{x^{stud}}= 1 = s_{y^{stud}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der y-Achsenabschnitt wird nun durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0^{stud} 
= \bar{y}^{stud} - \hat\beta_1^{stud} \cdot \bar{x}^{stud}
= 0 - \hat\beta_1^{stud} \cdot 0 = 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und die Steigung durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta_1^{stud} 
= \frac{s_{x^{stud}}}{s_{y^{stud}}}\cdot r_{x^{stud},y^{stud}}
= \frac{1}{1}\cdot r_{x^{stud},y^{stud}} = r_{x^{stud},y^{stud}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;geschätzt.&lt;/p&gt;
&lt;p&gt;Für den Korrelationskoeffienten gilt nun
&lt;span class=&#34;math display&#34;&gt;\[
r_{x^{stud},y^{stud}} 
= \frac{s_{x^{stud},y^{stud}}}{s_{x^{stud}}\cdot_{y^{stud}}}
= \frac{s_{x^{stud},y^{stud}}}{1 \cdot 1}
= s_{x^{stud},y^{stud}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Damit Schätzen wir unsere Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1^{stud}\)&lt;/span&gt; direkt aus der Kovarianz &lt;span class=&#34;math inline&#34;&gt;\(s_{x^{stud},y^{stud}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Damit gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1^{stud} = r_{x^{stud},y^{stud}} = s_{x^{stud},y^{stud}} \in [-1, 1]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In Worten zusammengefasst:
&lt;em&gt;Im studentisierten Fall ist&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;der y-Achsenabschnitt immer 0 und&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;die Steigung immer ein Wert zwischen -1 und 1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;beispiel-mtcars--daten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Beispiel: &lt;code&gt;mtcars&lt;/code&gt;- Daten&lt;/h3&gt;
&lt;p&gt;Auf Grundlage der Datentabelle &lt;em&gt;mtcars&lt;/em&gt; wollen wir den linearer
Zusammenhang zwischen dem Verbrauch (in Meilen pro Gallone &lt;em&gt;mpg&lt;/em&gt;)
und der Leistung (Pferdestärke &lt;em&gt;hp&lt;/em&gt;) modellieren.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)

# Wir nehmen die Datentabelle &amp;#39;mtcars&amp;#39;:
mtcars %&amp;gt;%
  select(hp, mpg) -&amp;gt; dt

# Ein kurzer Blick aus die Daten:
df_stats( ~ hp + mpg, mean, sd, data = dt)
#&amp;gt;   response      mean        sd
#&amp;gt; 1       hp 146.68750 68.562868
#&amp;gt; 2      mpg  20.09062  6.026948

# Wir vergleichen den Verbrauch (mpg, miles per gallon) 
# mit den Pferdestärken (hp) mit Hilfe eines Streudiagramms.
# Dazu berechnen wir vorab die Mittelwerte
mean_hp &amp;lt;- mean(~ hp, data = dt)
mean_mpg &amp;lt;- mean(~ mpg, data = dt)

# und berechnen nun die Schätzwerte für die Regressionsgerade
beta_1 &amp;lt;- cov(mpg ~ hp, data = dt) / var(~ hp, data = dt)
beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp

# schliesslich zeichnen alles in das Streudiagramm ein:
gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, 
           color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1, intercept = ~beta_0, 
            color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988605 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Studentisieren wir nun die &lt;em&gt;mpg&lt;/em&gt; und &lt;em&gt;hp&lt;/em&gt; Werte. In &lt;strong&gt;R&lt;/strong&gt; können wir das mit der Funktion ‘zscore()’&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; wie folgt machen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dt %&amp;gt;%
  mutate(
    hp_stud = zscore(hp),
    mpg_stud = zscore(mpg)
  ) -&amp;gt; dt

# Ein kurzer Blick aus die Daten:
df_stats( ~ hp_stud + mpg_stud, mean, sd, data = dt)
#&amp;gt;   response         mean sd
#&amp;gt; 1  hp_stud 1.040834e-17  1
#&amp;gt; 2 mpg_stud 7.112366e-17  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Grund für die kleinen Abweichungen von der Null bei den Mittelwerten
sind unumgängliche Rundungsfehler, die der Computer macht!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir &amp;quot;berechnen&amp;quot; die Mittelwerte:
mean_hp_stud &amp;lt;- 0 # = mean(~ hp_stud, data = dt)
mean_mpg_stud &amp;lt;- 0 # = mean(~ mpg_stud, data = dt)

# Berechnen wir nun die Schätzwerte für die Regressionsgerade:
beta_1_stud &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt)
beta_0_stud &amp;lt;- 0 # = mean_mpg_stud - beta_1_stud * mean_hp_stud

# und zeichnen diese in unser Streudiagramm ein:
gf_point(mpg_stud ~ hp_stud, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg_stud, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp_stud, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg_stud ~ mean_hp_stud, 
           color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1_stud, intercept = ~beta_0_stud, 
            color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(-2,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade im studentisierten Problem lautet nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta^{stud}_0 + \hat\beta_1^{stud} \cdot x^{stud} \\ 
    &amp;amp;\approx 0 - 0.7761684 \cdot x^{stud} \\
    &amp;amp;\approx 0 -0.776 \cdot x^{stud} 
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;direkt-mit-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Direkt mit ‘R’&lt;/h3&gt;
&lt;p&gt;Wir erhalten unsere Ergebnisse natürlich auch direkt in R, ohne selber die Werte auszurechnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Ursprüngliches Modell:
erglm &amp;lt;- lm(mpg ~ hp, data = dt)
coef(erglm)
#&amp;gt; (Intercept)          hp 
#&amp;gt; 30.09886054 -0.06822828

# Studentisiertes Modell:
erglm_stud &amp;lt;- lm(mpg_stud ~ hp_stud, data = dt)
coef(erglm_stud)
#&amp;gt;   (Intercept)       hp_stud 
#&amp;gt; -3.149357e-17 -7.761684e-01&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;zurückrechnen-der-studentisierten-werte-in-das-ursprüngliche-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zurückrechnen der studentisierten Werte in das ursprüngliche Problem&lt;/h3&gt;
&lt;p&gt;Aus dem Ergebnis des studentisierten Modells können wir die Koeffizenten des ursprünglichen Modells wie folgt berechnen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1 = \hat\beta_1^{stud} \cdot \frac{s_y}{s_x}\]&lt;/span&gt;
und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0 = \bar{y} - \hat\beta_1 \cdot \bar{x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; geht das wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_mpg &amp;lt;- mean( ~ mpg, data = dt)
sd_mpg &amp;lt;- sd( ~ mpg, data = dt)
mean_hp &amp;lt;- mean( ~ hp, data = dt)
sd_hp &amp;lt;- sd( ~ hp, data = dt)

(beta_1 &amp;lt;- beta_1_stud * sd_mpg / sd_hp)
#&amp;gt; [1] -0.06822828
(beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp)
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
### Fazit

...

## Reproduzierbarkeitsinformationen

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt;
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt;
#&amp;gt; Package version:
#&amp;gt; mosaic_1.8.3 tidyr_1.1.3 xfun_0.24
```&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Das “Cookbook” zur Datentabelle können Sie mit Hilfe von &lt;code&gt;help(&#34;mtcars&#34;)&lt;/code&gt; aufrufen!&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Sie können hier auch die Funktion &lt;code&gt;scale()&lt;/code&gt; verwenden!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Wege zur Normalverteilung</title>
      <link>https://sefiroth.net/nab/post/wege-zur-normalverteilung/</link>
      <pubDate>Fri, 11 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/wege-zur-normalverteilung/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Der fairen Wurf einer fairen Münze, also eine Münze bei der Kopf und Zahl gleich wahrscheinlich geworfen wird, sei der Ausgang des ersten Weges.&lt;/p&gt;
&lt;p&gt;Wir können den Münzwurf mit R simulieren:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
set.seed(2009)

rflip(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Flipping 1 coin [ Prob(Heads) = 0.5 ] ...
## 
## T
## 
## Number of Heads: 0 [Proportion Heads: 0]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Genauso wie den Wurf zweier Münzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rflip(2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Flipping 2 coins [ Prob(Heads) = 0.5 ] ...
## 
## H H
## 
## Number of Heads: 2 [Proportion Heads: 1]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oder auch von 20 Münzwürfen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rflip(20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Flipping 20 coins [ Prob(Heads) = 0.5 ] ...
## 
## T T T T H H T T T H H H H T H T T H H H
## 
## Number of Heads: 10 [Proportion Heads: 0.5]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir wollen uns dafür interessieren, wie der Zufall auf jeweils &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; Münzwürfe einwirkt&lt;/p&gt;
&lt;p&gt;Und wieder holen dafür die drei Experiment jeweils &lt;span class=&#34;math inline&#34;&gt;\(N=10^{4}\)&lt;/span&gt; mal und schauen
uns danach anwie die Anzahl der &lt;em&gt;Kopf&lt;/em&gt; Würfe variiert:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N &amp;lt;- 10000&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1
vrtlg_1 &amp;lt;- do(N) * rflip(n)
gf_bar(~ heads, data = vrtlg_1) %&amp;gt;%
  gf_refine(scale_x_continuous(breaks = 0:n, limits = c(-0.5,n + 0.5)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n=2\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 2
vrtlg_2 &amp;lt;- do(N) * rflip(n)
gf_bar(~ heads, data = vrtlg_2) %&amp;gt;%
  gf_refine(scale_x_continuous(breaks = 0:n, limits = c(-0.5, n + 0.5)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(n=20\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 20
vrtlg_20 &amp;lt;- do(N) * rflip(n)
gf_bar(~ heads, data = vrtlg_20) %&amp;gt;%
  gf_refine(scale_x_continuous(breaks = 0:n, limits = c(-0.5, n + 0.5)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;
&lt;span class=&#34;math inline&#34;&gt;\(n=50\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt; -50&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vrtlg_50 &amp;lt;- do(N) * rflip(n)
gf_bar(~ heads, data = vrtlg_50) %&amp;gt;%
  gf_refine(scale_x_continuous(breaks = 0:n, limits = c(-0.5, n + 0.5)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Der faire Wurf eine fairen Münze &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; ist aber vorallem ein Gedanken-Expermiment,
bei dem wir davon ausgehen, dass die Wahrscheinlichkeit für Kopf gleich der Wahrscheinlichkeit für Zahl ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X = \text{&amp;quot;Kopf&amp;quot;}) = P(X = \text{&amp;quot;Zahl&amp;quot;}) = 50\,\% = 0{,}5\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir wollen die beiden Ergebnisse kodieren: &lt;span class=&#34;math inline&#34;&gt;\(\text{&amp;quot;Kopf&amp;quot;}\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\text{&amp;quot;Zahl&amp;quot;}\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt;. Somit können wir schreiben:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X = 0)  = 0{,}5 = P(X = 1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Für denn Fall, dass die Münze nicht mehr fair ist wollen wir vereinbaren, dass wir
mit &lt;span class=&#34;math inline&#34;&gt;\(q = P(X = 0)\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p = P(X = 1)\)&lt;/span&gt; die jeweiligen Wahrscheinlichkeiten bezeichnen wollen. Es gilt aber immer, dass &lt;span class=&#34;math inline&#34;&gt;\(q+p = 1\)&lt;/span&gt; ist!&lt;/p&gt;
&lt;p&gt;Eine Variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; die dem Zufall ein Wert &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; zuweist, wollen wir &lt;strong&gt;Zufallsvariable&lt;/strong&gt; nennen.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Ausgehen von der Annahme können wir uns diese theoretischen Verteilungen auch einmal ansehen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p = 0.5
n = 1
gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = 2
tab &amp;lt;- tally( ~ heads, format = &amp;quot;proportion&amp;quot;, data = vrtlg_2)
dist_2 &amp;lt;- data.frame(
  x = as.numeric(names(tab)),
  density = as.numeric(tab)
) 

gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p) %&amp;gt;%
  gf_point(density ~ x, data = dist_2, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = 20
gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = 20
tab &amp;lt;- tally( ~ heads, format = &amp;quot;proportion&amp;quot;, data = vrtlg_20)
dist_20 &amp;lt;- data.frame(
  x = as.numeric(names(tab)),
  density = as.numeric(tab)
) 

gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p) %&amp;gt;%
  gf_point(density ~ x, data = dist_20, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n = 50
tab &amp;lt;- tally( ~ heads, format = &amp;quot;proportion&amp;quot;, data = vrtlg_50)
dist_50 &amp;lt;- data.frame(
  x = as.numeric(names(tab)),
  density = as.numeric(tab)
) 

gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = 0.5) %&amp;gt;%
  gf_point(density ~ x, data = dist_50, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 100
N &amp;lt;- 5 * n**2
vrtlg_100 &amp;lt;- do(N) * rflip(n)
tab &amp;lt;- tally( ~ heads, format = &amp;quot;proportion&amp;quot;, data = vrtlg_100)
dist_100 &amp;lt;- data.frame(
  x = as.numeric(names(tab)),
  density = as.numeric(tab)
) 

gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p) %&amp;gt;%
  gf_point(density ~ x, data = dist_100, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 300
N &amp;lt;- 5 * n**2
vrtlg_300 &amp;lt;- do(N) * rflip(n)
tab &amp;lt;- tally( ~ heads, format = &amp;quot;proportion&amp;quot;, data = vrtlg_300)
dist_300 &amp;lt;- data.frame(
  x = as.numeric(names(tab)),
  density = as.numeric(tab)
) 

gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p) %&amp;gt;%
  gf_point(density ~ x, data = dist_300, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Zeichnen wir nun die &lt;em&gt;Gauß’sche Glockenkurve&lt;/em&gt; in rot dazu:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;binom&amp;quot;, size = n, prob = p) %&amp;gt;%
  gf_point(density ~ x, data = dist_300, color = &amp;quot;lightgreen&amp;quot;, alpha = 0.7) %&amp;gt;%
  gf_dist(&amp;quot;norm&amp;quot;, mean = n*p, sd = sqrt(n*p*(1 - p)), color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;Gauß’sche Glockenkurve&lt;/em&gt; ist die &lt;strong&gt;Dichtefunktion&lt;/strong&gt; der Normalverteilung und ist definiert durch:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x-\mu)^2}{2\sigma^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Mit den beiden Parameter &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; kann man den &lt;em&gt;Mittelwert der Verteilung&lt;/em&gt; (auch &lt;strong&gt;Erwartungswert&lt;/strong&gt; genannt) und die &lt;em&gt;Varianz der Verteilung&lt;/em&gt; einstellen.&lt;/p&gt;
&lt;p&gt;Wir haben diese Werte oben mit den theoretischen Werten der &lt;em&gt;Binomialverteilung&lt;/em&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\mu = E[X] = p \cdot n\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\sigma = \sqrt{\sigma^2}= \sqrt{Var[X]} = \sqrt{n \cdot p \cdot (1-p)}\)&lt;/span&gt; belegt.&lt;/p&gt;
&lt;p&gt;Wir sehen, die (simulierten) relativen Häufigkeiten der Münzwürfe streben mit steigendem &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; mehr und mehr in Richtung der (theoretischen) Wahrscheinlichkeiten der Binomialverteilung und diese (mit steigendem &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;) gegen die Gauß’sche Glockenkurve der Normalverteilung.&lt;/p&gt;
&lt;p&gt;Eine &lt;strong&gt;Verteilungsfunktion&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(F(x)\)&lt;/span&gt; gibt an, wie wahrscheinlich es ist, einen Wert &lt;span class=&#34;math inline&#34;&gt;\(\leq x\)&lt;/span&gt; zu beobachten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F(x) = P(X \leq x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Natürlich ist damit immer &lt;span class=&#34;math inline&#34;&gt;\(0 \leq F(x) \leq 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Eine &lt;em&gt;empirische Verteilungsfunktion&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(F_n(x)\)&lt;/span&gt;gibt an, wie groß die relative Häufigkeit
des eintretens von Werten &lt;span class=&#34;math inline&#34;&gt;\(\leq x\)&lt;/span&gt; bei einem Stichprobenumfang von &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; waren:
&lt;span class=&#34;math display&#34;&gt;\[F_n(x) = \frac{\text{Anzahl der Werte} \leq x}{n}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Betrachen wir nun &lt;em&gt;empirische Verteilungsfunktion&lt;/em&gt; unserer Experimente:&lt;/p&gt;
&lt;p&gt;n = 2&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_ecdf( ~ heads, data=vrtlg_2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;n = 20&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_ecdf( ~ heads, data=vrtlg_20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;
n = 50&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_ecdf( ~ heads, data=vrtlg_50)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;n = 300&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_ecdf( ~ heads, data=vrtlg_300)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;
Tragen wir zur &lt;em&gt;empirische Verteilungsfunktion&lt;/em&gt; auch die &lt;em&gt;Verteilungsfunktion&lt;/em&gt; der Normalverteilung von oben ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 300
gf_ecdf( ~ heads, data = vrtlg_300) %&amp;gt;%
  gf_dist(&amp;quot;norm&amp;quot;, mean = n*p, sd = sqrt(n*p*(1 - p)), kind=&amp;quot;cdf&amp;quot;, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/wege-zur-normalverteilung/index.de_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;empirische Verteilungsfunktion&lt;/em&gt; strebt also gegen die (theoretisch) &lt;em&gt;Verteilungsfunktion&lt;/em&gt; der Normalverteilung. Sie lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F(x) = \int_{-\infty}^x f(u)\, \text{d} u = \int_{-\infty}^x\frac{1}{\sqrt{2 \pi \sigma^2}} e^{- \frac{(x-\mu)^2}{2\sigma^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Eigentlich handelt es sich damit strenggenommen um eine Funktion. Und es müssen noch weitere Eigenschaften erfüllt sein. Aber darauf gehen wir hier nicht weiter ein.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Über die Koeffizienten einer linearen Regression</title>
      <link>https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Bei einer &lt;em&gt;einfachen Regression&lt;/em&gt; versuchen wir zu gegebenen
Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1), ..., (x_n, y_n)\)&lt;/span&gt; eine &lt;em&gt;möglichst passende&lt;/em&gt; Funktion
&lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt; zu finden, so dass
&lt;span class=&#34;math display&#34;&gt;\[y_i = g(x_i) + e_i\]&lt;/span&gt;
gilt. Dabei tolerieren wir eine (kleine) Abweichung &lt;span class=&#34;math inline&#34;&gt;\(e_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Bei einer &lt;em&gt;einfachen &lt;strong&gt;linearen&lt;/strong&gt; Regression&lt;/em&gt; gehen wir davon aus, dass die Datenpunkte (im wesentlichen) auf einer Geraden liegen. Mit &lt;span class=&#34;math inline&#34;&gt;\(g(x)=\beta_0 + \beta1 \cdot x\)&lt;/span&gt; ergibt sich dann für die Datenpunkte die Gleichung:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i = \beta_0 + \beta_1 \cdot x_i + e_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Unsere Aufgabe besteht nun darin die Parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (y-Achsenabschnitt) und &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; (Steigung) an Hand der &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; Datenpunkte zu schätzen.
Alle unsere Schätzungen kennzeichnen wir mit einem Dach (&lt;span class=&#34;math inline&#34;&gt;\(\hat{.}\)&lt;/span&gt;), um sie von den (in der Regel unbekannten) Parametern besser zu unterscheiden.&lt;/p&gt;
&lt;p&gt;Wir suchen somit nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta= \left(\hat\beta_0,\, \hat\beta_1\right)\)&lt;/span&gt;,
so dass die Gerade &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 + \hat\beta_1 \cdot x\)&lt;/span&gt; zu gegebenem &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;
eine möglichst gute Schätzung von &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; (genannt &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;) hat:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{y_i} = \hat\beta_0 + \hat\beta_1 \cdot x_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Abweichung &lt;span class=&#34;math inline&#34;&gt;\(\hat{e_i}\)&lt;/span&gt; unserer Schätzung &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt; von dem
gegebenen Wert &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; lässt sich schreiben als:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{e_i} =  \hat{y_i} - y_i =  \hat\beta_0 + \hat\beta_1 \cdot x_i - y_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wenn wir diese Abweichung über alle &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; minimieren, finden wir unser &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Doch das wirft eine Frage auf:
&lt;em&gt;Wie genau messen wir die möglichst &lt;strong&gt;kleinste Abweichung&lt;/strong&gt; der &lt;span class=&#34;math inline&#34;&gt;\(\hat{e_i}\)&lt;/span&gt; konkret?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wir betrachten zunächst drei einfache Ideen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Betrag der Summe der Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Summe der absoluten Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Summe der quadratischen Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Gewöhnlich nutzen wir die &lt;em&gt;quadratischen Abweichungen&lt;/em&gt;, weshalb
wir die drei Ideen ebenso in umgekehrter Reihenfolge betrachten wollen:&lt;/p&gt;
&lt;div id=&#34;idee-summe-der-quadratischen-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Idee: Summe der quadratischen Abweichungen&lt;/h2&gt;
&lt;p&gt;Wir bezeichnen mit&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
QS &amp;amp;= QS(\hat\beta) = QS(\hat\beta_0, \hat\beta_1) \\
  &amp;amp;= \sum\limits_{i=1}^n \hat{e_i}^2 = \sum\limits_{i=1}^n \left(\hat{y_i} - y_i \right)^2 \\
  &amp;amp;= \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right)^2
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;die &lt;strong&gt;Q&lt;/strong&gt;uadrat-&lt;strong&gt;S&lt;/strong&gt;umme der Abweichungen.&lt;/p&gt;
&lt;p&gt;Gesucht wird &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta=\left(\hat\beta_0,\,\hat\beta_1\right)\)&lt;/span&gt;,
so das &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; minimiert wird.&lt;/p&gt;
&lt;p&gt;Dies ist ein Minimierungsproblem, bei dem wir zu mindestens eine (exakte)
mathematisch-algebraisch Lösung in Form eines stationären Punktes finden können.
Dazu berechnen wir die Nullstelle der ersten partiellen Ableitung von &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;vorbemerkungen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vorbemerkungen&lt;/h3&gt;
&lt;p&gt;Wegen &lt;span class=&#34;math inline&#34;&gt;\(\bar{x} = \frac{1}{n} \sum\limits_{i=1}^n x_i\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(n \cdot \bar{x} =\sum\limits_{i=1}^n x_i\)&lt;/span&gt; und analog &lt;span class=&#34;math inline&#34;&gt;\(n \cdot \bar{y} =\sum\limits_{i=1}^n y_i\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;schätzen-des-y-achenabschnitts-hatbeta_0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Schätzen des y-Achenabschnitts &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Es ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
 \frac{\partial}{\partial \hat\beta_0} \, QS &amp;amp;= 2 \cdot \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right) \cdot 1 \\
  &amp;amp;= 2 \cdot \left(\sum\limits_{i=1}^n \hat\beta_0 + \sum\limits_{i=1}^n\hat\beta_1 \cdot x_i - \sum\limits_{i=1}^n y_i\right) \\
  &amp;amp;= 2 \cdot \left( n \cdot \hat\beta_0 + \hat\beta_1\cdot\sum\limits_{i=1}^n x_i - \sum\limits_{i=1}^n y_i \right) \\
  &amp;amp;= 2 \cdot \left( n \cdot \hat\beta_0 + \hat\beta_1\cdot n \cdot \bar{x} - n \cdot\bar{y} \right) \\
  &amp;amp;= 2 \cdot n \cdot \left( \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y} \right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um stationäre Punkte zu ermitteln, müssen wir den Ausdruck nun gleich Null setzen und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  0 &amp;amp;= \frac{\partial}{\partial \hat\beta_0} \, QS \\
  &amp;amp;= 2 \cdot n \cdot \left( \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y} \right) \qquad | : (2 \cdot n) \\
  &amp;amp;= \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Stellen wir nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; um, erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat\beta_0 &amp;amp;= - \hat\beta_1\cdot\bar{x} + \bar{y} \\
  \hat\beta_0 &amp;amp;= \bar{y} - \hat\beta_1\cdot\bar{x}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; zu bestimmen, benötigen wir &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;schätzen-der-steigung-hatbeta_1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Schätzen der Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Es ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS &amp;amp;= 2 \cdot \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right) \cdot x_i \\
  &amp;amp;= 2 \cdot \left(\sum\limits_{i=1}^n \hat\beta_0 \cdot x_i + \sum\limits_{i=1}^n \hat\beta_1 \cdot x_i\cdot x_i- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_0 \cdot \sum\limits_{i=1}^n  x_i + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_0 \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir ersetzen nun &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; durch &lt;span class=&#34;math inline&#34;&gt;\(\bar{y} - \hat\beta_1\cdot \bar{x}\)&lt;/span&gt; und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS  &amp;amp;=
  2 \cdot \left(\hat\beta_0 \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(\left(\bar{y} - \hat\beta_1\cdot \bar{x}\right) \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n  x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - n \cdot \hat\beta_1 \cdot  \bar{x}^2  + \hat\beta_1 \cdot\sum\limits_{i=1}^n  x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - \sum\limits_{i=1}^n y_i \cdot x_i  + \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Mit Hilfe des &lt;a href=&#34;https://de.wikipedia.org/wiki/Verschiebungssatz_(Statistik)&#34;&gt;&lt;em&gt;Verschiebesatzes von Steiner&lt;/em&gt;&lt;/a&gt; (zweimal angewendet) erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS  
    &amp;amp;=2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - \sum\limits_{i=1}^n y_i \cdot x_i  + \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
    &amp;amp;=2 \cdot \left(- \left(\sum\limits_{i=1}^n y_i \cdot x_i - n \cdot \bar{y} \cdot \bar{x}   \right)+ \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
    &amp;amp;=2 \cdot \left(\hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)- \left(\sum\limits_{i=1}^n y_i \cdot x_i - n \cdot \bar{y} \cdot \bar{x}   \right)\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir setzen nun wieder den Ausdruck gleich Null:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
 0 &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right)  \qquad | : 2\\
   &amp;amp;= \hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})
 \end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Und stellen dann nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 
    &amp;amp;= \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y}) \\
  \hat\beta_1 
    &amp;amp;= \frac{\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\sum\limits_{i=1}^n(x_i-\bar{x})^2}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun Zähler und Nenner der rechten Seite mit &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\)&lt;/span&gt; erweitern
und erhalten so:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 
      &amp;amp;= \frac{\frac{1}{n} \cdot\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\frac{1}{n} \cdot\sum\limits_{i=1}^n  (x_i-\bar{x})^2} \\
      &amp;amp;= \frac{\sigma_{x,y}}{\sigma^2_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Oder aber wir erweitern mit &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n-1}\)&lt;/span&gt; und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 
      &amp;amp;= \frac{\frac{1}{n-1} \cdot\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\frac{1}{n-1} \cdot\sum\limits_{i=1}^n  (x_i-\bar{x})^2} \\
      &amp;amp;= \frac{s_{x,y}}{s^2_{x}}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Damit können wir zur Berechnung sowohl die Kovarianz der Grundgesamtheit &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{x,y}\)&lt;/span&gt; und die Varianz &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_x\)&lt;/span&gt; von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, als auch deren Schätzer &lt;span class=&#34;math inline&#34;&gt;\(s_{x,y}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(s^2_x\)&lt;/span&gt; verwendet werden!&lt;/p&gt;
&lt;p&gt;Diese Methode nennt sich &lt;strong&gt;Methode der kleinsten Quadrate&lt;/strong&gt;
(engl. &lt;em&gt;ordenary least square method&lt;/em&gt;) und wir sprechen
dann auch von den &lt;strong&gt;Kleinste-Quadrate-Schätzern&lt;/strong&gt;
(oder kurz &lt;strong&gt;KQ-Schätzer&lt;/strong&gt; bzw. &lt;strong&gt;OLS-Schätzer&lt;/strong&gt;) &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Erweitern wir den Ausdruck mit Standardabweichung &lt;span class=&#34;math inline&#34;&gt;\(\sigma_y\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(s_y\)&lt;/span&gt;, so erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 &amp;amp;= \frac{\sigma_{x,y}}{\sigma^2_x} \cdot \frac{\sigma_y}{\sigma_y} = \frac{\sigma_{x,y}}{\sigma_x \cdot \sigma_x} \cdot \frac{\sigma_y}{\sigma_y} = \frac{\sigma_{x,y}}{\sigma_x \cdot \sigma_y} \cdot \frac{\sigma_y}{\sigma_x} \\
 &amp;amp;= \rho_{x,y} \cdot \frac{\sigma_y}{\sigma_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und analog für die Schätzer:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 &amp;amp;= \frac{s_{x,y}}{s^2_x} \cdot \frac{s_y}{s_y} 
  = \frac{s_{x,y}}{s_x \cdot s_x} \cdot \frac{s_y}{s_y}
  = \frac{s_{x,y}}{s_x \cdot s_y} \cdot \frac{s_y}{s_x} \\
 &amp;amp;= r_{x,y} \cdot \frac{s_y}{s_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; hat somit eine direkte Beziehung mit dem &lt;em&gt;Korrelationskoeffizenten&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; (der Grundgesamtheit) bzw. &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; (der Stichprobe).&lt;/p&gt;
&lt;p&gt;Für eine Berechnung in &lt;strong&gt;R&lt;/strong&gt; heißt dies: wir können die Regressionskoeffizienten
&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; direkt algebraisch ausrechnen, wenn wir&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;die Standardabweichungen von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; und den Korrelationskoeffizienten oder&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;die Varianz von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und Kovarianz von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;haben.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-beispiel-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein Beispiel in R:&lt;/h3&gt;
&lt;p&gt;Auf Grundlage der Datentabelle &lt;em&gt;mtcars&lt;/em&gt; wollen wir Prüfen wie ein linearer
Zusammenhang zwischen dem Verbrauch (in Meilen pro Gallone &lt;em&gt;mpg&lt;/em&gt;) und der Leistung
(Pferdestärke &lt;em&gt;hp&lt;/em&gt;) modelliert werden kann.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)

# Wir nehmen die Datentabelle &amp;#39;mtcars&amp;#39;:
mtcars %&amp;gt;%
  select(hp, mpg) -&amp;gt; dt

# Ein kurzer Blick auf die Daten:
favstats(~ hp, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;      mean       sd
#&amp;gt;  146.6875 68.56287
favstats(~ mpg, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;      mean       sd
#&amp;gt;  20.09062 6.026948

# Wir vergleichen den Verbrauch (mpg, miles per gallon) 
# mit den Pferdestärken (hp) mit Hilfe eines Streudiagramms:
gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Berechnen wir zunächst die Mittelwerte von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (also ‘hp’) und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; (also ‘mpg’)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(mean_hp &amp;lt;- mean(~ hp, data = dt))
#&amp;gt; [1] 146.6875
(mean_mpg &amp;lt;- mean(~ mpg, data = dt))
#&amp;gt; [1] 20.09062&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und zeichnen die Punkt &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y}) = (146.69, 20.09)\)&lt;/span&gt; in unser
Streudiagramm ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Berechnen wir nun die Schätzwerte für die Regressionsgerade&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(beta_1 &amp;lt;- cov(mpg ~ hp, data = dt) / var(~ hp, data = dt))
#&amp;gt; [1] -0.06822828
(beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp)
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und zeichnen diese in unser Streudiagramm ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1, intercept = ~beta_0, color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988605 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;studentisieren-einmal-hin-und-einmal-zurück&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Studentisieren – einmal hin und einmal zurück&lt;/h3&gt;
&lt;p&gt;Was passiert eigentlich, wenn wir unsere &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; Werte studentisieren (aka standardisieren oder z-transformieren)?&lt;/p&gt;
&lt;p&gt;Zur Erinnerung, studentisieren geht so:
&lt;span class=&#34;math display&#34;&gt;\[x^{stud} = \frac{x - \bar{x}}{s_x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; können wir das mit der Funktion ‘zscore’ wie folgt machen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dt %&amp;gt;%
  mutate(
    hp_stud = zscore(hp),
    mpg_stud = zscore(mpg)
  ) -&amp;gt; dt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Natürlich sind die Mittelwerte nun Null und die Standardabweichungen Eins:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(~ hp_stud, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;          mean sd
#&amp;gt;  1.040834e-17  1
favstats(~ mpg_stud, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;          mean sd
#&amp;gt;  7.112366e-17  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Grund für die kleinen Abweichungen von der Null bei den Mittelwerten
sind unumgängliche Rundungsfehler, die der Computer macht!&lt;/p&gt;
&lt;p&gt;Schauen wir uns nun das Streudiagramm an, zusammen mit dem Mittelpunkt &lt;span class=&#34;math inline&#34;&gt;\((0,0)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg_stud ~ hp_stud, data = dt) %&amp;gt;%
  gf_point(0 ~ 0, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_lims(y = c(-2, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
Auch wenn die Skalierungen sich geändert haben, die Diagramme sind sehr ähnlich.&lt;/p&gt;
&lt;p&gt;Bestimmen wir die Koeffizienten der Regressionsgerade&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(beta_stud_1 &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt))
#&amp;gt; [1] -0.7761684
(beta_stud_0 &amp;lt;- 0 - beta_stud_1 * 0)
#&amp;gt; [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und setzen sie in das Streudiagramm ein:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können das studentisierte Problem auch wieder auf unser ursprüngliches
zurück rechnen.&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade im studentisierten Problem lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta^{stud}_0 + \hat\beta_1^{stud} \cdot x^{stud} \\ 
          &amp;amp;\approx 0 -0.7761684 \cdot x^{stud} \\
          &amp;amp;\approx 0 -0.776 \cdot x^{stud}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Rechnen wir nun mittels der Formel
&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1 = \hat\beta_1^{stud} \cdot \frac{s_y}{s_x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;die Steigung um, so erhalten wir:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b1 &amp;lt;- beta_stud_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06822828&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und setzen wir das in unsere Gleichung zur Bestimmung von &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b0 &amp;lt;- mean(dt$mpg) - b1 * mean(dt$hp))
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so erhalten wir die Schätzwerte des ursprünglichen Problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-anderer-weg-um-die-regressionskoeffizenten-zu-bestimmen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein anderer Weg um die Regressionskoeffizenten zu bestimmen…&lt;/h3&gt;
&lt;p&gt;Gehen wir das Problem noch einmal neu an. Wir suchen &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta=(\hat\beta_0, \hat\beta_1)\)&lt;/span&gt; welches &lt;span class=&#34;math inline&#34;&gt;\(QS(\hat\beta) = QS(\hat\beta_0, \hat\beta_1) = \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right)^2\)&lt;/span&gt; minimiert.&lt;/p&gt;
&lt;p&gt;Statt es direkt, wie oben durch Null setzen der partiellen Ableitungen, zu bestimmen, wählen wir nun einen mathematisch-&lt;em&gt;numerischen&lt;/em&gt; Ansatz und wollen &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta \in \mathbf{R}^2\)&lt;/span&gt; als &lt;em&gt;Optimierungsproblem&lt;/em&gt; mit Hilfe des &lt;em&gt;Gradientenverfahrens&lt;/em&gt; lösen.&lt;/p&gt;
&lt;p&gt;Beim Gradientenverfahren wird versucht, ausgehend von einem Startwert &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta^0 \in \mathbf{R}^2\)&lt;/span&gt;, gemäß der Iterationsvorschrift&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta^{k+1} = \hat\beta^{k} + \alpha^k \cdot d^k
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;für alle &lt;span class=&#34;math inline&#34;&gt;\(k=0,1, ...\)&lt;/span&gt; eine Näherungslösung für &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt; zu finden.
Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(\alpha^k &amp;gt; 0\)&lt;/span&gt; eine &lt;em&gt;positive Schrittweite&lt;/em&gt; und &lt;span class=&#34;math inline&#34;&gt;\(d^k\in\mathbf{R}^n\)&lt;/span&gt; eine &lt;em&gt;Abstiegsrichtung&lt;/em&gt;, welche wir in jedem Iterationsschritt &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; so bestimmen,
dass die Folge &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta^k\)&lt;/span&gt; zu einem stationären Punkt, unserer Näherungslösung, konvergiert.&lt;/p&gt;
&lt;p&gt;Im einfachsten Fall, dem &lt;strong&gt;Verfahren des steilsten Abstieges&lt;/strong&gt;, wird der
Abstiegsvektor &lt;span class=&#34;math inline&#34;&gt;\(d^k\)&lt;/span&gt; aus dem Gradienten &lt;span class=&#34;math inline&#34;&gt;\(\nabla QS\)&lt;/span&gt; wie folgt bestimmt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d^k = -\nabla QS\left(\hat\beta^k\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_0} \, QS = 2 \cdot n \cdot \left(  \hat\beta_0 + \hat\beta_1\cdot\bar{x} - \bar{y} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_1} \, QS = 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y}) \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\nabla QS(\hat\beta) &amp;amp;= \nabla QS(\hat\beta_0, \hat\beta_1) \\
&amp;amp;= 2 \cdot \begin{pmatrix}
n \cdot(\hat\beta_0 + \hat\beta_1\cdot\bar{x} - \bar{y})  \\
\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})
\end{pmatrix}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir wollen hier von Anfang an mit den studentisierten Werten arbeiten, weil diese numerisch viele Vorteile haben.
Darum vereinfachen sich die beiden partiellen Ableitungen noch einmal zu:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_0} \, QS = 2 \cdot v
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\frac{\partial}{\partial \hat\beta_1} \, QS &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right) \\
 &amp;amp;= 2 \cdot (n-1) \left(\hat\beta_1 \cdot s^2_{x} - s_{x,y}\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Somit gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\nabla QS(\hat\beta) &amp;amp;= \nabla QS(\hat\beta_0, \hat\beta_1) \\
&amp;amp;= 2 \cdot \begin{pmatrix}
n \cdot \hat\beta_0 \\
 (n-1) \left(\hat\beta_1 \cdot s^2_{x} - s_{x,y}\right) 
\end{pmatrix}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um die Varianz und die Kovarianz nicht jedesmal neu zu berechnen, speichern
wir die Ergebnisse vorab. Ebenso, damit der Quellcode kürzer wird, speichern
wir in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; die studentisierten Werte von &lt;span class=&#34;math inline&#34;&gt;\(hp\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(mpg\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Vorbereitungen 
var_x &amp;lt;- var(~ hp_stud, data = dt)
cov_xy &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt)

n &amp;lt;- length(dt$hp_stud)

x &amp;lt;- dt$hp_stud
y &amp;lt;- dt$mpg_stud&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun erstellen wir die &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\nabla QS\)&lt;/span&gt; Funktionen:
Wir definieren diese Funktion wie folgt in &lt;strong&gt;R&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qs &amp;lt;- function(b_0, b_1) {
  sum((b_1 * x - y)**2)
}

nabla_qs &amp;lt;- function(b_0, b_1) {
  c(2 * n * b_0,
    2 * (n - 1) * (b_1 * var_x - cov_xy)
  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Schrittweite &lt;span class=&#34;math inline&#34;&gt;\(alpha\)&lt;/span&gt; bestimmen wir mit Hilfe der &lt;em&gt;Armijo-Bedingung&lt;/em&gt; und der &lt;em&gt;Backtracking Liniensuche&lt;/em&gt;:
Diese formalisiert das Konzept “genügend” in der geforderten Verringerung des Funktionswertes. Die Bedingung &lt;span class=&#34;math inline&#34;&gt;\(f(x^k + \alpha d^k) &amp;lt; f(x^k)\)&lt;/span&gt; wird modifiziert zu
&lt;span class=&#34;math display&#34;&gt;\[f(x^k + \alpha d^k) \leq f(x^k) + \sigma \alpha \left(\nabla f(x^k)\right)^T d^k,\]&lt;/span&gt;
mit &lt;span class=&#34;math inline&#34;&gt;\(\sigma\in (0,1)\)&lt;/span&gt;.
Die Armijo-Bedingung umgeht Konvergenzprobleme der einfachen Bedingung, indem sie fordert, dass die Verringerung zumindest proportional zur Schrittweite und zur Richtungsableitung &lt;span class=&#34;math inline&#34;&gt;\(\left(\nabla f(x^k)\right)^T d^k\)&lt;/span&gt; ist, mit Hilfe der Proportionalitätskonstante &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.
In der Praxis werden oft sehr kleine Werte verwendet, z.B. &lt;span class=&#34;math inline&#34;&gt;\(\sigma=0.0001\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;Backtracking-Liniensuche&lt;/em&gt; verringert die Schrittweite wiederholt um den
Faktor &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; (&lt;code&gt;rho&lt;/code&gt;) , bis die Armijo-Bedingung erfüllt ist.
Sie terminiert garantiert nach einer endlichen Anzahl von Schritten. Weshalb wir
sie hier einsetzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha_k &amp;lt;- function(b_0, b_1, d_k, alpha = 1, sigma = 0.0001, rho = 0.5) {
  d_0 &amp;lt;- d_k[1]
  d_1 &amp;lt;- d_k[2]
  nabla &amp;lt;- nabla_qs(b_0, b_1)
  n_0 &amp;lt;- nabla[1]
  n_1 &amp;lt;- nabla[2]

  lhs &amp;lt;- qs(b_0 + alpha*d_0, b_1 + alpha*d_1)
  rhs &amp;lt;- qs(b_0, b_1) + sigma*alpha*(n_0*d_0 + n_1*d_1)

  while (lhs &amp;gt; rhs) {
    alpha &amp;lt;- rho * alpha
    lhs &amp;lt;- qs(b_0 + alpha*d_0, b_1 + alpha*d_1)
    rhs &amp;lt;- qs(b_0, b_1) + sigma*alpha*(n_0*d_0 + n_1*d_1)
  }
  return(alpha)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ein paar Einstellungen vorab:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# maximale Anzahl an Iterationen
max_iter &amp;lt;- 1000
iter &amp;lt;- 0

# Genauigkeit
eps &amp;lt;- 10**-6

# Startwerte
b_0 &amp;lt;- 0 
b_1 &amp;lt;- -1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Für eine vorgegebene Genauigkeit &lt;span class=&#34;math inline&#34;&gt;\(eps=10^{-6}\)&lt;/span&gt;, den Startwerten &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0^0 = 0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1^0 = -1\)&lt;/span&gt; können wir somit das Verfahren starten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;while (TRUE) {
  iter &amp;lt;- iter + 1

  d_k &amp;lt;- -nabla_qs(b_0, b_1)

  ad_ &amp;lt;- alpha_k(b_0, b_1, d_k) * d_k

  x0 &amp;lt;- b_0 + ad_[1]
  x1 &amp;lt;- b_1 + ad_[2]

  if ((abs(b_0 - x0) &amp;lt; eps) &amp;amp; (abs(b_1 - x1) &amp;lt; eps) | (iter &amp;gt; max_iter)) {
    break
  }
  b_0 &amp;lt;- x0
  b_1 &amp;lt;- x1
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir haben in &lt;span class=&#34;math inline&#34;&gt;\(203\)&lt;/span&gt; Iterationsschritten das folgende Ergebnis für die Regressionskoeffizienten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0^{stud} = 0 \qquad \hat\beta_1^{stud} = -0.7761689\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Betrachten wir die daraus erstellte Regressionsgerade:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Um die Regressionskoeffizienten für unser ursprüngliches Problem zu erhalten
müssen wir wie folgt zurück rechnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b1 &amp;lt;- b_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06822832
(b0 &amp;lt;- mean(dt$mpg) -  b1 * mean(dt$hp))
#&amp;gt; [1] 30.09887&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Geradengleichung für das ursprüngliches Problem lautet somit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988668 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-r-funktion-optim&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Die R Funktion &lt;code&gt;optim&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; gibt es bessere Optimierungsmethoden, als die hier verwendete.
Zum Beispiel können wir die Funktion &lt;code&gt;optim&lt;/code&gt; verwenden.
Die Funktion &lt;code&gt;optim&lt;/code&gt; benötigt die zu optimierende &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; und
ggf. die Gradientenfunktion &lt;span class=&#34;math inline&#34;&gt;\(gf(x)\)&lt;/span&gt; sowie einen Startpunkt &lt;span class=&#34;math inline&#34;&gt;\(x^0\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(beta) {
  qs(beta[1], beta[2])
}

grf &amp;lt;- function(beta) {
  nabla_qs(beta[1], beta[2])
}

# Der eigentliche Aufruf von optim:
ergb &amp;lt;- optim(c(0,-0.5),f ,grf, method = &amp;quot;CG&amp;quot;)

# Auslesen der Schätzer aus dem Ergebnis:
(optim_beta_0 &amp;lt;- ergb$par[1])
#&amp;gt; [1] 0
(optim_beta_1 &amp;lt;- ergb$par[2])
#&amp;gt; [1] -0.7761683&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir erhalten somit für das studentisierte Problem die Gerade:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta_0^{stud} + \hat\beta_1^{stud} \cdot x^{stud} \\ 
          &amp;amp;\approx 0 -0.7761683 \cdot  x^{stud} \\
          &amp;amp;\approx 0 -0.776 \cdot  x^{stud}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Für das ursprüngliche Problem rechnen wir mittels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optim_b1 &amp;lt;- optim_beta_1 * sd(dt$mpg) / sd(dt$hp)
optim_b0 &amp;lt;- mean(dt$mpg) -  optim_b1 * mean(dt$hp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;um und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988601 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;idee-summe-der-absoluten-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Idee: Summe der absoluten Abweichungen&lt;/h2&gt;
&lt;p&gt;Wir ändern nun die Abweichungsmessfunktion von der &lt;em&gt;Q&lt;/em&gt;uadrat-&lt;em&gt;S&lt;/em&gt;umme hin zu
den &lt;strong&gt;A&lt;/strong&gt;bsolut-&lt;em&gt;S&lt;/em&gt;ummen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[AS = AS(\hat\beta) = AS(\hat\beta_0, \hat\beta_1) = \sum_{i=1}^n |\hat{y}_i - y_i|\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Auch hier wollen wir mit den studentisierten Daten arbeiten und stellen
die Funktion der &lt;em&gt;A&lt;/em&gt;bsolut-&lt;em&gt;S&lt;/em&gt;ummen auf:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Absolute Abweichungssummen
as &amp;lt;- function(b_0, b_1) {
  return(sum(abs(b_0 + b_1 * x - y)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Danach konstruieren wir die zu optimierende Funktion &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Zu optimierende Funktion
f &amp;lt;- function(beta) {
  as(beta[1], beta[2])
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Diesmal nutzen wir &lt;code&gt;optim&lt;/code&gt; ohne eine Gradientenfunktion:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ergb &amp;lt;- optim(c(0,-1), f)

# Schätzer auslesen
(opti_as_beta_0 &amp;lt;- ergb$par[1])
#&amp;gt; [1] -0.1304518
(opti_as_beta_1 &amp;lt;- ergb$par[2])
#&amp;gt; [1] -0.6844911&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Schauen wir uns nun die so erhaltene Gerade im Vergleich mit der ‘normalen’ Regressionsgerade an:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In grün und gestrichelt sehen wir die Gerade aus der &lt;em&gt;Idee der quadratischen Abweichungssummen&lt;/em&gt;, in blau die aus der &lt;em&gt;Idee der absoluten Abweichungssummen&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Für unser ursprüngliches Problem rechnen wir um:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Umrechnen in die ursprüngliche Fragestellung
(as_b1 &amp;lt;- opti_as_beta_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06016948
(as_b0 &amp;lt;- (mean(dt$mpg) - as_b1 * mean(dt$hp)) + opti_as_beta_0 * sd(dt$mpg))
#&amp;gt; [1] 28.13051&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und die dazu gehörige Darstellung:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 28.1305094 -0.0601695 \cdot x \\
          &amp;amp;\approx 28.131 -0.06 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Diese Methode nennt sich &lt;strong&gt;Median-Regression&lt;/strong&gt; und ein ein Spezialfall der &lt;strong&gt;Quantilsregression&lt;/strong&gt;, die sich u.a. mit dem R-Paket &lt;a href=&#34;https://cran.r-project.org/web/packages/quantreg/index.html&#34;&gt;&lt;em&gt;quantreg&lt;/em&gt;&lt;/a&gt;
unmittelbar umsetzen lässt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(quantreg)
ergmedianreg &amp;lt;- rq(mpg ~ hp, data = dt)
coef(ergmedianreg)
#&amp;gt; (Intercept)          hp 
#&amp;gt; 28.13050847 -0.06016949&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;idee-betrag-der-summe-der-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Idee: Betrag der Summe der Abweichungen&lt;/h2&gt;
&lt;p&gt;Wenn wir die Summe der Abweichungen &lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^n \hat{e}_i\)&lt;/span&gt; minimieren
wollen, dann ist es sinnvoll den Betrag davon zu minimieren.
Wir suchen also die Schätzer &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;, so dass der Ausdruck&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\left| \sum_{i=1}^n \hat{e}_i \right| = \left| \sum_{i=1}^n (\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i) \right|
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;minimal ist.&lt;/p&gt;
&lt;p&gt;Wegen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\sum_{i=1}^n (\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i)
&amp;amp;= \sum_{i=1}^n \hat\beta_0 + \sum_{i=1}^n \hat\beta_1 \cdot x_i - \sum_{i=1}^n y_i \\
&amp;amp;= n \cdot \hat\beta_0 + \hat\beta_1 \cdot \sum_{i=1}^n x_i - \sum_{i=1}^n y_i \\
&amp;amp;= n \cdot \hat\beta_0 + \hat\beta_1 \cdot n \cdot \bar{x} - n \cdot \bar{y} \\
&amp;amp;= n \cdot \left( \hat\beta_0 + \hat\beta_1 \cdot \bar{x} - \bar{y} \right) \\
&amp;amp;= n \cdot \left( \hat\beta_0 - \bar{y} + \hat\beta_1 \cdot \bar{x}  \right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;können wir das absolute Minimum bei &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 - \bar{y} =0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1 \cdot \bar{x}=0\)&lt;/span&gt; erreichen, was zur Lösung
&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 =\bar{y}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1 = 0\)&lt;/span&gt; führt.
Dies ist unser &lt;em&gt;Nullmodel&lt;/em&gt; in dem die &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; keinen Einfluss auf die &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; haben und
wir daher pauschal die &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i=\bar{y}\)&lt;/span&gt;, also dem Mittelwert der &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; abschätzen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;zusammenfassung&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Zusammenfassung&lt;/h2&gt;
&lt;p&gt;Als Vergleich können wir uns die Quadratsumme &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; und Absolutsumme &lt;span class=&#34;math inline&#34;&gt;\(AS\)&lt;/span&gt; der drei
Modelle einmal ansehen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quadratische Abweichungssummen
qs &amp;lt;- function(b_0, b_1) {
  sum(((b_0 + b_1 * dt$hp) - dt$mpg )**2)
}

# Absolute Abweichungssummen
as &amp;lt;- function(b_0, b_1) {
  sum(abs((b_0 + b_1 * dt$hp) - dt$mpg))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quadratsummen:
quad_sum &amp;lt;- c(qs(b0, b1), qs(as_b0, as_b1), qs(mean_mpg, 0))

# Absolutsummen:
abs_sum &amp;lt;- c(as(b0, b1), as(as_b0, as_b1), as(mean_mpg, 0))

tab &amp;lt;- tibble(
  sums = c(quad_sum, abs_sum),
  sum_type = rep(c(&amp;quot;quad&amp;quot;, &amp;quot;abs&amp;quot;), each = 3),
  methode = rep(c(&amp;quot;Idee 3&amp;quot;, &amp;quot;Idee 2&amp;quot;, &amp;quot;Idee 1&amp;quot;), 2)
)

pivot_wider(tab, names_from=sum_type, values_from=sums, names_sort=T)
#&amp;gt; # A tibble: 3 x 3
#&amp;gt;   methode   abs  quad
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1 Idee 3   93.0  448.
#&amp;gt; 2 Idee 2   87.3  477.
#&amp;gt; 3 Idee 1  151.  1126.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reproduzierbarkeitsinformationen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproduzierbarkeitsinformationen&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt; 
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt; 
#&amp;gt; Package version:
#&amp;gt;   mosaic_1.8.3  quantreg_5.86 tidyr_1.1.3   xfun_0.24&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Das “Cookbook” zur Datentabelle können Sie mit Hilfe von &lt;code&gt;help(&#34;mtcars&#34;)&lt;/code&gt; aufrufen!&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Über die t-Verteilung mit einem bzw. zwei Freiheitsgraden</title>
      <link>https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;vorbereitungen-für-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vorbereitungen für R&lt;/h2&gt;
&lt;p&gt;Für die graphischen Ausgaben nutzen wir R und das Paket &lt;code&gt;mosaic&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;vorbemerkungen-und-notationen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vorbemerkungen und Notationen&lt;/h2&gt;
&lt;p&gt;Da alle t-Verteilungen symmetrisch sind, betrachten wir im wesendlichen nur den
positiven Teil.&lt;/p&gt;
&lt;p&gt;Zwei reelle Funktionen &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; sind genau dann, im Sinne von de Bruijn&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; (§1.4), &lt;strong&gt;asymptotisch äquivalent&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\(f \sim g\)&lt;/span&gt;, wenn&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\lim\limits_{x \to \infty} \frac{f(x)}{g(x)} = 1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt.&lt;/p&gt;
&lt;p&gt;Ist &lt;span class=&#34;math inline&#34;&gt;\(f \sim g\)&lt;/span&gt;, so können wir auch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f(x) = g(x)\cdot(1+o(1))
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;dafür schreiben.
Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(h(x) = o(\phi(x))\)&lt;/span&gt; für &lt;span class=&#34;math inline&#34;&gt;\(x \to \infty\)&lt;/span&gt;, falls &lt;span class=&#34;math inline&#34;&gt;\(\lim\limits_{x \to \infty} \frac{h(x)}{\phi(x)} = 0\)&lt;/span&gt; gilt.
Aus der asymptotischen Äquivalenz von &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; folgt nun direkt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\lim\limits_{x \to \infty}\frac{f(x)}{g(x)}-1 =\frac{f(x)-g(x)}{g(x)} = 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Mit &lt;span class=&#34;math inline&#34;&gt;\(h(x) = \frac{f(x)-g(x)}{g(x)}\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(h(x) = o(1)\)&lt;/span&gt; und daher &lt;span class=&#34;math inline&#34;&gt;\(f(x)-g(x) = g(x)o(1)\)&lt;/span&gt; und schliesslich &lt;span class=&#34;math inline&#34;&gt;\(f(x) = g(x)+g(x)o(1)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Ein wichtiges Korrolar sagt:&lt;/p&gt;
&lt;p&gt;Ist &lt;span class=&#34;math inline&#34;&gt;\(f \sim g\)&lt;/span&gt;, so ist auch &lt;span class=&#34;math inline&#34;&gt;\(\log(f) \sim \log(g)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-t-verteilung-im-allgemeinen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Die t-Verteilung im Allgemeinen&lt;/h2&gt;
&lt;p&gt;Die Dichtefunktion der t-Verteilung lauten im Allgemeinen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_n(x) = \frac{\Gamma\left(\frac{n+1}{2}\right)} {\sqrt{n\pi}~\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^{2}}{n}\right)^{-\frac{n+1}{2}}\quad \mathrm{für}\quad -\infty &amp;lt; x &amp;lt; +\infty
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;wobei wir mit &lt;span class=&#34;math inline&#34;&gt;\(\Gamma(x)\)&lt;/span&gt; die Gammafunktion&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\Gamma(x)=\int\limits_{0}^{+\infty}t^{x-1}e^{-t}\operatorname{d}t
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;bezeichnen.
Für einige &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; nimmt die Gammafunktion leicht zu berechnende Werte an:&lt;/p&gt;
&lt;p&gt;So ist für alle &lt;span class=&#34;math inline&#34;&gt;\(n\in\mathbf{N_0}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Gamma(n+1) = n!\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\Gamma\left(n + \frac{1}{2}\right) = \frac{(2n)!}{n!4^n}\sqrt{\pi}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit der gewöhnlichen Fakultät &lt;span class=&#34;math inline&#34;&gt;\(n! = \prod_{i=0}^n i\)&lt;/span&gt;, wobei per Definition &lt;span class=&#34;math inline&#34;&gt;\(0!=1\)&lt;/span&gt; ist.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-t-verteilung-mit-einem-freiheitsgrad&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Die t-Verteilung mit einem Freiheitsgrad&lt;/h2&gt;
&lt;p&gt;Für &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\)&lt;/span&gt; ergibt sich somit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
f_1(x) &amp;amp;= \frac{\Gamma\left(\frac{n+1}{2}\right)} {\sqrt{n\pi}~\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^{2}}{n}\right)^{-\frac{n+1}{2}} \\
 &amp;amp;= \frac{\Gamma\left(\frac{2}{2}\right)} {\sqrt{\pi}~\Gamma\left(\frac{1}{2}\right)}\left(1+x^{2}\right)^{-\frac{2}{2}} \\
 &amp;amp;= \frac{\Gamma\left(1\right)} {\sqrt{\pi}~\Gamma\left(\frac{1}{2}\right)}\left(1+x^{2}\right)^{-1} \\
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen &lt;span class=&#34;math inline&#34;&gt;\(\Gamma(1) = 0! = 1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}\)&lt;/span&gt; ergibt sich nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
f_1(x) &amp;amp;= \frac{1} {\sqrt{\pi} \cdot \sqrt{\pi}} \cdot \left(1+x^{2}\right)^{-1} \\
       &amp;amp;= \frac{1}{\pi} \cdot \frac{1}{1+x^{2}} 
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Das ist die Dichtefunktion der standardisierten Cauchy-Verteilung&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_{(\mu,\lambda)}(x) = \frac{1}{\pi} \cdot \frac{\lambda}{\lambda^2+(x-\mu)^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit (&lt;span class=&#34;math inline&#34;&gt;\(\mu = 0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\lambda=1\)&lt;/span&gt;), welche – bekanntermaßen – keinen Erwartungwert hat.&lt;/p&gt;
&lt;p&gt;Wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\lim_{x \to +\infty} \frac{f_1(k \cdot x)}{f_1(x)} 
      &amp;amp;= \lim_{x \to +\infty} \frac{\frac{1}{\pi} \cdot \frac{1}{1+(kx)^{2}}}{\frac{1}{\pi} \cdot \frac{1}{1+x^{2}}} = \lim_{x \to +\infty} \frac{1+x^2}{1+k^2x^2} \\
      &amp;amp;=\lim_{x \to +\infty} \frac{\frac{1}{x^2}+\frac{x^2}{x^2}}{\frac{1}{x^2}+k^2\frac{x^2}{x^2}} =\frac{1}{k^2}=k^{-2}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;für alle reellen &lt;span class=&#34;math inline&#34;&gt;\(k&amp;gt;0\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(f_1(x)\)&lt;/span&gt; eine regulär variierende Funktion mit Variationsindex &lt;span class=&#34;math inline&#34;&gt;\(\rho = -2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Die Überlebensfunktion zur t-Verteilung mit einem Freiheitsgrad lautet nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\overline{F}_1(x) = \int_x^\infty f_1(t) \operatorname{d}t = \frac{1}{\pi} \cdot \int_x^\infty  \frac{1}{1+x^{2}} \operatorname{d}t = \frac{\arctan(x)}{\pi}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;da wir das optionale &lt;span class=&#34;math inline&#34;&gt;\(+C\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(C=0\)&lt;/span&gt; annehmen dürfen.&lt;/p&gt;
&lt;p&gt;Es gilt nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\arctan`(x)= \frac{1}{1+x^2} \to \frac{1}{x^2} \text{ für } x\to \infty
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Genauer gilt wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\lim\limits_{x \to \infty} \frac{\frac{1}{1+x^2}}{\frac{1}{x^2}} 
 = \lim\limits_{x \to \infty} \frac{x^2}{1+x^2} =1,
\]&lt;/span&gt;
dass &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{1+x^2} \sim \frac{1}{x^2}\)&lt;/span&gt;,
also asymptotisch äquivalent sind und somit auch
&lt;span class=&#34;math inline&#34;&gt;\(\log\left(\frac{1}{1+x^2}\right) \sim \log\left(\frac{1}{x^2}\right)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Zusammen gefasst gilt somit:
&lt;span class=&#34;math display&#34;&gt;\[
 \log\left(\frac{1}{\pi} \cdot \frac{1}{1+x^{2}}\right) \to -2\log(x) - \log(\pi) \text{ für } x \to \infty
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Sei &lt;span class=&#34;math inline&#34;&gt;\(f_1^*(x) = C \cdot x^{-\alpha}\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 2\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(C=\frac{1}{\pi} \approx0.3183\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Schauen wir uns das einmal als Grafik an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 2
upper_bound &amp;lt;- 100
dfree &amp;lt;- 1

f_star &amp;lt;- function(x) {
  alpha &amp;lt;- 2
  C &amp;lt;- 1/pi
  C * x**(-alpha)
}

x &amp;lt;- seq(lower_bound, upper_bound, 0.1)

gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line(f_star(x) ~ x, 
          color = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hier eine doppelt-logarithmische Darstellung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line( f_star(x) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wie groß ist nun der (absolute) Fehler zwischen &lt;span class=&#34;math inline&#34;&gt;\(f_1^*\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(f_1\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Eine Grafik von &lt;span class=&#34;math inline&#34;&gt;\(f_1^*-f_1\)&lt;/span&gt; zeigt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(1,1000,1)
  gf_line(x**-2 - 1/(1+x**2) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Genauer gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_1^*(x) - f_1(x) = \frac{1}{x^2+x^4}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können also für ein hinreichend großes &lt;span class=&#34;math inline&#34;&gt;\(x &amp;gt;&amp;gt; 1\)&lt;/span&gt; statt &lt;span class=&#34;math inline&#34;&gt;\(f_1\)&lt;/span&gt; auch &lt;span class=&#34;math inline&#34;&gt;\(f_1^*\)&lt;/span&gt;
verwenden und erhalten somit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\overline{F}_1(x) &amp;amp;\approx \int_x^\infty f_1^*(t) \operatorname{d}t 
  = \int_x^\infty  C \cdot t^{-\alpha} \operatorname{d}t \\
  &amp;amp;= \frac{1}{\pi} \cdot \int_x^\infty  t^{-2} \operatorname{d}t
  = \frac{1}{\pi}\left[\lim\limits_{\epsilon \to \infty} \left(-\epsilon^{-1}\right) -\left(-x^{-1}\right)\right]\\
  &amp;amp;= \frac{1}{\pi}\cdot\left[0 + \frac{1}{x}\right] = \frac{1}{\pi \cdot x}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wie hinreichend ist hier hinreichend groß?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Taleb schreibt an dieser Stelle gerne, dass man jenseits des &lt;em&gt;Karamata-Punktes&lt;/em&gt;
die &lt;em&gt;Karamata-Konstante&lt;/em&gt; anwenden kann.
Beides Begriffe, die keine echte Definition haben und ausserhalb der Sphäre von Taleb auch kaum Verwendung finden.&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;Karamata-Konstante&lt;/em&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(\rho = -\alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Der &lt;em&gt;Karamata-Punkt&lt;/em&gt; bleibt nebulös. Vermutlich könnte man hier so argumentieren:&lt;/p&gt;
&lt;p&gt;Wenn die Fehler zwischen &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(f^*\)&lt;/span&gt; hinreichend klein ist.&lt;/p&gt;
&lt;p&gt;Hierfür könnte man einen absoluten Fehler oder einen relativen Fehler als Maßstab ansehen.&lt;/p&gt;
&lt;p&gt;Für einen relativen Fehler vielleicht &lt;span class=&#34;math inline&#34;&gt;\(\frac{f^*-f}{x} &amp;lt; k\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;Oder man betrachtet hier gleich &lt;span class=&#34;math inline&#34;&gt;\(\frac{f^*-f}{\log(x)} &amp;lt; k^*\)&lt;/span&gt;?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;t-verteilung-mit-zwei-freiheitsgeraden&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;t-Verteilung mit zwei Freiheitsgeraden&lt;/h2&gt;
&lt;p&gt;Für &lt;span class=&#34;math inline&#34;&gt;\(f_2(x)\)&lt;/span&gt; ergibt sich somit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
f_2(x) &amp;amp;= \frac{\Gamma\left(\frac{n+1}{2}\right)} {\sqrt{n\pi}~\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^{2}}{n}\right)^{-\frac{n+1}{2}} \\
       &amp;amp;= \frac{\Gamma\left(\frac{3}{2}\right)} {\sqrt{2\pi}~\Gamma\left(\frac{2}{2}\right)}\left(1+\frac{x^{2}}{2}\right)^{-\frac{3}{2}} \\
       &amp;amp;= \frac{\Gamma\left(\frac{3}{2}\right)} {\sqrt{2\pi}~\Gamma\left(1\right)}\left(1+\frac{x^{2}}{2}\right)^{-\frac{3}{2}} \\
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen &lt;span class=&#34;math inline&#34;&gt;\(\Gamma(1) = 0! = 1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\Gamma\left(\frac{3}{2}\right)=\frac{\sqrt{\pi}}{2}\)&lt;/span&gt; ergibt sich nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
f_2(x) &amp;amp;= \frac{1}{2\sqrt{2}} \cdot \left(1+\frac{x^{2}}{2}\right)^{-\frac{3}{2}} \\
  &amp;amp;= \frac{1}{\sqrt[2]{2^3} \cdot \sqrt[2]{\left(1+\frac{x^{2}}{2}\right)^3}}  \\
  &amp;amp;= \frac{1}{(x^2+2)^{\frac{3}{2}}} \\
  &amp;amp;= \frac{1}{\sqrt{(x^2+2)^3}}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\lim_{x \to +\infty} \frac{f_2(k \cdot x)}{f_2(x)} 
    &amp;amp;= \lim_{x \to +\infty} \frac{\frac{1}{\sqrt{((k\cdot x)^2+2)^3}}}{\frac{1}{\sqrt{(x^2+2)^3}}} = \lim_{x \to +\infty} \frac{\sqrt{(x^2+2)^3}}{\sqrt{((k\cdot x)^2+2)^3}} \\
    &amp;amp;= \lim_{x \to +\infty} \left(\frac{x^2+2}{k^2x^2+2}\right)^\frac{3}{2}=\lim_{x \to +\infty} \left(\frac{\frac{x^2}{x^2}+\frac{2}{x^2}}{k^2\frac{x^2}{x^2}+\frac{2}{x^2}}\right)^\frac{3}{2} \\ 
    &amp;amp;=\left(\frac{1}{k^2}\right)^\frac{3}{2}=\frac{1}{k^3}=k^{-3}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;für alle reellen &lt;span class=&#34;math inline&#34;&gt;\(k&amp;gt;0\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(f_2(x)\)&lt;/span&gt; eine regulär variierende Funktion mit Variationsindex &lt;span class=&#34;math inline&#34;&gt;\(\rho = -3\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Die Überlebensfunktion zur t-Verteilung mit einem Freiheitsgrad lautet nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\overline{F}_2(x) &amp;amp;= \int_x^\infty f_2(t) \operatorname{d}t = \int_x^\infty \frac{1}{\sqrt{(t^2+2)^3}} \operatorname{d}t \\
  &amp;amp;= \frac{x}{2 \cdot \sqrt{x^2+2}}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;da wir das optionale &lt;span class=&#34;math inline&#34;&gt;\(+C\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(C=0\)&lt;/span&gt; annehmen dürfen.&lt;/p&gt;
&lt;p&gt;Es gilt für jedes feste &lt;span class=&#34;math inline&#34;&gt;\(k&amp;gt;0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\lim\limits_{x \to \infty} \frac{\overline{F}_2(k x)}{\overline{F}_2(x)} &amp;amp;= \lim\limits_{x \to \infty}k \cdot \sqrt{\frac{x^2+2}{k^2x^2+2}} \\
  &amp;amp;=  k \cdot \lim\limits_{x \to \infty}  \sqrt{\frac{1}{k^2} \cdot \frac{x^2+2}{x^2+\frac{2}{k^2}}} \\
  &amp;amp;= \frac{k}{k} \cdot \lim\limits_{x \to \infty}  \sqrt{ \frac{x^2+2}{x^2+\frac{2}{k^2}}} = 1\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\lim_{x \to \infty} \frac{\frac{1}{\sqrt{(x^2+2)^3}}}{\frac{1}{x^3}} =\lim\limits_{x \to \infty} \frac{x^3}{(\sqrt{x^2+2})^3} = \lim\limits_{x \to \infty} \left(\frac{x}{\sqrt{x^2+2}}\right)^3= 1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;ist &lt;span class=&#34;math inline&#34;&gt;\(f_2 \sim f^*_2\)&lt;/span&gt; und somit auch &lt;span class=&#34;math inline&#34;&gt;\(\log(f_2) \sim \log(f^*_2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Aus &lt;span class=&#34;math inline&#34;&gt;\(\log\left(\frac{1}{x^3}\right) = \log(1)- 3\cdot\log(x)\)&lt;/span&gt; können wir daher
auf &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 3\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(C=1\)&lt;/span&gt; schliesse und schreiben:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f_2^*(x) = C \cdot x^{-\alpha} = x^{-3}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Schauen wir uns das einmal als Grafik an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 2
upper_bound &amp;lt;- 100
dfree &amp;lt;- 2

f_star &amp;lt;- function(x) {
  alpha &amp;lt;- 3
  C &amp;lt;- 1
  C * x**(-alpha)
}

x &amp;lt;- seq(lower_bound, upper_bound, 0.1)

gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line(f_star(x) ~ x, 
          color = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hier eine doppelt-logarithmische Darstellung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line( f_star(x) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wie groß ist nun der absolute Fehler zwischen &lt;span class=&#34;math inline&#34;&gt;\(f_2^*\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(f_2\)&lt;/span&gt; genau?&lt;/p&gt;
&lt;p&gt;Eine Grafik zeigt von &lt;span class=&#34;math inline&#34;&gt;\(f_2^*-2_1\)&lt;/span&gt; zeigt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(1,1000,1)
  gf_line(f_star(x) - dt(x,df=2) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-14-uber-die-t-verteilung-mit-einem-bzw-zwei-freiheitsgraden/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fussnoten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fussnoten&lt;/h2&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://de.wikipedia.org/wiki/Nicolaas_Govert_de_Bruijn&#34;&gt;de Bruijn, N. G.&lt;/a&gt; (1981), &lt;a href=&#34;https://books.google.com/books?id=Oqj9AgAAQBAJ&#34;&gt;Asymptotic Methods in Analysis&lt;/a&gt;, Dover Publications, ISBN 9780486642215&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Behäbige Funktionen aka slowly varying function</title>
      <link>https://sefiroth.net/nab/post/2021-02-13-behabige-funktionen-aka-slowly-varying-function/</link>
      <pubDate>Sat, 13 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/2021-02-13-behabige-funktionen-aka-slowly-varying-function/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/2021-02-13-behabige-funktionen-aka-slowly-varying-function/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Reelle Funktionen, die ihren Funktionswert kaum ändern, kann man mit
Fug und Recht durchaus behäbig nennen,
korrekter wäre aber von &lt;strong&gt;langsam variierenden&lt;/strong&gt; Funktionen zu sprechen&lt;/p&gt;
&lt;p&gt;Im Kontext von potenzgesetzlichen Verteilungen kommt der Begriff
&lt;strong&gt;slowly varying function&lt;/strong&gt; vor, der Funktionen beschreibt die nur sehr gering
auf Änderungen ihres Parameters reagieren.&lt;/p&gt;
&lt;p&gt;Die Definition dieser &lt;em&gt;behäbigen&lt;/em&gt; besser &lt;strong&gt;langsam variierenden&lt;/strong&gt; Funktionen
stammt von &lt;a href=&#34;https://de.wikipedia.org/wiki/Jovan_Karamata&#34;&gt;Jovan Karamata&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;Eine positive stetige Funktion &lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; auf den positiven reelen Zahlen ist
&lt;strong&gt;langsam variierend (im unendlichen)&lt;/strong&gt;, falls für alle reellen &lt;span class=&#34;math inline&#34;&gt;\(t&amp;gt;0\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\lim_{x \to +\infty} \frac{L(t\cdot x)}{L(x)} = 1\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Beispiele:&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Jede konstante Funktionen (&lt;span class=&#34;math inline&#34;&gt;\(\neq 0\)&lt;/span&gt;) ist &lt;em&gt;langsam variierend&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Beweisskizze:&lt;/strong&gt;
Mit &lt;span class=&#34;math inline&#34;&gt;\(L(x) = c\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(L(x) = L(t x) = c\)&lt;/span&gt; und damit &lt;span class=&#34;math inline&#34;&gt;\(\frac{L(t x)}{L(x)}= 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Jeder Funktion &lt;span class=&#34;math inline&#34;&gt;\(L(x)\)&lt;/span&gt; mit einem Grenzwert &lt;span class=&#34;math inline&#34;&gt;\(b&amp;gt;0\)&lt;/span&gt; ist &lt;em&gt;langsam variierend&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Beweisskizze:&lt;/strong&gt;
Da &lt;span class=&#34;math inline&#34;&gt;\(\lim_{x \to +\infty} L(x) = b = \lim_{x \to +\infty} L(t\cdot x)\)&lt;/span&gt; ist
&lt;span class=&#34;math inline&#34;&gt;\(\lim_{x \to +\infty} \frac{L(t\cdot x)}{L(x)} = \frac{\lim_{x \to +\infty} L(t\cdot x)}{\lim_{x \to +\infty} L(x)} = \frac{b}{b} = 1\)&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Für jedes reellwertige &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(L(x) = log_\beta(x)\)&lt;/span&gt; &lt;em&gt;langsam variierend&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Beweisskizze:&lt;/strong&gt;
Es gilt:
- Für jede reelle Zahl &lt;span class=&#34;math inline&#34;&gt;\(x&amp;gt;0\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(\log_x(x) = 1\)&lt;/span&gt;.
- Für reelle Zahlen &lt;span class=&#34;math inline&#34;&gt;\(a, b\)&lt;/span&gt; gilt: &lt;span class=&#34;math inline&#34;&gt;\(\frac{log(a)}{\log(b)} = \log_b(a)\)&lt;/span&gt;
- Für reelle Zahlen &lt;span class=&#34;math inline&#34;&gt;\(a, b\)&lt;/span&gt; gilt. &lt;span class=&#34;math inline&#34;&gt;\(\log(a \cdot b) = log(a) + log(b)\)&lt;/span&gt;
- Für jede Konstante &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; gilt &lt;span class=&#34;math inline&#34;&gt;\(\lim_{x \to +\infty} \log_x (k) = 0\)&lt;/span&gt;
Somit gilt &lt;span class=&#34;math inline&#34;&gt;\(\frac{\log_\beta(k \cdot x)}{\log_\beta(x)} = \log_x(k\cdot x) = \log_x(k) + \log_x(x) = \log_x(k) +1 \to 1\)&lt;/span&gt; wenn &lt;span class=&#34;math inline&#34;&gt;\(x \to +\infty\)&lt;/span&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Die Funktion &lt;span class=&#34;math inline&#34;&gt;\(x^\beta\)&lt;/span&gt; ist für alle &lt;span class=&#34;math inline&#34;&gt;\(\beta \neq 0\)&lt;/span&gt; &lt;em&gt;&lt;strong&gt;nicht&lt;/strong&gt; langsam variierend&lt;/em&gt;.
&lt;strong&gt;Beweisskizze:&lt;/strong&gt;
Für &lt;span class=&#34;math inline&#34;&gt;\(t \neq 1\)&lt;/span&gt; gilt:
&lt;span class=&#34;math display&#34;&gt;\[\lim_{x \to +\infty} \frac{(tx)^\beta}{x^\beta} = t^\beta \neq 1\]&lt;/span&gt;
Damit sind die Funktionen zwar (s.u.) &lt;em&gt;regulär variierend&lt;/em&gt;, aber nicht &lt;em&gt;langsam variierend&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Eine &lt;strong&gt;regulär variierende&lt;/strong&gt; Funktion &lt;span class=&#34;math inline&#34;&gt;\(L:(0,+\infty) \to (0,+\infty)\)&lt;/span&gt;
ist eine Funktion für die der Term&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\lim_{x \to +\infty} \frac{L(t\cdot x)}{L(x)} = g(t)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit &lt;span class=&#34;math inline&#34;&gt;\(g(t)\)&lt;/span&gt; für alle &lt;span class=&#34;math inline&#34;&gt;\(t&amp;gt;0\)&lt;/span&gt; einen endlichen aber nicht verschwindenen Wert
(m.a.W.: &lt;span class=&#34;math inline&#34;&gt;\(g(t) \neq 0\)&lt;/span&gt;) hat .&lt;/p&gt;
&lt;p&gt;Karamata hat die regulär variierenden Funktionen nun wie folgt charaterisiert:&lt;/p&gt;
&lt;div id=&#34;charakterisierungssatz-von-karamata&#34; class=&#34;section level3 theorem&#34;&gt;
&lt;h3&gt;Charakterisierungssatz von Karamata&lt;/h3&gt;
&lt;p&gt;Jede &lt;em&gt;regulär variierende&lt;/em&gt; Funktion &lt;span class=&#34;math inline&#34;&gt;\(f:(0,+\infty) \to (0,+\infty)\)&lt;/span&gt; ist
von der Form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = x^\beta \cdot L(x),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;wobei &lt;span class=&#34;math inline&#34;&gt;\(\beta \in \mathbf{R}\)&lt;/span&gt; eine reelle Zahl
und &lt;span class=&#34;math inline&#34;&gt;\(L(x)\)&lt;/span&gt; eine &lt;em&gt;langsam variiernde&lt;/em&gt; Funktion ist.&lt;/p&gt;
&lt;!-- ENDE THEOREM--&gt;
&lt;p&gt;Eine Konsequenz aus dem &lt;em&gt;Charakterisierungssatz von Karamata&lt;/em&gt; ist, das die
Funktion &lt;span class=&#34;math inline&#34;&gt;\(g(t)\)&lt;/span&gt; aus der Definition der &lt;em&gt;regulär variierenden&lt;/em&gt; Funktionen
notwendigerweise die Gestalt&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[g(t) = t^\rho,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit einem &lt;span class=&#34;math inline&#34;&gt;\(\rho \in \mathbf{R}\)&lt;/span&gt;, haben muss.&lt;/p&gt;
&lt;p&gt;Dieser Wert &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; wird &lt;strong&gt;Index der Varition&lt;/strong&gt; (engl. &lt;em&gt;index of variation&lt;/em&gt;)
genannt.&lt;/p&gt;
&lt;p&gt;Die Katamata Theorie ist eine Theorie “erster Ordnung” für reguläre Variation.
Weiterführend gibt es mit der
&lt;a href=&#34;https://encyclopediaofmath.org/wiki/De_Haan_theory&#34;&gt;de Haan Theorie&lt;/a&gt; als Theorie “zweiter Ordnung”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quellen:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://encyclopediaofmath.org/index.php?title=Karamata_theory&amp;amp;direction=next&amp;amp;oldid=25937&#34;&gt;Encylopedia of Math&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://archive.org/details/regularvariation0000bing&#34;&gt;Bingham, N. H.; Goldie, C. M.; Teugels, J. L. (1987), Regular Variation, Encyclopedia of Mathematics and its Applications, 27, Cambridge: Cambridge University Press, ISBN 0-521-30787-2, MR 0898871, Zbl 0617.26001&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(L\)&lt;/span&gt; oder auch &lt;span class=&#34;math inline&#34;&gt;\(l\)&lt;/span&gt; wird (angeblich) hier für den Begriff &lt;em&gt;lente&lt;/em&gt; (serb. für &lt;strong&gt;faul&lt;/strong&gt;) verwendet. Behäbig ist also doch nicht so falsch. ;-)&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ein paar Gedanken über potenzgesetzliche Verteilungen (power law distributions)</title>
      <link>https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Eine Funktion &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; heißt &lt;strong&gt;potenzgesetzlich&lt;/strong&gt;,
falls&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = C \cdot x^a\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt, für mindestens alle reellen &lt;span class=&#34;math inline&#34;&gt;\(x &amp;gt; x_{min}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Gewöhnlich setzt man &lt;span class=&#34;math inline&#34;&gt;\(\alpha = -a\)&lt;/span&gt; und schreibt&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f(x) = C \cdot x^{-\alpha}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Damit ergibt sich für &lt;span class=&#34;math inline&#34;&gt;\(f&amp;#39;(x)\)&lt;/span&gt; die Form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
f&amp;#39;(x) = -C \cdot \alpha \cdot x^{-\alpha -1} = C^* \cdot x^{-(\alpha + 1)}
\]&lt;/span&gt;
mit &lt;span class=&#34;math inline&#34;&gt;\(C^* = -C \cdot \alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Eine &lt;strong&gt;(streng) potenzgesetzliche Verteilungen&lt;/strong&gt; (engl. &lt;strong&gt;(strong) power-law probability distribution&lt;/strong&gt;)
zur ZV &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;
ist eine Verteilung deren Überlebensfunktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}_X(x)=P(X &amp;gt; x)\)&lt;/span&gt; die folgende Gestalt hat:
&lt;span class=&#34;math display&#34;&gt;\[\overline{F}(x)=P(X &amp;gt; x) = C \cdot x^{-\alpha}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Mit der Dichte &lt;span class=&#34;math inline&#34;&gt;\(f_X\)&lt;/span&gt; ergibt sich:
&lt;span class=&#34;math display&#34;&gt;\[\overline{F}(x)=P(X &amp;gt; x) = C \cdot x^{-\alpha} =\int_x^\infty f_X(t) \text{d}t = C^* \cdot \int_x^\infty  t^{-(\alpha+1)} \text{d}t = C^* \cdot \int_x^\infty t^{-\alpha} \text{d}t\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Anstelle der Konstanten &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; tritt oft eine &lt;strong&gt;langsam variierende Funktion&lt;/strong&gt;
(engl. &lt;strong&gt;slowly varying funktion&lt;/strong&gt;).
Wir erhalten somit die folgende, allgemeinere Definition:&lt;/p&gt;
&lt;p&gt;Eine &lt;strong&gt;potenzgesetzliche Verteilungen&lt;/strong&gt;
(engl. &lt;strong&gt;power-law probability distribution&lt;/strong&gt;)
(zu einer Zufallsvariable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;)
ist eine Verteilung deren Überlebensfunktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}(x)=P(X &amp;gt; x)\)&lt;/span&gt;
die folgende Gestalt hat:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\overline{F}(x)=P(X &amp;gt; x) = L(x) \cdot x^{-\alpha}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(L(x):(x_{\min}, +\infty) \to (x_{\min}, +\infty)\)&lt;/span&gt; eine &lt;em&gt;langsam variierende Funktion&lt;/em&gt;,
also gilt für alle &lt;span class=&#34;math inline&#34;&gt;\(t&amp;gt;0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\lim_{x \to +\infty} \frac{L(t \cdot x)}{L(x)} = 1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ist nun wieder &lt;span class=&#34;math inline&#34;&gt;\(f_X\)&lt;/span&gt; die Dichte, so erhalten wir:
&lt;span class=&#34;math display&#34;&gt;\[\overline{F}(x)=P(X &amp;gt; x) = L(x) \cdot x^{-\alpha} = \int_x^\infty f_X(t) dt\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[f&amp;#39;(x) = [L(x)x^{-\alpha}]&amp;#39;\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[\int_x^\infty f_X(t) dt= \int_x^\infty [L(t)t^{-\alpha}]&amp;#39; dt\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\Delta x_0 = h = x_1 - x_0\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1 = x_0 + \Delta x_0 = x_0 + h\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_1 = c \cdot x_0\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(x_0 + h = c \cdot x_0 &amp;lt;=&amp;gt; c = 1 + \frac{h}{x_0}\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(L(x_1) = L(x_0+h) = L(c \cdot x_0)\)&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(L(x_1) - L(x_0) = L(c \cdot x_0) - L(x_0) = L(x_0 + h) - L(x_0)}\)&lt;/span&gt;
$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Fakten&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sinnvoll nur, wenn &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;gt; 0\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Ist &lt;span class=&#34;math inline&#34;&gt;\(\alpha &amp;lt; 3\)&lt;/span&gt;, dann ist die &lt;em&gt;Varianz&lt;/em&gt; und die
&lt;em&gt;Schiefe&lt;/em&gt; (engl. &lt;em&gt;skewness&lt;/em&gt;) (mathematisch) nicht definiert.&lt;/li&gt;
&lt;li&gt;Für &lt;span class=&#34;math inline&#34;&gt;\(k &amp;gt; \alpha-1\)&lt;/span&gt; ist das k. Moment unendlich.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Logarithmiert man &lt;span class=&#34;math inline&#34;&gt;\(y=f(x)=C \cdot x^{-\alpha}\)&lt;/span&gt;, so erhält mensch:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log(y) = \log(C) -\alpha \cdot \log(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ist eine Verteilung potenzgesetzlich, dann kann man &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;,
wie folgt abschätzen:&lt;/p&gt;
&lt;p&gt;Seien &lt;span class=&#34;math inline&#34;&gt;\(x_0, x_1 &amp;gt; x_{min}\)&lt;/span&gt; zwei reelle Zahlen, &lt;span class=&#34;math inline&#34;&gt;\(y_0=f(x_0)\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(y_1 = f(y_1)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Dann kann mensch wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
  \log(y_1) - \log(y_0) &amp;amp;= \log(C) - \alpha \cdot\log(x_1) - \log(C) + \alpha \cdot \log(x_0) \\
                        &amp;amp;= \alpha \cdot\left(\log(x_0)- \log(x_1) \right)
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;den Wert für &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, so kann man mittels&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\alpha = \frac{\log(y_1) - \log(y_0)}{\log(x_0)- \log(x_1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;den Wert für &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; bestimmen.&lt;/p&gt;
&lt;p&gt;Mit dem so ermittelten &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, können wir &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\log(C) = \log(y)+ \alpha\log(x)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit Hilfe von&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[C = y \cdot x_0^\alpha = f(x_0) \cdot x_0^\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;für ein &lt;span class=&#34;math inline&#34;&gt;\(x_0 &amp;gt; x_{min}\)&lt;/span&gt; abschätzen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Beispiel&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;Nehmen wir die t-Verteilung mit &lt;span class=&#34;math inline&#34;&gt;\(n=2\)&lt;/span&gt; Freiheitsgeraden.
Die Dichtefunktion bezeichnen wir mit &lt;span class=&#34;math inline&#34;&gt;\(t_{2}(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Dann dann können wir &lt;span class=&#34;math inline&#34;&gt;\(\alpha=3\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(C=1\)&lt;/span&gt; abschätzen.&lt;/p&gt;
&lt;p&gt;Schauen wir uns das einmal als Grafik an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 2
upper_bound &amp;lt;- 100
x &amp;lt;- seq(lower_bound, upper_bound, 0.1)

gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line(C*x**(-alpha) ~ x, 
          color = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hier eine doppelt-logarithmische Darstellung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line( C*x**(-alpha) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Noch ein Beispiel:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Nehmen wir die t-Verteilung mit &lt;span class=&#34;math inline&#34;&gt;\(n=1\)&lt;/span&gt; Freiheitsgeraden.
Die Dichtefunktion bezeichnen wir mit &lt;span class=&#34;math inline&#34;&gt;\(t_{1}(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Dann dann können wir &lt;span class=&#34;math inline&#34;&gt;\(\alpha=2\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(C=0.32\)&lt;/span&gt; abschätzen.&lt;/p&gt;
&lt;p&gt;Schauen wir uns das einmal als Grafik an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 2
upper_bound &amp;lt;- 100
x &amp;lt;- seq(lower_bound, upper_bound, 0.1)

gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line(C*x**(-alpha) ~ x, 
          color = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hier eine doppelt-logarithmische Darstellung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;t&amp;quot;, df = dfree, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line( C*x**(-alpha) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ein ’Gegen-’Beispiel:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Betrachten wir nun die (rechte Seite – &lt;span class=&#34;math inline&#34;&gt;\(x&amp;gt;1=x_{min}\)&lt;/span&gt;) einer Gauß’schen Standardnormalverteilung.&lt;/p&gt;
&lt;p&gt;Mit den Stützstellen &lt;span class=&#34;math inline&#34;&gt;\(x_0 = 1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(x_1 = 5\)&lt;/span&gt; können wir &lt;span class=&#34;math inline&#34;&gt;\(\alpha=7.46\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(C=0.24\)&lt;/span&gt; abschätzen.
Schauen wir uns das einmal als Grafik an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 1
upper_bound &amp;lt;- 8
x &amp;lt;- seq(lower_bound, upper_bound, 0.1)

gf_dist(&amp;quot;norm&amp;quot;,
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line(C*x**(-alpha) ~ x, 
          color = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hier eine doppelt-logarithmische Darstellung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dist(&amp;quot;norm&amp;quot;, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_line( C*x**(-alpha) ~ x, 
           color = &amp;quot;darkgreen&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir erkennen, dass hier etwas nicht passt.
Die Standardnormalverteilung ist (vielleicht) keine &lt;em&gt;potenzgesetzich&lt;/em&gt; Verteilung?&lt;/p&gt;
&lt;p&gt;Ein oft verwendetes Kriterium ist, dass sich die Funktion in der doppelt-logarithmischen Darstellung als Gerade offenbart.&lt;/p&gt;
&lt;p&gt;Schauen wir daher einmal nach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lower_bound &amp;lt;- 1
upper_bound &amp;lt;- 8

gf_dist(&amp;quot;norm&amp;quot;, 
        xlim = c(lower_bound, upper_bound), 
        color = &amp;quot;darkred&amp;quot;) %&amp;gt;%
  gf_refine(
    scale_x_log10(),
    scale_y_log10()
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/2021-02-12-ein-paar-gedanken-uber-potenzgesetzliche-verteilungen-power-law-distributions/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;** — **&lt;/p&gt;
&lt;p&gt;Weiter gilt für &lt;em&gt;potenzgesetzliche Verteilungen&lt;/em&gt; wegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{f(x)}{f(c\cdot x)} = \frac{C \cdot x^{-\alpha}}{C \cdot (c\cdot x)^{-\alpha}}
 = c^\alpha\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(f(c\cdot x)\)&lt;/span&gt; für alle (beliebig aber festen) &lt;span class=&#34;math inline&#34;&gt;\(c&amp;gt;0\)&lt;/span&gt; &lt;em&gt;proportional&lt;/em&gt;,
was man gerne als &lt;span class=&#34;math inline&#34;&gt;\(f(x) \propto f(c \cdot x)\)&lt;/span&gt; schreibt.&lt;/p&gt;
&lt;p&gt;** — **&lt;/p&gt;
&lt;p&gt;Die Wahrscheinlichkeit für ein (mindestens) &lt;span class=&#34;math inline&#34;&gt;\(8-\sigma\)&lt;/span&gt; Ereignis liegt bei einer Standardnormalverteilung bei etwa &lt;span class=&#34;math inline&#34;&gt;\(6.66133814775094\times 10^{-16}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Bei einer t-Verteilung mit 2 Freiheitsgeraden bei etwa 0.00763403608266899$.&lt;/p&gt;
&lt;p&gt;Während die Eintrittschance eines (mindestens) &lt;span class=&#34;math inline&#34;&gt;\(8-\sigma\)&lt;/span&gt; Ereignisses bei der Standardnormalverteilung bei etwa &lt;span class=&#34;math inline&#34;&gt;\(1 : round(1/(1-pnorm(8)),0)\)&lt;/span&gt; liegt, ist diese der t-Verteilung mit einem Freiheitsgrad bei etwa $1 : 131&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gedankenstütze zu wichtigen Funktionsbegriffen in der Statistik</title>
      <link>https://sefiroth.net/nab/post/2021-02-12-gedankenstutze-zu-wichtigen-funktionsbegriffen-in-der-statistik/</link>
      <pubDate>Fri, 12 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/2021-02-12-gedankenstutze-zu-wichtigen-funktionsbegriffen-in-der-statistik/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/2021-02-12-gedankenstutze-zu-wichtigen-funktionsbegriffen-in-der-statistik/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;eine-kleine-liste-von-fundermentalen-begriffen-in-der-statistik.&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Eine kleine Liste von fundermentalen Begriffen in der Statistik.&lt;/h1&gt;
&lt;p&gt;Gilt für eine reelle Funktion &lt;span class=&#34;math inline&#34;&gt;\(f: \mathbf{R} \to \mathbf{R}\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; ist &lt;em&gt;nichtnegativ&lt;/em&gt;, d.h., &lt;span class=&#34;math inline&#34;&gt;\(f(x) \geq 0\)&lt;/span&gt;, für alle &lt;span class=&#34;math inline&#34;&gt;\(x \in \mathbf{R}\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; ist &lt;em&gt;integrierbar&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; ist &lt;em&gt;normiert&lt;/em&gt; in dem Sinne, dass
&lt;span class=&#34;math display&#34;&gt;\[\int_{-\infty}^\infty f(x) \text{d}x = 1\]&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dann nennen wir &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; eine &lt;strong&gt;Wahrscheinlichkeitsdichtefunktion&lt;/strong&gt; (engl. &lt;strong&gt;probability density funktion&lt;/strong&gt; kurz &lt;strong&gt;pdf&lt;/strong&gt;) oder kurz &lt;strong&gt;Dichte&lt;/strong&gt; (engl. &lt;strong&gt;density&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Durch
&lt;span class=&#34;math display&#34;&gt;\[P([a, b]) := \int_a^b f(x) \text{d} x\]&lt;/span&gt;
definiert &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; eine &lt;em&gt;Wahrscheinlichkeitsverteilung&lt;/em&gt; auf den reellen Zahlen.&lt;/p&gt;
&lt;p&gt;Ist &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; eine reelwertige &lt;em&gt;Zufallsvariable&lt;/em&gt; (kurz &lt;strong&gt;ZV&lt;/strong&gt;) und existiert eine
reelle Funktion &lt;span class=&#34;math inline&#34;&gt;\(f_X(x)\)&lt;/span&gt; der Art, dass für alle &lt;span class=&#34;math inline&#34;&gt;\(a \in \mathbf{R}\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X \leq a) = \int_{-\infty}^a f_X(x) \text{d}x\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt, so nennt man &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; die &lt;strong&gt;Wahrscheinlichkeitsdichtefunktion von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Die Funktion&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F_X(a) = P(X \leq a)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;nenen wir &lt;strong&gt;(Wahrscheinlichkeits-)Verteilung(-sfunktion)&lt;/strong&gt;
(engl. &lt;strong&gt;cumulative distribution function&lt;/strong&gt; kurz &lt;strong&gt;cdf&lt;/strong&gt;
aber auch nur &lt;strong&gt;distribution function&lt;/strong&gt;) &lt;strong&gt;von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Genau dann ist eine Funktion &lt;span class=&#34;math inline&#34;&gt;\(F: \mathbf{R} \to [0, 1]\)&lt;/span&gt;
eine &lt;strong&gt;Verteilungsfunktion&lt;/strong&gt;, wenngilt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es ist &lt;span class=&#34;math inline&#34;&gt;\(\lim_{t \to -\infty} F(t)=0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\lim_{t \to +\infty} F(t)=1\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Die Funktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}(t)\)&lt;/span&gt; ist &lt;strong&gt;monoton wachsend&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Die Funktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}(t)\)&lt;/span&gt; ist &lt;strong&gt;rechtsseitig stetig&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Die Funktion&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\overline{F}_X(a) = 1 - F_X(a)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;nennen wir
&lt;strong&gt;Überlebensfunktion&lt;/strong&gt; (engl. &lt;strong&gt;survival function&lt;/strong&gt;, &lt;strong&gt;complementarey cumulative distribution funktion&lt;/strong&gt; kurz &lt;strong&gt;ccdf&lt;/strong&gt;, &lt;strong&gt;tail distribution&lt;/strong&gt;, &lt;strong&gt;exceedance&lt;/strong&gt; oder &lt;strong&gt;reliability function&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Es gilt &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}_X(a) + F_X(a) = 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Genau dann ist eine Funktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}: \mathbf{R} \to [0, 1]\)&lt;/span&gt;
eine &lt;strong&gt;Überlebensfunktion&lt;/strong&gt;, wenn gilt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Es ist &lt;span class=&#34;math inline&#34;&gt;\(\lim_\limits{t \to -\infty} \overline{F}(t)=1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\lim_{t \to + \infty}\overline{F}(t)=0\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Die Funktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}(t)\)&lt;/span&gt; ist &lt;strong&gt;monoton fallend&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Die Funktion &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}(t)\)&lt;/span&gt; ist &lt;strong&gt;rechtsseitig stetig&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ein paar weitere Eigenschaften von &lt;em&gt;Überlebensfunktionen&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nicht-negative stetige ZV &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; mit Erwartungswert, also &lt;span class=&#34;math inline&#34;&gt;\(\int_0^\infty x f(x) \text{d} x = \mu &amp;lt; \infty\)&lt;/span&gt;, erfüllen die &lt;a href=&#34;https://de.wikipedia.org/wiki/Markow-Ungleichung_(Stochastik)&#34;&gt;Markov-Ungleichung&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\overline{F}_X(x) \leq \frac{\operatorname{E}(X)}{x}\]&lt;/span&gt;
- Ist &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; eine ZV und &lt;span class=&#34;math inline&#34;&gt;\(\overline{F}_X\)&lt;/span&gt; die zugehörige Überlebensfunktion.
Existiert &lt;span class=&#34;math inline&#34;&gt;\(E(X)\)&lt;/span&gt;, dann gilt &lt;span class=&#34;math inline&#34;&gt;\(\lim_{t \to +\infty}\overline{F}(x)=0 = o\left(\frac{1}{x}\right)\)&lt;/span&gt;.
&lt;strong&gt;Beweisskizze:&lt;/strong&gt;
Sei &lt;span class=&#34;math inline&#34;&gt;\(f_X\)&lt;/span&gt; die Dichtefunktion von &lt;span class=&#34;math inline&#34;&gt;\(F_X\)&lt;/span&gt; zur ZV &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Fü jedes &lt;span class=&#34;math inline&#34;&gt;\(c&amp;gt;0\)&lt;/span&gt; ist dann
$$&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
      E(X) = \int_0^\infty x \cdot f_X(x) \text{d}x &amp;amp;=  \int_0^cx \cdot f_X(x) \text{d}x +\int_c^\infty x \cdot f_X(x) \text{d}x \\
      &amp;amp;\geq  \int_0^cx \cdot f_X(x) \text{d}x +\int_c^\infty c \cdot f_X(x) \text{d}x \\
      &amp;amp;=  \int_0^cx \cdot f_X(x) \text{d}x + c \cdot \int_c^\infty f_X(x) \text{d}x \\
      &amp;amp;=  \int_0^cx \cdot f_X(x) \text{d}x +c \cdot \overline{F}(c)

  \end{align*}\]&lt;/span&gt;$$&lt;/p&gt;
&lt;p&gt;Damit gilt nun:
&lt;span class=&#34;math display&#34;&gt;\[0 \leq c \cdot \overline{F}(c) \leq E(X) - \int_0^cx \cdot f_X(x) \text{d}x\]&lt;/span&gt;
Wegen &lt;span class=&#34;math inline&#34;&gt;\(\lim\limits_{c \to +\infty} \int_0^cx \cdot f_X(x) \text{d}x = E(X)\)&lt;/span&gt;
folgt:
&lt;span class=&#34;math display&#34;&gt;\[0 \leq c \cdot \overline{F}(c) \leq E(X) - \int_0^cx \cdot f_X(x) \text{d}x\to 0 \text{ wenn } c \to \infty\]&lt;/span&gt;
- Für nicht-negative ZV &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; gilt:
&lt;span class=&#34;math display&#34;&gt;\[E(X) = \int_0^\infty \overline{F}_X(x) \text{d}    x\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Cook Abstand</title>
      <link>https://sefiroth.net/nab/post/cook-abstand/</link>
      <pubDate>Mon, 29 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/cook-abstand/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Frage: &lt;em&gt;Was macht einen Wert zum Ausreißer?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Eine mögliche Antwort wäre: &lt;em&gt;Er liegt weit weg von den anderen Werten &lt;strong&gt;und&lt;/strong&gt;
hat einen (starken) Einfluss auf unser Modell.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Eine Möglichkeit solche Ausreißer zu finden ist der &lt;em&gt;Cook Abstand&lt;/em&gt;
(eng.: &lt;em&gt;Cook’s distance&lt;/em&gt;).
Die Idee dabei ist es zu messen welchen Einfluss ein Wert auf das Modell hat.
Dazu schauen wir uns das Modell einmal mit und einmal ohne diesen Wert an und
vergleicht diese Ergebnisse.&lt;/p&gt;
&lt;p&gt;Schauen wir uns den Cook Abstand einmal für ein (einfaches) lineares
Regressionmodell konkret an:&lt;/p&gt;
&lt;div id=&#34;vorbereitungen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vorbereitungen&lt;/h3&gt;
&lt;p&gt;Wir wollen mit &lt;code&gt;mosaic&lt;/code&gt; arbeiten, also laden wir das Paket als erstes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Falls die &lt;strong&gt;tipping&lt;/strong&gt;-Daten noch nicht im Verzeichnis liegen,
laden wir diese aus dem Internet nach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!file.exists(&amp;quot;tips.csv&amp;quot;)) {
  download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun laden wir die &lt;strong&gt;tipping&lt;/strong&gt;-Daten in den Datenrahmen &lt;code&gt;tips&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir brauchen für unser Modell nur den Rechnungsbetrag &lt;code&gt;total_bill&lt;/code&gt; und den
Trinkgeldbetrag &lt;code&gt;tip&lt;/code&gt; für unser Modell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips %&amp;gt;% select(c(&amp;quot;total_bill&amp;quot;, &amp;quot;tip&amp;quot;)) -&amp;gt; tips&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unser-modell&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Unser Modell:&lt;/h2&gt;
&lt;p&gt;Werfen wir zunächst einen Blick auf das Streudiagramm unserer Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(tip ~ total_bill, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Und erstellen dann ein lineares Modell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erg_lm &amp;lt;- lm(tip ~ total_bill, data = tips)
summary(erg_lm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 0.920270   0.159735   5.761 2.53e-08 ***
## total_bill  0.105025   0.007365  14.260  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 
## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Betrachten wir nun die Regressionsgerade in unseren Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(tip ~ total_bill, data = tips) %&amp;gt;%
  gf_coefline(
    model = erg_lm,
    color = ~ &amp;quot;Regressionsgerade&amp;quot;,
    show.legend = FALSE
  ) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Für lineare Regressionsmodell können einflussreiche Ausreißer sehr hinderlich
sein.
Was ändert sich, wenn wir einen Wert, z.B. einen potentiellen Ausreißer,
nicht betrachten?&lt;/p&gt;
&lt;p&gt;Als Beispiel wählen wir die folgende Beobachtung aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips %&amp;gt;% slice(173) -&amp;gt; tips_removed
tips_removed&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   total_bill  tip
## 1       7.25 5.15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips %&amp;gt;% slice(-173) -&amp;gt; tips_red
erg_lm_red &amp;lt;- lm(tip ~ total_bill, data = tips_red)
summary(erg_lm_red)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tip ~ total_bill, data = tips_red)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2136 -0.5351 -0.0818  0.4951  3.6869 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  0.86065    0.15709   5.479 1.08e-07 ***
## total_bill   0.10731    0.00723  14.843  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.9992 on 241 degrees of freedom
## Multiple R-squared:  0.4776, Adjusted R-squared:  0.4754 
## F-statistic: 220.3 on 1 and 241 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(tip ~ total_bill, data = tips_red) %&amp;gt;%
  gf_coefline(
    model = erg_lm,
    color = ~ &amp;quot;Regressionsgerade&amp;quot;
    ) %&amp;gt;%
  gf_point(
    tip ~ total_bill, 
    colour = ~ &amp;quot;Entfernter Punkt&amp;quot;,
    data = tips_removed)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Um zu messen was diese Änderung bewirkt hat, schaut sich der Cook Abstand
zunächst die Summe der quadrierten Differenzen der vorhergesagten Werte in
beiden Modellen an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_data &amp;lt;- tibble(total_bill = tips$total_bill)
prognose_lm &amp;lt;- predict(erg_lm, newdata = new_data)
prognose_lm_red &amp;lt;- predict(erg_lm_red, newdata = new_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d_j = \sum_{i=1}^n \left(\hat{y}_i - \hat{y}_{i(j)}\right)^2\]&lt;/span&gt;
Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt; die Prognose des Wertes &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; auf Basis von &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; mit
dem Originalmodell und &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_{i(j)}\)&lt;/span&gt; die Prognose wenn man die &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-te
Beobachtung aus dem Modell gestrichen hat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_j &amp;lt;- sum((prognose_lm - prognose_lm_red)^2)
d_j&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1511406&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Cook Abstand &lt;span class=&#34;math inline&#34;&gt;\(D_j\)&lt;/span&gt; wird nun noch &lt;em&gt;normiert&lt;/em&gt; durch
&lt;span class=&#34;math display&#34;&gt;\[{\text{var}_{\text{cook}}} = p \cdot s_{\epsilon_i^2}^2\]&lt;/span&gt;
Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(s_{\epsilon_i^2}^2\)&lt;/span&gt; der erwartungstreue Schätzer der Varianz der
Residuen und &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; die Anzahl aller erklärenden Variablen (hier &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt;) &lt;span class=&#34;math inline&#34;&gt;\(+ 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Es ist also:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[D_j = \frac{d_j}{\text{var}_{\text{cook}}} = \frac{\sum\limits_{i=1}^n \left(\hat{y}_i - \hat{y}_{i(j)}\right)^2}{p \cdot s_{\epsilon_i^2}^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Summary des Modells
selm &amp;lt;- summary(erg_lm)

# Wir finden p als rank im Modell
p &amp;lt;- erg_lm$rank 

# Wir finden den erwatungtreuen Schätzer im Summary des Modells
s_quad_eps_quad &amp;lt;- (selm$sigma)^2 

var_cook = p * s_quad_eps_quad

D_j = d_j / var_cook
D_j&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.07234504&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir können den Wert aber auch viel einfacher direkt berechnen lassen und dass
für alle &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; mit Hilfe von &lt;code&gt;cooks.distance(..)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks.distance(erg_lm)[173]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        173 
## 0.07234504&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wann aber ist nun ein Wert ein &lt;em&gt;einflussreicher&lt;/em&gt; Ausreißer?&lt;/p&gt;
&lt;p&gt;Cook selber gibt dafür die Bedingung &lt;span class=&#34;math inline&#34;&gt;\(D_j &amp;gt; 1\)&lt;/span&gt; an. Andere Autor*innen schreiben &lt;span class=&#34;math inline&#34;&gt;\(D_j &amp;gt; 4/n\)&lt;/span&gt;, wobei &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; die Anzahl der Beobachtung ist.&lt;/p&gt;
&lt;p&gt;In unserem Beispiel liefert die Variante &lt;span class=&#34;math inline&#34;&gt;\(D_j &amp;gt; 1\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cooks &amp;lt;- cooks.distance(erg_lm)
names(cooks) &amp;lt;- NULL
n &amp;lt;- nrow(tips)

any(cooks &amp;gt; 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;keinen Ausreißer.&lt;/p&gt;
&lt;p&gt;Wenn wir jedoch mit &lt;span class=&#34;math inline&#34;&gt;\(D_j &amp;gt; 4/n\)&lt;/span&gt; suchen
.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;any(cooks &amp;gt; 4/n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;dann gibt es Ausreißer.&lt;/p&gt;
&lt;p&gt;Die Indices dieser finden wir mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;which(cooks &amp;gt; 4/n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  24  48  57 103 142 157 171 173 179 183 184 185 188 208 211 213 215 238&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bereinigen wir nun unsere Daten um genau diese Werte:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;remove &amp;lt;- which(cooks &amp;gt; 4/n)
tips %&amp;gt;% slice(-remove) -&amp;gt; tips_no_outliers
tips %&amp;gt;% slice(remove) -&amp;gt; tips_removed
erg_lm_no_outliers &amp;lt;- lm(tip ~ total_bill, data = tips_no_outliers)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und schauen uns das Ergebnis an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(erg_lm_no_outliers)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tip ~ total_bill, data = tips_no_outliers)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.22592 -0.48166 -0.06794  0.46992  2.31414 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 0.773324   0.139435   5.546  8.2e-08 ***
## total_bill  0.111799   0.006958  16.069  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.7778 on 224 degrees of freedom
## Multiple R-squared:  0.5355, Adjusted R-squared:  0.5334 
## F-statistic: 258.2 on 1 and 224 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(tip ~ total_bill, data = erg_lm_no_outliers) %&amp;gt;%
  gf_coefline(
    model = erg_lm_no_outliers, 
    color = ~&amp;quot;Regressionsgerade&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Im direkten Vergleich:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(tip ~ total_bill, data = erg_lm) %&amp;gt;%
  gf_coefline(
    model =  erg_lm,
    color = ~ &amp;quot;Regressionsgerade (Orginal)&amp;quot;
  ) %&amp;gt;%
  gf_coefline(
    model = erg_lm_no_outliers,
    color = ~ &amp;quot;Regressionsgerade (No Outliers)&amp;quot;
  ) %&amp;gt;%
  gf_point(
    tip ~ total_bill,
    color = ~ &amp;quot;Entfernte Punkte&amp;quot;,
    data = tips_removed
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/cook-abstand/index.de_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unsere-beiden-modelle-als-formeln&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Unsere beiden Modelle als Formeln&lt;/h2&gt;
&lt;p&gt;Das ursprüngliche Modell:
&lt;span class=&#34;math display&#34;&gt;\[\widehat{tips}_{lm} = 0.9202696 + 0.1050245 \cdot total\_bill + \epsilon\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Das um pot. Ausreißer bereinigte Modell:
&lt;span class=&#34;math display&#34;&gt;\[\widehat{tips}_{lm\_no} 0.7733236 + 0.1117985 \cdot total\_bill + \epsilon\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ein kleines Beispiel zum Rangkorrelationskoeffizienten</title>
      <link>https://sefiroth.net/nab/post/ein-kleines-beispiel-zum-rangkorrelationskoeffizienten/</link>
      <pubDate>Mon, 25 May 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/ein-kleines-beispiel-zum-rangkorrelationskoeffizienten/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;


&lt;p&gt;Bei der Rangkorrelation werden statt der Werte die Ränge der Werte zur Berechnung herangezogen.&lt;/p&gt;
&lt;div id=&#34;beispiel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Beispiel:&lt;/h3&gt;
&lt;p&gt;Es seien die folgenden Datenpunkte gegeben:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.06
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
y
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Das Streudiagramm dieser Daten sieht dann so aus:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-05-25-ein-kleines-beispiel-zum-rangkorrelationskoeffizienten_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;50%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Der Korrelationskoeffizient ist nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[r = r_{BP} = 0.7944953\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Schauen wir uns nun die Werte der Tabelle mit ihrem Rang an:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.06
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
y
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.87
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ry
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Das Streudiagramm der Ränge sieht nun wie folgt aus:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-05-25-ein-kleines-beispiel-zum-rangkorrelationskoeffizienten_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;50%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Und der Korrelationskoeffizient der Ränge ist nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[r_{sp} = r_{ry,rx}=0.8909091\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dieser Korrelationskoeffizient der Ränge wird &lt;em&gt;Rangkorrelationkoeffizient&lt;/em&gt; genannt.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aber Vorsicht:&lt;/strong&gt; Die Ränge anstatt der Werte in die Formel für den Korrelationskoeffizienten einzusetzen funktioniert nur, wenn jeder Wert genau &lt;strong&gt;einmal&lt;/strong&gt; vorkommt!&lt;/p&gt;
&lt;p&gt;Um das zu sehen, modifizieren wir unser Beispiel, so dass an zwei Stellen die Werte doppelt vorkommen. Wir erhalten damit die folgende, neue Tabelle:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.06
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
y
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ry
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Bevor wir nun einfach die &lt;em&gt;Ränge&lt;/em&gt; so in die Formel für den &lt;em&gt;Korrelationskoeffizienten&lt;/em&gt; (nach Pearson) einsetzen können, müssen wir noch etwas beachten, was die Definition von &lt;em&gt;Rängen&lt;/em&gt; angeht.
Denn dort steht im Kleingedruckten folgendes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Den ranggleichen Beobachtungen wird das arithmetische Mittel der auf sie fallenden Ränge zugeordnet!&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Darum müssen wir die Ränge noch etwas korrigieren und erhalten:&lt;/p&gt;
&lt;table class=&#34;table&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
x
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.91
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.63
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.88
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.80
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.70
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.96
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.71
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.06
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
y
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.38
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.30
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.90
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22.20
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
36.72
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
49.94
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
63.77
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
82.76
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
100.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
rx
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ry
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.50
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
6.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
7.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
8.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
9.00
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
10.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Nun können wir von den Rängen wieder “ganz normal” den Korrelationskoeffizienten berechnen und erhalten:
&lt;span class=&#34;math display&#34;&gt;\[r_{sp} = r_{ry,rx} = 0.8932927\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Eine typische Frage von Studierenden</title>
      <link>https://sefiroth.net/nab/post/eine-typische-frage-von-studierenden/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/eine-typische-frage-von-studierenden/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Vor kurzem fand ich mal wieder eine Anfrage einer Studierenden in meinem Email Postfach. Die Frage lautete in etwa wie folgt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Guten Tag Herr Markgraf,&lt;/p&gt;
&lt;p&gt;ich würde gerne die Hypothese untersuchen: Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.
Dazu habe ich eine Variable “iphones.tagsüber.unbeachtet” mit 1x, 2x und 3x täglich als Ausprägungen und eine andere Variable “wetter.ist.gut”, die als Ausprägung “Ja” und “Nein” hat.
Welchen Test kann ich dazu zur Überprüfung einer Abhängigkeit nehmen?&lt;/p&gt;
&lt;p&gt;Vielen Dank im Voraus.&lt;/p&gt;
&lt;p&gt;MfG Monika Mustermann&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Natürlich ist diese Frage im Prinzip einfach zu beantworten, sogar von Leuten, die Statistik an einer Hochschule gehört haben. – Aber da ich ja auch sonst nichts zu tun habe, gebe ich gerne statistische Hilfestellung für Studierende.
Sicher, ich verdiene damit eigentlich mein Geld.
Also ist es nur natürlich, dass ich so etwas vollkommen unentgeldlich mache.
Und wieso sollten Studierende einfach mal ein Buch in die Hand nehmen und
selber nachdenken?
Es gibt vermutlich keine Bücher zu diesem Thema, denn es ist ganz sicher eine Geheimwissenschaft.
Und wieso sollte man dann also seine Betreuungsperson zu diesem Probem fragen?
Die hat ja auch so viel zu tun… – Egal.&lt;/p&gt;
&lt;p&gt;Was haben wir hier vorliegen? – Im einfachsten Fall sind es zwei kategoriale Variablen, und wir wollen sehen ob diese von einander (un-)abhängig sind.&lt;/p&gt;
&lt;p&gt;Mangels tatsächlicher Daten basteln wir uns einfach mal ein Beispiel:&lt;/p&gt;
&lt;div id=&#34;wir-bastlen-uns-ein-beispiel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wir bastlen uns ein Beispiel&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wie immer zuerst das Paket &amp;#39;mosaic&amp;#39; laden
library(mosaic)

# Einen beliebigen Startwert für den Zufallszahlengenerator
# für die Reproduzierbarkeit
set.seed(123)

# Anzahl der Vorfälle insgesamt
n &amp;lt;- 176

# Anzahl der Wiederholungen für die SBI-Methoden
loops &amp;lt;- 10000

# Erfinden eines Beispieldatensatzes
daten &amp;lt;- data.frame(
  iphones.tagsüber.unbeachtet = sample(rep(c(&amp;quot;1xtäglich&amp;quot;,&amp;quot;2xtäglich&amp;quot;,&amp;quot;3xtäglich&amp;quot;),n),n),
  wetter.ist.gut = sample(rep(c(&amp;quot;Ja&amp;quot;,&amp;quot;Nein&amp;quot;),n),n)
)

# Ausgabe der ersten Zeilen des Datensatzes
head(daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   iphones.tagsüber.unbeachtet wetter.ist.gut
## 1                   1xtäglich             Ja
## 2                   1xtäglich           Nein
## 3                   2xtäglich             Ja
## 4                   3xtäglich           Nein
## 5                   1xtäglich             Ja
## 6                   2xtäglich             Ja&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-blick-auf-kennzahlen-und-visualisierungsmöglichkeiten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein Blick auf Kennzahlen und Visualisierungsmöglichkeiten&lt;/h3&gt;
&lt;p&gt;Man kann diese Daten als Kreuztabelle zusammenfassen und diese dann mit Hilfe eines Mosaikplots darstellen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet Ja Nein
##                   1xtäglich 29   33
##                   2xtäglich 34   26
##                   3xtäglich 27   27&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mosaicplot(wetter.ist.gut ~ iphones.tagsüber.unbeachtet, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Für später speichern wir die Kreuztabelle in obs.tab
obs.tab &amp;lt;- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;von-der-forschungsthese-zur-hypothese&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Von der Forschungsthese zur Hypothese&lt;/h3&gt;
&lt;p&gt;Um nun zwischen abhängig und unabhängig statistisch zu unterscheiden, sollte man sich die Null- und Alternativhypothese genau überlegen und &lt;em&gt;operationalisieren&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Ein Blick auf die (orginale) Forschungsthese: “Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.”&lt;/p&gt;
&lt;p&gt;Oh je, eine kausale Forschungsthese. Ein dezenter Hinweis auf das Werk von Judea Pearl und Dana Mackenzie &lt;a href=&#34;https://www.amazon.de/Book-Why-Science-Cause-Effect/dp/046509760X/ref=sr_1_1?adgrpid=70747374853&amp;amp;dchild=1&amp;amp;gclid=EAIaIQobChMIio7A5a-57gIVBKOyCh1zPAemEAAYAyAAEgKbXPD_BwE&amp;amp;hvadid=352621590167&amp;amp;hvdev=c&amp;amp;hvlocphy=9043910&amp;amp;hvnetw=g&amp;amp;hvqmt=b&amp;amp;hvrand=4305248996988708271&amp;amp;hvtargid=kwd-422343395170&amp;amp;hydadcr=16871_1724817&amp;amp;keywords=the+book+of+why+judea+pearl&amp;amp;qid=1611656438&amp;amp;sr=8-1&amp;amp;tag=googhydr08-21&#34;&gt;“The Book of Why!”&lt;/a&gt; muss an dieser Stelle sein. – Aber da wir keine kausale Modellierung machen wollen, müssen wir das Problem sinngetreu umformulieren:&lt;/p&gt;
&lt;p&gt;“Es besteht ein Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.”&lt;/p&gt;
&lt;p&gt;Warum diese neue Formulierung? – Nun, in der orginal Forschungsthese wird ein &lt;strong&gt;kausal&lt;/strong&gt; Zusammenhang geprüft. Da es sich vermutlich um eine Beobachtungstudie handelt können wir einen solchen Ursache-Wirkungs-Zusammenhang aber hier nicht so einfach prüfen. Wie das gehen könnte, dazu schaut man mal bei J.Pearl und D.Mackenzie (s.o.) nach.
Zwar kann man von außen sagen: “Wenn es einen Zusammenhang gibt, dann führt das schöne Wetter zur Nichtbeachtung.” mit klassischer Statistik können wir hier aber nur den Zusammenhang (und zwar ungerichtet!) testen.
Liegt dieser &lt;strong&gt;nicht&lt;/strong&gt; vor, so spricht erstmal auch nichts für einen kausalen Zusammenhang, aber ein Zusammenhang an sich spricht noch nicht für einen kausalen Zusammenhang!
(Korrelation ist ebeb &lt;strong&gt;nicht&lt;/strong&gt; Kausalität!)&lt;/p&gt;
&lt;p&gt;Aus der umformulierten Forschungsfrage können wir die Alternativ- und auch die Nullhypothese ableiten:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Alternativhypothese:&lt;/strong&gt; Es besteht ein Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nullhypothese:&lt;/strong&gt; Es besteht &lt;strong&gt;kein&lt;/strong&gt; Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wie-kann-man-nun-den-zusammenhang-messen-und-wie-sieht-kein-zusammenhang-dabei-aus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wie kann man nun den Zusammenhang &lt;em&gt;messen&lt;/em&gt; und wie sieht &lt;em&gt;kein Zusammenhang&lt;/em&gt; dabei aus?&lt;/h2&gt;
&lt;p&gt;Um zu sehen ob unsere Werte keinen Zusammenhang haben, also rein zufällig sind, oder es einen inneren Zusammenhang gibt müssen wir die äußeren von den inneren Häufigkeiten trennen.&lt;/p&gt;
&lt;p&gt;Konkret heißt das, wir schauen uns an wie die Häufigkeiten oder auch Verteilung der einzelnen Variabeln ausssehen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## wetter.ist.gut
##   Ja Nein 
##   90   86&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(~ iphones.tagsüber.unbeachtet, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## iphones.tagsüber.unbeachtet
## 1xtäglich 2xtäglich 3xtäglich 
##        62        60        54&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;freiheitsgrade&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Freiheitsgrade&lt;/h4&gt;
&lt;p&gt;Die Werte innerhalb der Kreuztabelle oben werden im wesendlichen durch diese Werte bestimmt. Die außeren Werte sind also unsere Rahmenbedingungen. Dabei ist der Einfluss der sogenannten &lt;em&gt;Randhäufigkeiten&lt;/em&gt; (&lt;em&gt;Marginale Häufigkeit&lt;/em&gt;) nicht zu unterschätzen. Denn wenn wir diese als &lt;em&gt;fix&lt;/em&gt;/&lt;em&gt;gegeben&lt;/em&gt; ansehen, können wir nur mit den sechs Werten in der Mitte unserer Kreuztabelle &lt;em&gt;spielen&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Doch sind nicht alle sechs Werte wirklich frei wählbar. Denn um zum Beispiel die Summe 62 in der ersten Zeile zu erhalten haben wir ja die Summe von 29 und 33 gebildet.&lt;/p&gt;
&lt;p&gt;Ist nun der Rand, also 62, fest, so kann ich nicht &lt;em&gt;beide&lt;/em&gt; Summanden frei wählen, denn&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 = 29 + 33\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;impliziert ja, dass allgemein&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 = x + y\]&lt;/span&gt;
gelten muss und somit durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x = 62 - y \qquad\text{ bzw. }\qquad y = 62 - x\]&lt;/span&gt;
immer maximal eine der Variabeln – &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; oder &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; – wirklich frei wählen kann.&lt;/p&gt;
&lt;p&gt;Da dies für jede Zeile, aber auch für jede Spalte gilt, denn z.B. ist die Summe der ersten Spalte gegeben durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[90 = 29 + 34 + 27,\]&lt;/span&gt;
sind von den sechs Werten in der Kreuztabelle in der Tat nur 2 Werte wirklich frei zu wählen.
Wir haben also ein Problem mit &lt;em&gt;2 Freiheitsgraden&lt;/em&gt;, man schreibt das kurz mit &lt;span class=&#34;math inline&#34;&gt;\(df=2\)&lt;/span&gt; (&lt;em&gt;df&lt;/em&gt; steht dabei für &lt;em&gt;degree of freedom&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unabhängigkeit-in-der-statistik&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unabhängigkeit in der Statistik&lt;/h3&gt;
&lt;p&gt;Wir sagen, in der Statistik, dass ein gemeinsames Ereignis unabhängig ist wenn sich das Ereignis als Produkt der beiden Einzelereignisse berechnen lässt.
Seien &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; also zwei Ereignisse, dann gilt im Falle der Unabhängigkeit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(A \cap B) = P(A) \cdot P(B)\]&lt;/span&gt;
Oder etwas informeller: &lt;em&gt;Die Wahrscheinlichkeit das beide Ereignisse eintreffen ist das Produkt der Wahrscheinlichkeiten, dass jeweils eines der beiden Ereignisse eintrifft.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wir können diese Definition aus der Wahrscheinlichkeitstheorie an unser Problem adaptieren, in dem wir die Wahrscheinlichkeiten durch die relativen Häufigkeiten ersetzen.&lt;/p&gt;
&lt;p&gt;Der Wert für das gemeinsame Ereignis &lt;code&gt;iphone.tagsüber.unbeachtet = 1xtäglich&lt;/code&gt; und das &lt;code&gt;wetter.ist.gut=ja&lt;/code&gt; wird im Falle der Unabhägigkeit durch die beiden Randhäufigkeiten bestimmt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 \cdot 90 = 31.7045455\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun mit eine Kreuztabelle erstellen, wie sie seien müsste, falls wir tatsächlich &lt;em&gt;statitische Unabhängigkeit&lt;/em&gt; hätten. Wir nutzen dafür eine sehr allgemein gehaltene, aber selbst programmierte, Funktion &lt;code&gt;expectation.tab()&lt;/code&gt;, der wir eine Tabelle mit den Häufigkeiten der Beobachtungen geben und die uns dann die Tabelle liefert, wie sie aussehen würde, falls tatsächlich &lt;em&gt;statitische Unabhängigkeit&lt;/em&gt; herrschen würde.&lt;/p&gt;
&lt;p&gt;Die Tabelle mit den beobchteten Werten speichern wir in &lt;code&gt;obs.tab&lt;/code&gt;, die der erwarteten Werte in &lt;code&gt;exp.tab&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expectation.tab &amp;lt;- function(tab.obs) {
  ret &amp;lt;- tab.obs
  max.i &amp;lt;- dim(tab.obs)[1]
  max.j &amp;lt;- dim(tab.obs)[2]
  
  # Randhäufigkeiten 
  x &amp;lt;- rep(0, max.i)
  for (i in 0:max.i) x[i] = sum(tab.obs[i,])

  y &amp;lt;- rep(0, max.j)
  for (j in 0:max.j) y[j] = sum(tab.obs[,j])

  # Anzahl aller Beobachtungen
  n = sum(tab.obs)
  
  for (i in 0:max.i) {
    for (j in 0:max.j) {
       ret[i,j] &amp;lt;- (x[i] * y[j] / n)
    }
  }

  ret
}

# Kreuztabelle der beobachtete Werte
obs.tab &amp;lt;- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)

# Kreuztabelle der erwarteten Werte auf Grundlage der beobachteten Werte
exp.tab &amp;lt;- expectation.tab(obs.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Schauen wir uns die beiden Tabellen kurz an. Zuerst die der beobachteten Werte:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs.tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet Ja Nein
##                   1xtäglich 29   33
##                   2xtäglich 34   26
##                   3xtäglich 27   27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dann die der erwarteten Werte:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exp.tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet       Ja     Nein
##                   1xtäglich 31.70455 30.29545
##                   2xtäglich 30.68182 29.31818
##                   3xtäglich 27.61364 26.38636&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;was-können-wir-nun-messen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was können wir nun messen?&lt;/h3&gt;
&lt;p&gt;Unsicherheit und Zufall spielen eine große Rolle. Wir können also nicht erwarten, dass die Werte für die Kreuztabelle in der Realität genau getroffen werden. (Vorallem, weil wir hier ja mit Nachkommastellen arbeiten!) Aber wir können versuchen den Abstand zu diesen Werten zu messen. Je weiter weg die Werte in der Kreuztabelle von den theoretischen Werten liegen, um so unwarscheinlicher ist es, dass die Werte zufällig aus einer unabhängigen Population gezogen wurden. D.h. wir könnten uns für eine Abhägigkeit aussprechen.&lt;/p&gt;
&lt;div id=&#34;messen-mit-dem-absolutabstand&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Messen mit dem Absolutabstand?&lt;/h4&gt;
&lt;p&gt;Man könnte nun auf die Idee kommen die Abstände an jeder Stelle zu messen und den absoluten Abstand zu summieren:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(abs(obs.tab - exp.tab))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13.27273&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nur was sagt dieser Wert aus? – Ist das ein kleiner Abstand oder ein großer?&lt;/p&gt;
&lt;p&gt;Wir brauchen Referenzwerte zur Orientierung. Eine Idee lautet: &lt;strong&gt;Permutationstest&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sind die Werte unabhängig von einander, dann spielt die konkrete Zuordnung keine Rolle, sondern nur die Anzahl der Ereignisse an sich. Ordnen wir nun zufällig einem &lt;code&gt;iphones.tagsüber.unbeachtet&lt;/code&gt;-Wert einen beliebigen &lt;code&gt;wetter.ist.gut&lt;/code&gt;-Wert zu, dann besteht kein Zusammenhang mehr zwischen den Werten. Dies machen wir mittels &lt;code&gt;iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Wir simulieren so den Zustand, dass es keine Abhängigkeit zwischen den Werten gibt.&lt;/p&gt;
&lt;p&gt;Dabei messen wir den Abstand zwischen den Abstand zwischen den beobachteten Werten und den Werten, die wir erwarten würden, falls Unabhägigkeit vorliegen würde. Dafür nutzen wir die selbsterstellte Funktioen &lt;code&gt;diffabsobsexp&lt;/code&gt;, welche die Summe der absoluten Abweichungen berechnet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffabsobsexp}(obs, exp) = \sum\limits_i \left|obs_i - exp_i\right|\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen das ganze mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, die wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der absoluten Differenz zwischen
# beobachteten und erwarteten Werte
diffabsobsexp &amp;lt;- function(obs, exp) {
  sum(abs(obs - exp))
}

# Absolute Abweichung der gemessenen Werte
obs.abs &amp;lt;- diffabsobsexp(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffabsobsexp(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_histogram(~ diffabsobsexp, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert, also die relative Fläche rechts von der roten Linie in unseren Histogramm, abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffabsobsexp &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5714&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Absolute Abweichungen (oder auch &lt;em&gt;absolute Fehler&lt;/em&gt;) haben die Tendenz bei großen Zahlen auch große Abweichungswerte zu liefern und bei kleinen Werten eher kleine Abweichungswerte.
Das kann man als Markel ansehen.
Daher arbeitet man vielleicht lieber mit relativen Abweichungen (oder auch &lt;em&gt;relativen Fehlern&lt;/em&gt;).
Dabei setzt man die absolute Abweichung jedesmal in Bezug auf den erwarteten Wert.
Die dazu passenden Funktion haben wir unten mit &lt;code&gt;diffabsobsexprel&lt;/code&gt; implementiert.
Dabei ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffabsobsexprel}(obs, exp) = \sum\limits_i \frac{\left|obs_i - exp_i\right|}{exp_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen das ganze mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der korrigierten absoluten 
# Differenz zwischen beobachteten und erwarteten Werten
diffabsobsexprel &amp;lt;- function(obs, exp) {
  sum((abs(obs - exp))/exp)
}

# Absolute Abweichung der gemessenen Werte -- korrigiert
obs.abs &amp;lt;- diffabsobsexprel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffabsobsexprel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_dhistogram(~ diffabsobsexprel, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Auch hier können wir den p-Wert abschätzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffabsobsexprel &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Ist der absolute Abstand überhaupt gut gewählt? – Wäre nicht eher der quadratische Abstand angebracht?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ein Vorteil des quadratischen Abstand ist es, dass er kleine Abstände kleiner und große Abstände größer bewertet, als der absolute Abstand. Außerdem hat er mathematisch einige Vorteile. Wir messen nun den quadratischen Abstande mit der Funktion
&lt;code&gt;diffquad&lt;/code&gt;, die wie folgt arbeitet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffquad}(obs, exp) = \sum\limits_i \left(obs_i - exp_i\right)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen dies nun mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquad &amp;lt;- function(obs, exp) {
  sum((obs - exp)^2)
}

# Quadratische Abweichung der gemessenen Werte
obs.abs &amp;lt;- diffquad(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffquad(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_dhistogram(~ diffquad, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffquad &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5389&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie beim absoluten Abstand werden hier die Größe der Werte ausser acht gelassen und vielleicht fühlen wir uns etwas wohler, wenn wir statt des quadratischen Abstands den relativen quadratischen Abstand benutzen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffquadrel}(obs, exp) = \sum\limits_i \frac{\left(obs_i - exp_i\right)^2}{exp_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dies wiederholen wir nun mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der korrigierten quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquadrel &amp;lt;- function(obs, exp) {
  sum(((obs - exp)^2)/exp)
}

# Quadratische Abweichung der gemessenen Werte -- korrigiert
obs.abs &amp;lt;- diffquadrel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffquadrel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_histogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Den Wert 1.2344597, den wir mit Hilfe der relativen quadratischen Abweichung berechnet haben, nennen wir auch &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; Wert.&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffquadrel &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5599&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An Hand der p-Werte können wir nun über die Nullhypothese entscheiden:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;was-sagt-die-klassische-statistik&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was sagt die klassische Statistik?&lt;/h3&gt;
&lt;p&gt;In der klassischen Statistik könnte man hier den &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-Unabhängigkeitstest anwenden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test
## 
## data:  x
## X-squared = 1.2345, df = 2, p-value = 0.5394
## 
##    29       33   
## (31.70)  (30.30) 
## [0.231]  [0.241] 
## &amp;lt;-0.48&amp;gt;  &amp;lt; 0.49&amp;gt; 
##    
##    34       26   
## (30.68)  (29.32) 
## [0.359]  [0.376] 
## &amp;lt; 0.60&amp;gt;  &amp;lt;-0.61&amp;gt; 
##    
##    27       27   
## (27.61)  (26.39) 
## [0.014]  [0.014] 
## &amp;lt;-0.12&amp;gt;  &amp;lt; 0.12&amp;gt; 
##    
## key:
##  observed
##  (expected)
##  [contribution to X-squared]
##  &amp;lt;Pearson residual&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vergleichen wir nun die beiden Ansätze, SBI auf der einen und der klassische Ansatz auf der anderern Seite, einmal in einem Diagramm. Das (Dichte-)Histogramm sind die Daten aus der Nullverteilung für die quadratische, korrigierte Differenz. Die rote Linie ist der gemessene Abweichungswert. Die schwarze Linie ist der Graph der &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-Verteilung mit zwei Freiheitsgraden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dhistogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data = NullVert) %&amp;gt;%
  gf_fun(dchisq(x, df=2) ~ x, xlim = c(0:20), color = &amp;quot;blue&amp;quot;) %&amp;gt;% 
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Aber es gibt auch den (exakten) Fisher-Test:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fisher.test(obs.tab, alternative = &amp;quot;greater&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Fisher&amp;#39;s Exact Test for Count Data
## 
## data:  obs.tab
## p-value = 0.5609
## alternative hypothesis: greater&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fazit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Wir können die p-Werte der einzelnen Tests nun gegenüber stellen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Scale for &amp;#39;y&amp;#39; is already present. Adding another scale for &amp;#39;y&amp;#39;, which will
## replace the existing scale.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gewöhnlich haben wir ein Signifikanznivau von &lt;span class=&#34;math inline&#34;&gt;\(5\% = 0{,}05\)&lt;/span&gt; angenommen.
Die rote Linie zeigt diese Grenze.
Liegt der Balken links vor dieser Linie, so sprechen wir davon, dass der
gemessene Wert selten bei unabhänigen Daten vorliegt und würden uns gegen die
Nullhypothese und damit quasi für die Alternativhypothese entscheiden.
Liegt der Balken recht der roten Linie, so haben wir übliche Werte für
unabhängige Daten und keinen Grund gefunden, der gegen die Nullhypothese
spricht.
Warum wir sie dann, auf Grundlage unserer Daten, auch nicht ablehnen können.&lt;/p&gt;
&lt;p&gt;Bleibt Sie Frage, gibt es Situationen in denen die Entscheidung über die
Nullhypothese bei den einzelen betrachteten Verfahren unterschiedlichen ist?
Und wenn ja, wann und wieoft?&lt;/p&gt;
&lt;p&gt;Diese Fragen sind nicht Thema dieses Beitrags, aber vielleicht habe ich Zeit
und betrachte das später einmal.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Warum das Nachrechnen von Veröffentlichungen so wichtig ist</title>
      <link>https://sefiroth.net/nab/post/warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Im Internet fand ich vor kurzem einen sehr interessanten &lt;a href=&#34;http://www.stefanbartz.de/dateien/Vorsicht-bei-der-sigma-Regel.pdf&#34;&gt;Text&lt;/a&gt; von &lt;a href=&#34;http://www.stefanbartz.de&#34;&gt;Stefan Bart&lt;/a&gt;. Eine Aufgabe daraus fand meine besondere Aufmerksamkeit.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;HSB gesucht (Grundgesamtheit mit &lt;span class=&#34;math inline&#34;&gt;\(H_0 \rightarrow\)&lt;/span&gt; Stichprobe)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Es soll die Nullhypothese, dass die 500 Mädchen und 500 Jungen der Schule gleich intelligent sind, getestet werden.
Dazu werden 200 zufällige Junge-Mädchen-Paare gebildet.
Bei 112 davon hatte der Junge einen höheren IQ. Ist die Abweichung vom Mittelwert signifikant?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Als Lösungen wurden vorgeschlagen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;em&gt;grobe Näherung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[x \in [n \cdot p_0 \pm \sqrt{n}\,] = [200 \cdot 0{,}5 \pm \sqrt{200}\,] \approx [85{,}85786; 114{,}1421] \approx [85; 115]\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;bessere Näherung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}x \in \left[n \cdot p_0 \pm \Phi(0{,}975) \sqrt{n \cdot p_0 (1-p_0)}\,\right] &amp;amp;\approx \left[n \cdot p_0 \pm 1{,}96 \cdot \sqrt{n \cdot p_0 \cdot(1-p_0)} \,\right] \\ &amp;amp;\approx \left[200 \cdot 0{,}5 \pm 1.959964 \cdot \sqrt{200 \cdot 0{,}5 \cdot (1-0{,}5)}\,\right] \\ &amp;amp;\approx \left[86{,}14096; 113{,}859\right] \\&amp;amp;\approx \left[86; 114\right]\end{aligned}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;exakte Lösung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[x \in [89; 111]\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Auf Grundlage dieser drei Lösungen wurde dann entschieden, ob die Abweichung signifikant ist, also 112 im oder eben nicht im berechneten Intervall liegt. &lt;em&gt;Ergebnis:&lt;/em&gt; a), b) liefern nicht signifikante und c) ein signifikantes Ergebnis.&lt;/p&gt;
&lt;p&gt;Die Frage bleibt, was in der Aufgabenstellung mit “200 zufällige Junge-Mädchen-Paaren” gemeint ist.&lt;/p&gt;
&lt;p&gt;Bekannterweise kann man diesen Satz interpretieren:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Eine &lt;em&gt;uneingeschränkte Zufallsstichprobe&lt;/em&gt; erhält man z. B. bei einem &lt;em&gt;Ziehen ohne Zurücklegen&lt;/em&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Hypergeometrische Verteilung).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Eine &lt;em&gt;einfache Zufallsstichprobe&lt;/em&gt; z. B. bei einem &lt;em&gt;Ziehen mit Zurücklegen&lt;/em&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Binomialverteilung).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rechnet man mit Hilfe von &lt;em&gt;R&lt;/em&gt; die exakte Lösung nach, so erhält man:&lt;/p&gt;
&lt;p&gt;Für die Binomialverteilung (die “bessere Näherung”):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl &amp;lt;- 0.025 # 2,5% als untere Grenze
pr &amp;lt;- 0.975 # 97,5% als obere Grenze

iu &amp;lt;- qbinom(pl, 200, prob=0.5)
io &amp;lt;- qbinom(pr, 200, prob=0.5)
c(iu, io) # Ausgabe des (HSB-)Intervalls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  86 114&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Für die Hypergeometischeverteilung (hier “exakte Lösung” genannt) müssen wir die zwei Gruppen (500 Jungen und 500 Mädchen) jeweils als ein mögliches Paar ansehen. Es gibt somit insgesamt 500 solcher Paare, da jeder Junge und jedes Mädchen in nur einem Paar vorkommen können. – Sehr wohl aber 500! solcher Möglichen Paar-Reihen.&lt;/p&gt;
&lt;p&gt;Betrachten wir nun jedes Paar nur einmal, dann ziehen wir aus der Menge der Paare also eine &lt;em&gt;Stichprobe ohne Zurücklegen&lt;/em&gt;, also eine &lt;em&gt;uneingeschränkte Zufallsstichprobe&lt;/em&gt;.
Zum bestimmen der Quantiele und damit des HSB benötigen wir dann die &lt;em&gt;hypergeometrische Verteilung&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Oh ja, diese Annahme ist sehr verwirrend, logisch nicht ganz einzusehen und einfach von Mathematik-Lehrenden gemacht worden, damit man die Hypergeometrischeverteilung hier anwenden kann. Alleine schon die Annahme, dass zwei Personen immer einen unterschiedlichen IQ haben müssen … – Egal!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- 250 # Anzahl der Paare mit besseren Mädchen
n &amp;lt;- 250 # Anzahl der Paare mit besseren Jungen
k &amp;lt;- 200 # Umfang des Stichprobe
pl &amp;lt;- 0.025 # 2,5% als untere Grenze
pr &amp;lt;- 0.975 # 97,5% als obere Grenze

iu &amp;lt;- qhyper(pl, m, n, k) # Linke/untere Intervallgrenze
io &amp;lt;- qhyper(pr, m, n, k) # Rechte/obere Intervallgrenze
c(iu, io) # Ausgabe des (HSB-)Intervalls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  89 111&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; liefert aus &lt;em&gt;exakte Lösung&lt;/em&gt; das Intervall &lt;span class=&#34;math inline&#34;&gt;\([89; 111]\)&lt;/span&gt;. Schauen wir einmal genauer hin:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- 250 # Anzahl der Paare mit besseren Mädchen
n &amp;lt;- 250 # Anzahl der Paare mit besseren Jungen
k &amp;lt;- 200 # Umfang des Stichprobe

p &amp;lt;- dhyper(0:k, m, n, k)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Werte für die linke/untere Intervallgrenzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Werte für die linke/untere Intervallgrenzen:
sum(p[0:89])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01782071&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p[0:90])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02755396&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Werte für die rechte/untere Intervallgrenzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Werte für die rechte/untere Intervallgrenzen:
sum(p[0:111])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.972446&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p[0:112])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9821793&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie wird nun gerundet? – Im Text heißt es:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Werden 2,5% und 97,5% nicht genau getroffen, wird hier nicht […] nach außen / .  , sondern in beiden Fällen nach rechts . gerundet;
d.h. man nimmt diejenigen Werte in das zu bestimmende Intervall auf, bei denen 2,5% bzw. 97,5% zum ersten Mal
übertroffen werden. Somit verbleiben weniger als 2,5% der Histogrammfläche am linken bzw. rechten Rand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;ein-paar-überlegungen-zum-lösen-der-aufgabe-mit-sbi&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein paar Überlegungen zum Lösen der Aufgabe mit SBI&lt;/h3&gt;
&lt;p&gt;Eigentlich haben wir es mit drei Fällen je Paar zu tun:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} &amp;gt; IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} &amp;lt; IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} = IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tatsächlich spielt hier welches Mädchen und welcher Junge im Paar sind eine entscheidende Rolle.&lt;/p&gt;
&lt;p&gt;Simulieren wir nun einmal, dass unsere beiden Gruppe im wesendlichen (und im Mittel) gleich intelligent sind, was wir durch einen gleich mittlenem IQ von 100 und einer Standardabweichung von 15 modellieren wollen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir laden zuerst das Paket `mosaic`
library(mosaic)

# Zur Reproduzierbarkeit
set.seed(2009)

# IQs für Jungen und Mädchen normalverteilt mit den Parametern mu=100 und sigma=15

# 1. Fassung, aber hier ist F_iq_junger = F_iq_maedchen
#iq_jungen &amp;lt;- rnorm(500, mean=100, sd=15)
#iq_maedchen &amp;lt;- rnorm(500, mean=100, sd=15)

# 2. Fassung
#iq &amp;lt;- rnorm(500, mean=100, sd=15)
#iq_jungen &amp;lt;- iq
#iq_maedchen &amp;lt;- iq

# 3. Fassung
iq_jungen &amp;lt;- rnorm(500, mean=100, sd=15)
iq_maedchen &amp;lt;- rnorm(499, mean=100, sd=15)
iq_maedchen &amp;lt;- c(iq_maedchen, mean(iq_jungen)+499*(mean(iq_jungen)-mean(iq_maedchen)))

# Ein Blick auf die beinden Datenreihen
length(iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(iq_jungen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 99.22318&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(iq_jungen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 99.22318&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bilden wir nun die Paare:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paare &amp;lt;- data.frame(jungen = iq_jungen, maedchen = iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und schauen uns nun einmal an, wie oft – bei zufälliger Auswahl von 200 Paarungen – es vorkommen kann, dass Jungen in den Paarungen einen höheren IQ haben als Mädchen. Das wäre dann dem Zufall geschuldet und nicht der übermässigen Intelligenz der Jungen. (Da nach Vereinbarung beide Gruppen gleich intelligent waren!)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NullVerteilung &amp;lt;- do(5000) * count( ~ sample(jungen, 200) - sample(maedchen, 200) &amp;gt; 0, data=paare)
gf_bar( ~ n_TRUE, data=NullVerteilung)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-01-27-warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Das HSB für diesen Fall wäre dann:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(hsb &amp;lt;- quantile( ~ n_TRUE, prob=c(0.025, 0.975), data=NullVerteilung))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  2.5% 97.5% 
##    83   107&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Anders formuliert, der zu erwartende Hauptstreubereich ist das Intervall &lt;span class=&#34;math inline&#34;&gt;\([83, 107]\)&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;Die 112 Paare in denen die Jungen einen höheren IQ haben, sind also nicht zu erwarten. (Also &lt;em&gt;signifikant!&lt;/em&gt;)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Moderator und Mediation - Formen der Interaktion bei Analyse von Zusammenhängen</title>
      <link>https://sefiroth.net/nab/post/moderator-und-mediation-formen-der-interaktion-bei-analyse-von-zusammenhaengen/</link>
      <pubDate>Tue, 31 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/moderator-und-mediation-formen-der-interaktion-bei-analyse-von-zusammenhaengen/</guid>
      <description>
&lt;script src=&#34;2019-12-31-moderator-und-mediation-formen-der-interaktion-bei-analyse-von-zusammenhängen_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Bei der Analyse von Zusammenhängen tauchen sowohl &lt;em&gt;Moderation&lt;/em&gt; als auch &lt;em&gt;Mediation&lt;/em&gt; auf. Es geht um Zusammenhänge zwischen drei Variablen &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt;.
Untersucht wird der Effekt einer unabhägigen Variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (&lt;em&gt;Prädiktor&lt;/em&gt;, &lt;em&gt;UV&lt;/em&gt;) auf ein abhängige Variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (&lt;em&gt;AV&lt;/em&gt;).
Wir untersuchen dies mit einem Regressionsmodell &lt;span class=&#34;math inline&#34;&gt;\(Y \sim X\)&lt;/span&gt;.
Dabei wird zusätzlich eine dritte Variable &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; berücksichtigt, die man entweder der &lt;em&gt;Moderator&lt;/em&gt; oder &lt;em&gt;Mediator&lt;/em&gt; nennt.&lt;/p&gt;
&lt;p&gt;Ist die abhängige Variable metrisch, so können wir mittels eine linearer Regression vorgehen, ist die AB dagegen dichotom, so nutzen wir eine logistische Regression.&lt;/p&gt;
&lt;div id=&#34;moderation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Moderation&lt;/h2&gt;
&lt;p&gt;Bei einer &lt;em&gt;Moderation&lt;/em&gt; wirkt die dritte Variable &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; (&lt;em&gt;Moderator&lt;/em&gt;) auf die Beziehung zwischen &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-31-moderator-und-mediation-formen-der-interaktion-bei-analyse-von-zusammenha%CC%88ngen_files/figure-html/Moderation-1.png&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Der Einfluss von &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; ändert also den Effekt von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; auf &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Der Zusammenhang zwischen &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; ist also je nach &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; unterschiedlich.&lt;/p&gt;
&lt;p&gt;Statistisch gesehen liegt eine &lt;em&gt;Interaktion&lt;/em&gt; zwischen &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; vor.&lt;/p&gt;
&lt;div id=&#34;wie-untersucht-man-einen-zusammenhang-auf-eine-moderation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wie untersucht man einen Zusammenhang auf eine Moderation?&lt;/h3&gt;
&lt;p&gt;Dazu stellen wir ein Regressionsmodell mit den drei Faktoren &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; und der Interaktion zwischen &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; auf.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(Y ~ X * M, data=daten)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Oder alternativ:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm(Y ~ X + M + M:X, data=daten)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Diese drei Faktoren wirken auf &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. Ist in diesem Modell die Interaktion &lt;span class=&#34;math inline&#34;&gt;\(M:X\)&lt;/span&gt; &lt;em&gt;signifikant&lt;/em&gt;, so liegt eine (signifikante) &lt;em&gt;Moderation&lt;/em&gt; vor.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mediation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mediation&lt;/h2&gt;
&lt;p&gt;Bei der &lt;em&gt;Mediation&lt;/em&gt; steht die Variable &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; (der &lt;em&gt;Mediator&lt;/em&gt;) sowohl zu &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; als auch zu &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; in Beziehung.
Der direkte Effekt zwischen &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; wird durch den indirekten Effekt über &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; erklärt, also durch
&lt;span class=&#34;math inline&#34;&gt;\(X \to M \to Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-31-moderator-und-mediation-formen-der-interaktion-bei-analyse-von-zusammenha%CC%88ngen_files/figure-html/Mediator-1.png&#34; width=&#34;30%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;wie-untersucht-man-auf-eine-mediation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wie untersucht man auf eine Mediation?&lt;/h3&gt;
&lt;p&gt;In diesem Fall stellen wir mehrere Regressionsmodelle auf. Eine (signifikante) Mediation liegt dann vor, wenn die folgenden Bedinungen erfüllt sind:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erstesModell &amp;lt;- lm(Y ~ X, data=daten)
zweitesModell &amp;lt;- lm(M ~ X, data=daten)
drittesModell &amp;lt;- lm(Y ~ X + M, data=daten)&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Im ersten Modell (&lt;span class=&#34;math inline&#34;&gt;\(X \to Y\)&lt;/span&gt;) ist der Regressionskoeffizient von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; signifikant.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Im zweiten Modell (&lt;span class=&#34;math inline&#34;&gt;\(X \to M\)&lt;/span&gt;) ist der Regressionskoeffizient von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; signifikant.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Im dritten Modell (&lt;span class=&#34;math inline&#34;&gt;\(X,M \to Y\)&lt;/span&gt;) ist der Regressionskoeffizient von &lt;span class=&#34;math inline&#34;&gt;\(M\)&lt;/span&gt; signifikant und&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;der Regressionskoeffizient von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; im dritten Modell kleiner als im ersten Modell.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Die ersten Schritte zur Prognose mitteles linearer Regression</title>
      <link>https://sefiroth.net/nab/post/die-ersten-schritte-zur-prognose-mitteles-linearer-regression/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/die-ersten-schritte-zur-prognose-mitteles-linearer-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Prognosen sind ein wichtiger Bestandteil von Data Science und ist durchaus nicht nur auf moderne Ansätze, wie Neuronale Netze, deep lerning etc. begrenzt. Auch die gute, alte Regression kann ein sehr sinnvolles Mittel sein solche Prognosen zu erstellen.&lt;/p&gt;
&lt;p&gt;Um ein wenig die Ideen hinter Prognosen zu beleuchten wollen wir uns an Prognosen mit dem &lt;strong&gt;tipping&lt;/strong&gt;-Daten heranwagen.&lt;/p&gt;
&lt;div id=&#34;einlesen-der-tipping-daten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Einlesen der tipping-Daten&lt;/h2&gt;
&lt;p&gt;Zuerst laden wir die notwenidgen Pakete:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Falls die &lt;strong&gt;tipping&lt;/strong&gt;-Daten noch nicht im Verzeichnis liegen, laden wir sie aus dem Internet nach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!file.exists(&amp;quot;tips.csv&amp;quot;)) {
  download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun laden wir die &lt;strong&gt;tipping&lt;/strong&gt;-Daten in den Speicher in den Datenrahmen &lt;code&gt;tips&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir werfen einen ersten Blick auf die &lt;strong&gt;tipping&lt;/strong&gt;-Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspect(tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## categorical variables:  
##     name     class levels   n missing
## 1    sex character      2 244       0
## 2 smoker character      2 244       0
## 3    day character      4 244       0
## 4   time character      2 244       0
##                                    distribution
## 1 Male (64.3%), Female (35.7%)                 
## 2 No (61.9%), Yes (38.1%)                      
## 3 Sat (35.7%), Sun (31.1%), Thur (25.4%) ...   
## 4 Dinner (72.1%), Lunch (27.9%)                
## 
## quantitative variables:  
##            name   class  min      Q1 median      Q3   max      mean        sd
## ...1 total_bill numeric 3.07 13.3475 17.795 24.1275 50.81 19.785943 8.9024120
## ...2        tip numeric 1.00  2.0000  2.900  3.5625 10.00  2.998279 1.3836382
## ...3       size integer 1.00  2.0000  2.000  3.0000  6.00  2.569672 0.9510998
##        n missing
## ...1 244       0
## ...2 244       0
## ...3 244       0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;vorbereiten-der-test-trainings--und-auswertungesdaten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vorbereiten der Test-/Trainings- und Auswertungesdaten&lt;/h2&gt;
&lt;p&gt;Zunächst schränken wir die &lt;strong&gt;tipping&lt;/strong&gt;-Daten auf die Variabeln “total_bill”, “sex”, “smoker”, “day”, “time”, “size” ein und speichern das Ergebnis wieder in &lt;code&gt;tips&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips %&amp;gt;%
    select(c(&amp;quot;total_bill&amp;quot;, &amp;quot;sex&amp;quot;, &amp;quot;smoker&amp;quot;, &amp;quot;day&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;size&amp;quot;)) -&amp;gt; tips&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ziel ist es, den Rechnungsbetrag (“total_bill”) auf Grundlage der Variabeln “sex”, “smoker”, “day”, “time” und/oder “size” vorherzusagen.&lt;/p&gt;
&lt;p&gt;Wir teilen den tipping-Datensatz auf in eine Trainingsdatensatz (“tipstrain”), einem Testdatensatz (“tipstest”) und einem Prüfdatensatz (“tipspruef”).
Der Trainingsdatensatz sollte rund zweidrittel der Daten die wir haben umfassen.
Der Testdatensatz die restlich ca. eindrittel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trainings_anteil = 2/3

# n.train ist ein Index für alle Werte, 
# die wir im Trainingsdatensatz haben wollen:
x.train &amp;lt;- sample(1:nrow(tips), floor(trainings_anteil*nrow(tips)))

# Trainingsdatensatz erstellen:
tipstrain &amp;lt;- slice(tips, x.train)

# Prüfdatensatz erstellen, also alles was 
# nicht in den Trainingsdatensatz gekommen ist:
tipspruef &amp;lt;- slice(tips, -(x.train))

# Der Testdatensatz ist der Prüfdatensatz 
# ohne die Variable total_bill:
tipspruef %&amp;gt;% 
    select(-total_bill) -&amp;gt; tipstest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit dem Tainingsdatensatz versuchen wir nun ein Prognosemodell zu erstellen, um aus den Testdatensatz eine Prognose für “total_bill” zu erstellen.&lt;/p&gt;
&lt;p&gt;Das Prognose-Modell wird ausschließlich auf Grundlage des Trainingsdatensatzes erstellt. Am Ende wollen wir unser Modell dann aber mit Hilfe des Prüfdatensatzes bewertet.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-datenlage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Die Datenlage&lt;/h2&gt;
&lt;p&gt;Ein (paar) Blick(e) auf unsere Trainingsdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(total_bill ~ jitter(size), color=~time, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-18-die-ersten-schritte-zur-prognose-mitteles-linearer-regression_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(total_bill ~ day | time, color = ~ sex, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-18-die-ersten-schritte-zur-prognose-mitteles-linearer-regression_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prognosemodel-nullmodell&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prognosemodel: Nullmodell&lt;/h2&gt;
&lt;div id=&#34;aufstellen-des-nullmodel-aka-regression-mit-der-achse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aufstellen des Nullmodel aka Regression mit der Achse&lt;/h3&gt;
&lt;p&gt;Wir erstellen das Nullmodell wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.null &amp;lt;- lm( total_bill ~ 1, data=tipstrain)
summary(lm.null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = total_bill ~ 1, data = tipstrain)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.159  -6.989  -2.429   4.171  30.401 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  20.4086     0.7311   27.91   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 9.306 on 161 degrees of freedom&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das Nullmodell sagt in jedem Fall den Rechnungsbetrag vorher als den Mittelwert der Trainingsdaten!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(~ total_bill, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20.40864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun bestimmten wir mit Hilfe des Nullmodells “lm.null” eine Vorhersage für die Testdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict.null &amp;lt;- predict(lm.null, newdata=tipstest)
head(predict.null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5        6 
## 20.40864 20.40864 20.40864 20.40864 20.40864 20.40864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie gesagt, das Nullmodell liefert als Prognose immer den Mittelwert der Trainingsdaten zurück,
das mathematische Nullmodell lautet also:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{total\_bill_i} = 20.408642  \]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;auswertung-des-nullmodells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Auswertung des Nullmodells&lt;/h3&gt;
&lt;p&gt;Zur Auswertung Nutzen wir den &lt;em&gt;mittleren Absolutabstand&lt;/em&gt; zwischen der Vorhersage und den Prüfdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maa.null &amp;lt;-sum( abs( tipspruef$total_bill - predict.null))
maa.null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 544.772&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prognosemodell-lineare-regression-gegen-size-als-metrischer-wert&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prognosemodell: Lineare Regression gegen “size” als metrischer Wert&lt;/h2&gt;
&lt;div id=&#34;aufstellen-des-modells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aufstellen des Modells&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;auswertung-des-regressionsmodell&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Auswertung des Regressionsmodell&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>SBI - Simulation Based Inference</title>
      <link>https://sefiroth.net/nab/post/sbi-simulation-based-inference/</link>
      <pubDate>Mon, 11 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/sbi-simulation-based-inference/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Wenn meine Tochter &lt;em&gt;SBI&lt;/em&gt; hört, denkt sie an &lt;em&gt;Sally Bollywood Investigation&lt;/em&gt;. – Und ich oft auch. – Mit &lt;em&gt;SBI&lt;/em&gt; ist hier aber nicht der Trickfilm für Kinder, sondern &lt;em&gt;&lt;strong&gt;S&lt;/strong&gt;imulation &lt;strong&gt;B&lt;/strong&gt;ased &lt;strong&gt;I&lt;/strong&gt;nference&lt;/em&gt;, gemeint.&lt;/p&gt;
&lt;p&gt;Angestachelt von Prof. Dr. Karsten Lübke und im Schlepptau von Prof. Dr. Oliver Gansser, Prof. Dr. Matthias Gehrke und Prof. Dr. Bianca Krol haben ein paar kluge Köpfe bei der &lt;a href=&#34;http://www.fom.de&#34;&gt;FOM&lt;/a&gt; den Unterricht für Statistik auf eine neue Grundlage gestellt.
Und ich habe das Glück gehabt,dabei mitwirken zu dürfen.&lt;/p&gt;
&lt;p&gt;Unser Mastermind, Karsten Lübke, hat dazu einen sehr schönen und lesenswerten Blog-Eintrag geschrieben: &lt;a href=&#34;https://www.causeweb.org/sbi/?p=1559&#34; class=&#34;uri&#34;&gt;https://www.causeweb.org/sbi/?p=1559&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ein wenig schneller zur simulierten Nullverteilung</title>
      <link>https://sefiroth.net/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/d3/d3.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/profvis.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/profvis.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/scroll.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/highlight/textmate.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/highlight/highlight.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis-binding/profvis.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Ein Nullhypothesentest ist schnell geschrieben.
Will man den approximativen Weg gehen, so hilft &lt;strong&gt;R&lt;/strong&gt; einem mit entsprechenden Tests mit einfachen Befehlen.
Nimmt man &lt;strong&gt;MOSAIC&lt;/strong&gt; dazu, so bekommt man u.a. für den Test auf Anteils- oder Mittelwerte sogar einen sehr einfachen, weil einheitlichen, Syntax.&lt;/p&gt;
&lt;div id=&#34;zwei-beispiele-für-approximative-hypothesentests-mit-mosaic&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zwei Beispiele für approximative Hypothesentests mit MOSAIC&lt;/h3&gt;
&lt;p&gt;Laden wir unsere Testdaten, die &lt;strong&gt;tipping&lt;/strong&gt; Daten wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)
set.seed(2009)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dann erstellen wir zwei Forschungsfragen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Ist der mittlere Frauenanteil unter der Bezahler*innen zu den Zeitpunkten Lunch und Dinner gleich?&lt;/li&gt;
&lt;li&gt;Ist der mittlere Rechnungsbetrag zu den Zeitpunkten Lunch und Dinner gleich?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Im ersten Fall ist die Hypothese schnell geschrieben:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0 : \pi_{\text{Lunch}} = \pi_{\text{Dinner}} \quad\text{vs.}\quad H_1 : \pi_{\text{Lunch}} \neq \pi_{\text{Dinner}}
\]&lt;/span&gt;
Der approximative Test mit R und MOSAIC lautet nun:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.test(sex ~ time, success = &amp;quot;Female&amp;quot;, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  tally(sex ~ time)
## X-squared = 9.3438, df = 1, p-value = 0.002237
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.36602563 -0.07247705
## sample estimates:
##    prop 1    prop 2 
## 0.2954545 0.5147059&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ähnlich sieht es für den zweiten Fall aus. Die Hypothese lautet hier:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0 : \mu_{Lunch} = \mu_{Dinner} \quad\text{vs.}\quad H_1 : \mu_{Lunch} \neq \mu_{Dinner}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der dazugehörige Test lautet dann:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(total_bill ~ time, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  total_bill by time
## t = 3.123, df = 143.29, p-value = 0.002167
## alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0
## 95 percent confidence interval:
##  1.331877 5.925088
## sample estimates:
## mean in group Dinner  mean in group Lunch 
##             20.79716             17.16868&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-der-nullverteilung-mit-mosaic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulation der Nullverteilung mit MOSAIC&lt;/h2&gt;
&lt;p&gt;Ein anderer Weg ist es die Stichprobe selber zu nutzen um daraus eine Verteilung der Nullhypothese (die Nullverteilung) ableiten zu können.
Im ersten Fall schaut man sich die Anteilsunterschiede an, wenn man die (potentielle) Abhängigkeit von der Tageszeit (Lunch und Dinner) künstlich “abschaltet”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2009)
NullVtlgAntwert &amp;lt;- do(10000) * diffprop(sex ~ shuffle(time),
    success = &amp;quot;Female&amp;quot;, data = tips)
gf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Schaut man sich nun die Lage der Anteilsdifferenz der Stichprobe &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.2192513\)&lt;/span&gt; in Bezug auf diese Nullverteilung geometrisch an, so kann man schon einen ersten Eindruck erlangen, ob die Nullhypothese abzulehnen ist oder nicht:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diffpropdach &amp;lt;- diffprop(sex ~ time, success = &amp;quot;Female&amp;quot;, data = tips)
gf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert) +
    geom_vline(xintercept = diffpropdach, color = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Offenbar ist &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi\)&lt;/span&gt; kein sehr häufiges Ereignis.&lt;/p&gt;
&lt;p&gt;Der &lt;em&gt;p-Wert&lt;/em&gt; ist ebenfalls leicht zu ermitteln:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pvalue_aw &amp;lt;- prop(~abs(diffprop) &amp;gt;= abs(diffpropdach), data = NullVtlgAntwert)
pvalue_aw&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.0018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit einem Anteilswert (p-Wert) von 0.0018 zweigen wir wie selten das Ereignis unter der &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; ist.&lt;/p&gt;
&lt;p&gt;Ähnlich sieht die Situation im zweien Fall aus. Mit Hilfe weniger Befehle erzeugen wir die Nullverteilung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2009)
NullVtlgMittelwert &amp;lt;- do(10000) * diffmean(total_bill ~ shuffle(time),
    data = tips)
gf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Und können im Anschluss die Mittelwertsdifferenz der Stichprobe geometrisch einordnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diffmeandach &amp;lt;- diffmean(total_bill ~ time, data = tips)
gf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert) +
    geom_vline(xintercept = diffmeandach, color = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Auch den &lt;em&gt;p-Wert&lt;/em&gt; können wir wieder leicht bestimmen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pvalue_mw &amp;lt;- prop(~abs(diffmean) &amp;gt;= abs(diffmeandach), data = NullVtlgMittelwert)
pvalue_mw&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.0047&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;das-problem-zeit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Das Problem – Zeit&lt;/h2&gt;
&lt;p&gt;Das Problem bei der Simulation ist die Zeit, die &lt;strong&gt;R&lt;/strong&gt; braucht um die Nullverteilungen zu generieren.
Das liegt im wesentlichen an Mosaic.
Mit den Routinen aus &lt;a href=&#34;https://github.com/NMarkgraf/FastSimNullDistR&#34;&gt;FastSimNullDistR&lt;/a&gt; lassen sich die Nullverteilungen deutlich schneller berechnen.
Ein Vergleich:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,20,20,20,20,20,20,21,21,22,22,22,22,22,22,22,22,23,23,24,24,24,24,24,24,24,24,24,24,24,25,25,26,26,26,26,26,26,26,27,27,27,27,27,27,27,28,28,28,28,28,29,29,29,29,30,30,30,30,30,30,30,30,30,30,31,31,31,31,32,32,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,35,35,35,35,35,36,36,36,36,36,37,37,37,37,37,38,38,38,38,38,38,39,39,39,39,39,39,39,40,40,40,40,40,40,40,41,41,41,41,41,42,42,42,42,42,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,49,49,49,49,49,50,50,50,50,50,50,51,51,51,51,51,52,52,52,52,52,52,53,53,53,53,53,54,54,54,54,54,55,55,55,55,55,56,56,56,56,56,57,57,57,57,57,58,58,58,58,58,59,59,59,59,59,59,59,60,60,60,60,60,60,61,61,61,61,61,61,61,62,62,62,62,62,62,62,63,63,64,64,64,64,64,64,64,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,66,67,67,67,67,67,67,68,68,68,68,68,69,69,69,69,69,70,70,70,70,70,70,71,71,72,72,72,72,73,73,73,73,73,73,73,74,74,74,74,74,74,74,74,75,75,75,75,76,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,81,81,81,81,82,82,82,82,82,83,83,83,83,83,83,83,83,83,83,84,84,84,84,85,85,85,85,85,85,85,85,86,86,86,86,86,86,86,86,87,87,87,87,87,87,87,87,88,88,88,88,88,88,88,88,89,89,89,89,89,89,89,89,89,90,90,90,90,90,90,90,90,90,91,91,91,91,91,91,91,92,92,92,92,92,92,92,93,93,93,93,93,93,93,94,94,94,94,94,94,94,95,95,95,95,95,95,95,96,96,97,97,97,97,97,97,97,97,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,100,100,100,100,100,100,101,101,101,101,102,102,102,102,102,102,102,102,102,102,103,103,103,103,103,103,103,103,103,104,104,104,104,104,104,104,104,104,104,104,105,105,105,105,105,106,106,106,106,106,106,106,107,107,108,108,108,108,108,108,108,108,108,108,108,109,109,109,109,109,109,110,110,110,110,110,111,111,111,111,111,111,111,112,112,113,113,113,113,113,113,114,114,114,114,114,114,114,115,115,115,115,115,116,116,116,117,117,117,117,117,117,117,117,118,118,118,118,118,118,118,119,119,119,119,119,119,119,119,120,120,120,120,120,120,121,121,121,121,121,121,121,121,121,121,122,122,122,122,122,122,122,122,122,122,122,122,122,122,123,123,123,123,123,124,124,124,124,124,124,124,124,124,124,124,125,125,125,125,125,125,126,126,126,126,126,127,127,127,127,127,127,127,127,128,128,128,128,128,128,128,128,128,128,128,128,129,129,129,129,129,129,129,129,129,130,130,130,130,130,130,130,130,130,130,130,131,131,132,132,132,132,132,133,133,133,133,134,134,135,135,135,135,135,135,135,135,135,135,135,135,135,136,136,136,136,136,136,136,136,136,137,137,137,137,137,137,137,137,138,138,138,138,138,139,139,139,139,139,139,139,139,139,139,140,140,140,140,140,140,140,140,140,140,140,141,141,141,141,141,141,142,142,142,142,142,142,142,142,143,143,143,143,143,143,143,144,144,144,144,144,144,145,145,145,145,145,145,145,145,146,146,146,146,146,146,146,147,147,147,147,147,147,147,147,147,148,148,148,149,149,149,149,149,149,149,150,150,150,150,150,150,150,150,150,151,151,151,151,151,151,151,151,151,151,151,152,152,152,152,152,152,152,153,153,153,153,153,153,153,154,154,155,155,155,155,155,156,156,156,156,156,156,156,156,157,157,157,157,157,157,157,157,157,157,157,157,157,158,158,158,158,158,158,158,158,158,158,159,159,159,159,159,159,159,160,160,160,161,161,161,161,161,161,161,162,162,162,162,162,162,162,163,163,163,163,163,163,163,164,164,164,164,164,164,164,164,165,165,165,165,165,165,165,165,166,166,166,166,166,166,166,166,166,167,167,167,167,167,167,167,168,168,168,168,168,168,169,169,169,169,169,170,170,170,170,170,170,170,170,171,171,171,171,171,171,171,171,172,172,172,172,172,173,173,173,173,173,173,173,174,174,174,174,174,174,175,175,175,175,175,175,176,176,176,176,176,176,177,177,177,177,177,177,177,177,177,177,177,178,178,178,178,179,179,179,179,179,179,179,179,180,180,180,180,180,180,180,180,180,180,180,181,181,182,182,182,182,182,182,183,183,183,183,183,183,183,183,184,184,184,184,184,184,185,185,185,185,185,186,186,186,186,186,186,186,186,186,186,187,187,187,187,187,187,187,187,188,188,188,188,188,188,189,189,189,189,189,190,190,190,190,190,190,190,190,190,191,191,191,191,191,191,192,192,192,192,192,192,192,193,193,193,193,193,193,193,193,194,194,194,194,194,194,195,195,195,195,195,195,195,195,195,195,195,195,195,196,196,196,196,196,196,196,196,197,197,197,197,197,197,197,197,197,197,197,197,198,198,198,198,198,198,199,199,199,199,199,200,200,200,200,200,200,200,201,201,201,201,201,201,201,202,202,202,202,202,203,203,203,203,203,203,203,203,204,204,204,204,204,204,205,205,205,205,205,205,205,206,206,206,206,206,206,207,207,207,207,207,207,207,207,208,208,208,208,208,208,208,209,209,209,209,209,209,209,210,210,210,210,210,211,211,211,211,211,211,211,212,212,212,212,212,212,213,213,213,213,213,213,213,213,214,214,214,214,214,215,215,215,215,215,215,215,215,215,215,215,215,215,216,216,216,216,217,217,217,217,217,217,217,217,217,218,218,218,218,218,218,218,218,218,218,219,219,219,219,219,219,219,220,220,220,220,220,221,221,222,222,222,222,222,222,222,223,223,223,223,223,223,223,223,223,223,224,224,224,224,224,224,225,225,225,225,225,225,225,226,226,226,226,226,227,227,227,227,227,227,227,228,228,228,228,228,229,229,229,229,229,229,229,230,230,230,230,230,230,231,231,231,231,231,231,231,231,231,231,231,232,232,232,232,232,232,232,232,232,232,232,233,233,234,234,234,234,234,234,234,234,234,235,235,235,235,235,235,235,235,235,235,235,236,236,236,236,236,236,236,237,237,237,237,237,237,237,237,237,238,238,238,238,239,239,239,239,239,239,239,240,240,240,240,240,240,241,241,241,241,241,242,242,242,243,243,243,243,243,243,243,243,243,243,244,244,245,245,245,245,245,245,245,245,246,246,246,246,246,246,246,246,247,247,247,247,247,247,247,247,248,248,248,248,248,248,248,248,249,249,249,249,249,249,249,249,249,249,250,250,251,251,251,251,251,252,252,252,252,252,252,252,252,252,252,253,253,254,254,254,254,254,254,254,254,254,254,255,255,255,255,255,255,255,255,255,255,256,256,256,256,256,257,257,257,257,257,257,258,258,258,258,259,259,259,259,259,259,259,259,260,260,260,260,260,261,261,261,261,261,261,261,261,261,262,262,263,263,264,264,264,264,264,264,264,264,264,265,265,265,265,266,266,266,266,266,266,266,266,267,267,267,267,267,267,267,268,268,268,268,268,269,269,269,269,269,269,269,269,269,269,270,270,270,270,270,270,271,271,271,271,271,271,271,271,272,272,272,272,272,272,272,272,272,272,273,273,273,273,273,273,274,274,274,274,274,274,274,274,275,275,275,275,275,275,276,276,276,276,276,276,276,276,276,277,277,277,277,277,277,277,278,278,278,278,278,278,278,278,278,278,279,279,279,279,279,279,279,280,280,280,280,280,280,281,281,281,281,281,281,281,282,282,282,282,282,282,282,283,283,283,283,283,284,284,284,284,284,285,285,286,286,286,286,286,287,287,287,287,287,287,287,287,287,288,288,288,288,288,288,288,288,288,288,289,289,289,289,289,289,290,290,290,290,290,290,291,291,291,291,291,291,291,291,292,292,292,292,292,292,292,292,292,293,293,293,293,293,293,293,293,294,294,294,294,294,294,295,295,295,295,295,296,296,296,296,296,296,296,297,297,297,297,298,298,298,298,298,298,299,299,299,299,299,299,299,299,300,300,300,300,300,300,301,301,301,301,301,301,301,302,302,302,302,302,302,302,302,303,303,303,303,303,303,303,304,304,304,304,304,304,304,304,304,304,304,304,305,305,305,305,305,305,305,305,305,305,305,305,306,306,306,306,306,306,306,306,306,307,307,307,307,307,307,308,308,308,308,308,308,308,308,309,309,309,309,309,310,310,310,310,310,310,310,311,311,311,311,311,311,311,311,311,311,311,311,311,311,312,312,312,312,312,312,312,312,313,313,313,313,313,313,313,313,313,314,314,314,314,314,315,315,315,315,315,315,315,315,315,315,315,316,316,316,316,316,316,316,317,317,317,317,317,317,317,318,318,319,319,319,319,319,319,319,319,319,319,320,320,320,320,320,320,320,321,321,321,321,321,321,321,322,322,322,322,322,322,322,322,323,323,324,324,324,324,324,324,324,324,324,324,325,325,325,325,325,325,325,325,326,326,326,326,326,326,326,327,327,327,327,327,327,327,327,327,328,328,328,328,328,328,328,328,329,329,329,329,329,329,329,329,330,330,330,330,330,330,330,330,330,330,330,330,330,331,331,331,331,331,331,331,332,332,332,332,332,332,332,333,333,333,333,333,333,333,333,334,334,334,334,334,334,335,335,335,335,335,335,335,335,335,335,335,336,336,336,336,336,336,336,336,337,337,337,337,337,337,337,338,338,338,338,338,338,338,339,339,339,339,339,339,339,339,340,340,340,341,341,341,341,341,341,341,341,341,341,341,341,342,342,342,342,342,342,342,342,342,342,343,343,343,344,344,344,344,344,344,344,344,345,345,345,345,345,345,345,345,345,345,345,346,346,346,346,346,346,346,346,347,347,348,348,349,349,349,349,349,349,349,350,350,350,350,350,351,351,351,351,351,351,351,352,352,352,352,352,352,352,353,353,353,353,353,354,354,354,354,354,354,354,355,355,356,356,356,356,356,356,356,356,356,356,357,357,357,357,357,357,357,357,358,358,358,358,358,358,358,358,358,358,358,359,359,359,359,360,360,360,360,360,360,360,361,361,361,361,361,361,361,362,362,362,363,363,363,363,364,364,364,364,364,364,364,365,365,365,365,365,365,365,365,366,366,366,366,366,366,366,366,366,366,367,367,367,367,367,367,367,367,367,368,368,368,368,368,369,369,369,369,369,369,369,370,370,370,370,370,370,370,370,370,371,371,371,371,371,371,371,371,371,371,372,372,372,373,373,373,373,373,373,373,373,374,374,374,374,374,374,374,374,375,375,375,375,376,376,376,376,377,377,377,377,377,377,377,377,377,377,378,378,378,378,378,378,378,379,379,379,379,379,379,379,379,380,380,381,381,381,381,381,381,382,382,382,382,382,382,382,382,383,383,383,383,383,383,383,383,383,383,384,384,384,384,384,384,384,385,385,385,385,385,385,385,385,385,386,386,386,386,386,386,386,386,386,387,387,387,387,387,387,387,388,388,388,388,388,389,389,389,389,389,389,390,390,390,390,390,390,390,390,391,391,391,391,391,391,391,392,392,392,392,392,392,392,392,392,393,393,393,393,393,393,393,393,393,393,393,394,394,394,394,394,394,394,394,394,395,395,395,395,395,395,395,395,395,396,396,396,396,396,396,396,396,397,397,397,397,397,397,398,398,398,398,398,398,398,399,399,400,400,400,400,400,400,400,400,400,400,400,401,401,401,401,402,402,402,402,402,402,402,403,403,403,403,403,403,403,403,403,404,404,404,404,404,404,404,405,405,405,405,405,405,405,406,406,406,406,406,406,406,406,406,406,407,407,407,407,407,407,407,407,407,408,408,408,408,408,408,408,408,409,409,409,409,409,409,409,410,410,410,410,410,410,411,411,411,411,411,411,411,411,411,411,412,412,413,413,413,413,413,414,414,414,414,414,414,414,414,414,414,414,414,415,415,415,415,415,415,415,415,416,416,416,416,416,416,416,416,416,416,416,416,417,417,417,417,417,417,417,417,417,417,418,418,418,418,418,418,418,418,418,418,419,419,419,419,419,419,420,420,420,421,421,421,421,421,421,421,422,422,423,423,423,423,423,423,423,423,424,424,424,424,424,425,425,425,426,426,426,426,426,427,427,427,427,427,427,427,428,428,428,428,428,428,428,428,429,429,429,429,429,429,429,430,430,430,430,430,430,430,430,430,431,431,431,431,431,431,431,431,431,431,431,431,432,432,432,432,432,432,433,433,433,433,433,433,434,434,434,434,434,434,434,434,434,434,434,434,434,434,435,435,435,435,435,435,436,436,436,436,436,437,437,437,437,437,437,437,438,438,438,438,438,439,439,439,439,439,439,439,440,440,440,440,440,441,441,441,441,441,441,442,442,442,442,442,442,442,442,443,443,443,443,443,444,444,444,444,444,444,445,445,445,445,445,446,446,446,446,446,446,446,447,447,447,447,447,448,448,448,448,448,449,449,449,449,449,449,449,450,450,450,450,450,450,450,451,451,451,451,451,452,452,452,452,452,452,452,453,453,453,453,453,454,454,454,454,454,454,455,455,455,455,455,456,456,456,456,456,456,456,457,457,457,457,457,458,458,458,458,458,458,458,459,459,459,459,459,460,460,460,460,460,460,461,461,462,462,462,462,462,462,462,463,463,463,463,463,463,464,464,464,464,464,464,464,465,465,465,465,465,465,465,465,466,466,467,467,467,467,467,467,467,468,468,468,468,468,468,469,469,469,469,469,469,469,469,470,470,470,470,470,470,470,470,471,471,471,471,471,471,471,472,472,472,472,472,472,472,472,473,473,473,473,473,473,473,473,473,473,473,474,474,475,475,475,475,475,475,475,475,475,475,475,475,475,476,476,476,476,476,476,476,476,477,477,477,477,477,477,477,477,478,478,478,478,479,479,479,479,479,479,479,479,479,479,479,479,479,479,480,480,480,481,481,482,482,482,482,482,483,483,483,483,483,483,483,483,484,484,484,484,485,485,485,485,485,485,485,485,486,486,486,486,486,486,486,486,486,486,486,487,487,487,487,487,487,487,487,487,487,488,488,488,488,488,488,488,489,489,489,489,489,489,489,490,490,490,490,491,491,491,491,491,492,492,493,493,494,494,494,494,494,495,495,495,495,495,495,496,496,496,496,496,497,497,497,497,497,497,497,497,497,498,498,498,498,498,498,498,498,498,499,499,499,499,499,499,499,499,499,500,500,500,500,500,500,500,501,501,501,501,501,501,501,502,502,503,503,503,503,503,503,503,504,504,504,504,504,505,505,505,505,505,506,506,506,506,506,507,507,508,508,508,508,508,509,509,509,509,509,509,510,510,510,510,510,511,511,511,511,511,511,511,512,512,512,512,512,512,512,512,512,512,512,512,513,513,513,513,513,513,513,513,514,514,514,514,514,514,514,514,515,515,515,515,515,515,516,516,516,516,516,516,516,517,517,517,517,517,517,517,517,518,518,518,518,518,518,518,518,518,518,518,519,519,519,519,519,519,519,520,520,520,520,520,520,520,520,520,521,521,521,521,521,521,521,521,522,522,522,522,522,522,522,522,523,523,523,523,523,523,523,523,523,523,523,524,524,524,524,524,524,524,524,524,525,525,525,525,525,525,525,525,525,525,525,525,526,526,527,527,527,527,527,527,527,527,527,527,527,528,528,529,529,529,529,529,529,529,529,529,529,530,530,530,530,530,530,530,530,530,530,530,531,531,531,531,531,531,531,531,531,531,531,531,532,532,532,532,532,532,532,532,533,533,533,533,533,533,534,534,534,535,535,535,535,535,535,536,536,536,536,536,536,536,536,537,537,537,537,537,537,537,537,537,537,537,538,538,538,538,538,538,538,538,539,539,539,539,539,539,540,540,541,541,541,541,541,541,541,541,541,541,541,541,542,542,542,542,542,542,542,543,543,543,543,543,543,543,543,544,544,544,544,544,544,544,545,545,545,545,545,545,545,545,545,545,545,546,546,546,546,547,547,548,548,548,548,548,548,549,549,549,549,549,549,549,549,549,550,550,550,550,550,550,550,550,550,550,551,551,551,551,551,552,552,552,552,552,552,552,553,553,553,553,553,553,553,553,553,553,553,554,554,554,554,554,554,554,555,555,555,555,555,555,555,555,556,556,556,556,556,556,556,556,557,557,557,557,557,557,557,557,557],&#34;depth&#34;:[11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,2,1,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,3,2,1,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;%in%&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.ordered&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaicCore::tally&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;-&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;[&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.data.frame&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;integer&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;integer&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;array&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;...names&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;logical2factor&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;array&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;attributes&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;integer&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;startsWith&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.subset&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;ncol&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.subset&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;any&#34;,&#34;local&#34;,&#34;rlang::eval_tidy&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.set_row_names&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;tail.default&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;local&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaicCore::tally&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;baseenv&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.expression&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;array&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;memalloc&#34;:[27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,27.8221054077148,28.6686172485352,28.6686172485352,28.6686172485352,28.6686172485352,28.6686172485352,28.6686172485352,28.6686172485352,29.5432891845703,29.5432891845703,29.5432891845703,29.5432891845703,29.5432891845703,29.5432891845703,30.145263671875,30.145263671875,30.145263671875,30.145263671875,30.145263671875,30.145263671875,30.145263671875,30.145263671875,30.7506103515625,30.7506103515625,31.4330596923828,31.4330596923828,31.4330596923828,31.4330596923828,31.4330596923828,31.4330596923828,32.2837066650391,32.2837066650391,32.2837066650391,32.2837066650391,32.2837066650391,32.2837066650391,32.2837066650391,32.2837066650391,33.0696716308594,33.0696716308594,33.0696716308594,34.0327453613281,34.0327453613281,34.0327453613281,34.0327453613281,34.0327453613281,34.0327453613281,34.0327453613281,34.0327453613281,34.6774826049805,34.6774826049805,34.6774826049805,34.6774826049805,34.6774826049805,34.6774826049805,34.6774826049805,35.5967407226562,35.5967407226562,35.5967407226562,35.5967407226562,35.5967407226562,35.5967407226562,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,36.5851974487305,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,37.2441635131836,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,27.3899383544922,28.0021362304688,28.0021362304688,28.0021362304688,28.0021362304688,28.0021362304688,28.0021362304688,28.0021362304688,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,28.6135711669922,29.3626937866211,29.3626937866211,29.3626937866211,29.3626937866211,29.3626937866211,29.3626937866211,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,30.5718078613281,31.3144836425781,31.3144836425781,31.3144836425781,31.3144836425781,31.3144836425781,31.3144836425781,31.3144836425781,32.1635284423828,32.1635284423828,32.1635284423828,32.1635284423828,32.1635284423828,32.1635284423828,32.8150253295898,32.8150253295898,33.5162658691406,33.5162658691406,33.5162658691406,33.5162658691406,33.5162658691406,33.5162658691406,33.5162658691406,33.5162658691406,34.1125106811523,34.1125106811523,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,34.7281036376953,35.3380432128906,35.3380432128906,36.5432815551758,36.5432815551758,36.5432815551758,36.5432815551758,36.5432815551758,36.5432815551758,36.5432815551758,37.1547012329102,37.1547012329102,37.1547012329102,37.1547012329102,37.1547012329102,37.1547012329102,37.1547012329102,37.7540435791016,37.7540435791016,37.7540435791016,37.7540435791016,37.7540435791016,28.1328506469727,28.1328506469727,28.1328506469727,28.1328506469727,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.3544921875,29.9658737182617,29.9658737182617,29.9658737182617,29.9658737182617,31.1837997436523,31.1837997436523,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,31.7952423095703,32.4113693237305,32.4113693237305,32.4113693237305,32.4113693237305,32.4113693237305,33.0249786376953,33.0249786376953,33.0249786376953,33.0249786376953,33.0249786376953,33.6376495361328,33.6376495361328,33.6376495361328,33.6376495361328,33.6376495361328,34.2527084350586,34.2527084350586,34.2527084350586,34.2527084350586,34.2527084350586,34.8358993530273,34.8358993530273,34.8358993530273,34.8358993530273,34.8358993530273,34.8358993530273,35.4452285766602,35.4452285766602,35.4452285766602,35.4452285766602,35.4452285766602,35.4452285766602,35.4452285766602,36.0578994750977,36.0578994750977,36.0578994750977,36.0578994750977,36.0578994750977,36.0578994750977,36.0578994750977,36.6572418212891,36.6572418212891,36.6572418212891,36.6572418212891,36.6572418212891,37.2699127197266,37.2699127197266,37.2699127197266,37.2699127197266,37.2699127197266,34.0221557617188,34.0221557617188,34.0221557617188,34.0221557617188,34.0221557617188,34.0221557617188,34.0221557617188,34.0221557617188,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,27.7760543823242,28.9928359985352,28.9928359985352,28.9928359985352,28.9928359985352,28.9928359985352,28.9928359985352,28.9928359985352,30.1882705688477,30.1882705688477,30.1882705688477,30.1882705688477,30.1882705688477,30.1882705688477,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.3964767456055,31.9960861206055,31.9960861206055,31.9960861206055,31.9960861206055,31.9960861206055,31.9960861206055,32.582893371582,32.582893371582,32.582893371582,32.582893371582,32.582893371582,33.1776657104492,33.1776657104492,33.1776657104492,33.1776657104492,33.1776657104492,33.1776657104492,33.7644729614258,33.7644729614258,33.7644729614258,33.7644729614258,33.7644729614258,34.3510208129883,34.3510208129883,34.3510208129883,34.3510208129883,34.3510208129883,34.3510208129883,34.9469909667969,34.9469909667969,34.9469909667969,34.9469909667969,34.9469909667969,35.5596618652344,35.5596618652344,35.5596618652344,35.5596618652344,35.5596618652344,36.1747207641602,36.1747207641602,36.1747207641602,36.1747207641602,36.1747207641602,36.784065246582,36.784065246582,36.784065246582,36.784065246582,36.784065246582,37.3976745605469,37.3976745605469,37.3976745605469,37.3976745605469,37.3976745605469,27.6980590820312,27.6980590820312,27.6980590820312,27.6980590820312,27.6980590820312,28.9145050048828,28.9145050048828,28.9145050048828,28.9145050048828,28.9145050048828,28.9145050048828,28.9145050048828,30.1397171020508,30.1397171020508,30.1397171020508,30.1397171020508,30.1397171020508,30.1397171020508,30.7574081420898,30.7574081420898,30.7574081420898,30.7574081420898,30.7574081420898,30.7574081420898,30.7574081420898,31.3626327514648,31.3626327514648,31.3626327514648,31.3626327514648,31.3626327514648,31.3626327514648,31.3626327514648,32.5715026855469,32.5715026855469,33.7273483276367,33.7273483276367,33.7273483276367,33.7273483276367,33.7273483276367,33.7273483276367,33.7273483276367,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,34.3260879516602,35.5218048095703,35.5218048095703,35.5218048095703,35.5218048095703,35.5218048095703,35.5218048095703,35.5218048095703,35.5218048095703,36.7311096191406,36.7311096191406,36.7311096191406,36.7311096191406,36.7311096191406,36.7311096191406,37.6035537719727,37.6035537719727,37.6035537719727,37.6035537719727,37.6035537719727,27.6857604980469,27.6857604980469,27.6857604980469,27.6857604980469,27.6857604980469,28.8973617553711,28.8973617553711,28.8973617553711,28.8973617553711,28.8973617553711,28.8973617553711,29.5075302124023,29.5075302124023,30.11572265625,30.11572265625,30.11572265625,30.11572265625,30.7018280029297,30.7018280029297,30.7018280029297,30.7018280029297,30.7018280029297,30.7018280029297,30.7018280029297,31.8726577758789,31.8726577758789,31.8726577758789,31.8726577758789,31.8726577758789,31.8726577758789,31.8726577758789,31.8726577758789,32.4794921875,32.4794921875,32.4794921875,32.4794921875,33.6776428222656,33.6776428222656,33.6776428222656,33.6776428222656,33.6776428222656,33.6776428222656,33.6776428222656,33.6776428222656,34.886833190918,34.886833190918,34.886833190918,34.886833190918,34.886833190918,34.886833190918,34.886833190918,34.886833190918,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,35.4786834716797,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,36.6845703125,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.2812118530273,37.856575012207,37.856575012207,37.856575012207,37.856575012207,27.3849105834961,27.3849105834961,27.3849105834961,27.3849105834961,27.3849105834961,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,28.3165740966797,29.5265045166016,29.5265045166016,29.5265045166016,29.5265045166016,30.1280212402344,30.1280212402344,30.1280212402344,30.1280212402344,30.1280212402344,30.1280212402344,30.1280212402344,30.1280212402344,31.3274230957031,31.3274230957031,31.3274230957031,31.3274230957031,31.3274230957031,31.3274230957031,31.3274230957031,31.3274230957031,32.4210739135742,32.4210739135742,32.4210739135742,32.4210739135742,32.4210739135742,32.4210739135742,32.4210739135742,32.4210739135742,32.984245300293,32.984245300293,32.984245300293,32.984245300293,32.984245300293,32.984245300293,32.984245300293,32.984245300293,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.1386260986328,34.69677734375,34.69677734375,34.69677734375,34.69677734375,34.69677734375,34.69677734375,34.69677734375,34.69677734375,34.69677734375,35.2470703125,35.2470703125,35.2470703125,35.2470703125,35.2470703125,35.2470703125,35.2470703125,35.7917251586914,35.7917251586914,35.7917251586914,35.7917251586914,35.7917251586914,35.7917251586914,35.7917251586914,36.3308944702148,36.3308944702148,36.3308944702148,36.3308944702148,36.3308944702148,36.3308944702148,36.3308944702148,36.9300231933594,36.9300231933594,36.9300231933594,36.9300231933594,36.9300231933594,36.9300231933594,36.9300231933594,37.7163009643555,37.7163009643555,37.7163009643555,37.7163009643555,37.7163009643555,37.7163009643555,37.7163009643555,27.5240173339844,27.5240173339844,28.3984222412109,28.3984222412109,28.3984222412109,28.3984222412109,28.3984222412109,28.3984222412109,28.3984222412109,28.3984222412109,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.0670700073242,29.800422668457,29.800422668457,29.800422668457,29.800422668457,29.800422668457,29.800422668457,29.800422668457,30.5370407104492,30.5370407104492,30.5370407104492,30.5370407104492,30.5370407104492,30.5370407104492,31.1500091552734,31.1500091552734,31.1500091552734,31.1500091552734,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,31.8102493286133,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.3916091918945,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,32.9926605224609,33.646369934082,33.646369934082,33.646369934082,33.646369934082,33.646369934082,34.3644180297852,34.3644180297852,34.3644180297852,34.3644180297852,34.3644180297852,34.3644180297852,34.3644180297852,35.0078964233398,35.0078964233398,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,35.6737976074219,36.2521591186523,36.2521591186523,36.2521591186523,36.2521591186523,36.2521591186523,36.2521591186523,36.8481292724609,36.8481292724609,36.8481292724609,36.8481292724609,36.8481292724609,37.4303665161133,37.4303665161133,37.4303665161133,37.4303665161133,37.4303665161133,37.4303665161133,37.4303665161133,27.4395141601562,27.4395141601562,28.6400756835938,28.6400756835938,28.6400756835938,28.6400756835938,28.6400756835938,28.6400756835938,29.2467269897461,29.2467269897461,29.2467269897461,29.2467269897461,29.2467269897461,29.2467269897461,29.2467269897461,29.8480606079102,29.8480606079102,29.8480606079102,29.8480606079102,29.8480606079102,31.0664978027344,31.0664978027344,31.0664978027344,32.1607666015625,32.1607666015625,32.1607666015625,32.1607666015625,32.1607666015625,32.1607666015625,32.1607666015625,32.1607666015625,32.8634033203125,32.8634033203125,32.8634033203125,32.8634033203125,32.8634033203125,32.8634033203125,32.8634033203125,33.4479598999023,33.4479598999023,33.4479598999023,33.4479598999023,33.4479598999023,33.4479598999023,33.4479598999023,33.4479598999023,34.6304092407227,34.6304092407227,34.6304092407227,34.6304092407227,34.6304092407227,34.6304092407227,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,35.4581298828125,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.4091644287109,36.9952926635742,36.9952926635742,36.9952926635742,36.9952926635742,36.9952926635742,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,37.5931015014648,28.0136566162109,28.0136566162109,28.0136566162109,28.0136566162109,28.0136566162109,28.0136566162109,28.6191177368164,28.6191177368164,28.6191177368164,28.6191177368164,28.6191177368164,29.8536224365234,29.8536224365234,29.8536224365234,29.8536224365234,29.8536224365234,29.8536224365234,29.8536224365234,29.8536224365234,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.0906753540039,31.706657409668,31.706657409668,31.706657409668,31.706657409668,31.706657409668,31.706657409668,31.706657409668,31.706657409668,31.706657409668,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,32.9286956787109,34.1427459716797,34.1427459716797,34.98291015625,34.98291015625,34.98291015625,34.98291015625,34.98291015625,35.9771728515625,35.9771728515625,35.9771728515625,35.9771728515625,37.1744995117188,37.1744995117188,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,37.775390625,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,28.2217483520508,29.4665832519531,29.4665832519531,29.4665832519531,29.4665832519531,29.4665832519531,29.4665832519531,29.4665832519531,29.4665832519531,30.0994491577148,30.0994491577148,30.0994491577148,30.0994491577148,30.0994491577148,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,31.3302459716797,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,32.5558776855469,33.7775497436523,33.7775497436523,33.7775497436523,33.7775497436523,33.7775497436523,33.7775497436523,34.9762725830078,34.9762725830078,34.9762725830078,34.9762725830078,34.9762725830078,34.9762725830078,34.9762725830078,34.9762725830078,36.1851501464844,36.1851501464844,36.1851501464844,36.1851501464844,36.1851501464844,36.1851501464844,36.1851501464844,36.775146484375,36.775146484375,36.775146484375,36.775146484375,36.775146484375,36.775146484375,37.3706512451172,37.3706512451172,37.3706512451172,37.3706512451172,37.3706512451172,37.3706512451172,37.3706512451172,37.3706512451172,27.8019027709961,27.8019027709961,27.8019027709961,27.8019027709961,27.8019027709961,27.8019027709961,27.8019027709961,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,29.0260314941406,30.2018356323242,30.2018356323242,30.2018356323242,31.2147598266602,31.2147598266602,31.2147598266602,31.2147598266602,31.2147598266602,31.2147598266602,31.2147598266602,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,31.8387069702148,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,32.535400390625,33.4114151000977,33.4114151000977,33.4114151000977,33.4114151000977,33.4114151000977,33.4114151000977,33.4114151000977,34.1459045410156,34.1459045410156,34.1459045410156,34.1459045410156,34.1459045410156,34.1459045410156,34.1459045410156,34.8438720703125,34.8438720703125,35.4464492797852,35.4464492797852,35.4464492797852,35.4464492797852,35.4464492797852,36.1724014282227,36.1724014282227,36.1724014282227,36.1724014282227,36.1724014282227,36.1724014282227,36.1724014282227,36.1724014282227,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,36.7801361083984,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,37.7330932617188,27.5267181396484,27.5267181396484,27.5267181396484,27.5267181396484,27.5267181396484,27.5267181396484,27.5267181396484,28.7389602661133,28.7389602661133,28.7389602661133,29.4513092041016,29.4513092041016,29.4513092041016,29.4513092041016,29.4513092041016,29.4513092041016,29.4513092041016,30.263916015625,30.263916015625,30.263916015625,30.263916015625,30.263916015625,30.263916015625,30.263916015625,30.9706649780273,30.9706649780273,30.9706649780273,30.9706649780273,30.9706649780273,30.9706649780273,30.9706649780273,31.9323883056641,31.9323883056641,31.9323883056641,31.9323883056641,31.9323883056641,31.9323883056641,31.9323883056641,31.9323883056641,32.5188140869141,32.5188140869141,32.5188140869141,32.5188140869141,32.5188140869141,32.5188140869141,32.5188140869141,32.5188140869141,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.1684799194336,33.8136672973633,33.8136672973633,33.8136672973633,33.8136672973633,33.8136672973633,33.8136672973633,33.8136672973633,34.4987258911133,34.4987258911133,34.4987258911133,34.4987258911133,34.4987258911133,34.4987258911133,35.0864715576172,35.0864715576172,35.0864715576172,35.0864715576172,35.0864715576172,35.8678131103516,35.8678131103516,35.8678131103516,35.8678131103516,35.8678131103516,35.8678131103516,35.8678131103516,35.8678131103516,36.7909469604492,36.7909469604492,36.7909469604492,36.7909469604492,36.7909469604492,36.7909469604492,36.7909469604492,36.7909469604492,37.834228515625,37.834228515625,37.834228515625,37.834228515625,37.834228515625,27.7175750732422,27.7175750732422,27.7175750732422,27.7175750732422,27.7175750732422,27.7175750732422,27.7175750732422,28.3111877441406,28.3111877441406,28.3111877441406,28.3111877441406,28.3111877441406,28.3111877441406,28.9238586425781,28.9238586425781,28.9238586425781,28.9238586425781,28.9238586425781,28.9238586425781,29.9672775268555,29.9672775268555,29.9672775268555,29.9672775268555,29.9672775268555,29.9672775268555,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.0021438598633,31.9596939086914,31.9596939086914,31.9596939086914,31.9596939086914,32.9258575439453,32.9258575439453,32.9258575439453,32.9258575439453,32.9258575439453,32.9258575439453,32.9258575439453,32.9258575439453,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,33.9877319335938,34.8486175537109,34.8486175537109,35.5111389160156,35.5111389160156,35.5111389160156,35.5111389160156,35.5111389160156,35.5111389160156,36.4870834350586,36.4870834350586,36.4870834350586,36.4870834350586,36.4870834350586,36.4870834350586,36.4870834350586,36.4870834350586,37.0831451416016,37.0831451416016,37.0831451416016,37.0831451416016,37.0831451416016,37.0831451416016,37.6586685180664,37.6586685180664,37.6586685180664,37.6586685180664,37.6586685180664,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,27.5088958740234,28.1030731201172,28.1030731201172,28.1030731201172,28.1030731201172,28.1030731201172,28.1030731201172,28.1030731201172,28.1030731201172,28.702766418457,28.702766418457,28.702766418457,28.702766418457,28.702766418457,28.702766418457,29.466667175293,29.466667175293,29.466667175293,29.466667175293,29.466667175293,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,30.2513961791992,31.0206069946289,31.0206069946289,31.0206069946289,31.0206069946289,31.0206069946289,31.0206069946289,32.0471572875977,32.0471572875977,32.0471572875977,32.0471572875977,32.0471572875977,32.0471572875977,32.0471572875977,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,33.4721755981445,33.4721755981445,33.4721755981445,33.4721755981445,33.4721755981445,33.4721755981445,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,34.1865921020508,35.1380920410156,35.1380920410156,35.1380920410156,35.1380920410156,35.1380920410156,35.1380920410156,35.1380920410156,35.1380920410156,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,35.8400039672852,36.6986923217773,36.6986923217773,36.6986923217773,36.6986923217773,36.6986923217773,36.6986923217773,37.2888107299805,37.2888107299805,37.2888107299805,37.2888107299805,37.2888107299805,27.2727127075195,27.2727127075195,27.2727127075195,27.2727127075195,27.2727127075195,27.2727127075195,27.2727127075195,28.0525512695312,28.0525512695312,28.0525512695312,28.0525512695312,28.0525512695312,28.0525512695312,28.0525512695312,29.0518112182617,29.0518112182617,29.0518112182617,29.0518112182617,29.0518112182617,29.9844665527344,29.9844665527344,29.9844665527344,29.9844665527344,29.9844665527344,29.9844665527344,29.9844665527344,29.9844665527344,30.5834197998047,30.5834197998047,30.5834197998047,30.5834197998047,30.5834197998047,30.5834197998047,31.1759185791016,31.1759185791016,31.1759185791016,31.1759185791016,31.1759185791016,31.1759185791016,31.1759185791016,32.0982971191406,32.0982971191406,32.0982971191406,32.0982971191406,32.0982971191406,32.0982971191406,32.7003784179688,32.7003784179688,32.7003784179688,32.7003784179688,32.7003784179688,32.7003784179688,32.7003784179688,32.7003784179688,33.8861236572266,33.8861236572266,33.8861236572266,33.8861236572266,33.8861236572266,33.8861236572266,33.8861236572266,34.4849472045898,34.4849472045898,34.4849472045898,34.4849472045898,34.4849472045898,34.4849472045898,34.4849472045898,35.0564956665039,35.0564956665039,35.0564956665039,35.0564956665039,35.0564956665039,35.6387329101562,35.6387329101562,35.6387329101562,35.6387329101562,35.6387329101562,35.6387329101562,35.6387329101562,36.21923828125,36.21923828125,36.21923828125,36.21923828125,36.21923828125,36.21923828125,36.8033752441406,36.8033752441406,36.8033752441406,36.8033752441406,36.8033752441406,36.8033752441406,36.8033752441406,36.8033752441406,37.3740234375,37.3740234375,37.3740234375,37.3740234375,37.3740234375,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,27.4453125,28.1746826171875,28.1746826171875,28.1746826171875,28.1746826171875,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,29.4155120849609,30.0370025634766,30.0370025634766,30.0370025634766,30.0370025634766,30.0370025634766,30.0370025634766,30.0370025634766,30.9509201049805,30.9509201049805,30.9509201049805,30.9509201049805,30.9509201049805,31.7255783081055,31.7255783081055,32.5313949584961,32.5313949584961,32.5313949584961,32.5313949584961,32.5313949584961,32.5313949584961,32.5313949584961,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,33.4753189086914,34.071418762207,34.071418762207,34.071418762207,34.071418762207,34.071418762207,34.071418762207,34.6744766235352,34.6744766235352,34.6744766235352,34.6744766235352,34.6744766235352,34.6744766235352,34.6744766235352,35.2738189697266,35.2738189697266,35.2738189697266,35.2738189697266,35.2738189697266,35.8560562133789,35.8560562133789,35.8560562133789,35.8560562133789,35.8560562133789,35.8560562133789,35.8560562133789,36.4553985595703,36.4553985595703,36.4553985595703,36.4553985595703,36.4553985595703,37.0385665893555,37.0385665893555,37.0385665893555,37.0385665893555,37.0385665893555,37.0385665893555,37.0385665893555,37.7037124633789,37.7037124633789,37.7037124633789,37.7037124633789,37.7037124633789,37.7037124633789,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,27.5820465087891,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,28.1832427978516,29.0147705078125,29.0147705078125,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,29.5971603393555,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.2839508056641,30.8937072753906,30.8937072753906,30.8937072753906,30.8937072753906,30.8937072753906,30.8937072753906,30.8937072753906,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,31.4933624267578,32.0815582275391,32.0815582275391,32.0815582275391,32.0815582275391,32.8208923339844,32.8208923339844,32.8208923339844,32.8208923339844,32.8208923339844,32.8208923339844,32.8208923339844,33.8486557006836,33.8486557006836,33.8486557006836,33.8486557006836,33.8486557006836,33.8486557006836,34.4325866699219,34.4325866699219,34.4325866699219,34.4325866699219,34.4325866699219,35.1010513305664,35.1010513305664,35.1010513305664,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,35.9749298095703,36.6840438842773,36.6840438842773,37.3404769897461,37.3404769897461,37.3404769897461,37.3404769897461,37.3404769897461,37.3404769897461,37.3404769897461,37.3404769897461,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,27.9384384155273,27.9384384155273,27.9384384155273,27.9384384155273,27.9384384155273,27.9384384155273,27.9384384155273,27.9384384155273,28.5419387817383,28.5419387817383,28.5419387817383,28.5419387817383,28.5419387817383,28.5419387817383,28.5419387817383,28.5419387817383,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,29.5894775390625,30.3306884765625,30.3306884765625,30.9197845458984,30.9197845458984,30.9197845458984,30.9197845458984,30.9197845458984,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,31.5180130004883,32.1250228881836,32.1250228881836,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,32.883544921875,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,33.4854431152344,34.1144256591797,34.1144256591797,34.1144256591797,34.1144256591797,34.1144256591797,34.8370819091797,34.8370819091797,34.8370819091797,34.8370819091797,34.8370819091797,34.8370819091797,35.4498291015625,35.4498291015625,35.4498291015625,35.4498291015625,36.3012466430664,36.3012466430664,36.3012466430664,36.3012466430664,36.3012466430664,36.3012466430664,36.3012466430664,36.3012466430664,37.2444305419922,37.2444305419922,37.2444305419922,37.2444305419922,37.2444305419922,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,37.8649063110352,28.0431747436523,28.0431747436523,28.8006057739258,28.8006057739258,29.93017578125,29.93017578125,29.93017578125,29.93017578125,29.93017578125,29.93017578125,29.93017578125,29.93017578125,29.93017578125,30.6499252319336,30.6499252319336,30.6499252319336,30.6499252319336,31.8517379760742,31.8517379760742,31.8517379760742,31.8517379760742,31.8517379760742,31.8517379760742,31.8517379760742,31.8517379760742,32.9879379272461,32.9879379272461,32.9879379272461,32.9879379272461,32.9879379272461,32.9879379272461,32.9879379272461,33.5817031860352,33.5817031860352,33.5817031860352,33.5817031860352,33.5817031860352,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.1682510375977,34.7662811279297,34.7662811279297,34.7662811279297,34.7662811279297,34.7662811279297,34.7662811279297,35.7326812744141,35.7326812744141,35.7326812744141,35.7326812744141,35.7326812744141,35.7326812744141,35.7326812744141,35.7326812744141,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,36.5294876098633,37.1041564941406,37.1041564941406,37.1041564941406,37.1041564941406,37.1041564941406,37.1041564941406,37.8336181640625,37.8336181640625,37.8336181640625,37.8336181640625,37.8336181640625,37.8336181640625,37.8336181640625,37.8336181640625,27.6924285888672,27.6924285888672,27.6924285888672,27.6924285888672,27.6924285888672,27.6924285888672,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,28.2866821289062,29.3185043334961,29.3185043334961,29.3185043334961,29.3185043334961,29.3185043334961,29.3185043334961,29.3185043334961,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.0967407226562,30.750846862793,30.750846862793,30.750846862793,30.750846862793,30.750846862793,30.750846862793,30.750846862793,31.4496078491211,31.4496078491211,31.4496078491211,31.4496078491211,31.4496078491211,31.4496078491211,32.0375518798828,32.0375518798828,32.0375518798828,32.0375518798828,32.0375518798828,32.0375518798828,32.0375518798828,32.8510131835938,32.8510131835938,32.8510131835938,32.8510131835938,32.8510131835938,32.8510131835938,32.8510131835938,33.4716644287109,33.4716644287109,33.4716644287109,33.4716644287109,33.4716644287109,34.0740585327148,34.0740585327148,34.0740585327148,34.0740585327148,34.0740585327148,34.781867980957,34.781867980957,35.614143371582,35.614143371582,35.614143371582,35.614143371582,35.614143371582,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,36.6295776367188,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.3170623779297,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,27.9955444335938,27.9955444335938,27.9955444335938,27.9955444335938,27.9955444335938,27.9955444335938,28.5887603759766,28.5887603759766,28.5887603759766,28.5887603759766,28.5887603759766,28.5887603759766,28.5887603759766,28.5887603759766,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.1890335083008,29.8642654418945,29.8642654418945,29.8642654418945,29.8642654418945,29.8642654418945,29.8642654418945,29.8642654418945,29.8642654418945,30.5157012939453,30.5157012939453,30.5157012939453,30.5157012939453,30.5157012939453,30.5157012939453,31.1114273071289,31.1114273071289,31.1114273071289,31.1114273071289,31.1114273071289,32.1349029541016,32.1349029541016,32.1349029541016,32.1349029541016,32.1349029541016,32.1349029541016,32.1349029541016,33.0513000488281,33.0513000488281,33.0513000488281,33.0513000488281,33.8309478759766,33.8309478759766,33.8309478759766,33.8309478759766,33.8309478759766,33.8309478759766,34.5861587524414,34.5861587524414,34.5861587524414,34.5861587524414,34.5861587524414,34.5861587524414,34.5861587524414,34.5861587524414,35.564826965332,35.564826965332,35.564826965332,35.564826965332,35.564826965332,35.564826965332,36.5599060058594,36.5599060058594,36.5599060058594,36.5599060058594,36.5599060058594,36.5599060058594,36.5599060058594,37.1817932128906,37.1817932128906,37.1817932128906,37.1817932128906,37.1817932128906,37.1817932128906,37.1817932128906,37.1817932128906,37.7547988891602,37.7547988891602,37.7547988891602,37.7547988891602,37.7547988891602,37.7547988891602,37.7547988891602,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,27.6626739501953,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,28.8344116210938,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,29.5104904174805,30.1612777709961,30.1612777709961,30.1612777709961,30.1612777709961,30.1612777709961,30.1612777709961,30.7615432739258,30.7615432739258,30.7615432739258,30.7615432739258,30.7615432739258,30.7615432739258,30.7615432739258,30.7615432739258,31.6955184936523,31.6955184936523,31.6955184936523,31.6955184936523,31.6955184936523,32.6882858276367,32.6882858276367,32.6882858276367,32.6882858276367,32.6882858276367,32.6882858276367,32.6882858276367,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,33.2972793579102,34.478141784668,34.478141784668,34.478141784668,34.478141784668,34.478141784668,34.478141784668,34.478141784668,34.478141784668,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,35.6633529663086,36.2355194091797,36.2355194091797,36.2355194091797,36.2355194091797,36.2355194091797,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.4123077392578,37.8777465820312,37.8777465820312,37.8777465820312,37.8777465820312,37.8777465820312,37.8777465820312,37.8777465820312,27.8624496459961,27.8624496459961,27.8624496459961,27.8624496459961,27.8624496459961,27.8624496459961,27.8624496459961,29.0540542602539,29.0540542602539,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.2243881225586,30.8092803955078,30.8092803955078,30.8092803955078,30.8092803955078,30.8092803955078,30.8092803955078,30.8092803955078,32.0162811279297,32.0162811279297,32.0162811279297,32.0162811279297,32.0162811279297,32.0162811279297,32.0162811279297,32.5888671875,32.5888671875,32.5888671875,32.5888671875,32.5888671875,32.5888671875,32.5888671875,32.5888671875,33.1722564697266,33.1722564697266,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.0770492553711,34.6595840454102,34.6595840454102,34.6595840454102,34.6595840454102,34.6595840454102,34.6595840454102,34.6595840454102,34.6595840454102,35.4025573730469,35.4025573730469,35.4025573730469,35.4025573730469,35.4025573730469,35.4025573730469,35.4025573730469,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.0458068847656,36.8717727661133,36.8717727661133,36.8717727661133,36.8717727661133,36.8717727661133,36.8717727661133,36.8717727661133,36.8717727661133,37.4463119506836,37.4463119506836,37.4463119506836,37.4463119506836,37.4463119506836,37.4463119506836,37.4463119506836,37.4463119506836,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,35.2912826538086,28.3450088500977,28.3450088500977,28.3450088500977,28.3450088500977,28.3450088500977,28.3450088500977,28.3450088500977,29.3992385864258,29.3992385864258,29.3992385864258,29.3992385864258,29.3992385864258,29.3992385864258,29.3992385864258,30.3568878173828,30.3568878173828,30.3568878173828,30.3568878173828,30.3568878173828,30.3568878173828,30.3568878173828,30.3568878173828,30.9535369873047,30.9535369873047,30.9535369873047,30.9535369873047,30.9535369873047,30.9535369873047,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.1404571533203,32.79443359375,32.79443359375,32.79443359375,32.79443359375,32.79443359375,32.79443359375,32.79443359375,32.79443359375,33.8875198364258,33.8875198364258,33.8875198364258,33.8875198364258,33.8875198364258,33.8875198364258,33.8875198364258,34.828987121582,34.828987121582,34.828987121582,34.828987121582,34.828987121582,34.828987121582,34.828987121582,35.4802322387695,35.4802322387695,35.4802322387695,35.4802322387695,35.4802322387695,35.4802322387695,35.4802322387695,35.4802322387695,36.1181106567383,36.1181106567383,36.1181106567383,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,36.745246887207,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,37.65576171875,27.8872680664062,27.8872680664062,27.8872680664062,28.856086730957,28.856086730957,28.856086730957,28.856086730957,28.856086730957,28.856086730957,28.856086730957,28.856086730957,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,29.832893371582,30.501594543457,30.501594543457,30.501594543457,30.501594543457,30.501594543457,30.501594543457,30.501594543457,30.501594543457,31.1024932861328,31.1024932861328,31.7524642944336,31.7524642944336,32.6621398925781,32.6621398925781,32.6621398925781,32.6621398925781,32.6621398925781,32.6621398925781,32.6621398925781,33.269889831543,33.269889831543,33.269889831543,33.269889831543,33.269889831543,33.8874664306641,33.8874664306641,33.8874664306641,33.8874664306641,33.8874664306641,33.8874664306641,33.8874664306641,34.5275497436523,34.5275497436523,34.5275497436523,34.5275497436523,34.5275497436523,34.5275497436523,34.5275497436523,35.1105880737305,35.1105880737305,35.1105880737305,35.1105880737305,35.1105880737305,36.0154647827148,36.0154647827148,36.0154647827148,36.0154647827148,36.0154647827148,36.0154647827148,36.0154647827148,36.6007385253906,36.6007385253906,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.1850280761719,37.7413482666016,37.7413482666016,37.7413482666016,37.7413482666016,37.7413482666016,37.7413482666016,37.7413482666016,37.7413482666016,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,27.599983215332,28.1975860595703,28.1975860595703,28.1975860595703,28.1975860595703,28.8737564086914,28.8737564086914,28.8737564086914,28.8737564086914,28.8737564086914,28.8737564086914,28.8737564086914,29.7180252075195,29.7180252075195,29.7180252075195,29.7180252075195,29.7180252075195,29.7180252075195,29.7180252075195,30.3416137695312,30.3416137695312,30.3416137695312,31.1296691894531,31.1296691894531,31.1296691894531,31.1296691894531,31.7169342041016,31.7169342041016,31.7169342041016,31.7169342041016,31.7169342041016,31.7169342041016,31.7169342041016,32.6852798461914,32.6852798461914,32.6852798461914,32.6852798461914,32.6852798461914,32.6852798461914,32.6852798461914,32.6852798461914,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,33.5398635864258,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.1695327758789,34.9805755615234,34.9805755615234,34.9805755615234,34.9805755615234,34.9805755615234,35.6008682250977,35.6008682250977,35.6008682250977,35.6008682250977,35.6008682250977,35.6008682250977,35.6008682250977,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,36.5724258422852,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.2296676635742,37.8892440795898,37.8892440795898,37.8892440795898,27.7970123291016,27.7970123291016,27.7970123291016,27.7970123291016,27.7970123291016,27.7970123291016,27.7970123291016,27.7970123291016,28.5876922607422,28.5876922607422,28.5876922607422,28.5876922607422,28.5876922607422,28.5876922607422,28.5876922607422,28.5876922607422,29.2871551513672,29.2871551513672,29.2871551513672,29.2871551513672,30.1157836914062,30.1157836914062,30.1157836914062,30.1157836914062,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.0413436889648,31.6250228881836,31.6250228881836,31.6250228881836,31.6250228881836,31.6250228881836,31.6250228881836,31.6250228881836,32.525016784668,32.525016784668,32.525016784668,32.525016784668,32.525016784668,32.525016784668,32.525016784668,32.525016784668,33.0989837646484,33.0989837646484,33.9417495727539,33.9417495727539,33.9417495727539,33.9417495727539,33.9417495727539,33.9417495727539,34.6402893066406,34.6402893066406,34.6402893066406,34.6402893066406,34.6402893066406,34.6402893066406,34.6402893066406,34.6402893066406,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,35.4158020019531,36.3812866210938,36.3812866210938,36.3812866210938,36.3812866210938,36.3812866210938,36.3812866210938,36.3812866210938,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,37.3546524047852,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.2544631958008,27.8780364990234,27.8780364990234,27.8780364990234,27.8780364990234,27.8780364990234,27.8780364990234,27.8780364990234,28.5156021118164,28.5156021118164,28.5156021118164,28.5156021118164,28.5156021118164,29.3748168945312,29.3748168945312,29.3748168945312,29.3748168945312,29.3748168945312,29.3748168945312,30.0042495727539,30.0042495727539,30.0042495727539,30.0042495727539,30.0042495727539,30.0042495727539,30.0042495727539,30.0042495727539,30.7510147094727,30.7510147094727,30.7510147094727,30.7510147094727,30.7510147094727,30.7510147094727,30.7510147094727,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,31.4972534179688,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.0807723999023,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,32.6906127929688,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,33.4497451782227,34.4303359985352,34.4303359985352,34.4303359985352,34.4303359985352,34.4303359985352,34.4303359985352,34.4303359985352,34.4303359985352,35.3876876831055,35.3876876831055,35.3876876831055,35.3876876831055,35.3876876831055,35.3876876831055,35.9753570556641,35.9753570556641,35.9753570556641,35.9753570556641,35.9753570556641,35.9753570556641,35.9753570556641,36.8226470947266,36.8226470947266,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,37.416862487793,27.2609558105469,27.2609558105469,27.2609558105469,27.2609558105469,28.0128631591797,28.0128631591797,28.0128631591797,28.0128631591797,28.0128631591797,28.0128631591797,28.0128631591797,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.0161819458008,29.9985961914062,29.9985961914062,29.9985961914062,29.9985961914062,29.9985961914062,29.9985961914062,29.9985961914062,30.6113967895508,30.6113967895508,30.6113967895508,30.6113967895508,30.6113967895508,30.6113967895508,30.6113967895508,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.2607040405273,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,31.8610534667969,32.4702987670898,32.4702987670898,32.4702987670898,32.4702987670898,32.4702987670898,32.4702987670898,32.4702987670898,32.4702987670898,33.4381637573242,33.4381637573242,33.4381637573242,33.4381637573242,33.4381637573242,33.4381637573242,33.4381637573242,34.0245513916016,34.0245513916016,34.0245513916016,34.0245513916016,34.0245513916016,34.0245513916016,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,34.8914108276367,35.6204528808594,35.6204528808594,36.3392562866211,36.3392562866211,36.3392562866211,36.3392562866211,36.3392562866211,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,36.9376907348633,37.518440246582,37.518440246582,37.518440246582,37.518440246582,37.518440246582,37.518440246582,37.518440246582,37.518440246582,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,27.652458190918,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,28.5377883911133,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,29.5882034301758,30.3439254760742,30.3439254760742,30.3439254760742,30.3439254760742,30.3439254760742,30.3439254760742,30.9807586669922,30.9807586669922,30.9807586669922,31.8056640625,31.8056640625,31.8056640625,31.8056640625,31.8056640625,31.8056640625,31.8056640625,32.985725402832,32.985725402832,33.9548416137695,33.9548416137695,33.9548416137695,33.9548416137695,33.9548416137695,33.9548416137695,33.9548416137695,33.9548416137695,34.9548110961914,34.9548110961914,34.9548110961914,34.9548110961914,34.9548110961914,35.6990737915039,35.6990737915039,35.6990737915039,36.3562240600586,36.3562240600586,36.3562240600586,36.3562240600586,36.3562240600586,37.0447463989258,37.0447463989258,37.0447463989258,37.0447463989258,37.0447463989258,37.0447463989258,37.0447463989258,37.8210067749023,37.8210067749023,37.8210067749023,37.8210067749023,37.8210067749023,37.8210067749023,37.8210067749023,37.8210067749023,28.3923645019531,28.3923645019531,28.3923645019531,28.3923645019531,28.3923645019531,28.3923645019531,28.3923645019531,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,29.1830062866211,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,30.1889572143555,31.3859024047852,31.3859024047852,31.3859024047852,31.3859024047852,31.3859024047852,31.3859024047852,32.5808639526367,32.5808639526367,32.5808639526367,32.5808639526367,32.5808639526367,32.5808639526367,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.1751556396484,33.7571029663086,33.7571029663086,33.7571029663086,33.7571029663086,33.7571029663086,33.7571029663086,34.3521423339844,34.3521423339844,34.3521423339844,34.3521423339844,34.3521423339844,34.9343795776367,34.9343795776367,34.9343795776367,34.9343795776367,34.9343795776367,34.9343795776367,34.9343795776367,35.5337219238281,35.5337219238281,35.5337219238281,35.5337219238281,35.5337219238281,36.1168899536133,36.1168899536133,36.1168899536133,36.1168899536133,36.1168899536133,36.1168899536133,36.1168899536133,36.7176895141602,36.7176895141602,36.7176895141602,36.7176895141602,36.7176895141602,37.2990188598633,37.2990188598633,37.2990188598633,37.2990188598633,37.2990188598633,37.2990188598633,34.1177749633789,34.1177749633789,34.1177749633789,34.1177749633789,34.1177749633789,34.1177749633789,34.1177749633789,34.1177749633789,28.0204086303711,28.0204086303711,28.0204086303711,28.0204086303711,28.0204086303711,28.6162796020508,28.6162796020508,28.6162796020508,28.6162796020508,28.6162796020508,28.6162796020508,29.2165298461914,29.2165298461914,29.2165298461914,29.2165298461914,29.2165298461914,29.7944259643555,29.7944259643555,29.7944259643555,29.7944259643555,29.7944259643555,29.7944259643555,29.7944259643555,30.3938522338867,30.3938522338867,30.3938522338867,30.3938522338867,30.3938522338867,31.007453918457,31.007453918457,31.007453918457,31.007453918457,31.007453918457,31.5906295776367,31.5906295776367,31.5906295776367,31.5906295776367,31.5906295776367,31.5906295776367,31.5906295776367,32.159538269043,32.159538269043,32.159538269043,32.159538269043,32.159538269043,32.159538269043,32.159538269043,32.7457962036133,32.7457962036133,32.7457962036133,32.7457962036133,32.7457962036133,33.3411178588867,33.3411178588867,33.3411178588867,33.3411178588867,33.3411178588867,33.3411178588867,33.3411178588867,33.9404602050781,33.9404602050781,33.9404602050781,33.9404602050781,33.9404602050781,34.5270004272461,34.5270004272461,34.5270004272461,34.5270004272461,34.5270004272461,34.5270004272461,35.1220397949219,35.1220397949219,35.1220397949219,35.1220397949219,35.1220397949219,35.7042770385742,35.7042770385742,35.7042770385742,35.7042770385742,35.7042770385742,35.7042770385742,35.7042770385742,36.3036193847656,36.3036193847656,36.3036193847656,36.3036193847656,36.3036193847656,36.8867874145508,36.8867874145508,36.8867874145508,36.8867874145508,36.8867874145508,36.8867874145508,36.8867874145508,37.4875869750977,37.4875869750977,37.4875869750977,37.4875869750977,37.4875869750977,27.4324798583984,27.4324798583984,27.4324798583984,27.4324798583984,27.4324798583984,27.4324798583984,28.1175231933594,28.1175231933594,28.9920120239258,28.9920120239258,28.9920120239258,28.9920120239258,28.9920120239258,28.9920120239258,28.9920120239258,29.6026382446289,29.6026382446289,29.6026382446289,29.6026382446289,29.6026382446289,29.6026382446289,30.1944732666016,30.1944732666016,30.1944732666016,30.1944732666016,30.1944732666016,30.1944732666016,30.1944732666016,31.1409149169922,31.1409149169922,31.1409149169922,31.1409149169922,31.1409149169922,31.1409149169922,31.1409149169922,31.1409149169922,32.0101013183594,32.0101013183594,32.5849533081055,32.5849533081055,32.5849533081055,32.5849533081055,32.5849533081055,32.5849533081055,32.5849533081055,33.7946319580078,33.7946319580078,33.7946319580078,33.7946319580078,33.7946319580078,33.7946319580078,35.0041046142578,35.0041046142578,35.0041046142578,35.0041046142578,35.0041046142578,35.0041046142578,35.0041046142578,35.0041046142578,36.2238006591797,36.2238006591797,36.2238006591797,36.2238006591797,36.2238006591797,36.2238006591797,36.2238006591797,36.2238006591797,37.174186706543,37.174186706543,37.174186706543,37.174186706543,37.174186706543,37.174186706543,37.174186706543,27.3076019287109,27.3076019287109,27.3076019287109,27.3076019287109,27.3076019287109,27.3076019287109,27.3076019287109,27.3076019287109,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,28.4844665527344,29.0974884033203,29.0974884033203,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,29.708381652832,30.4410095214844,30.4410095214844,30.4410095214844,30.4410095214844,30.4410095214844,30.4410095214844,30.4410095214844,30.4410095214844,31.4895858764648,31.4895858764648,31.4895858764648,31.4895858764648,31.4895858764648,31.4895858764648,31.4895858764648,31.4895858764648,32.4074249267578,32.4074249267578,32.4074249267578,32.4074249267578,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,33.3736419677734,34.3468322753906,34.3468322753906,34.3468322753906,34.9658050537109,34.9658050537109,35.7516784667969,35.7516784667969,35.7516784667969,35.7516784667969,35.7516784667969,36.3491668701172,36.3491668701172,36.3491668701172,36.3491668701172,36.3491668701172,36.3491668701172,36.3491668701172,36.3491668701172,37.0144653320312,37.0144653320312,37.0144653320312,37.0144653320312,37.7057952880859,37.7057952880859,37.7057952880859,37.7057952880859,37.7057952880859,37.7057952880859,37.7057952880859,37.7057952880859,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.1893615722656,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,28.9747924804688,29.5757217407227,29.5757217407227,29.5757217407227,29.5757217407227,29.5757217407227,29.5757217407227,29.5757217407227,30.797477722168,30.797477722168,30.797477722168,30.797477722168,30.797477722168,30.797477722168,30.797477722168,31.4083709716797,31.4083709716797,31.4083709716797,31.4083709716797,32.0281829833984,32.0281829833984,32.0281829833984,32.0281829833984,32.0281829833984,33.1905136108398,33.1905136108398,34.3831100463867,34.3831100463867,35.5607681274414,35.5607681274414,35.5607681274414,35.5607681274414,35.5607681274414,36.7384948730469,36.7384948730469,36.7384948730469,36.7384948730469,36.7384948730469,36.7384948730469,37.3276672363281,37.3276672363281,37.3276672363281,37.3276672363281,37.3276672363281,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,27.7476959228516,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,28.7650985717773,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,29.5946426391602,30.2680435180664,30.2680435180664,30.2680435180664,30.2680435180664,30.2680435180664,30.2680435180664,30.2680435180664,31.3373641967773,31.3373641967773,31.3373641967773,31.3373641967773,31.3373641967773,31.3373641967773,31.3373641967773,32.5748748779297,32.5748748779297,33.1908721923828,33.1908721923828,33.1908721923828,33.1908721923828,33.1908721923828,33.1908721923828,33.1908721923828,33.7892761230469,33.7892761230469,33.7892761230469,33.7892761230469,33.7892761230469,34.4028854370117,34.4028854370117,34.4028854370117,34.4028854370117,34.4028854370117,35.0179443359375,35.0179443359375,35.0179443359375,35.0179443359375,35.0179443359375,35.611328125,35.611328125,36.1995239257812,36.1995239257812,36.1995239257812,36.1995239257812,36.1995239257812,36.7891082763672,36.7891082763672,36.7891082763672,36.7891082763672,36.7891082763672,36.7891082763672,37.3768463134766,37.3768463134766,37.3768463134766,37.3768463134766,37.3768463134766,27.8042602539062,27.8042602539062,27.8042602539062,27.8042602539062,27.8042602539062,27.8042602539062,27.8042602539062,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,28.4244537353516,29.6548919677734,29.6548919677734,29.6548919677734,29.6548919677734,29.6548919677734,29.6548919677734,29.6548919677734,29.6548919677734,30.8846435546875,30.8846435546875,30.8846435546875,30.8846435546875,30.8846435546875,30.8846435546875,30.8846435546875,30.8846435546875,32.1183471679688,32.1183471679688,32.1183471679688,32.1183471679688,32.1183471679688,32.1183471679688,33.3310699462891,33.3310699462891,33.3310699462891,33.3310699462891,33.3310699462891,33.3310699462891,33.3310699462891,34.5504608154297,34.5504608154297,34.5504608154297,34.5504608154297,34.5504608154297,34.5504608154297,34.5504608154297,34.5504608154297,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,35.1652145385742,36.1444473266602,36.1444473266602,36.1444473266602,36.1444473266602,36.1444473266602,36.1444473266602,36.1444473266602,36.948974609375,36.948974609375,36.948974609375,36.948974609375,36.948974609375,36.948974609375,36.948974609375,36.948974609375,36.948974609375,27.4797973632812,27.4797973632812,27.4797973632812,27.4797973632812,27.4797973632812,27.4797973632812,27.4797973632812,27.4797973632812,28.0940093994141,28.0940093994141,28.0940093994141,28.0940093994141,28.0940093994141,28.0940093994141,28.0940093994141,28.0940093994141,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,28.7205047607422,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,29.9774780273438,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,31.2126846313477,32.4406204223633,32.4406204223633,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,33.6548614501953,34.8749313354492,34.8749313354492,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,36.0711822509766,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,37.2960357666016,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,27.8079071044922,28.7912063598633,28.7912063598633,28.7912063598633,28.7912063598633,28.7912063598633,28.7912063598633,28.7912063598633,28.7912063598633,29.582275390625,29.582275390625,29.582275390625,29.582275390625,29.582275390625,29.582275390625,30.8317489624023,30.8317489624023,30.8317489624023,32.0767288208008,32.0767288208008,32.0767288208008,32.0767288208008,32.0767288208008,32.0767288208008,33.0134353637695,33.0134353637695,33.0134353637695,33.0134353637695,33.0134353637695,33.0134353637695,33.0134353637695,33.0134353637695,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,33.8167953491211,34.4201278686523,34.4201278686523,34.4201278686523,34.4201278686523,34.4201278686523,34.4201278686523,34.4201278686523,34.4201278686523,35.6372833251953,35.6372833251953,35.6372833251953,35.6372833251953,35.6372833251953,35.6372833251953,36.8360748291016,36.8360748291016,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,37.4360427856445,27.9520111083984,27.9520111083984,27.9520111083984,27.9520111083984,27.9520111083984,27.9520111083984,27.9520111083984,29.1686248779297,29.1686248779297,29.1686248779297,29.1686248779297,29.1686248779297,29.1686248779297,29.1686248779297,29.1686248779297,29.7732391357422,29.7732391357422,29.7732391357422,29.7732391357422,29.7732391357422,29.7732391357422,29.7732391357422,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,30.3826522827148,31.6040649414062,31.6040649414062,31.6040649414062,31.6040649414062,32.1969451904297,32.1969451904297,33.3818664550781,33.3818664550781,33.3818664550781,33.3818664550781,33.3818664550781,33.3818664550781,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,34.3665237426758,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.1661071777344,35.7639541625977,35.7639541625977,35.7639541625977,35.7639541625977,35.7639541625977,36.3493499755859,36.3493499755859,36.3493499755859,36.3493499755859,36.3493499755859,36.3493499755859,36.3493499755859,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,37.5320663452148,27.4352416992188,27.4352416992188,27.4352416992188,27.4352416992188,27.4352416992188,27.4352416992188,27.4352416992188,28.6551513671875,28.6551513671875,28.6551513671875,28.6551513671875,28.6551513671875,28.6551513671875,28.6551513671875,28.6551513671875,29.6664962768555,29.6664962768555,29.6664962768555,29.6664962768555,29.6664962768555,29.6664962768555,29.6664962768555,29.6664962768555,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375,30.4974365234375],&#34;meminc&#34;:[0,0,0,0,0,0,0,0,0,0,0,0.846511840820312,0,0,0,0,0,0,0.874671936035156,0,0,0,0,0,0.601974487304688,0,0,0,0,0,0,0,0.6053466796875,0,0.682449340820312,0,0,0,0,0,0.85064697265625,0,0,0,0,0,0,0,0.785964965820312,0,0,0.96307373046875,0,0,0,0,0,0,0,0.644737243652344,0,0,0,0,0,0,0.919258117675781,0,0,0,0,0,0.988456726074219,0,0,0,0,0,0,0,0,0,0,0,0,0,0.658966064453125,0,0,0,0,0,0,0,0,-9.85422515869141,0,0,0,0,0,0,0,0,0.612197875976562,0,0,0,0,0,0,0.611434936523438,0,0,0,0,0,0,0,0,0,0.749122619628906,0,0,0,0,0,1.20911407470703,0,0,0,0,0,0,0,0,0,0.74267578125,0,0,0,0,0,0,0.849044799804688,0,0,0,0,0,0.651496887207031,0,0.701240539550781,0,0,0,0,0,0,0,0.596244812011719,0,0.615592956542969,0,0,0,0,0,0,0,0,0,0,0.609939575195312,0,1.20523834228516,0,0,0,0,0,0,0.611419677734375,0,0,0,0,0,0,0.599342346191406,0,0,0,0,-9.62119293212891,0,0,0,1.22164154052734,0,0,0,0,0,0,0,0,0,0.611381530761719,0,0,0,1.21792602539062,0,0.611442565917969,0,0,0,0,0,0,0,0,0,0,0,0.616127014160156,0,0,0,0,0.613609313964844,0,0,0,0,0.6126708984375,0,0,0,0,0.615058898925781,0,0,0,0,0.58319091796875,0,0,0,0,0,0.609329223632812,0,0,0,0,0,0,0.6126708984375,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.6126708984375,0,0,0,0,-3.24775695800781,0,0,0,0,0,0,0,-6.24610137939453,0,0,0,0,0,0,0,0,0,1.21678161621094,0,0,0,0,0,0,1.1954345703125,0,0,0,0,0,1.20820617675781,0,0,0,0,0,0,0,0,0,0,0,0.599609375,0,0,0,0,0,0.586807250976562,0,0,0,0,0.594772338867188,0,0,0,0,0,0.586807250976562,0,0,0,0,0.5865478515625,0,0,0,0,0,0.595970153808594,0,0,0,0,0.6126708984375,0,0,0,0,0.615058898925781,0,0,0,0,0.609344482421875,0,0,0,0,0.613609313964844,0,0,0,0,-9.69961547851562,0,0,0,0,1.21644592285156,0,0,0,0,0,0,1.22521209716797,0,0,0,0,0,0.617691040039062,0,0,0,0,0,0,0.605224609375,0,0,0,0,0,0,1.20886993408203,0,1.15584564208984,0,0,0,0,0,0,0.598739624023438,0,0,0,0,0,0,0,0,1.19571685791016,0,0,0,0,0,0,0,1.20930480957031,0,0,0,0,0,0.872444152832031,0,0,0,0,-9.91779327392578,0,0,0,0,1.21160125732422,0,0,0,0,0,0.61016845703125,0,0.608192443847656,0,0,0,0.586105346679688,0,0,0,0,0,0,1.17082977294922,0,0,0,0,0,0,0,0.606834411621094,0,0,0,1.19815063476562,0,0,0,0,0,0,0,1.20919036865234,0,0,0,0,0,0,0,0.591850280761719,0,0,0,0,0,0,0,0,1.20588684082031,0,0,0,0,0,0,0,0,0,0.596641540527344,0,0,0,0,0,0,0,0,0.575363159179688,0,0,0,-10.4716644287109,0,0,0,0,0.931663513183594,0,0,0,0,0,0,0,0,0,1.20993041992188,0,0,0,0.601516723632812,0,0,0,0,0,0,0,1.19940185546875,0,0,0,0,0,0,0,1.09365081787109,0,0,0,0,0,0,0,0.56317138671875,0,0,0,0,0,0,0,1.15438079833984,0,0,0,0,0,0,0,0,0.558151245117188,0,0,0,0,0,0,0,0,0.55029296875,0,0,0,0,0,0,0.544654846191406,0,0,0,0,0,0,0.539169311523438,0,0,0,0,0,0,0.599128723144531,0,0,0,0,0,0,0.786277770996094,0,0,0,0,0,0,-10.1922836303711,0,0.874404907226562,0,0,0,0,0,0,0,0.668647766113281,0,0,0,0,0,0,0,0,0.733352661132812,0,0,0,0,0,0,0.736618041992188,0,0,0,0,0,0.612968444824219,0,0,0,0.660240173339844,0,0,0,0,0,0,0,0,0,0.58135986328125,0,0,0,0,0,0,0,0,0.601051330566406,0,0,0,0,0,0,0,0,0,0,0.653709411621094,0,0,0,0,0.718048095703125,0,0,0,0,0,0,0.643478393554688,0,0.665901184082031,0,0,0,0,0,0,0,0,0,0,0.578361511230469,0,0,0,0,0,0.595970153808594,0,0,0,0,0.582237243652344,0,0,0,0,0,0,-9.99085235595703,0,1.2005615234375,0,0,0,0,0,0.606651306152344,0,0,0,0,0,0,0.601333618164062,0,0,0,0,1.21843719482422,0,0,1.09426879882812,0,0,0,0,0,0,0,0.70263671875,0,0,0,0,0,0,0.584556579589844,0,0,0,0,0,0,0,1.18244934082031,0,0,0,0,0,0.827720642089844,0,0,0,0,0,0,0,0,0,0.951034545898438,0,0,0,0,0,0,0,0,0,0,0,0,0,0.586128234863281,0,0,0,0,0.597808837890625,0,0,0,0,0,0,0,0,0,0,-9.57944488525391,0,0,0,0,0,0.605461120605469,0,0,0,0,1.23450469970703,0,0,0,0,0,0,0,1.23705291748047,0,0,0,0,0,0,0,0,0,0,0,0.615982055664062,0,0,0,0,0,0,0,0,1.22203826904297,0,0,0,0,0,0,0,0,0,0,1.21405029296875,0,0.840164184570312,0,0,0,0,0.9942626953125,0,0,0,1.19732666015625,0,0.60089111328125,0,0,0,0,0,0,0,0,0,0,0,0,-9.55364227294922,0,0,0,0,0,0,0,0,1.24483489990234,0,0,0,0,0,0,0,0.632865905761719,0,0,0,0,1.23079681396484,0,0,0,0,0,0,0,0,0,1.22563171386719,0,0,0,0,0,0,0,0,0,0,1.22167205810547,0,0,0,0,0,1.19872283935547,0,0,0,0,0,0,0,1.20887756347656,0,0,0,0,0,0,0.589996337890625,0,0,0,0,0,0.595504760742188,0,0,0,0,0,0,0,-9.56874847412109,0,0,0,0,0,0,1.22412872314453,0,0,0,0,0,0,0,0,1.17580413818359,0,0,1.01292419433594,0,0,0,0,0,0,0.623947143554688,0,0,0,0,0,0,0,0,0.696693420410156,0,0,0,0,0,0,0,0,0,0,0.876014709472656,0,0,0,0,0,0,0.734489440917969,0,0,0,0,0,0,0.697967529296875,0,0.602577209472656,0,0,0,0,0.7259521484375,0,0,0,0,0,0,0,0.607734680175781,0,0,0,0,0,0,0,0,0,0,0,0,0.952957153320312,0,0,0,0,0,0,0,0,0,-10.2063751220703,0,0,0,0,0,0,1.21224212646484,0,0,0.712348937988281,0,0,0,0,0,0,0.812606811523438,0,0,0,0,0,0,0.706748962402344,0,0,0,0,0,0,0.961723327636719,0,0,0,0,0,0,0,0.58642578125,0,0,0,0,0,0,0,0.649665832519531,0,0,0,0,0,0,0,0,0.645187377929688,0,0,0,0,0,0,0.68505859375,0,0,0,0,0,0.587745666503906,0,0,0,0,0.781341552734375,0,0,0,0,0,0,0,0.923133850097656,0,0,0,0,0,0,0,1.04328155517578,0,0,0,0,-10.1166534423828,0,0,0,0,0,0,0.593612670898438,0,0,0,0,0,0.6126708984375,0,0,0,0,0,1.04341888427734,0,0,0,0,0,1.03486633300781,0,0,0,0,0,0,0,0,0,0,0.957550048828125,0,0,0,0.966163635253906,0,0,0,0,0,0,0,1.06187438964844,0,0,0,0,0,0,0,0,0,0,0.860885620117188,0,0.662521362304688,0,0,0,0,0,0.975944519042969,0,0,0,0,0,0,0,0.596061706542969,0,0,0,0,0,0.575523376464844,0,0,0,0,-10.149772644043,0,0,0,0,0,0,0,0,0,0.59417724609375,0,0,0,0,0,0,0,0.599693298339844,0,0,0,0,0,0.763900756835938,0,0,0,0,0.78472900390625,0,0,0,0,0,0,0,0,0.769210815429688,0,0,0,0,0,1.02655029296875,0,0,0,0,0,0,0.59930419921875,0,0,0,0,0,0,0,0.825714111328125,0,0,0,0,0,0.71441650390625,0,0,0,0,0,0,0,0,0,0,0,0,0.951499938964844,0,0,0,0,0,0,0,0.701911926269531,0,0,0,0,0,0,0,0,0,0,0,0.858688354492188,0,0,0,0,0,0.590118408203125,0,0,0,0,-10.0160980224609,0,0,0,0,0,0,0.779838562011719,0,0,0,0,0,0,0.999259948730469,0,0,0,0,0.932655334472656,0,0,0,0,0,0,0,0.598953247070312,0,0,0,0,0,0.592498779296875,0,0,0,0,0,0,0.922378540039062,0,0,0,0,0,0.602081298828125,0,0,0,0,0,0,0,1.18574523925781,0,0,0,0,0,0,0.598823547363281,0,0,0,0,0,0,0.571548461914062,0,0,0,0,0.582237243652344,0,0,0,0,0,0,0.58050537109375,0,0,0,0,0,0.584136962890625,0,0,0,0,0,0,0,0.570648193359375,0,0,0,0,-9.9287109375,0,0,0,0,0,0,0,0,0,0,0,0,0.7293701171875,0,0,0,0.633003234863281,0,0,0,0,0,0,0,0,0.607826232910156,0,0,0,0,0,0,0,0,0,0.621490478515625,0,0,0,0,0,0,0.913917541503906,0,0,0,0,0.774658203125,0,0.805816650390625,0,0,0,0,0,0,0.943923950195312,0,0,0,0,0,0,0,0,0,0.596099853515625,0,0,0,0,0,0.603057861328125,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.582237243652344,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.583168029785156,0,0,0,0,0,0,0.665145874023438,0,0,0,0,0,-10.1216659545898,0,0,0,0,0,0,0,0,0,0,0.6011962890625,0,0,0,0,0,0,0,0,0,0,0.831527709960938,0,0.582389831542969,0,0,0,0,0,0,0,0,0.686790466308594,0,0,0,0,0,0,0,0,0,0,0.609756469726562,0,0,0,0,0,0,0.599655151367188,0,0,0,0,0,0,0,0,0.58819580078125,0,0,0,0.739334106445312,0,0,0,0,0,0,1.02776336669922,0,0,0,0,0,0.583930969238281,0,0,0,0,0.668464660644531,0,0,0.873878479003906,0,0,0,0,0,0,0,0,0,0.709114074707031,0,0.65643310546875,0,0,0,0,0,0,0,0.526649475097656,0,0,0,0,0,0,0,-9.92868804931641,0,0,0,0,0,0,0,0.603500366210938,0,0,0,0,0,0,0,1.04753875732422,0,0,0,0,0,0,0,0,0,0.7412109375,0,0.589096069335938,0,0,0,0,0.598228454589844,0,0,0,0,0,0,0,0,0,0.607009887695312,0,0.758522033691406,0,0,0,0,0,0,0,0,0,0.601898193359375,0,0,0,0,0,0,0,0,0,0.628982543945312,0,0,0,0,0.72265625,0,0,0,0,0,0.612747192382812,0,0,0,0.851417541503906,0,0,0,0,0,0,0,0.943183898925781,0,0,0,0,0.620475769042969,0,0,0,0,0,0,0,0,-9.82173156738281,0,0.757431030273438,0,1.12957000732422,0,0,0,0,0,0,0,0,0.719749450683594,0,0,0,1.20181274414062,0,0,0,0,0,0,0,1.13619995117188,0,0,0,0,0,0,0.593765258789062,0,0,0,0,0.5865478515625,0,0,0,0,0,0,0,0,0,0.598030090332031,0,0,0,0,0,0.966400146484375,0,0,0,0,0,0,0,0.796806335449219,0,0,0,0,0,0,0,0,0,0.574668884277344,0,0,0,0,0,0.729461669921875,0,0,0,0,0,0,0,-10.1411895751953,0,0,0,0,0,0.594253540039062,0,0,0,0,0,0,0,0,1.03182220458984,0,0,0,0,0,0,0.778236389160156,0,0,0,0,0,0,0,0,0,0.654106140136719,0,0,0,0,0,0,0.698760986328125,0,0,0,0,0,0.587944030761719,0,0,0,0,0,0,0.813461303710938,0,0,0,0,0,0,0.620651245117188,0,0,0,0,0.602394104003906,0,0,0,0,0.707809448242188,0,0.832275390625,0,0,0,0,1.01543426513672,0,0,0,0,0,0,0,0,0.687484741210938,0,0,0,0,0,0,0,0,0,0.550437927246094,0,0,0,0,0,-9.87195587158203,0,0,0,0,0,0.593215942382812,0,0,0,0,0,0,0,0.600273132324219,0,0,0,0,0,0,0,0,0.67523193359375,0,0,0,0,0,0,0,0.651435852050781,0,0,0,0,0,0.595726013183594,0,0,0,0,1.02347564697266,0,0,0,0,0,0,0.916397094726562,0,0,0,0.779647827148438,0,0,0,0,0,0.755210876464844,0,0,0,0,0,0,0,0.978668212890625,0,0,0,0,0,0.995079040527344,0,0,0,0,0,0,0.62188720703125,0,0,0,0,0,0,0,0.573005676269531,0,0,0,0,0,0,-10.0921249389648,0,0,0,0,0,0,0,0,0,0,0,1.17173767089844,0,0,0,0,0,0,0,0,0,0,0,0.676078796386719,0,0,0,0,0,0,0,0,0.650787353515625,0,0,0,0,0,0.600265502929688,0,0,0,0,0,0,0,0.933975219726562,0,0,0,0,0.992767333984375,0,0,0,0,0,0,0.608993530273438,0,0,0,0,0,0,0,0,0,0,0,0,0,1.18086242675781,0,0,0,0,0,0,0,1.18521118164062,0,0,0,0,0,0,0,0,0.572166442871094,0,0,0,0,1.17678833007812,0,0,0,0,0,0,0,0,0,0,0.465438842773438,0,0,0,0,0,0,-10.0152969360352,0,0,0,0,0,0,1.19160461425781,0,1.17033386230469,0,0,0,0,0,0,0,0,0,0.584892272949219,0,0,0,0,0,0,1.20700073242188,0,0,0,0,0,0,0.572586059570312,0,0,0,0,0,0,0,0.583389282226562,0,0.904792785644531,0,0,0,0,0,0,0,0,0,0.582534790039062,0,0,0,0,0,0,0,0.742973327636719,0,0,0,0,0,0,0.64324951171875,0,0,0,0,0,0,0,0,0.825965881347656,0,0,0,0,0,0,0,0.574539184570312,0,0,0,0,0,0,0,-2.155029296875,0,0,0,0,0,0,0,0,0,0,0,0,-6.94627380371094,0,0,0,0,0,0,1.05422973632812,0,0,0,0,0,0,0.957649230957031,0,0,0,0,0,0,0,0.596649169921875,0,0,0,0,0,1.18692016601562,0,0,0,0,0,0,0,0,0,0,0.653976440429688,0,0,0,0,0,0,0,1.09308624267578,0,0,0,0,0,0,0.94146728515625,0,0,0,0,0,0,0.6512451171875,0,0,0,0,0,0,0,0.63787841796875,0,0,0.62713623046875,0,0,0,0,0,0,0,0,0,0,0,0.910514831542969,0,0,0,0,0,0,0,0,0,-9.76849365234375,0,0,0.968818664550781,0,0,0,0,0,0,0,0.976806640625,0,0,0,0,0,0,0,0,0,0,0.668701171875,0,0,0,0,0,0,0,0.600898742675781,0,0.649971008300781,0,0.909675598144531,0,0,0,0,0,0,0.607749938964844,0,0,0,0,0.617576599121094,0,0,0,0,0,0,0.640083312988281,0,0,0,0,0,0,0.583038330078125,0,0,0,0,0.904876708984375,0,0,0,0,0,0,0.585273742675781,0,0.58428955078125,0,0,0,0,0,0,0,0,0,0.556320190429688,0,0,0,0,0,0,0,-10.1413650512695,0,0,0,0,0,0,0,0,0,0,0.597602844238281,0,0,0,0.676170349121094,0,0,0,0,0,0,0.844268798828125,0,0,0,0,0,0,0.623588562011719,0,0,0.788055419921875,0,0,0,0.587265014648438,0,0,0,0,0,0,0.968345642089844,0,0,0,0,0,0,0,0.854583740234375,0,0,0,0,0,0,0,0,0,0.629669189453125,0,0,0,0,0,0,0,0,0.811042785644531,0,0,0,0,0.620292663574219,0,0,0,0,0,0,0.9715576171875,0,0,0,0,0,0,0,0,0.657241821289062,0,0,0,0,0,0,0,0,0,0.659576416015625,0,0,-10.0922317504883,0,0,0,0,0,0,0,0.790679931640625,0,0,0,0,0,0,0,0.699462890625,0,0,0,0.828628540039062,0,0,0,0.925559997558594,0,0,0,0,0,0,0,0,0,0.58367919921875,0,0,0,0,0,0,0.899993896484375,0,0,0,0,0,0,0,0.573966979980469,0,0.842765808105469,0,0,0,0,0,0.698539733886719,0,0,0,0,0,0,0,0.7755126953125,0,0,0,0,0,0,0,0,0,0.965484619140625,0,0,0,0,0,0,0.973365783691406,0,0,0,0,0,0,0,0,-10.1001892089844,0,0,0,0,0,0,0,0,0.623573303222656,0,0,0,0,0,0,0.637565612792969,0,0,0,0,0.859214782714844,0,0,0,0,0,0.629432678222656,0,0,0,0,0,0,0,0.74676513671875,0,0,0,0,0,0,0.746238708496094,0,0,0,0,0,0,0,0,0.583518981933594,0,0,0,0,0,0,0,0,0,0,0.609840393066406,0,0,0,0,0,0,0,0,0.759132385253906,0,0,0,0,0,0,0,0,0.9805908203125,0,0,0,0,0,0,0,0.957351684570312,0,0,0,0,0,0.587669372558594,0,0,0,0,0,0,0.8472900390625,0,0.594215393066406,0,0,0,0,0,0,0,0,0,0,-10.1559066772461,0,0,0,0.751907348632812,0,0,0,0,0,0,1.00331878662109,0,0,0,0,0,0,0,0,0.982414245605469,0,0,0,0,0,0,0.612800598144531,0,0,0,0,0,0,0.649307250976562,0,0,0,0,0,0,0,0,0,0.600349426269531,0,0,0,0,0,0,0,0,0.609245300292969,0,0,0,0,0,0,0,0.967864990234375,0,0,0,0,0,0,0.586387634277344,0,0,0,0,0,0.866859436035156,0,0,0,0,0,0,0,0,0,0.729042053222656,0,0.718803405761719,0,0,0,0,0.598434448242188,0,0,0,0,0,0,0,0,0,0,0,0.58074951171875,0,0,0,0,0,0,0,-9.86598205566406,0,0,0,0,0,0,0,0,0,0,0,0.885330200195312,0,0,0,0,0,0,0,0,0,1.0504150390625,0,0,0,0,0,0,0,0,0,0.755722045898438,0,0,0,0,0,0.636833190917969,0,0,0.824905395507812,0,0,0,0,0,0,1.18006134033203,0,0.9691162109375,0,0,0,0,0,0,0,0.999969482421875,0,0,0,0,0.7442626953125,0,0,0.657150268554688,0,0,0,0,0.688522338867188,0,0,0,0,0,0,0.776260375976562,0,0,0,0,0,0,0,-9.42864227294922,0,0,0,0,0,0,0.790641784667969,0,0,0,0,0,0,0,0,1.00595092773438,0,0,0,0,0,0,0,0,0,0,0,1.19694519042969,0,0,0,0,0,1.19496154785156,0,0,0,0,0,0.594291687011719,0,0,0,0,0,0,0,0,0,0,0,0,0,0.581947326660156,0,0,0,0,0,0.595039367675781,0,0,0,0,0.582237243652344,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.583168029785156,0,0,0,0,0,0,0.600799560546875,0,0,0,0,0.581329345703125,0,0,0,0,0,-3.18124389648438,0,0,0,0,0,0,0,-6.09736633300781,0,0,0,0,0.595870971679688,0,0,0,0,0,0.600250244140625,0,0,0,0,0.577896118164062,0,0,0,0,0,0,0.59942626953125,0,0,0,0,0.613601684570312,0,0,0,0,0.583175659179688,0,0,0,0,0,0,0.56890869140625,0,0,0,0,0,0,0.586257934570312,0,0,0,0,0.595321655273438,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.586540222167969,0,0,0,0,0,0.595039367675781,0,0,0,0,0.582237243652344,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.583168029785156,0,0,0,0,0,0,0.600799560546875,0,0,0,0,-10.0551071166992,0,0,0,0,0,0.685043334960938,0,0.874488830566406,0,0,0,0,0,0,0.610626220703125,0,0,0,0,0,0.591835021972656,0,0,0,0,0,0,0.946441650390625,0,0,0,0,0,0,0,0.869186401367188,0,0.574851989746094,0,0,0,0,0,0,1.20967864990234,0,0,0,0,0,1.20947265625,0,0,0,0,0,0,0,1.21969604492188,0,0,0,0,0,0,0,0.950386047363281,0,0,0,0,0,0,-9.86658477783203,0,0,0,0,0,0,0,1.17686462402344,0,0,0,0,0,0,0,0,0,0,0.613021850585938,0,0.610893249511719,0,0,0,0,0,0,0,0,0,0,0,0,0.732627868652344,0,0,0,0,0,0,0,1.04857635498047,0,0,0,0,0,0,0,0.917839050292969,0,0,0,0.966217041015625,0,0,0,0,0,0,0,0,0,0,0,0,0,0.973190307617188,0,0,0.618972778320312,0,0.785873413085938,0,0,0,0,0.597488403320312,0,0,0,0,0,0,0,0.665298461914062,0,0,0,0.691329956054688,0,0,0,0,0,0,0,-9.51643371582031,0,0,0,0,0,0,0,0,0,0,0.785430908203125,0,0,0,0,0,0,0,0,0,0.600929260253906,0,0,0,0,0,0,1.22175598144531,0,0,0,0,0,0,0.610893249511719,0,0,0,0.61981201171875,0,0,0,0,1.16233062744141,0,1.19259643554688,0,1.17765808105469,0,0,0,0,1.17772674560547,0,0,0,0,0,0.58917236328125,0,0,0,0,-9.57997131347656,0,0,0,0,0,0,0,0,1.01740264892578,0,0,0,0,0,0,0,0,0.829544067382812,0,0,0,0,0,0,0,0,0.67340087890625,0,0,0,0,0,0,1.06932067871094,0,0,0,0,0,0,1.23751068115234,0,0.615997314453125,0,0,0,0,0,0,0.598403930664062,0,0,0,0,0.613609313964844,0,0,0,0,0.615058898925781,0,0,0,0,0.5933837890625,0,0.58819580078125,0,0,0,0,0.589584350585938,0,0,0,0,0,0.587738037109375,0,0,0,0,-9.57258605957031,0,0,0,0,0,0,0.620193481445312,0,0,0,0,0,0,0,0,0,0,0,1.23043823242188,0,0,0,0,0,0,0,1.22975158691406,0,0,0,0,0,0,0,1.23370361328125,0,0,0,0,0,1.21272277832031,0,0,0,0,0,0,1.21939086914062,0,0,0,0,0,0,0,0.614753723144531,0,0,0,0,0,0,0,0,0,0,0.979232788085938,0,0,0,0,0,0,0.804527282714844,0,0,0,0,0,0,0,0,-9.46917724609375,0,0,0,0,0,0,0,0.614212036132812,0,0,0,0,0,0,0,0.626495361328125,0,0,0,0,0,0,0,0,0,0,1.25697326660156,0,0,0,0,0,0,0,0,1.23520660400391,0,0,0,0,0,0,0,0,0,0,0,1.22793579101562,0,1.21424102783203,0,0,0,0,0,0,0,0,0,0,1.22006988525391,0,1.19625091552734,0,0,0,0,0,0,0,0,0,1.224853515625,0,0,0,0,0,0,0,0,0,0,-9.48812866210938,0,0,0,0,0,0,0,0,0,0,0,0.983299255371094,0,0,0,0,0,0,0,0.791069030761719,0,0,0,0,0,1.24947357177734,0,0,1.24497985839844,0,0,0,0,0,0.93670654296875,0,0,0,0,0,0,0,0.803359985351562,0,0,0,0,0,0,0,0,0,0,0.60333251953125,0,0,0,0,0,0,0,1.21715545654297,0,0,0,0,0,1.19879150390625,0,0.599967956542969,0,0,0,0,0,0,0,0,0,0,0,-9.48403167724609,0,0,0,0,0,0,1.21661376953125,0,0,0,0,0,0,0,0.6046142578125,0,0,0,0,0,0,0.609413146972656,0,0,0,0,0,0,0,0,0,0,1.22141265869141,0,0,0,0.592880249023438,0,1.18492126464844,0,0,0,0,0,0.984657287597656,0,0,0,0,0,0,0,0,0.799583435058594,0,0,0,0,0,0,0,0,0,0.597846984863281,0,0,0,0,0.585395812988281,0,0,0,0,0,0,1.18271636962891,0,0,0,0,0,0,0,0,0,0,-10.0968246459961,0,0,0,0,0,0,1.21990966796875,0,0,0,0,0,0,0,1.01134490966797,0,0,0,0,0,0,0,0.830940246582031,0,0,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//Rtmp1qSIqk/file8fa4cf9a54e.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11],&#34;depth&#34;:[20,19,18,17,16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;as.list.default&#34;,&#34;constantFoldCall&#34;,&#34;constantFold&#34;,&#34;cmp&#34;,&#34;cmpSymbolAssign&#34;,&#34;h&#34;,&#34;tryInline&#34;,&#34;cmpCall&#34;,&#34;cmp&#34;,&#34;h&#34;,&#34;tryInline&#34;,&#34;cmpCall&#34;,&#34;cmp&#34;,&#34;genCode&#34;,&#34;cmpfun&#34;,&#34;compiler:::tryCmpfun&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;getOption&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null],&#34;memalloc&#34;:[28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,28.4219970703125,32.0299453735352,32.0299453735352,32.0299453735352,32.0299453735352,32.0299453735352,32.0299453735352,32.0299453735352,37.2729187011719,37.2729187011719,37.2729187011719,37.2729187011719,37.2729187011719,37.2729187011719,37.2729187011719,37.2729187011719,47.4978332519531,47.4978332519531,47.4978332519531,47.4978332519531,47.4978332519531,47.4978332519531,47.4978332519531,47.4978332519531,54.3225784301758,54.3225784301758,54.3225784301758,54.3225784301758,54.3225784301758,54.3225784301758,54.3225784301758,54.3225784301758,60.5688095092773,60.5688095092773,60.5688095092773,60.5688095092773,60.5688095092773,60.5688095092773,60.5688095092773,60.5688095092773,34.71875,34.71875,34.71875,34.71875,34.71875,34.71875,34.71875,34.71875,38.9223022460938,38.9223022460938,38.9223022460938,38.9223022460938,38.9223022460938,38.9223022460938,38.9223022460938,50.4635467529297,50.4635467529297,50.4635467529297,50.4635467529297,50.4635467529297,50.4635467529297,50.4635467529297,50.4635467529297,62.2318801879883,62.2318801879883,62.2318801879883,62.2318801879883,62.2318801879883,62.2318801879883,62.2318801879883,62.2318801879883,34.5724029541016,34.5724029541016,34.5724029541016,34.5724029541016,34.5724029541016,34.5724029541016,34.5724029541016],&#34;meminc&#34;:[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3.60794830322266,0,0,0,0,0,0,5.24297332763672,0,0,0,0,0,0,0,10.2249145507812,0,0,0,0,0,0,0,6.82474517822266,0,0,0,0,0,0,0,6.24623107910156,0,0,0,0,0,0,0,-25.8500595092773,0,0,0,0,0,0,0,4.20355224609375,0,0,0,0,0,0,11.5412445068359,0,0,0,0,0,0,0,11.7683334350586,0,0,0,0,0,0,0,-27.6594772338867,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[{&#34;filename&#34;:&#34;&lt;expr&gt;&#34;,&#34;content&#34;:&#34;set.seed(2009)\nprofvis({\n    NullDistFSNDR_aw &lt;- fastSimNullDistRProp(sex ~ time, success=\&#34;Female\&#34;, data=tips)\n})&#34;,&#34;normpath&#34;:&#34;&lt;expr&gt;&#34;}],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//Rtmp1qSIqk/file8fa1fcc53ea.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-3&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-3&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,6,7,7,7,7,7,8,8,9,9,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,16,16,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,22,22,22,22,22,23,23,23,23,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,26,26,26,26,26,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,29,29,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,38,38,38,38,38,38,38,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,42,42,42,42,42,42,42,43,43,43,43,43,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,50,50,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,54,54,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,58,58,58,58,58,58,58,58,58,59,59,59,59,59,60,60,60,60,60,60,60,61,61,61,61,61,61,62,62,63,63,63,63,63,64,64,64,64,64,65,65,65,65,65,65,65,66,66,66,66,66,67,67,68,68,68,68,68,69,69,69,69,69,70,70,71,71,71,71,71,71,72,72,72,72,72,72,72,73,73,73,73,73,74,74,74,74,74,75,75,75,75,75,75,76,76,76,76,76,77,77,77,77,77,77,77,78,78,78,78,78,78,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,81,81,81,81,81,81,81,82,82,82,82,82,82,82,82,82,82,82,82,83,83,83,83,83,83,83,83,83,83,83,83,83,83,84,84,84,84,84,85,85,85,85,85,86,86,86,86,86,86,86,86,86,87,87,87,87,87,87,87,88,88,88,88,88,88,88,88,88,88,89,89,89,89,89,90,90,90,90,90,90,91,91,91,91,91,92,92,92,92,92,93,93,93,93,93,93,93,93,93,94,94,94,94,94,94,94,95,95,95,95,95,95,95,95,95,95,95,95,95,96,96,96,96,96,97,97,97,97,97,97,97,97,97,97,97,97,97,97,98,98,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,100,100,100,100,100,101,101,101,101,101,101,101,102,102,102,102,102,103,103,104,104,104,104,104,104,104,105,105,106,106,106,106,106,106,106,106,106,107,107,107,107,107,107,107,107,108,108,108,108,108,108,108,108,109,109,109,109,109,109,109,109,110,110,110,110,110,110,111,111,111,111,111,111,112,112,112,112,112,112,112,112,113,113,113,113,113,113,114,114,114,114,114,114,114,114,114,115,115,115,115,115,115,115,115,116,116,116,116,116,116,116,116,116,116,117,117,117,117,117,118,118,118,118,118,119,119,119,119,119,120,120,120,120,120,120,120,120,120,120,120,121,121,121,121,122,122,122,122,122,122,122,122,122,122,123,123,123,123,123,123,123,123,123,123,124,124,124,124,124,124,124,125,125,125,125,125,125,125,125,125,125,125,126,126,126,126,126,126,126,126,126,126,127,127,127,127,127,127,127,128,128,128,128,128,128,128,129,129,129,129,129,130,130,130,130,130,130,130,130,131,131,131,132,132,132,132,132,132,133,133,133,133,133,133,133,134,134,134,134,134,134,134,135,135,135,135,135,135,136,136,136,136,136,136,136,136,136,136,136,136,137,137,138,138,138,138,138,138,138,138,139,139,139,139,139,139,139,139,140,140,140,140,140,140,140,140,140,141,141,141,141,141,141,141,141,142,142,142,143,143,143,143,143,143,143,144,144,144,144,144,145,145,145,145,145,145,145,145,145,145,145,145,145,145,146,146,146,146,146,146,147,147,147,147,147,147,147,148,148,148,148,148,148,148,148,148,148,148,149,149,149,149,149,149,149,149,149,149,150,150,150,150,150,150,150,151,151,152,152,152,152,152,152,152,153,153,153,153,153,153,153,153,153,153,153,154,154,154,154,154,154,154,154,154,154,155,155,155,155,155,155,156,156,156,156,156,156,156,157,157,157,157,157,157,157,157,158,158,158,158,158,158,158,158,158,158,159,159,159,159,159,159,159,160,160,160,160,160,160,160,161,161,161,161,161,161,161,162,162,162,163,163,163,163,163,163,164,164,164,164,164,164,164,164,165,165,165,165,165,165,165,166,166,166,166,166,166,166,167,167,167,167,167,167,168,168,169,169,169,169,169,169,169,169,170,170,170,170,170,170,170,170,171,171,171,171,171,171,171,171,172,172,172,172,172,172,172,172,173,173,173,173,173,173,173,173,173,174,174,174,174,174,174,174,174,174,175,175,175,175,175,175,175,175,175,176,176,176,176,176,176,176,176,177,177,177,177,177,177,177,177,177,177,177,178,178,178,178,178,178,178,178,178,178,178,178,178,178,179,179,179,179,179,179,179,180,180,180,180,180,180,180,180,181,181,181,181,181,181,181,182,182,182,182,182,182,183,183,183,183,183,183,183,183,183,183,184,184,184,185,185,185,185,185,185,185,185,185,185,186,186,186,186,186,186,186,186,187,187,188,188,188,188,188,188,188,189,189,189,189,189,189,189,190,190,190,190,190,190,190,190,190,190,191,191,191,191,192,192,192,192,192,192,192,192,193,193,193,193,193,193,193,193,194,194,194,194,194,194,194,194,194,194,195,195,196,196,196,196,196,196,196,196,196,196,196,196,197,197,198,198,198,198,198,198,198,198,199,199,199,199,199,200,200,200,200,200,200,200,201,201,201,201,201,201,201,201,202,202,202,202,202,202,202,202,202,203,203,203,203,203,203,203,203,204,204,204,204,204,205,205,205,205,205,205,206,206,206,206,206,206,207,207,207,207,207,207,208,208,208,208,208,208,208,208,208,209,209,209,209,209,209,210,210,210,210,210,210,210,210,210,210,211,211,211,211,211,211,211,212,212,212,212,212,212,212,212,213,213,213,213,213,213,213,214,214,214,214,214,214,215,215,215,215,215,216,216,216,216,216,216,216,217,217,217,217,217,217,217,218,218,219,219,219,219,219,219,219,219,219,220,220,220,220,220,220,220,220,221,221,221,221,221,221,221,221,221,222,222,222,222,222,222,223,223,223,223,223,223,223,223,223,223,223,224,224,224,224,224,224,224,224,225,225,225,225,225,225,225,225,225,226,226,226,226,226,227,227,228,228,228,228,228,228,229,229,229,229,229,229,229,229,229,229,230,230,230,230,230,230,230,230,230,231,231,231,231,231,232,232,232,233,233,233,233,233,233,233,233,234,234,234,234,234,235,235,235,235,235,235,235,235,235,235,235,235,236,236,236,236,236,236,236,237,237,237,237,237,237,237,237,238,238,238,238,238,238,238,238,238,239,239,239,239,239,239,239,239,239,239,240,240,240,240,240,240,241,241,241,241,241,241,241,241,241,241,242,242,242,242,242,243,243,243,243,244,244,244,244,244,244,245,245,245,245,245,245,245,245,245,245,245,246,246,246,246,246,247,247,247,247,247,247,247,248,248,248,248,248,248,249,249,249,249,249,250,250,250,250,250,250,250,250,251,251,252,252,252,252,252,252,252,252,253,253,253,253,253,253,253,254,254,254,254,254,254,254,254,254,255,255,255,255,255,255,255,255,256,256,257,257,257,257,258,258,258,258,259,259,259,259,259,260,260,260,260,260,260,260,260,260,261,261,261,261,261,261,261,261,262,262,262,262,262,263,263,263,263,263,263,263,264,264,264,264,264,265,265,265,265,265,265,265,265,265,265,265,265,266,266,266,266,266,266,266,266,267,267,267,267,267,267,267,268,268,268,268,268,268,268,269,269,269,269,269,269,269,270,270,270,270,270,270,270,270,271,271,271,271,271,271,271,272,272,272,272,273,273,273,273,273,273,273,274,274,274,274,274,274,274,274,274,275,275,275,276,276,276,276,276,276,276,277,277,277,277,277,277,277,278,278,278,278,278,278,278,278,279,279,279,279,279,279,279,279,280,280,280,280,280,280,280,280,280,280,280,281,281,281,281,281,281,281,281,282,282,282,282,282,282,282,283,283,283,283,283,283,283,283,283,284,284,284,284,284,285,285,285,285,285,285,285,285,285,286,286,286,286,286,286,286,286,286,286,286,287,287,287,287,287,287,287,288,288,288,288,288,288,288,288,288,288,288,288,288,289,289,289,289,289,290,290,290,290,290,290,290,290,290,290,290,290,291,291,291,291,291,291,291,292,292,292,292,292,293,293,293,294,294,294,294,294,294,294,295,295,295,295,295,295,295,295,296,296,296,296,296,296,296,296,296,297,297,297,297,297,297,297,297,297,297,297,298,298,298,298,298,298,298,298,298,298,299,299,299,299,299,300,300,301,301,301,301,301,302,302,302,302,302,302,302,302,302,302,303,303,303,303,303,303,303,303,303,303,304,304,304,304,304,304,305,305,305,305,305,305,305,305,306,306,306,306,306,307,307,307,307,307,307,307,307,307,307,307,307,308,308,308,308,309,309,309,310,310,310,310,310,310,310,310,311,311,311,311,311,311,311,311,312,312,312,312,312,312,312,312,312,312,312,312,313,313,313,313,313,313,313,313,313,313,313,313,314,314,314,314,314,314,314,314,314,314,314,314,315,315,315,315,315,315,315,315,315,315,315,315,316,316,316,316,316,316,316,316,316,316,316,316,317,317,317,317,317,317,317,317,317,317,317,317,318,318,318,318,318,318,318,318,318,318,318,318,319,319,319,319,319,319,319,319,319,319,319,319,320,320,320,320,320,320,320,320,320,320,320,320,321,321,321,321,321,321,321,322,322,323,323,324,324,324,324,324,325,325,325,325,325,325,326,326,326,326,326,326,326,326,327,327,327,327,327,327,327,327,328,328,328,328,328,329,329,329,329,329,329,330,330,330,330,330,331,331,331,331,331,331,331,332,332,332,332,332,332,332,332,332,332,333,333,333,333,333,334,334,334,334,334,334,334,335,335,336,336,336,337,337,337,337,337,337,337,337,337,338,338,338,338,338,338,338,339,339,339,339,340,340,340,340,340,340,340,340,341,341,341,341,341,341,341,341,342,342,342,342,342,342,342,342,343,343,343,343,343,343,343,344,344,344,344,344,344,344,344,344,344,344,345,345,345,345,345,345,345,345,345,345,345,346,346,346,346,346,346,346,346,347,347,347,347,347,348,348,348,348,348,348,348,349,349,350,350,350,350,350,350,350,351,351,351,351,351,351,351,351,351,351,351,352,352,352,352,352,352,352,352,352,352,352,353,353,353,353,353,353,353,353,354,354,355,355,355,355,355,355,355,355,355,355,356,356,356,356,356,357,357,357,357,357,357,357,357,357,357,358,358,358,358,358,358,358,359,359,359,359,359,359,359,359,359,359,360,360,360,360,360,360,360,360,360,361,361,361,361,361,361,361,361,361,361,361,362,362,362,362,362,362,362,362,362,363,363,363,363,363,363,363,364,364,364,364,364,364,364,364,365,365,365,366,366,366,366,366,366,366,366,367,367,367,367,367,367,367,368,368,368,368,368,368,368,368,369,369,369,369,369,370,370,370,370,370,370,370,371,371,371,371,371,371,371,371,371,371,371,372,372,372,372,372,372,373,373,373,373,373,373,373,373,373,373,374,374,375,375,375,375,376,376,376,376,376,376,376,376,376,376,376,376,376,376,377,377,377,377,377,378,378,378,378,378,378,378,379,379,379,379,379,379,379,379,380,380,380,380,380,380,380,381,381,381,381,382,382,382,382,382,382,382,382,383,383,383,383,383,384,384,384,384,384,384,384,385,385,385,385,385,385,385,386,386,386,386,386,386,386,386,387,387,387,387,387,387,387,387,388,388,388,388,388,388,388,389,389,389,389,390,390,391,391,391,391,391,391,391,391,391,391,391,392,392,392,392,392,392,392,392,393,393,393,393,393,394,394,394,394,394,394,394,394,394,395,395,395,395,395,395,395,395,395,395,395,396,396,397,397,397,397,397,397,397,397,398,398,398,398,398,398,398,398,399,399,399,399,399,399,399,400,400,400,400,400,400,400,400,400,400,400,401,401,401,401,401,401,402,402,402,402,402,402,402,402,403,403,404,404,404,404,404,404,404,405,405,405,405,405,405,405,405,405,406,406,406,406,406,407,407,408,408,408,408,408,408,409,409,409,409,409,409,410,410,411,411,411,411,411,411,411,411,411,411,411,411,412,412,412,412,412,412,412,413,413,413,413,413,413,413,413,413,413,413,413,413,414,414,414,414,414,414,414,414,415,415,415,415,415,415,415,415,416,416,416,416,416,416,416,416,416,417,417,418,418,419,419,419,419,419,419,419,419,419,419,419,419,420,420,420,420,420,421,421,421,421,421,421,421,422,422,422,422,422,422,422,423,423,423,423,423,424,424,424,424,424,424,424,424,425,425,425,425,425,425,425,425,426,426,426,426,426,426,426,427,427,427,427,427,427,428,428,428,428,428,429,429,429,429,429,430,430,430,430,430,430,430,430,430,431,431,431,431,431,431,431,432,432,432,432,432,433,433,433,434,434,434,434,434,435,435,435,435,436,436,436,436,436,436,436,436,436,436,436,437,437,438,438,438,438,438,438,438,438,438,438,439,439,439,439,439,439,439,439,439,439,439,439,440,440,440,440,440,440,440,440,441,441,441,441,441,442,442,442,442,442,442,443,443,444,444,444,444,444,444,445,445,445,445,445,445,445,445,445,445,446,446,446,446,446,446,447,447,447,447,447,447,447,447,448,448,448,448,448,448,449,449,449,449,449,449,449,450,450,450,450,450,450,450,450,450,450,451,451,451,451,451,451,451,451,451,452,452,452,452,452,453,453,453,453,453,453,453,453,454,454,454,455,455,456,456,456,456,456,457,457,457,457,457,457,458,458,458,458,458,458,458,459,459,459,459,459,459,459,460,460,460,460,460,460,460,461,461,461,461,461,461,461,461,461,461,461,462,462,463,463,463,463,463,463,463,464,464,464,464,464,464,464,464,464,464,464,465,465,465,465,465,465,465,466,466,466,466,466,467,467,467,467,467,467,467,468,468,468,468,468,468,468,469,469,469,469,469,469,469,470,470,470,470,470,470,471,471,471,471,471,471,471,471,472,472,472,472,472,472,472,472,473,473,473,474,474,475,475,476,476,476,476,476,476,477,477,477,478,478,478,478,478,478,478,478,478,479,479,479,479,479,479,479,479,480,480,480,480,480,480,480,480,481,481,481,482,482,482,482,482,482,482,482,482,482,482,483,483,484,484,484,484,484,485,485,485,485,485,486,486,486,486,486,486,487,487,487,487,487,487,487,487,487,487,488,488,488,488,488,489,489,489,489,489,489,489,490,490,490,490,490,491,491,491,491,491,491,491,492,492,492,493,493,493,493,493,493,494,494,494,494,494,494,494,495,495,496,496,496,496,496,496,496,496,496,497,497,497,497,497,497,497,497,498,498,499,499,499,499,499,499,499,499,500,500,500,500,500,500,500,501,501,501,501,501,501,502,502,502,502,502,503,503,503,503,503,504,504,504,504,504,504,504],&#34;depth&#34;:[7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,2,1,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,2,1,5,4,3,2,1,5,4,3,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,2,1,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,4,3,2,1,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,2,1,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,6,5,4,3,2,1,6,5,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,2,1,2,1,6,5,4,3,2,1,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;as.logical&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;dim.data.frame&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.list&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;~&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;[&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.na&#34;,&#34;local&#34;,&#34;$&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rownames&lt;-&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rownames&lt;-&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;list&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.ordered&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;row.names&lt;-&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;condition&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;~&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;force&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;cull_for_do.default&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.set_row_names&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;row.names&lt;-&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;rownames&lt;-&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;max&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.na&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;startsWith&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;.set_row_names&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.expression&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;oldClass&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.set_row_names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;c&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mean.default&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;attributes&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;memalloc&#34;:[28.737060546875,28.737060546875,28.737060546875,28.737060546875,28.737060546875,28.737060546875,28.737060546875,29.2853698730469,29.2853698730469,29.2853698730469,29.2853698730469,29.2853698730469,29.7733993530273,29.7733993530273,29.7733993530273,29.7733993530273,29.7733993530273,29.7733993530273,29.7733993530273,29.7733993530273,30.7682952880859,30.7682952880859,30.7682952880859,30.7682952880859,30.7682952880859,30.7682952880859,30.7682952880859,31.3374099731445,31.3374099731445,31.3374099731445,31.3374099731445,31.3374099731445,31.3374099731445,31.3374099731445,32.0026702880859,32.0026702880859,32.0026702880859,32.0026702880859,32.0026702880859,32.0026702880859,32.9082489013672,32.9082489013672,32.9082489013672,32.9082489013672,32.9082489013672,33.3825073242188,33.3825073242188,34.3250503540039,34.3250503540039,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,34.8051605224609,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,35.7432403564453,28.228157043457,28.228157043457,28.228157043457,28.228157043457,28.228157043457,28.228157043457,28.7212600708008,28.7212600708008,28.7212600708008,28.7212600708008,28.7212600708008,28.7212600708008,28.7212600708008,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,29.5563278198242,30.0518951416016,30.0518951416016,30.0518951416016,30.0518951416016,30.0518951416016,30.0518951416016,30.0518951416016,30.0518951416016,31.0298461914062,31.0298461914062,31.5307464599609,31.5307464599609,31.5307464599609,31.5307464599609,31.5307464599609,31.5307464599609,31.5307464599609,31.5307464599609,32.5402374267578,32.5402374267578,32.5402374267578,32.5402374267578,32.5402374267578,32.5402374267578,32.5402374267578,32.5402374267578,33.5342407226562,33.5342407226562,33.5342407226562,33.5342407226562,33.5342407226562,33.5342407226562,33.5342407226562,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,34.5197219848633,35.5142974853516,35.5142974853516,35.5142974853516,35.5142974853516,35.5142974853516,36.4919815063477,36.4919815063477,36.4919815063477,36.4919815063477,36.4919815063477,28.5257186889648,28.5257186889648,28.5257186889648,28.5257186889648,29.0650253295898,29.0650253295898,29.0650253295898,29.0650253295898,29.0650253295898,29.0650253295898,29.0650253295898,29.0650253295898,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,29.5828475952148,30.3007583618164,30.3007583618164,30.3007583618164,30.3007583618164,30.3007583618164,30.8135757446289,30.8135757446289,30.8135757446289,30.8135757446289,30.8135757446289,30.8135757446289,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.2262496948242,31.7124481201172,31.7124481201172,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,32.6333084106445,33.1837844848633,33.1837844848633,33.1837844848633,33.1837844848633,33.1837844848633,33.9091873168945,33.9091873168945,33.9091873168945,33.9091873168945,33.9091873168945,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,34.6316223144531,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,35.4545822143555,36.0812530517578,36.0812530517578,36.0812530517578,36.0812530517578,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,28.5945053100586,29.5956649780273,29.5956649780273,29.5956649780273,29.5956649780273,29.5956649780273,29.5956649780273,29.5956649780273,30.3622360229492,30.3622360229492,30.3622360229492,30.3622360229492,30.3622360229492,30.3622360229492,30.3622360229492,31.1100082397461,31.1100082397461,31.1100082397461,31.1100082397461,31.1100082397461,31.1100082397461,31.1100082397461,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,32.1226959228516,33.1147079467773,33.1147079467773,33.1147079467773,33.1147079467773,33.1147079467773,33.1147079467773,34.1048583984375,34.1048583984375,34.1048583984375,34.1048583984375,34.1048583984375,34.1048583984375,34.1048583984375,35.0930557250977,35.0930557250977,35.0930557250977,35.0930557250977,35.0930557250977,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.0864410400391,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,36.5644912719727,29.1081848144531,29.1081848144531,29.1081848144531,29.1081848144531,29.1081848144531,29.1081848144531,29.9464569091797,29.9464569091797,29.9464569091797,29.9464569091797,29.9464569091797,29.9464569091797,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,30.6034317016602,31.6124496459961,31.6124496459961,31.6124496459961,31.6124496459961,31.6124496459961,31.6124496459961,31.6124496459961,31.6124496459961,32.610725402832,32.610725402832,33.587028503418,33.587028503418,33.587028503418,33.587028503418,33.587028503418,33.587028503418,33.587028503418,33.587028503418,33.587028503418,34.575927734375,34.575927734375,34.575927734375,34.575927734375,34.575927734375,34.575927734375,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,35.5516738891602,36.0675888061523,36.0675888061523,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,36.554557800293,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,28.2205276489258,29.1237258911133,29.1237258911133,29.1237258911133,29.1237258911133,29.1237258911133,29.1237258911133,29.1237258911133,29.1237258911133,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,29.9439926147461,30.6297760009766,30.6297760009766,30.6297760009766,30.6297760009766,30.6297760009766,31.1347045898438,31.1347045898438,31.1347045898438,31.1347045898438,31.1347045898438,31.1347045898438,31.1347045898438,32.1388244628906,32.1388244628906,32.1388244628906,32.1388244628906,32.1388244628906,32.1388244628906,32.6080322265625,32.6080322265625,33.4900588989258,33.4900588989258,33.4900588989258,33.4900588989258,33.4900588989258,34.4497146606445,34.4497146606445,34.4497146606445,34.4497146606445,34.4497146606445,35.3983306884766,35.3983306884766,35.3983306884766,35.3983306884766,35.3983306884766,35.3983306884766,35.3983306884766,36.3622665405273,36.3622665405273,36.3622665405273,36.3622665405273,36.3622665405273,28.9148483276367,28.9148483276367,29.7524719238281,29.7524719238281,29.7524719238281,29.7524719238281,29.7524719238281,30.7246475219727,30.7246475219727,30.7246475219727,30.7246475219727,30.7246475219727,31.7138290405273,31.7138290405273,32.7045135498047,32.7045135498047,32.7045135498047,32.7045135498047,32.7045135498047,32.7045135498047,33.660774230957,33.660774230957,33.660774230957,33.660774230957,33.660774230957,33.660774230957,33.660774230957,34.1440505981445,34.1440505981445,34.1440505981445,34.1440505981445,34.1440505981445,35.0156631469727,35.0156631469727,35.0156631469727,35.0156631469727,35.0156631469727,35.5855484008789,35.5855484008789,35.5855484008789,35.5855484008789,35.5855484008789,35.5855484008789,36.1554641723633,36.1554641723633,36.1554641723633,36.1554641723633,36.1554641723633,28.569580078125,28.569580078125,28.569580078125,28.569580078125,28.569580078125,28.569580078125,28.569580078125,29.5442199707031,29.5442199707031,29.5442199707031,29.5442199707031,29.5442199707031,29.5442199707031,30.3230667114258,30.3230667114258,30.3230667114258,30.3230667114258,30.3230667114258,30.3230667114258,30.3230667114258,31.0367126464844,31.0367126464844,31.0367126464844,31.0367126464844,31.0367126464844,31.0367126464844,31.0367126464844,31.0367126464844,32.0250473022461,32.0250473022461,32.0250473022461,32.0250473022461,32.0250473022461,32.0250473022461,32.0250473022461,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.0014419555664,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,33.9734115600586,34.9410781860352,34.9410781860352,34.9410781860352,34.9410781860352,34.9410781860352,35.5104217529297,35.5104217529297,35.5104217529297,35.5104217529297,35.5104217529297,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,36.2220840454102,28.4258270263672,28.4258270263672,28.4258270263672,28.4258270263672,28.4258270263672,28.4258270263672,28.4258270263672,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.0478668212891,29.8120574951172,29.8120574951172,29.8120574951172,29.8120574951172,29.8120574951172,30.3094024658203,30.3094024658203,30.3094024658203,30.3094024658203,30.3094024658203,30.3094024658203,31.2982025146484,31.2982025146484,31.2982025146484,31.2982025146484,31.2982025146484,32.2806777954102,32.2806777954102,32.2806777954102,32.2806777954102,32.2806777954102,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.2532424926758,33.7399978637695,33.7399978637695,33.7399978637695,33.7399978637695,33.7399978637695,33.7399978637695,33.7399978637695,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,34.71240234375,35.6907272338867,35.6907272338867,35.6907272338867,35.6907272338867,35.6907272338867,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,36.455940246582,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,28.5931777954102,29.0813217163086,29.0813217163086,29.0813217163086,29.0813217163086,29.0813217163086,29.0813217163086,29.0813217163086,29.6841506958008,29.6841506958008,29.6841506958008,29.6841506958008,29.6841506958008,30.2890090942383,30.2890090942383,30.2890090942383,30.2890090942383,30.2890090942383,30.2890090942383,30.2890090942383,30.8348388671875,30.8348388671875,30.8348388671875,30.8348388671875,30.8348388671875,31.4345321655273,31.4345321655273,32.0487594604492,32.0487594604492,32.0487594604492,32.0487594604492,32.0487594604492,32.0487594604492,32.0487594604492,32.5830383300781,32.5830383300781,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.0776596069336,33.605110168457,33.605110168457,33.605110168457,33.605110168457,33.605110168457,33.605110168457,33.605110168457,33.605110168457,34.0938339233398,34.0938339233398,34.0938339233398,34.0938339233398,34.0938339233398,34.0938339233398,34.0938339233398,34.0938339233398,34.6499252319336,34.6499252319336,34.6499252319336,34.6499252319336,34.6499252319336,34.6499252319336,34.6499252319336,34.6499252319336,35.1840209960938,35.1840209960938,35.1840209960938,35.1840209960938,35.1840209960938,35.1840209960938,35.6859893798828,35.6859893798828,35.6859893798828,35.6859893798828,35.6859893798828,35.6859893798828,36.272705078125,36.272705078125,36.272705078125,36.272705078125,36.272705078125,36.272705078125,36.272705078125,36.272705078125,28.5183944702148,28.5183944702148,28.5183944702148,28.5183944702148,28.5183944702148,28.5183944702148,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.0270156860352,29.6892852783203,29.6892852783203,29.6892852783203,29.6892852783203,29.6892852783203,29.6892852783203,29.6892852783203,29.6892852783203,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.2327880859375,30.7495346069336,30.7495346069336,30.7495346069336,30.7495346069336,30.7495346069336,31.3107299804688,31.3107299804688,31.3107299804688,31.3107299804688,31.3107299804688,31.8707733154297,31.8707733154297,31.8707733154297,31.8707733154297,31.8707733154297,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.3549728393555,32.9110717773438,32.9110717773438,32.9110717773438,32.9110717773438,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,33.5026550292969,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.1006088256836,34.7176361083984,34.7176361083984,34.7176361083984,34.7176361083984,34.7176361083984,34.7176361083984,34.7176361083984,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.3072814941406,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,35.8103408813477,36.3976135253906,36.3976135253906,36.3976135253906,36.3976135253906,36.3976135253906,36.3976135253906,36.3976135253906,28.6077423095703,28.6077423095703,28.6077423095703,28.6077423095703,28.6077423095703,28.6077423095703,28.6077423095703,29.29296875,29.29296875,29.29296875,29.29296875,29.29296875,30.2867431640625,30.2867431640625,30.2867431640625,30.2867431640625,30.2867431640625,30.2867431640625,30.2867431640625,30.2867431640625,30.7804870605469,30.7804870605469,30.7804870605469,31.2748489379883,31.2748489379883,31.2748489379883,31.2748489379883,31.2748489379883,31.2748489379883,31.764274597168,31.764274597168,31.764274597168,31.764274597168,31.764274597168,31.764274597168,31.764274597168,32.3456344604492,32.3456344604492,32.3456344604492,32.3456344604492,32.3456344604492,32.3456344604492,32.3456344604492,33.3209838867188,33.3209838867188,33.3209838867188,33.3209838867188,33.3209838867188,33.3209838867188,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,34.2966232299805,35.2803649902344,35.2803649902344,35.7696304321289,35.7696304321289,35.7696304321289,35.7696304321289,35.7696304321289,35.7696304321289,35.7696304321289,35.7696304321289,28.2721405029297,28.2721405029297,28.2721405029297,28.2721405029297,28.2721405029297,28.2721405029297,28.2721405029297,28.2721405029297,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,29.2648849487305,30.2647857666016,30.2647857666016,30.2647857666016,30.2647857666016,30.2647857666016,30.2647857666016,30.2647857666016,30.2647857666016,30.7586212158203,30.7586212158203,30.7586212158203,31.7593765258789,31.7593765258789,31.7593765258789,31.7593765258789,31.7593765258789,31.7593765258789,31.7593765258789,32.254768371582,32.254768371582,32.254768371582,32.254768371582,32.254768371582,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,32.7430801391602,33.2306060791016,33.2306060791016,33.2306060791016,33.2306060791016,33.2306060791016,33.2306060791016,34.2047424316406,34.2047424316406,34.2047424316406,34.2047424316406,34.2047424316406,34.2047424316406,34.2047424316406,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,35.1810073852539,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,36.1652297973633,28.7135314941406,28.7135314941406,28.7135314941406,28.7135314941406,28.7135314941406,28.7135314941406,28.7135314941406,29.7335815429688,29.7335815429688,30.7422714233398,30.7422714233398,30.7422714233398,30.7422714233398,30.7422714233398,30.7422714233398,30.7422714233398,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,31.7598724365234,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,32.7564086914062,33.7551574707031,33.7551574707031,33.7551574707031,33.7551574707031,33.7551574707031,33.7551574707031,34.7456588745117,34.7456588745117,34.7456588745117,34.7456588745117,34.7456588745117,34.7456588745117,34.7456588745117,35.7359848022461,35.7359848022461,35.7359848022461,35.7359848022461,35.7359848022461,35.7359848022461,35.7359848022461,35.7359848022461,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.2826843261719,28.7867279052734,28.7867279052734,28.7867279052734,28.7867279052734,28.7867279052734,28.7867279052734,28.7867279052734,29.8043060302734,29.8043060302734,29.8043060302734,29.8043060302734,29.8043060302734,29.8043060302734,29.8043060302734,30.3185043334961,30.3185043334961,30.3185043334961,30.3185043334961,30.3185043334961,30.3185043334961,30.3185043334961,31.3259735107422,31.3259735107422,31.3259735107422,32.0317764282227,32.0317764282227,32.0317764282227,32.0317764282227,32.0317764282227,32.0317764282227,32.8091659545898,32.8091659545898,32.8091659545898,32.8091659545898,32.8091659545898,32.8091659545898,32.8091659545898,32.8091659545898,33.8008728027344,33.8008728027344,33.8008728027344,33.8008728027344,33.8008728027344,33.8008728027344,33.8008728027344,34.7847900390625,34.7847900390625,34.7847900390625,34.7847900390625,34.7847900390625,34.7847900390625,34.7847900390625,35.4502868652344,35.4502868652344,35.4502868652344,35.4502868652344,35.4502868652344,35.4502868652344,36.256950378418,36.256950378418,28.3212356567383,28.3212356567383,28.3212356567383,28.3212356567383,28.3212356567383,28.3212356567383,28.3212356567383,28.3212356567383,29.3100967407227,29.3100967407227,29.3100967407227,29.3100967407227,29.3100967407227,29.3100967407227,29.3100967407227,29.3100967407227,29.8294372558594,29.8294372558594,29.8294372558594,29.8294372558594,29.8294372558594,29.8294372558594,29.8294372558594,29.8294372558594,30.3201293945312,30.3201293945312,30.3201293945312,30.3201293945312,30.3201293945312,30.3201293945312,30.3201293945312,30.3201293945312,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.2417907714844,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,31.7376098632812,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.2809906005859,32.7586059570312,32.7586059570312,32.7586059570312,32.7586059570312,32.7586059570312,32.7586059570312,32.7586059570312,32.7586059570312,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.2367172241211,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,33.9716110229492,34.9472885131836,34.9472885131836,34.9472885131836,34.9472885131836,34.9472885131836,34.9472885131836,34.9472885131836,35.9105529785156,35.9105529785156,35.9105529785156,35.9105529785156,35.9105529785156,35.9105529785156,35.9105529785156,35.9105529785156,36.3119659423828,36.3119659423828,36.3119659423828,36.3119659423828,36.3119659423828,36.3119659423828,36.3119659423828,28.8257675170898,28.8257675170898,28.8257675170898,28.8257675170898,28.8257675170898,28.8257675170898,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.2853240966797,29.7647018432617,29.7647018432617,29.7647018432617,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.3083419799805,30.8413772583008,30.8413772583008,30.8413772583008,30.8413772583008,30.8413772583008,30.8413772583008,30.8413772583008,30.8413772583008,31.6686172485352,31.6686172485352,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,32.6464614868164,33.1256942749023,33.1256942749023,33.1256942749023,33.1256942749023,33.1256942749023,33.1256942749023,33.1256942749023,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.0791015625,34.5587844848633,34.5587844848633,34.5587844848633,34.5587844848633,35.0319595336914,35.0319595336914,35.0319595336914,35.0319595336914,35.0319595336914,35.0319595336914,35.0319595336914,35.0319595336914,35.6884155273438,35.6884155273438,35.6884155273438,35.6884155273438,35.6884155273438,35.6884155273438,35.6884155273438,35.6884155273438,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,36.3854064941406,28.4464416503906,28.4464416503906,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,28.9317016601562,29.8169326782227,29.8169326782227,30.5190124511719,30.5190124511719,30.5190124511719,30.5190124511719,30.5190124511719,30.5190124511719,30.5190124511719,30.5190124511719,31.1716537475586,31.1716537475586,31.1716537475586,31.1716537475586,31.1716537475586,31.8236694335938,31.8236694335938,31.8236694335938,31.8236694335938,31.8236694335938,31.8236694335938,31.8236694335938,32.5995025634766,32.5995025634766,32.5995025634766,32.5995025634766,32.5995025634766,32.5995025634766,32.5995025634766,32.5995025634766,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.0881805419922,33.8395690917969,33.8395690917969,33.8395690917969,33.8395690917969,33.8395690917969,33.8395690917969,33.8395690917969,33.8395690917969,34.4269485473633,34.4269485473633,34.4269485473633,34.4269485473633,34.4269485473633,34.9679565429688,34.9679565429688,34.9679565429688,34.9679565429688,34.9679565429688,34.9679565429688,35.7664566040039,35.7664566040039,35.7664566040039,35.7664566040039,35.7664566040039,35.7664566040039,28.3198165893555,28.3198165893555,28.3198165893555,28.3198165893555,28.3198165893555,28.3198165893555,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.0482635498047,29.8613052368164,29.8613052368164,29.8613052368164,29.8613052368164,29.8613052368164,29.8613052368164,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,30.6715774536133,31.3387069702148,31.3387069702148,31.3387069702148,31.3387069702148,31.3387069702148,31.3387069702148,31.3387069702148,32.3132629394531,32.3132629394531,32.3132629394531,32.3132629394531,32.3132629394531,32.3132629394531,32.3132629394531,32.3132629394531,33.2840423583984,33.2840423583984,33.2840423583984,33.2840423583984,33.2840423583984,33.2840423583984,33.2840423583984,34.2545471191406,34.2545471191406,34.2545471191406,34.2545471191406,34.2545471191406,34.2545471191406,35.2263793945312,35.2263793945312,35.2263793945312,35.2263793945312,35.2263793945312,36.1948852539062,36.1948852539062,36.1948852539062,36.1948852539062,36.1948852539062,36.1948852539062,36.1948852539062,36.5867767333984,36.5867767333984,36.5867767333984,36.5867767333984,36.5867767333984,36.5867767333984,36.5867767333984,28.8145599365234,28.8145599365234,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,29.3152770996094,30.0033264160156,30.0033264160156,30.0033264160156,30.0033264160156,30.0033264160156,30.0033264160156,30.0033264160156,30.0033264160156,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,30.7884140014648,31.3423156738281,31.3423156738281,31.3423156738281,31.3423156738281,31.3423156738281,31.3423156738281,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,31.8834686279297,32.4465179443359,32.4465179443359,32.4465179443359,32.4465179443359,32.4465179443359,32.4465179443359,32.4465179443359,32.4465179443359,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,32.9327163696289,33.4208221435547,33.4208221435547,33.4208221435547,33.4208221435547,33.4208221435547,34.1667175292969,34.1667175292969,34.8700408935547,34.8700408935547,34.8700408935547,34.8700408935547,34.8700408935547,34.8700408935547,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,35.8576507568359,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,36.3428726196289,28.4318313598633,28.4318313598633,28.4318313598633,28.4318313598633,28.4318313598633,28.9685287475586,28.9685287475586,28.9685287475586,29.5223617553711,29.5223617553711,29.5223617553711,29.5223617553711,29.5223617553711,29.5223617553711,29.5223617553711,29.5223617553711,30.078010559082,30.078010559082,30.078010559082,30.078010559082,30.078010559082,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,30.6343536376953,31.1888427734375,31.1888427734375,31.1888427734375,31.1888427734375,31.1888427734375,31.1888427734375,31.1888427734375,31.7154006958008,31.7154006958008,31.7154006958008,31.7154006958008,31.7154006958008,31.7154006958008,31.7154006958008,31.7154006958008,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.2716369628906,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,32.8278198242188,33.3268051147461,33.3268051147461,33.3268051147461,33.3268051147461,33.3268051147461,33.3268051147461,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,33.8807830810547,34.4664535522461,34.4664535522461,34.4664535522461,34.4664535522461,34.4664535522461,35.0060272216797,35.0060272216797,35.0060272216797,35.0060272216797,35.5037231445312,35.5037231445312,35.5037231445312,35.5037231445312,35.5037231445312,35.5037231445312,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,35.9801483154297,36.4809494018555,36.4809494018555,36.4809494018555,36.4809494018555,36.4809494018555,28.6486740112305,28.6486740112305,28.6486740112305,28.6486740112305,28.6486740112305,28.6486740112305,28.6486740112305,29.2128677368164,29.2128677368164,29.2128677368164,29.2128677368164,29.2128677368164,29.2128677368164,29.7125778198242,29.7125778198242,29.7125778198242,29.7125778198242,29.7125778198242,30.2579650878906,30.2579650878906,30.2579650878906,30.2579650878906,30.2579650878906,30.2579650878906,30.2579650878906,30.2579650878906,30.8876647949219,30.8876647949219,31.5440292358398,31.5440292358398,31.5440292358398,31.5440292358398,31.5440292358398,31.5440292358398,31.5440292358398,31.5440292358398,32.0962677001953,32.0962677001953,32.0962677001953,32.0962677001953,32.0962677001953,32.0962677001953,32.0962677001953,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,32.5867538452148,33.0841979980469,33.0841979980469,33.0841979980469,33.0841979980469,33.0841979980469,33.0841979980469,33.0841979980469,33.0841979980469,33.6029510498047,33.6029510498047,34.1729202270508,34.1729202270508,34.1729202270508,34.1729202270508,34.6772384643555,34.6772384643555,34.6772384643555,34.6772384643555,35.2154235839844,35.2154235839844,35.2154235839844,35.2154235839844,35.2154235839844,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,35.8866348266602,36.4336624145508,36.4336624145508,36.4336624145508,36.4336624145508,36.4336624145508,36.4336624145508,36.4336624145508,36.4336624145508,28.5926895141602,28.5926895141602,28.5926895141602,28.5926895141602,28.5926895141602,29.1531066894531,29.1531066894531,29.1531066894531,29.1531066894531,29.1531066894531,29.1531066894531,29.1531066894531,29.6616287231445,29.6616287231445,29.6616287231445,29.6616287231445,29.6616287231445,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.2366943359375,30.8195495605469,30.8195495605469,30.8195495605469,30.8195495605469,30.8195495605469,30.8195495605469,30.8195495605469,30.8195495605469,31.3757400512695,31.3757400512695,31.3757400512695,31.3757400512695,31.3757400512695,31.3757400512695,31.3757400512695,31.8825607299805,31.8825607299805,31.8825607299805,31.8825607299805,31.8825607299805,31.8825607299805,31.8825607299805,32.446418762207,32.446418762207,32.446418762207,32.446418762207,32.446418762207,32.446418762207,32.446418762207,33.0200347900391,33.0200347900391,33.0200347900391,33.0200347900391,33.0200347900391,33.0200347900391,33.0200347900391,33.0200347900391,33.4869232177734,33.4869232177734,33.4869232177734,33.4869232177734,33.4869232177734,33.4869232177734,33.4869232177734,34.3537979125977,34.3537979125977,34.3537979125977,34.3537979125977,34.8274993896484,34.8274993896484,34.8274993896484,34.8274993896484,34.8274993896484,34.8274993896484,34.8274993896484,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.3142318725586,35.8638916015625,35.8638916015625,35.8638916015625,36.4991149902344,36.4991149902344,36.4991149902344,36.4991149902344,36.4991149902344,36.4991149902344,36.4991149902344,28.8522262573242,28.8522262573242,28.8522262573242,28.8522262573242,28.8522262573242,28.8522262573242,28.8522262573242,29.3386993408203,29.3386993408203,29.3386993408203,29.3386993408203,29.3386993408203,29.3386993408203,29.3386993408203,29.3386993408203,29.8768844604492,29.8768844604492,29.8768844604492,29.8768844604492,29.8768844604492,29.8768844604492,29.8768844604492,29.8768844604492,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,30.5289459228516,31.105339050293,31.105339050293,31.105339050293,31.105339050293,31.105339050293,31.105339050293,31.105339050293,31.105339050293,31.6601333618164,31.6601333618164,31.6601333618164,31.6601333618164,31.6601333618164,31.6601333618164,31.6601333618164,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.1727066040039,32.724723815918,32.724723815918,32.724723815918,32.724723815918,32.724723815918,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,33.1992263793945,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,34.1730575561523,35.1559524536133,35.1559524536133,35.1559524536133,35.1559524536133,35.1559524536133,35.1559524536133,35.1559524536133,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,36.1255111694336,28.4682006835938,28.4682006835938,28.4682006835938,28.4682006835938,28.4682006835938,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.2335052490234,29.784309387207,29.784309387207,29.784309387207,29.784309387207,29.784309387207,29.784309387207,29.784309387207,30.2686004638672,30.2686004638672,30.2686004638672,30.2686004638672,30.2686004638672,30.9719619750977,30.9719619750977,30.9719619750977,31.7486572265625,31.7486572265625,31.7486572265625,31.7486572265625,31.7486572265625,31.7486572265625,31.7486572265625,32.7327423095703,32.7327423095703,32.7327423095703,32.7327423095703,32.7327423095703,32.7327423095703,32.7327423095703,32.7327423095703,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.2166976928711,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,33.7256774902344,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,34.6665420532227,35.1620254516602,35.1620254516602,35.1620254516602,35.1620254516602,35.1620254516602,35.7658767700195,35.7658767700195,33.7540588378906,33.7540588378906,33.7540588378906,33.7540588378906,33.7540588378906,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,28.8369369506836,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.333869934082,29.8720550537109,29.8720550537109,29.8720550537109,29.8720550537109,29.8720550537109,29.8720550537109,30.8107681274414,30.8107681274414,30.8107681274414,30.8107681274414,30.8107681274414,30.8107681274414,30.8107681274414,30.8107681274414,31.5636520385742,31.5636520385742,31.5636520385742,31.5636520385742,31.5636520385742,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,32.3048248291016,33.2035751342773,33.2035751342773,33.2035751342773,33.2035751342773,34.1774826049805,34.1774826049805,34.1774826049805,35.1027450561523,35.1027450561523,35.1027450561523,35.1027450561523,35.1027450561523,35.1027450561523,35.1027450561523,35.1027450561523,35.6453399658203,35.6453399658203,35.6453399658203,35.6453399658203,35.6453399658203,35.6453399658203,35.6453399658203,35.6453399658203,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,36.6088409423828,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.2594375610352,28.9103393554688,28.9103393554688,28.9103393554688,28.9103393554688,28.9103393554688,28.9103393554688,28.9103393554688,29.9179534912109,29.9179534912109,30.4168167114258,30.4168167114258,30.9220809936523,30.9220809936523,30.9220809936523,30.9220809936523,30.9220809936523,31.9327545166016,31.9327545166016,31.9327545166016,31.9327545166016,31.9327545166016,31.9327545166016,32.9423522949219,32.9423522949219,32.9423522949219,32.9423522949219,32.9423522949219,32.9423522949219,32.9423522949219,32.9423522949219,33.6096496582031,33.6096496582031,33.6096496582031,33.6096496582031,33.6096496582031,33.6096496582031,33.6096496582031,33.6096496582031,34.4432067871094,34.4432067871094,34.4432067871094,34.4432067871094,34.4432067871094,35.4520263671875,35.4520263671875,35.4520263671875,35.4520263671875,35.4520263671875,35.4520263671875,36.4547576904297,36.4547576904297,36.4547576904297,36.4547576904297,36.4547576904297,28.5517349243164,28.5517349243164,28.5517349243164,28.5517349243164,28.5517349243164,28.5517349243164,28.5517349243164,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,29.5636901855469,30.2943572998047,30.2943572998047,30.2943572998047,30.2943572998047,30.2943572998047,30.7970733642578,30.7970733642578,30.7970733642578,30.7970733642578,30.7970733642578,30.7970733642578,30.7970733642578,31.8031234741211,31.8031234741211,32.3073196411133,32.3073196411133,32.3073196411133,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.2531051635742,33.9774398803711,33.9774398803711,33.9774398803711,33.9774398803711,33.9774398803711,33.9774398803711,33.9774398803711,34.7579650878906,34.7579650878906,34.7579650878906,34.7579650878906,35.7750015258789,35.7750015258789,35.7750015258789,35.7750015258789,35.7750015258789,35.7750015258789,35.7750015258789,35.7750015258789,36.2808151245117,36.2808151245117,36.2808151245117,36.2808151245117,36.2808151245117,36.2808151245117,36.2808151245117,36.2808151245117,28.8039932250977,28.8039932250977,28.8039932250977,28.8039932250977,28.8039932250977,28.8039932250977,28.8039932250977,28.8039932250977,29.8072509765625,29.8072509765625,29.8072509765625,29.8072509765625,29.8072509765625,29.8072509765625,29.8072509765625,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,30.5294952392578,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,31.3057098388672,32.3059005737305,32.3059005737305,32.3059005737305,32.3059005737305,32.3059005737305,32.3059005737305,32.3059005737305,32.3059005737305,32.8015975952148,32.8015975952148,32.8015975952148,32.8015975952148,32.8015975952148,33.7995452880859,33.7995452880859,33.7995452880859,33.7995452880859,33.7995452880859,33.7995452880859,33.7995452880859,34.3064804077148,34.3064804077148,35.3395767211914,35.3395767211914,35.3395767211914,35.3395767211914,35.3395767211914,35.3395767211914,35.3395767211914,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,35.8984375,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,28.3510208129883,29.3661041259766,29.3661041259766,29.3661041259766,29.3661041259766,29.3661041259766,29.3661041259766,29.3661041259766,29.3661041259766,30.3924179077148,30.3924179077148,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.033088684082,31.7294921875,31.7294921875,31.7294921875,31.7294921875,31.7294921875,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,32.2841491699219,33.0122756958008,33.0122756958008,33.0122756958008,33.0122756958008,33.0122756958008,33.0122756958008,33.0122756958008,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,33.9992904663086,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,34.9977340698242,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.0043106079102,36.497673034668,36.497673034668,36.497673034668,36.497673034668,36.497673034668,36.497673034668,36.497673034668,36.497673034668,36.497673034668,28.6099472045898,28.6099472045898,28.6099472045898,28.6099472045898,28.6099472045898,28.6099472045898,28.6099472045898,29.631103515625,29.631103515625,29.631103515625,29.631103515625,29.631103515625,29.631103515625,29.631103515625,29.631103515625,30.6468200683594,30.6468200683594,30.6468200683594,31.1515655517578,31.1515655517578,31.1515655517578,31.1515655517578,31.1515655517578,31.1515655517578,31.1515655517578,31.1515655517578,31.6565322875977,31.6565322875977,31.6565322875977,31.6565322875977,31.6565322875977,31.6565322875977,31.6565322875977,32.6746520996094,32.6746520996094,32.6746520996094,32.6746520996094,32.6746520996094,32.6746520996094,32.6746520996094,32.6746520996094,33.1715927124023,33.1715927124023,33.1715927124023,33.1715927124023,33.1715927124023,33.7304458618164,33.7304458618164,33.7304458618164,33.7304458618164,33.7304458618164,33.7304458618164,33.7304458618164,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,34.6879119873047,35.7072525024414,35.7072525024414,35.7072525024414,35.7072525024414,35.7072525024414,35.7072525024414,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,36.3176116943359,28.7893371582031,28.7893371582031,29.2938919067383,29.2938919067383,29.2938919067383,29.2938919067383,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,30.3133087158203,31.3367309570312,31.3367309570312,31.3367309570312,31.3367309570312,31.3367309570312,32.3506851196289,32.3506851196289,32.3506851196289,32.3506851196289,32.3506851196289,32.3506851196289,32.3506851196289,32.8814544677734,32.8814544677734,32.8814544677734,32.8814544677734,32.8814544677734,32.8814544677734,32.8814544677734,32.8814544677734,33.3893661499023,33.3893661499023,33.3893661499023,33.3893661499023,33.3893661499023,33.3893661499023,33.3893661499023,33.8515396118164,33.8515396118164,33.8515396118164,33.8515396118164,34.5718002319336,34.5718002319336,34.5718002319336,34.5718002319336,34.5718002319336,34.5718002319336,34.5718002319336,34.5718002319336,35.1248931884766,35.1248931884766,35.1248931884766,35.1248931884766,35.1248931884766,35.8030471801758,35.8030471801758,35.8030471801758,35.8030471801758,35.8030471801758,35.8030471801758,35.8030471801758,36.3997497558594,36.3997497558594,36.3997497558594,36.3997497558594,36.3997497558594,36.3997497558594,36.3997497558594,28.8557510375977,28.8557510375977,28.8557510375977,28.8557510375977,28.8557510375977,28.8557510375977,28.8557510375977,28.8557510375977,29.4977951049805,29.4977951049805,29.4977951049805,29.4977951049805,29.4977951049805,29.4977951049805,29.4977951049805,29.4977951049805,30.0134353637695,30.0134353637695,30.0134353637695,30.0134353637695,30.0134353637695,30.0134353637695,30.0134353637695,30.6304397583008,30.6304397583008,30.6304397583008,30.6304397583008,31.1295852661133,31.1295852661133,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,31.7936706542969,32.6489181518555,32.6489181518555,32.6489181518555,32.6489181518555,32.6489181518555,32.6489181518555,32.6489181518555,32.6489181518555,33.6583251953125,33.6583251953125,33.6583251953125,33.6583251953125,33.6583251953125,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,34.6588745117188,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,35.1633682250977,36.1618576049805,36.1618576049805,36.5510330200195,36.5510330200195,36.5510330200195,36.5510330200195,36.5510330200195,36.5510330200195,36.5510330200195,36.5510330200195,28.8654937744141,28.8654937744141,28.8654937744141,28.8654937744141,28.8654937744141,28.8654937744141,28.8654937744141,28.8654937744141,29.4882202148438,29.4882202148438,29.4882202148438,29.4882202148438,29.4882202148438,29.4882202148438,29.4882202148438,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.242805480957,30.7952575683594,30.7952575683594,30.7952575683594,30.7952575683594,30.7952575683594,30.7952575683594,31.3633728027344,31.3633728027344,31.3633728027344,31.3633728027344,31.3633728027344,31.3633728027344,31.3633728027344,31.3633728027344,31.8700180053711,31.8700180053711,32.369758605957,32.369758605957,32.369758605957,32.369758605957,32.369758605957,32.369758605957,32.369758605957,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.0488052368164,33.5454940795898,33.5454940795898,33.5454940795898,33.5454940795898,33.5454940795898,34.3330230712891,34.3330230712891,34.8162155151367,34.8162155151367,34.8162155151367,34.8162155151367,34.8162155151367,34.8162155151367,35.340446472168,35.340446472168,35.340446472168,35.340446472168,35.340446472168,35.340446472168,35.8218612670898,35.8218612670898,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,36.2654495239258,28.3230743408203,28.3230743408203,28.3230743408203,28.3230743408203,28.3230743408203,28.3230743408203,28.3230743408203,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.0273895263672,29.618034362793,29.618034362793,29.618034362793,29.618034362793,29.618034362793,29.618034362793,29.618034362793,29.618034362793,30.1334609985352,30.1334609985352,30.1334609985352,30.1334609985352,30.1334609985352,30.1334609985352,30.1334609985352,30.1334609985352,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,30.6049346923828,31.1741714477539,31.1741714477539,31.688102722168,31.688102722168,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.2150268554688,32.7009887695312,32.7009887695312,32.7009887695312,32.7009887695312,32.7009887695312,33.1872787475586,33.1872787475586,33.1872787475586,33.1872787475586,33.1872787475586,33.1872787475586,33.1872787475586,33.6761474609375,33.6761474609375,33.6761474609375,33.6761474609375,33.6761474609375,33.6761474609375,33.6761474609375,34.3123931884766,34.3123931884766,34.3123931884766,34.3123931884766,34.3123931884766,34.785285949707,34.785285949707,34.785285949707,34.785285949707,34.785285949707,34.785285949707,34.785285949707,34.785285949707,35.3216705322266,35.3216705322266,35.3216705322266,35.3216705322266,35.3216705322266,35.3216705322266,35.3216705322266,35.3216705322266,36.0368041992188,36.0368041992188,36.0368041992188,36.0368041992188,36.0368041992188,36.0368041992188,36.0368041992188,36.5250015258789,36.5250015258789,36.5250015258789,36.5250015258789,36.5250015258789,36.5250015258789,28.7129287719727,28.7129287719727,28.7129287719727,28.7129287719727,28.7129287719727,29.2592468261719,29.2592468261719,29.2592468261719,29.2592468261719,29.2592468261719,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,29.7597122192383,30.2962341308594,30.2962341308594,30.2962341308594,30.2962341308594,30.2962341308594,30.2962341308594,30.2962341308594,30.9274520874023,30.9274520874023,30.9274520874023,30.9274520874023,30.9274520874023,31.5291900634766,31.5291900634766,31.5291900634766,32.0354614257812,32.0354614257812,32.0354614257812,32.0354614257812,32.0354614257812,32.6553039550781,32.6553039550781,32.6553039550781,32.6553039550781,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.3292007446289,33.8991928100586,33.8991928100586,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,34.4185638427734,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.0204925537109,35.7517776489258,35.7517776489258,35.7517776489258,35.7517776489258,35.7517776489258,35.7517776489258,35.7517776489258,35.7517776489258,36.2330856323242,36.2330856323242,36.2330856323242,36.2330856323242,36.2330856323242,28.4835968017578,28.4835968017578,28.4835968017578,28.4835968017578,28.4835968017578,28.4835968017578,29.0879135131836,29.0879135131836,29.6255111694336,29.6255111694336,29.6255111694336,29.6255111694336,29.6255111694336,29.6255111694336,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.1644668579102,30.8958053588867,30.8958053588867,30.8958053588867,30.8958053588867,30.8958053588867,30.8958053588867,31.3716201782227,31.3716201782227,31.3716201782227,31.3716201782227,31.3716201782227,31.3716201782227,31.3716201782227,31.3716201782227,31.8704223632812,31.8704223632812,31.8704223632812,31.8704223632812,31.8704223632812,31.8704223632812,32.5416412353516,32.5416412353516,32.5416412353516,32.5416412353516,32.5416412353516,32.5416412353516,32.5416412353516,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,33.362060546875,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,34.1875381469727,35.0202026367188,35.0202026367188,35.0202026367188,35.0202026367188,35.0202026367188,35.8319244384766,35.8319244384766,35.8319244384766,35.8319244384766,35.8319244384766,35.8319244384766,35.8319244384766,35.8319244384766,36.5627212524414,36.5627212524414,36.5627212524414,28.7569046020508,28.7569046020508,29.4921798706055,29.4921798706055,29.4921798706055,29.4921798706055,29.4921798706055,29.9834289550781,29.9834289550781,29.9834289550781,29.9834289550781,29.9834289550781,29.9834289550781,30.7094650268555,30.7094650268555,30.7094650268555,30.7094650268555,30.7094650268555,30.7094650268555,30.7094650268555,31.6045379638672,31.6045379638672,31.6045379638672,31.6045379638672,31.6045379638672,31.6045379638672,31.6045379638672,32.0935974121094,32.0935974121094,32.0935974121094,32.0935974121094,32.0935974121094,32.0935974121094,32.0935974121094,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,32.8535614013672,33.6691360473633,33.6691360473633,34.4831390380859,34.4831390380859,34.4831390380859,34.4831390380859,34.4831390380859,34.4831390380859,34.4831390380859,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,35.3007659912109,36.0985717773438,36.0985717773438,36.0985717773438,36.0985717773438,36.0985717773438,36.0985717773438,36.0985717773438,28.5537719726562,28.5537719726562,28.5537719726562,28.5537719726562,28.5537719726562,29.375114440918,29.375114440918,29.375114440918,29.375114440918,29.375114440918,29.375114440918,29.375114440918,30.0362930297852,30.0362930297852,30.0362930297852,30.0362930297852,30.0362930297852,30.0362930297852,30.0362930297852,30.5487213134766,30.5487213134766,30.5487213134766,30.5487213134766,30.5487213134766,30.5487213134766,30.5487213134766,31.1513900756836,31.1513900756836,31.1513900756836,31.1513900756836,31.1513900756836,31.1513900756836,31.6258544921875,31.6258544921875,31.6258544921875,31.6258544921875,31.6258544921875,31.6258544921875,31.6258544921875,31.6258544921875,32.1289672851562,32.1289672851562,32.1289672851562,32.1289672851562,32.1289672851562,32.1289672851562,32.1289672851562,32.1289672851562,32.6234970092773,32.6234970092773,32.6234970092773,33.1015243530273,33.1015243530273,33.5919036865234,33.5919036865234,34.1334915161133,34.1334915161133,34.1334915161133,34.1334915161133,34.1334915161133,34.1334915161133,34.6101684570312,34.6101684570312,34.6101684570312,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.2230453491211,35.6918792724609,35.6918792724609,35.6918792724609,35.6918792724609,35.6918792724609,35.6918792724609,35.6918792724609,35.6918792724609,36.147575378418,36.147575378418,36.147575378418,36.147575378418,36.147575378418,36.147575378418,36.147575378418,36.147575378418,28.3620147705078,28.3620147705078,28.3620147705078,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,28.8298492431641,29.3552474975586,29.3552474975586,29.8318176269531,29.8318176269531,29.8318176269531,29.8318176269531,29.8318176269531,30.3083572387695,30.3083572387695,30.3083572387695,30.3083572387695,30.3083572387695,30.8523178100586,30.8523178100586,30.8523178100586,30.8523178100586,30.8523178100586,30.8523178100586,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,31.3550109863281,32.0394821166992,32.0394821166992,32.0394821166992,32.0394821166992,32.0394821166992,32.4138336181641,32.4138336181641,32.4138336181641,32.4138336181641,32.4138336181641,32.4138336181641,32.4138336181641,32.9326782226562,32.9326782226562,32.9326782226562,32.9326782226562,32.9326782226562,33.7709274291992,33.7709274291992,33.7709274291992,33.7709274291992,33.7709274291992,33.7709274291992,33.7709274291992,34.2534027099609,34.2534027099609,34.2534027099609,34.7235717773438,34.7235717773438,34.7235717773438,34.7235717773438,34.7235717773438,34.7235717773438,35.2124252319336,35.2124252319336,35.2124252319336,35.2124252319336,35.2124252319336,35.2124252319336,35.2124252319336,35.7357177734375,35.7357177734375,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.2036590576172,36.5702972412109,36.5702972412109,36.5702972412109,36.5702972412109,36.5702972412109,36.5702972412109,36.5702972412109,36.5702972412109,28.9445953369141,28.9445953369141,29.4474487304688,29.4474487304688,29.4474487304688,29.4474487304688,29.4474487304688,29.4474487304688,29.4474487304688,29.4474487304688,29.9205017089844,29.9205017089844,29.9205017089844,29.9205017089844,29.9205017089844,29.9205017089844,29.9205017089844,30.4858551025391,30.4858551025391,30.4858551025391,30.4858551025391,30.4858551025391,30.4858551025391,30.9728775024414,30.9728775024414,30.9728775024414,30.9728775024414,30.9728775024414,31.475715637207,31.475715637207,31.475715637207,31.475715637207,31.475715637207,32.0929336547852,32.0929336547852,32.0929336547852,32.0929336547852,32.0929336547852,32.0929336547852,32.0929336547852],&#34;meminc&#34;:[0,0,0,0,0,0,0,0.548309326171875,0,0,0,0,0.488029479980469,0,0,0,0,0,0,0,0.994895935058594,0,0,0,0,0,0,0.569114685058594,0,0,0,0,0,0,0.665260314941406,0,0,0,0,0,0.90557861328125,0,0,0,0,0.474258422851562,0,0.942543029785156,0,0.480110168457031,0,0,0,0,0,0,0,0,0.938079833984375,0,0,0,0,0,0,0,0,0,-7.51508331298828,0,0,0,0,0,0.49310302734375,0,0,0,0,0,0,0.835067749023438,0,0,0,0,0,0,0,0,0,0.495567321777344,0,0,0,0,0,0,0,0.977951049804688,0,0.500900268554688,0,0,0,0,0,0,0,1.00949096679688,0,0,0,0,0,0,0,0.994003295898438,0,0,0,0,0,0,0.985481262207031,0,0,0,0,0,0,0,0,0,0,0,0.994575500488281,0,0,0,0,0.977684020996094,0,0,0,0,-7.96626281738281,0,0,0,0.539306640625,0,0,0,0,0,0,0,0.517822265625,0,0,0,0,0,0,0,0,0.717910766601562,0,0,0,0,0.5128173828125,0,0,0,0,0,0.412673950195312,0,0,0,0,0,0,0,0,0.486198425292969,0,0.920860290527344,0,0,0,0,0,0,0,0,0,0.55047607421875,0,0,0,0,0.72540283203125,0,0,0,0,0.722434997558594,0,0,0,0,0,0,0,0,0,0,0.822959899902344,0,0,0,0,0,0,0,0,0,0,0.626670837402344,0,0,0,-7.48674774169922,0,0,0,0,0,0,0,0,1.00115966796875,0,0,0,0,0,0,0.766571044921875,0,0,0,0,0,0,0.747772216796875,0,0,0,0,0,0,1.01268768310547,0,0,0,0,0,0,0,0,0,0,0,0.992012023925781,0,0,0,0,0,0.990150451660156,0,0,0,0,0,0,0.988197326660156,0,0,0,0,0.993385314941406,0,0,0,0,0,0,0,0,0.478050231933594,0,0,0,0,0,0,0,0,0,-7.45630645751953,0,0,0,0,0,0.838272094726562,0,0,0,0,0,0.656974792480469,0,0,0,0,0,0,0,0,1.00901794433594,0,0,0,0,0,0,0,0.998275756835938,0,0.976303100585938,0,0,0,0,0,0,0,0,0.988899230957031,0,0,0,0,0,0.975746154785156,0,0,0,0,0,0,0,0,0,0,0.515914916992188,0,0.486968994140625,0,0,0,0,0,0,0,0,0,0,-8.33403015136719,0,0,0,0,0,0,0,0,0,0,0.9031982421875,0,0,0,0,0,0,0,0.820266723632812,0,0,0,0,0,0,0,0,0.685783386230469,0,0,0,0,0.504928588867188,0,0,0,0,0,0,1.00411987304688,0,0,0,0,0,0.469207763671875,0,0.882026672363281,0,0,0,0,0.95965576171875,0,0,0,0,0.948616027832031,0,0,0,0,0,0,0.963935852050781,0,0,0,0,-7.44741821289062,0,0.837623596191406,0,0,0,0,0.972175598144531,0,0,0,0,0.989181518554688,0,0.990684509277344,0,0,0,0,0,0.956260681152344,0,0,0,0,0,0,0.4832763671875,0,0,0,0,0.871612548828125,0,0,0,0,0.56988525390625,0,0,0,0,0,0.569915771484375,0,0,0,0,-7.58588409423828,0,0,0,0,0,0,0.974639892578125,0,0,0,0,0,0.778846740722656,0,0,0,0,0,0,0.713645935058594,0,0,0,0,0,0,0,0.988334655761719,0,0,0,0,0,0,0.976394653320312,0,0,0,0,0,0,0,0,0,0,0,0.971969604492188,0,0,0,0,0,0,0,0,0,0,0,0,0,0.967666625976562,0,0,0,0,0.569343566894531,0,0,0,0,0.711662292480469,0,0,0,0,0,0,0,0,-7.79625701904297,0,0,0,0,0,0,0.622039794921875,0,0,0,0,0,0,0,0,0,0.764190673828125,0,0,0,0,0.497344970703125,0,0,0,0,0,0.988800048828125,0,0,0,0,0.982475280761719,0,0,0,0,0.972564697265625,0,0,0,0,0,0,0,0,0.48675537109375,0,0,0,0,0,0,0.972404479980469,0,0,0,0,0,0,0,0,0,0,0,0,0.978324890136719,0,0,0,0,0.765213012695312,0,0,0,0,0,0,0,0,0,0,0,0,0,-7.86276245117188,0,0,0,0,0,0,0,0,0,0,0.488143920898438,0,0,0,0,0,0,0.602828979492188,0,0,0,0,0.6048583984375,0,0,0,0,0,0,0.545829772949219,0,0,0,0,0.599693298339844,0,0.614227294921875,0,0,0,0,0,0,0.534278869628906,0,0.494621276855469,0,0,0,0,0,0,0,0,0.527450561523438,0,0,0,0,0,0,0,0.488723754882812,0,0,0,0,0,0,0,0.55609130859375,0,0,0,0,0,0,0,0.534095764160156,0,0,0,0,0,0.501968383789062,0,0,0,0,0,0.586715698242188,0,0,0,0,0,0,0,-7.75431060791016,0,0,0,0,0,0.508621215820312,0,0,0,0,0,0,0,0,0.662269592285156,0,0,0,0,0,0,0,0.543502807617188,0,0,0,0,0,0,0,0,0,0.516746520996094,0,0,0,0,0.561195373535156,0,0,0,0,0.560043334960938,0,0,0,0,0.484199523925781,0,0,0,0,0,0,0,0,0,0,0.556098937988281,0,0,0,0.591583251953125,0,0,0,0,0,0,0,0,0,0.597953796386719,0,0,0,0,0,0,0,0,0,0.617027282714844,0,0,0,0,0,0,0.589645385742188,0,0,0,0,0,0,0,0,0,0,0.503059387207031,0,0,0,0,0,0,0,0,0,0.587272644042969,0,0,0,0,0,0,-7.78987121582031,0,0,0,0,0,0,0.685226440429688,0,0,0,0,0.9937744140625,0,0,0,0,0,0,0,0.493743896484375,0,0,0.494361877441406,0,0,0,0,0,0.489425659179688,0,0,0,0,0,0,0.58135986328125,0,0,0,0,0,0,0.975349426269531,0,0,0,0,0,0.975639343261719,0,0,0,0,0,0,0,0,0,0,0,0.983741760253906,0,0.489265441894531,0,0,0,0,0,0,0,-7.49748992919922,0,0,0,0,0,0,0,0.992744445800781,0,0,0,0,0,0,0,0,0.999900817871094,0,0,0,0,0,0,0,0.49383544921875,0,0,1.00075531005859,0,0,0,0,0,0,0.495391845703125,0,0,0,0,0.488311767578125,0,0,0,0,0,0,0,0,0,0,0,0,0,0.487525939941406,0,0,0,0,0,0.974136352539062,0,0,0,0,0,0,0.976264953613281,0,0,0,0,0,0,0,0,0,0,0.984222412109375,0,0,0,0,0,0,0,0,0,-7.45169830322266,0,0,0,0,0,0,1.02005004882812,0,1.00868988037109,0,0,0,0,0,0,1.01760101318359,0,0,0,0,0,0,0,0,0,0,0.996536254882812,0,0,0,0,0,0,0,0,0,0.998748779296875,0,0,0,0,0,0.990501403808594,0,0,0,0,0,0,0.990325927734375,0,0,0,0,0,0,0,-7.45330047607422,0,0,0,0,0,0,0,0,0,0.504043579101562,0,0,0,0,0,0,1.017578125,0,0,0,0,0,0,0.514198303222656,0,0,0,0,0,0,1.00746917724609,0,0,0.705802917480469,0,0,0,0,0,0.777389526367188,0,0,0,0,0,0,0,0.991706848144531,0,0,0,0,0,0,0.983917236328125,0,0,0,0,0,0,0.665496826171875,0,0,0,0,0,0.806663513183594,0,-7.93571472167969,0,0,0,0,0,0,0,0.988861083984375,0,0,0,0,0,0,0,0.519340515136719,0,0,0,0,0,0,0,0.490692138671875,0,0,0,0,0,0,0,0.921661376953125,0,0,0,0,0,0,0,0,0.495819091796875,0,0,0,0,0,0,0,0,0.543380737304688,0,0,0,0,0,0,0,0,0.477615356445312,0,0,0,0,0,0,0,0.478111267089844,0,0,0,0,0,0,0,0,0,0,0.734893798828125,0,0,0,0,0,0,0,0,0,0,0,0,0,0.975677490234375,0,0,0,0,0,0,0.963264465332031,0,0,0,0,0,0,0,0.401412963867188,0,0,0,0,0,0,-7.48619842529297,0,0,0,0,0,0.459556579589844,0,0,0,0,0,0,0,0,0,0.479377746582031,0,0,0.54364013671875,0,0,0,0,0,0,0,0,0,0.533035278320312,0,0,0,0,0,0,0,0.827239990234375,0,0.97784423828125,0,0,0,0,0,0,0.479232788085938,0,0,0,0,0,0,0.953407287597656,0,0,0,0,0,0,0,0,0,0.479682922363281,0,0,0,0.473175048828125,0,0,0,0,0,0,0,0.656455993652344,0,0,0,0,0,0,0,0.696990966796875,0,0,0,0,0,0,0,0,0,-7.93896484375,0,0.485260009765625,0,0,0,0,0,0,0,0,0,0,0,0.885231018066406,0,0.702079772949219,0,0,0,0,0,0,0,0.652641296386719,0,0,0,0,0.652015686035156,0,0,0,0,0,0,0.775833129882812,0,0,0,0,0,0,0,0.488677978515625,0,0,0,0,0,0,0,0,0.751388549804688,0,0,0,0,0,0,0,0.587379455566406,0,0,0,0,0.541007995605469,0,0,0,0,0,0.798500061035156,0,0,0,0,0,-7.44664001464844,0,0,0,0,0,0.728446960449219,0,0,0,0,0,0,0,0,0.813041687011719,0,0,0,0,0,0.810272216796875,0,0,0,0,0,0,0,0,0,0.667129516601562,0,0,0,0,0,0,0.974555969238281,0,0,0,0,0,0,0,0.970779418945312,0,0,0,0,0,0,0.970504760742188,0,0,0,0,0,0.971832275390625,0,0,0,0,0.968505859375,0,0,0,0,0,0,0.391891479492188,0,0,0,0,0,0,-7.772216796875,0,0.500717163085938,0,0,0,0,0,0,0,0,0.68804931640625,0,0,0,0,0,0,0,0.785087585449219,0,0,0,0,0,0,0,0,0.553901672363281,0,0,0,0,0,0.541152954101562,0,0,0,0,0,0,0,0,0,0,0.56304931640625,0,0,0,0,0,0,0,0.486198425292969,0,0,0,0,0,0,0,0,0.488105773925781,0,0,0,0,0.745895385742188,0,0.703323364257812,0,0,0,0,0,0.98760986328125,0,0,0,0,0,0,0,0,0,0.485221862792969,0,0,0,0,0,0,0,0,-7.91104125976562,0,0,0,0,0.536697387695312,0,0,0.5538330078125,0,0,0,0,0,0,0,0.555648803710938,0,0,0,0,0.556343078613281,0,0,0,0,0,0,0,0,0,0,0,0.554489135742188,0,0,0,0,0,0,0.526557922363281,0,0,0,0,0,0,0,0.556236267089844,0,0,0,0,0,0,0,0,0.556182861328125,0,0,0,0,0,0,0,0,0,0.498985290527344,0,0,0,0,0,0.553977966308594,0,0,0,0,0,0,0,0,0,0.585670471191406,0,0,0,0,0.539573669433594,0,0,0,0.497695922851562,0,0,0,0,0,0.476425170898438,0,0,0,0,0,0,0,0,0,0,0.500801086425781,0,0,0,0,-7.832275390625,0,0,0,0,0,0,0.564193725585938,0,0,0,0,0,0.499710083007812,0,0,0,0,0.545387268066406,0,0,0,0,0,0,0,0.62969970703125,0,0.656364440917969,0,0,0,0,0,0,0,0.552238464355469,0,0,0,0,0,0,0.490486145019531,0,0,0,0,0,0,0,0,0.497444152832031,0,0,0,0,0,0,0,0.518753051757812,0,0.569969177246094,0,0,0,0.504318237304688,0,0,0,0.538185119628906,0,0,0,0,0.671211242675781,0,0,0,0,0,0,0,0,0.547027587890625,0,0,0,0,0,0,0,-7.84097290039062,0,0,0,0,0.560417175292969,0,0,0,0,0,0,0.508522033691406,0,0,0,0,0.575065612792969,0,0,0,0,0,0,0,0,0,0,0,0.582855224609375,0,0,0,0,0,0,0,0.556190490722656,0,0,0,0,0,0,0.506820678710938,0,0,0,0,0,0,0.563858032226562,0,0,0,0,0,0,0.573616027832031,0,0,0,0,0,0,0,0.466888427734375,0,0,0,0,0,0,0.866874694824219,0,0,0,0.473701477050781,0,0,0,0,0,0,0.486732482910156,0,0,0,0,0,0,0,0,0.549659729003906,0,0,0.635223388671875,0,0,0,0,0,0,-7.64688873291016,0,0,0,0,0,0,0.486473083496094,0,0,0,0,0,0,0,0.538185119628906,0,0,0,0,0,0,0,0.652061462402344,0,0,0,0,0,0,0,0,0,0,0.576393127441406,0,0,0,0,0,0,0,0.554794311523438,0,0,0,0,0,0,0.5125732421875,0,0,0,0,0,0,0,0,0.552017211914062,0,0,0,0,0.474502563476562,0,0,0,0,0,0,0,0,0.973831176757812,0,0,0,0,0,0,0,0,0,0,0.982894897460938,0,0,0,0,0,0,0.969558715820312,0,0,0,0,0,0,0,0,0,0,0,0,-7.65731048583984,0,0,0,0,0.765304565429688,0,0,0,0,0,0,0,0,0,0,0,0.550804138183594,0,0,0,0,0,0,0.484291076660156,0,0,0,0,0.703361511230469,0,0,0.776695251464844,0,0,0,0,0,0,0.984085083007812,0,0,0,0,0,0,0,0.483955383300781,0,0,0,0,0,0,0,0,0.508979797363281,0,0,0,0,0,0,0,0,0,0,0.940864562988281,0,0,0,0,0,0,0,0,0,0.4954833984375,0,0,0,0,0.603851318359375,0,-2.01181793212891,0,0,0,0,-4.91712188720703,0,0,0,0,0,0,0,0,0,0.496932983398438,0,0,0,0,0,0,0,0,0,0.538185119628906,0,0,0,0,0,0.938713073730469,0,0,0,0,0,0,0,0.752883911132812,0,0,0,0,0.741172790527344,0,0,0,0,0,0,0,0,0,0,0,0.898750305175781,0,0,0,0.973907470703125,0,0,0.925262451171875,0,0,0,0,0,0,0,0.542594909667969,0,0,0,0,0,0,0,0.9635009765625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-8.34940338134766,0,0,0,0,0,0,0,0,0,0,0,0.650901794433594,0,0,0,0,0,0,1.00761413574219,0,0.498863220214844,0,0.505264282226562,0,0,0,0,1.01067352294922,0,0,0,0,0,1.00959777832031,0,0,0,0,0,0,0,0.66729736328125,0,0,0,0,0,0,0,0.83355712890625,0,0,0,0,1.00881958007812,0,0,0,0,0,1.00273132324219,0,0,0,0,-7.90302276611328,0,0,0,0,0,0,1.01195526123047,0,0,0,0,0,0,0,0,0,0.730667114257812,0,0,0,0,0.502716064453125,0,0,0,0,0,0,1.00605010986328,0,0.504196166992188,0,0,0.945785522460938,0,0,0,0,0,0,0,0,0.724334716796875,0,0,0,0,0,0,0.780525207519531,0,0,0,1.01703643798828,0,0,0,0,0,0,0,0.505813598632812,0,0,0,0,0,0,0,-7.47682189941406,0,0,0,0,0,0,0,1.00325775146484,0,0,0,0,0,0,0.722244262695312,0,0,0,0,0,0,0,0,0,0,0.776214599609375,0,0,0,0,0,0,0,0,0,0,1.00019073486328,0,0,0,0,0,0,0,0.495697021484375,0,0,0,0,0.997947692871094,0,0,0,0,0,0,0.506935119628906,0,1.03309631347656,0,0,0,0,0,0,0.558860778808594,0,0,0,0,0,0,0,0,0,0,-7.54741668701172,0,0,0,0,0,0,0,0,0,0,1.01508331298828,0,0,0,0,0,0,0,1.02631378173828,0,0.640670776367188,0,0,0,0,0,0,0,0,0,0.696403503417969,0,0,0,0,0.554656982421875,0,0,0,0,0,0,0,0,0,0.728126525878906,0,0,0,0,0,0,0.987014770507812,0,0,0,0,0,0,0,0,0,0.998443603515625,0,0,0,0,0,0,0,0,1.00657653808594,0,0,0,0,0,0,0,0,0,0,0.493362426757812,0,0,0,0,0,0,0,0,-7.88772583007812,0,0,0,0,0,0,1.02115631103516,0,0,0,0,0,0,0,1.01571655273438,0,0,0.504745483398438,0,0,0,0,0,0,0,0.504966735839844,0,0,0,0,0,0,1.01811981201172,0,0,0,0,0,0,0,0.496940612792969,0,0,0,0,0.558853149414062,0,0,0,0,0,0,0.957466125488281,0,0,0,0,0,0,0,0,0,0,1.01934051513672,0,0,0,0,0,0.610359191894531,0,0,0,0,0,0,0,0,0,-7.52827453613281,0,0.504554748535156,0,0,0,1.01941680908203,0,0,0,0,0,0,0,0,0,0,0,0,0,1.02342224121094,0,0,0,0,1.01395416259766,0,0,0,0,0,0,0.530769348144531,0,0,0,0,0,0,0,0.507911682128906,0,0,0,0,0,0,0.462173461914062,0,0,0,0.720260620117188,0,0,0,0,0,0,0,0.553092956542969,0,0,0,0,0.678153991699219,0,0,0,0,0,0,0.596702575683594,0,0,0,0,0,0,-7.54399871826172,0,0,0,0,0,0,0,0.642044067382812,0,0,0,0,0,0,0,0.515640258789062,0,0,0,0,0,0,0.61700439453125,0,0,0,0.4991455078125,0,0.664085388183594,0,0,0,0,0,0,0,0,0,0,0.855247497558594,0,0,0,0,0,0,0,1.00940704345703,0,0,0,0,1.00054931640625,0,0,0,0,0,0,0,0,0.504493713378906,0,0,0,0,0,0,0,0,0,0,0.998489379882812,0,0.389175415039062,0,0,0,0,0,0,0,-7.68553924560547,0,0,0,0,0,0,0,0.622726440429688,0,0,0,0,0,0,0.754585266113281,0,0,0,0,0,0,0,0,0,0,0.552452087402344,0,0,0,0,0,0.568115234375,0,0,0,0,0,0,0,0.506645202636719,0,0.499740600585938,0,0,0,0,0,0,0.679046630859375,0,0,0,0,0,0,0,0,0.496688842773438,0,0,0,0,0.787528991699219,0,0.483192443847656,0,0,0,0,0,0.52423095703125,0,0,0,0,0,0.481414794921875,0,0.443588256835938,0,0,0,0,0,0,0,0,0,0,0,-7.94237518310547,0,0,0,0,0,0,0.704315185546875,0,0,0,0,0,0,0,0,0,0,0,0,0.590644836425781,0,0,0,0,0,0,0,0.515426635742188,0,0,0,0,0,0,0,0.471473693847656,0,0,0,0,0,0,0,0,0.569236755371094,0,0.513931274414062,0,0.526924133300781,0,0,0,0,0,0,0,0,0,0,0,0.4859619140625,0,0,0,0,0.486289978027344,0,0,0,0,0,0,0.488868713378906,0,0,0,0,0,0,0.636245727539062,0,0,0,0,0.472892761230469,0,0,0,0,0,0,0,0.536384582519531,0,0,0,0,0,0,0,0.715133666992188,0,0,0,0,0,0,0.488197326660156,0,0,0,0,0,-7.81207275390625,0,0,0,0,0.546318054199219,0,0,0,0,0.500465393066406,0,0,0,0,0,0,0,0,0.536521911621094,0,0,0,0,0,0,0.631217956542969,0,0,0,0,0.601737976074219,0,0,0.506271362304688,0,0,0,0,0.619842529296875,0,0,0,0.673896789550781,0,0,0,0,0,0,0,0,0,0,0.569992065429688,0,0.519371032714844,0,0,0,0,0,0,0,0,0,0.6019287109375,0,0,0,0,0,0,0,0,0,0,0,0.731285095214844,0,0,0,0,0,0,0,0.481307983398438,0,0,0,0,-7.74948883056641,0,0,0,0,0,0.604316711425781,0,0.53759765625,0,0,0,0,0,0.538955688476562,0,0,0,0,0,0,0,0,0,0.731338500976562,0,0,0,0,0,0.475814819335938,0,0,0,0,0,0,0,0.498802185058594,0,0,0,0,0,0.671218872070312,0,0,0,0,0,0,0.820419311523438,0,0,0,0,0,0,0,0,0,0.825477600097656,0,0,0,0,0,0,0,0,0.832664489746094,0,0,0,0,0.811721801757812,0,0,0,0,0,0,0,0.730796813964844,0,0,-7.80581665039062,0,0.735275268554688,0,0,0,0,0.491249084472656,0,0,0,0,0,0.726036071777344,0,0,0,0,0,0,0.895072937011719,0,0,0,0,0,0,0.489059448242188,0,0,0,0,0,0,0.759963989257812,0,0,0,0,0,0,0,0,0,0,0.815574645996094,0,0.814002990722656,0,0,0,0,0,0,0.817626953125,0,0,0,0,0,0,0,0,0,0,0.797805786132812,0,0,0,0,0,0,-7.5447998046875,0,0,0,0,0.821342468261719,0,0,0,0,0,0,0.661178588867188,0,0,0,0,0,0,0.512428283691406,0,0,0,0,0,0,0.602668762207031,0,0,0,0,0,0.474464416503906,0,0,0,0,0,0,0,0.50311279296875,0,0,0,0,0,0,0,0.494529724121094,0,0,0.47802734375,0,0.490379333496094,0,0.541587829589844,0,0,0,0,0,0.476676940917969,0,0,0.612876892089844,0,0,0,0,0,0,0,0,0.468833923339844,0,0,0,0,0,0,0,0.455696105957031,0,0,0,0,0,0,0,-7.78556060791016,0,0,0.46783447265625,0,0,0,0,0,0,0,0,0,0,0.525398254394531,0,0.476570129394531,0,0,0,0,0.476539611816406,0,0,0,0,0.543960571289062,0,0,0,0,0,0.502693176269531,0,0,0,0,0,0,0,0,0,0.684471130371094,0,0,0,0,0.374351501464844,0,0,0,0,0,0,0.518844604492188,0,0,0,0,0.838249206542969,0,0,0,0,0,0,0.482475280761719,0,0,0.470169067382812,0,0,0,0,0,0.488853454589844,0,0,0,0,0,0,0.523292541503906,0,0.467941284179688,0,0,0,0,0,0,0,0,0.36663818359375,0,0,0,0,0,0,0,-7.62570190429688,0,0.502853393554688,0,0,0,0,0,0,0,0.473052978515625,0,0,0,0,0,0,0.565353393554688,0,0,0,0,0,0.487022399902344,0,0,0,0,0.502838134765625,0,0,0,0,0.617218017578125,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//Rtmp1qSIqk/file8fa428c608.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-4&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-4&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,7,7,7,7,7,7,7,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12],&#34;depth&#34;:[7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null],&#34;linenum&#34;:[null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null],&#34;memalloc&#34;:[32.4794616699219,32.4794616699219,32.4794616699219,32.4794616699219,32.4794616699219,32.4794616699219,32.4794616699219,38.2749099731445,38.2749099731445,38.2749099731445,38.2749099731445,38.2749099731445,38.2749099731445,38.2749099731445,38.2749099731445,45.5584869384766,45.5584869384766,45.5584869384766,45.5584869384766,45.5584869384766,45.5584869384766,51.8871002197266,51.8871002197266,51.8871002197266,51.8871002197266,51.8871002197266,51.8871002197266,51.8871002197266,51.8871002197266,61.241096496582,61.241096496582,61.241096496582,61.241096496582,61.241096496582,61.241096496582,61.241096496582,61.241096496582,29.3154525756836,29.3154525756836,29.3154525756836,29.3154525756836,29.3154525756836,29.3154525756836,29.3154525756836,36.5347442626953,36.5347442626953,36.5347442626953,36.5347442626953,36.5347442626953,36.5347442626953,36.5347442626953,45.6474914550781,45.6474914550781,45.6474914550781,45.6474914550781,45.6474914550781,45.6474914550781,45.6474914550781,53.1501388549805,53.1501388549805,53.1501388549805,53.1501388549805,53.1501388549805,53.1501388549805,53.1501388549805,53.1501388549805,58.9498672485352,58.9498672485352,58.9498672485352,58.9498672485352,58.9498672485352,58.9498672485352,58.9498672485352,58.9498672485352,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,57.5845947265625,36.3497924804688,36.3497924804688,36.3497924804688,36.3497924804688,36.3497924804688,36.3497924804688,36.3497924804688,36.3497924804688],&#34;meminc&#34;:[0,0,0,0,0,0,0,5.79544830322266,0,0,0,0,0,0,0,7.28357696533203,0,0,0,0,0,6.32861328125,0,0,0,0,0,0,0,9.35399627685547,0,0,0,0,0,0,0,-31.9256439208984,0,0,0,0,0,0,7.21929168701172,0,0,0,0,0,0,9.11274719238281,0,0,0,0,0,0,7.50264739990234,0,0,0,0,0,0,0,5.79972839355469,0,0,0,0,0,0,0,-1.36527252197266,0,0,0,0,0,0,0,0,-21.2348022460938,0,0,0,0,0,0,0],&#34;filename&#34;:[null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[{&#34;filename&#34;:&#34;&lt;expr&gt;&#34;,&#34;content&#34;:&#34;set.seed(2009)\nprofvis({\n    NullDistFSNDR_mw &lt;- fastSimNullDistRMean(total_bill ~ time, data=tips)\n})&#34;,&#34;normpath&#34;:&#34;&lt;expr&gt;&#34;}],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//Rtmp1qSIqk/file8fa327c4c5e.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Das mit den beiden Routinen aus FastSimNullDistR die gleichen Ergebnisse zu erwarten sind, sie also ein “(quasi-)drop-in-replacements” der Mosaic Routinen darstellen, kann man an den folgenden QQ-Plots erkennen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.diffprop &amp;lt;- data_frame(diffprop = c(NullDistFSNDR_aw$diffprop,
    NullDistMosaic_aw$diffprop), type = c(rep(&amp;quot;FSNDR&amp;quot;, 10000),
    rep(&amp;quot;mosaic&amp;quot;, 10000)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` was deprecated in tibble 1.1.0.
## Please use `tibble()` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_qq(~diffprop, color = ~type, data = df.diffprop)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.diffmean &amp;lt;- data_frame(diffmean = c(NullDistFSNDR_mw$diffmean,
    NullDistMosaic_mw$diffmean), type = c(rep(&amp;quot;FSNDR&amp;quot;, 10000),
    rep(&amp;quot;mosaic&amp;quot;, 10000)))
gf_qq(~diffmean, color = ~type, data = df.diffmean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;672&#34; /&gt;
# qqplot(NullDistFSNDR_aw&lt;span class=&#34;math inline&#34;&gt;\(diffprop, NullDistMosaic_aw\)&lt;/span&gt;diffprop)
gf_qq(FSNDR ~ Mosaic, data=df)
# qqplot(NullDistFSNDR_mw&lt;span class=&#34;math inline&#34;&gt;\(diffmean, NullDistMosaic_mw\)&lt;/span&gt;diffmean)
gf_qq(NullDistFSNDR_mw&lt;span class=&#34;math inline&#34;&gt;\(diffmean ~ NullDistMosaic_mw\)&lt;/span&gt;diffmean)
```&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;woher-kommt-die-geschwindigkeit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Woher kommt die Geschwindigkeit?&lt;/h2&gt;
&lt;p&gt;Schaut man sich den Quellcode von Mosaic an, wird einem schnell klar, dass es zwar didaktisch sinnvoll ist die unabhängige Variable mit &lt;code&gt;shuffle()&lt;/code&gt; zu bearbeiten, nicht aber programmiertechnisch. Und wenn, dann nicht in dem man die ganze Datenzeile für die Berechnung kopiert. Statt also &lt;span class=&#34;math inline&#34;&gt;\(10\,000\)&lt;/span&gt; mal die ganzen Daten im Speicher zu kopieren wäre es doch sinnvoller mit Hilfe eines Index auf die unveränderten Daten zuzugreifen. Und genau das machen die zwei Routinen. Es wird also nur dieser Zugriffsindex wird &lt;em&gt;geshuffelt&lt;/em&gt; und das spart Speicherplatz und deutlich auch Rechenzeit.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nur ein wenig lineare Regression</title>
      <link>https://sefiroth.net/nab/post/nur-ein-wenig-lineare-regression/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/nur-ein-wenig-lineare-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Der &lt;em&gt;tipping&lt;/em&gt; Datensatz wird oft analysiert. Das Verhältnis von Trinkgeld (&lt;em&gt;tip&lt;/em&gt;) und Rechnungsbetrag (&lt;em&gt;total_bill&lt;/em&gt;) steht dabei im Vordergrund einer lineare Regressionsanalyse.
So auch hier. Wir wollen die einzelnen Angaben von &lt;strong&gt;R&lt;/strong&gt; dabei in den Fokus rücken und einmal Hinterfragen, was wir bei der Ausgabe von &lt;strong&gt;R&lt;/strong&gt; eigentlich genau sehen, woher es kommt und wie man es interpretieren kann.&lt;/p&gt;
&lt;p&gt;Zunächst laden wir dazu die &lt;strong&gt;tipping&lt;/strong&gt; Daten mittels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in den Arbeitsspeicher.&lt;/p&gt;
&lt;p&gt;Eine lineares Modell wird schnell mit&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linMod &amp;lt;- lm(tip ~ total_bill, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;erstellt.
Betrachten wir die Zusammenfassung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(linMod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 0.920270   0.159735   5.761 2.53e-08 ***
## total_bill  0.105025   0.007365  14.260  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 
## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die zentrale Frage bei einer linearen Regression ist, finden wir einen linearen Zusammenhang in unserer Stichprobe, den wir auf die Population (als die Grundgesamtheit) übertragen können.&lt;/p&gt;
&lt;p&gt;Die Spalte &lt;strong&gt;Estimate&lt;/strong&gt; im Abschnitt &lt;strong&gt;Coefficients&lt;/strong&gt; liefert uns in unser Stichprobe einen möglichen linearen Zusammenhang gemäß&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{\text{tip}} = \hat{\beta}_{\text{0}} + \hat{\beta}_{\text{total_bill}} \cdot x_{\text{total_bill}},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit den &lt;em&gt;Regressionskoeffizienten&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0=0.9202696\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{\text{total_bill}}=0.1050245\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Graphisch ergibt sich damit das Modell wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linMod) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linMod, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;, padding.text = 8,
            lines = list(col = c(&amp;quot;red&amp;quot;), lty = c(2), lwd = 1.2),
            text = list(c(&amp;quot;Regressionsgerade&amp;quot;))
          )
     )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Was hat es mit dem y-Achsenabschnitt &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; auf sich?&lt;/p&gt;
&lt;p&gt;Ist es etwa eine Art &lt;em&gt;Grundtrinkgeld&lt;/em&gt;, mit dem der Kellern rechnen kann, auch wenn der Kunde gar nichts bestellt?&lt;/p&gt;
&lt;p&gt;Nun ja, es so etwas in der Art, aber eben ein rein fiktiver Wert, der durch die Konstruktion der Parameter entsteht.
Eine (affin-)lineare Gerade geht nun einmal irgendwann durch die y-Achse (wenn sie nicht parallel dazu ist) und es kann passieren, dass eine sinnvolle Interpretation nicht so ohne weiteres möglich ist.&lt;/p&gt;
&lt;p&gt;Wir können aber dieses &lt;em&gt;Grundtrinkgeld&lt;/em&gt; heraus nehmen und den y-Achsenabschnitt auf Null setzen. Dazu ziehen wir &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; einfach von alle Trinkgeldern ab. Wir erhalten quasi nur noch den &lt;em&gt;Trinkgeldzuwach&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta_0 &amp;lt;- coef(linMod)[&amp;quot;(Intercept)&amp;quot;]  # Grundtrinkgeld
tips$delta_tip &amp;lt;- tips$tip - beta_0    # wird abgezogen&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vergleichen wir das alte lineare Modell mit dem neuen Modell (&lt;em&gt;linModDelta&lt;/em&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linModDelta &amp;lt;- lm(delta_tip ~ total_bill, data = tips)
summary(linModDelta)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = delta_tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -4.549e-15  1.597e-01    0.00        1    
## total_bill   1.050e-01  7.365e-03   14.26   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 
## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In diesem Modell ist der Wert für den y-Achsenabschnitt numerisch gleich 0. – Ja, da mag zwar &lt;span class=&#34;math inline&#34;&gt;\(-4.5487837\times 10^{-15}\)&lt;/span&gt; stehen, jedoch sind so kleine Werte der jedem Rechner inne wohnenden Ungenauigkeit in der Gleitkomma-Arithmetik geschuldet und ist faktisch gleich 0.&lt;/p&gt;
&lt;p&gt;Der Wert für die Steigung lautet weiterhin &lt;span class=&#34;math inline&#34;&gt;\(0.1050245\)&lt;/span&gt;.
Das war auch zu erwarten, denn wir haben unsere Regressionsgerade eigentlich nur um &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; nach unten verschoben. (Der Fachmann spricht von einer Translation (Parallelverschiebung)&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; um &lt;span class=&#34;math inline&#34;&gt;\(-\hat{\beta}_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linModDelta) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linModDelta, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    delta_tip ~ total_bill, data=tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Delta Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Delta Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space=&amp;quot;bottom&amp;quot;, padding.text=8,
            lines=list(col=c(&amp;quot;red&amp;quot;), lty=c(2), lwd=1.2),
            text=list(c(&amp;quot;Regressionsgerade&amp;quot;)))
     )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Vergleichen wir die beiden Zusammenfassungen, so stellen wir fest das sich mit Ausnahme der &lt;em&gt;[Intercept]&lt;/em&gt; Zeile praktisch nichts geändert hat. Das ist kein Wunder, sondern Absicht!&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade stellt für unsere Stichprobe die Gerade mit dem geringsten Fehler an den Datenpunkten dar. Mathematisch heißt das folgendes:&lt;/p&gt;
&lt;p&gt;An den &lt;span class=&#34;math inline&#34;&gt;\(n=244\)&lt;/span&gt; Datenpunkten unserer Stichprobe &lt;span class=&#34;math inline&#34;&gt;\((x_i, y_i)=(tips\$total\_bill[i], tips\$tip[i])\)&lt;/span&gt; [für &lt;span class=&#34;math inline&#34;&gt;\((i=1, \dots, n)\)&lt;/span&gt;] sind die &lt;em&gt;Residuen&lt;/em&gt;, also die &lt;em&gt;Fehlerterme&lt;/em&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
 \hat{e}_i =\hat{y}_i - y_i = \left[\hat{\beta}_{\text{0}} + \hat{\beta}_{\text{total_bill}} \cdot x_i\right] - y_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;durch die verwendete &lt;em&gt;Methode der kleinsten Quadrate&lt;/em&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;em&gt;quadratisch minimal&lt;/em&gt;. Kurz:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \sum_{i=1}^n (\hat{e}_i)^2 \text{ ist minimal!}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können diese Fehlerterme graphisch ansehen um die Varianz der Residuen zu sehen.
Dazu ziehen wir von allen Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; den geschätzten Wert &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt; ab und erstellen ein neues lineares Modell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta_total_bill &amp;lt;- coef(linModDelta)[&amp;quot;total_bill&amp;quot;]
tips$error_tip &amp;lt;- (tips$tip - beta_0 - beta_total_bill * tips$total_bill)
linModError &amp;lt;- lm(error_tip ~ total_bill, data = tips)
summary(linModError)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = error_tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)  1.900e-15  1.597e-01       0        1
## total_bill  -8.740e-17  7.365e-03       0        1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  6.665e-31,  Adjusted R-squared:  -0.004132 
## F-statistic: 1.613e-28 on 1 and 242 DF,  p-value: 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also Diagramm sieht es dann so aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linModError) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linModError, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    error_tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Residuen&amp;quot;,
    ylab  = &amp;quot;Residuen&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;, rows = 3, padding.text = 8,
            lines = list(col=c(&amp;quot;red&amp;quot;), lty = c(2), lwd = 1.2),
            text = list(c(&amp;quot;Regressionsgerade / x-Achse&amp;quot;))
          )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können die Graphik im wesentlichen auch einfacher über den Befehl&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xyplot(residuals(linMod) ~ fitted(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;erhalten.&lt;/p&gt;
&lt;p&gt;Betrachten wir kurz nur die Residuen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(~residuals(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        min         Q1      median        Q3      max          mean       sd   n
##  -3.198225 -0.5651615 -0.09744499 0.4863111 3.743435 -2.022281e-17 1.019943 244
##  missing
##        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir sehe, dass wir in der Zusammenfassung immer genau diese Werte unter dem Abschnitt &lt;em&gt;Residuals&lt;/em&gt; gefunden haben. Minimum, das 1. Quantil, der Median, das 3. Quantil und das Maximum stimmen überein.&lt;/p&gt;
&lt;p&gt;Der erwartungstreue und unverzerrte Schätzer für den Standardfehler der Residuen, lautet&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
    SE_{\text{Residuen}} &amp;amp;= \sqrt{\frac{1}{n-2} \cdot \sum_{i=1}^n (\hat{e_i})^2} = \sqrt{\frac{n-1}{n-2} \cdot \frac{1}{n-1} \cdot \sum_{i=1}^n (\hat{e_i})^2} \\
                         &amp;amp;= \sqrt{\frac{n-1}{n-2}} \cdot \sqrt{\frac{1}{n-1} \cdot \sum_{i=1}^n (\hat{e_i})^2} \\
                         &amp;amp;= \sqrt{\frac{n-1}{n-2}} \cdot s_{\text{Residuen}}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Also finden wir den Wert &lt;em&gt;Residual standard error&lt;/em&gt; aus der Zeile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Residual standard error: 1.022 on 242 degrees of freedom&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in dem wir den in den &lt;em&gt;favstats&lt;/em&gt; gefundenen Wert für die Standardabweichung entsprechen korrigieren:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SE_{\text{Residuen}} = \sqrt{\frac{n-1}{n-2}} \cdot s_{\text{Residuen}} = \sqrt{\frac{243}{242}} \cdot 1.0199426 = 1.0220477
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der Median der Residuen ist nicht gleich Null, wie der Mittelwert. (Welcher auch hier als numerisch Null interpretiert werden muss!)
Es könnte also eine linkssteile, rechtsschiefe Verteilung der Residuen vorliegen.
Betrachten wir dazu das Histogramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;histogram(~residuals(linMod), nint = 19)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Schon beim ersten Blick auf das Histogramm kann an eine Normalverteilung der Residuen nicht mehr so ganz geglaubt werden.&lt;/p&gt;
&lt;p&gt;Ein Shapiro-Wilk-Test&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; hat als Nullhypothese die Annahme, dass die Daten normalverteilt sind!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shapiro.test(residuals(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(linMod)
## W = 0.96728, p-value = 2.171e-05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Davon ist nach dem Ergebnis eben sowenig auszugehen, wie nach einem Blick auf das QQ-Normal-Diagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(linMod), col = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ein K.O.-Kriterium für gute Prognosen.&lt;/p&gt;
&lt;p&gt;Wie gut aber beschreibt unsere Regressionsgerade die Daten?&lt;/p&gt;
&lt;p&gt;Als Maß dafür können wir das Bestimmtheitsmaß nehmen.&lt;/p&gt;
&lt;p&gt;Ein kurzer Blick auf die Situation, der Mittelwert der Trinkgelder ist&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \bar{y} =  \frac{1}{n} \cdot \sum_{i=1}^n y_i = 2.9982787.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir erhalten so folgendes Diagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mypanel &amp;lt;- function(x, y) {
    panel.xyplot(x, y)
    panel.abline(h = mean(y), lwd = 1.2, lty = 2, col = &amp;quot;darkgreen&amp;quot;)
    panel.lmline(x, y, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;,
            padding.text = 8,
            columns = 2,
            just = c(&amp;quot;center&amp;quot;, &amp;quot;bottom&amp;quot;),
            lines = list(col = c(&amp;quot;darkgreen&amp;quot;, &amp;quot;red&amp;quot;), lty = c(2, 2), lwd = 1.2),
            text = list(c(expression(bar(y)), expression(hat(beta)[0]+hat(beta)[total_bill] * x[total_bill]))),
            text = list(c(&amp;quot;Mittelwert Trinkgeld&amp;quot;, &amp;quot;Regressionsgerade&amp;quot;))
    )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Varianz &lt;span class=&#34;math inline&#34;&gt;\(s^2_{y_i}=1.9144546\)&lt;/span&gt; beschreibt die mittlere quadratische Abweichung der Datenpunkte &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; vom Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt;.
Diese Varianz lässt sich Zerlegen in einen Anteil, der durch die Regressionsgerade &lt;em&gt;erklärt&lt;/em&gt; wird und in einen Anteil, der durch die Regressionsgerade &lt;em&gt;nicht erklärt&lt;/em&gt; wird.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    s^2_{y_i} = s^2_{\hat{y}_i} + s^2_{\hat{e}_i}
\]&lt;/span&gt;
Dividiert man beider Seiten durch die Varianz &lt;span class=&#34;math inline&#34;&gt;\(s^2_{y_i}\)&lt;/span&gt;, so normiert man den Ausdruck und kann den Faktor &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n-1}\)&lt;/span&gt; (bzw. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\)&lt;/span&gt;) herauskürzen. Es bleibt dann:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    1 = \frac{\sum_{i=1}^n (\bar{y}- \hat{y_i})^2}{\sum_{i=1}^n (\bar{y}-y_i)^2} + \frac{\sum_{i=1}^n (\hat{e_i})^2}{\sum_{i=1}^n (\bar{y}-y_i)^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Multipliziert man beide Seiten mit &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^n (y_i)^2\)&lt;/span&gt;, so erhält man:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \sum_{i=1}^n (\bar{y}- y_i)^2 = \sum_{i=1}^n (\bar{y}- \hat{y_i})^2+ \sum_{i=1}^n (\hat{e_i})^2 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Zur Vereinfachung nennt man die einzelnen Summen in dem Ausdruck wie folgt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der erste Ausdruck heißt &lt;strong&gt;Gesamtvarianz&lt;/strong&gt; oder &lt;strong&gt;total sum of squares&lt;/strong&gt; oder kurz &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt;&lt;/strong&gt;, (oder &lt;strong&gt;TSS&lt;/strong&gt;) er ist die Summe der quadrierten Differenzen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_T = \sum_{i=1}^n (\bar{y}-y_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der zweite Ausdruck heißt &lt;strong&gt;Modellvarianz&lt;/strong&gt; oder &lt;strong&gt;model sum of squares&lt;/strong&gt; oder kurz &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt;&lt;/strong&gt; (oder &lt;strong&gt;RSS&lt;/strong&gt;), er ist die Summe der quadrierten Differenzen aus dem Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt; und der Punkte auf der Regressionsgeraden &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_M = \sum_{i=1}^n (\bar{y}-\hat{y}_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der dritte Ausdruck heißt &lt;strong&gt;Gesamt-Verhersage-Fehler&lt;/strong&gt;, &lt;strong&gt;Fehlersteuung der Regression&lt;/strong&gt; oder &lt;strong&gt;error sum of squares&lt;/strong&gt; oder kurz &lt;span class=&#34;math inline&#34;&gt;\(SS_E\)&lt;/span&gt; (oder &lt;strong&gt;ESS&lt;/strong&gt;), er ist die Summe der quadratischen Differenz aus den Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; und den Punkten der Regressionsgeraden &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_E = \sum_{i=1}^n (\hat{y}_i-y_i)^2 = \sum_{i=1}^n (\hat{e}_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können daher auch kurz&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_T = SS_M + SS_E
\]&lt;/span&gt;
schreiben und sparen uns die ganzen Summenzeichen.&lt;/p&gt;
&lt;p&gt;Die Güte einer Regression wollen wir durch den Anteil der durch das Model erklärten Varianz (also der &lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt;) ausdrücken und stellen daher nach &lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_M = SS_T - SS_E
\]&lt;/span&gt;
Teilen wir beide Seiten durch &lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt; also der maximalen (weil totalen) Quadratsumme, so erhalten wir:
&lt;span class=&#34;math display&#34;&gt;\[
    \frac{SS_M}{SS_T} = \frac{SS_T}{SS_T} - \frac{SS_E}{SS_T} = 1 - \frac{SS_E}{SS_T}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Den Ausdruck &lt;span class=&#34;math inline&#34;&gt;\(\frac{SS_M}{SS_T}\)&lt;/span&gt; nennen wir &lt;strong&gt;Bestimmtheitsmaß&lt;/strong&gt; und schreiben dafür &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;. Es ist ein Wert zwischen 0 und 1, der den Anteil der durch das Modell beschriebenen Varianz in Bezug auf die Gesamtvarianz angibt. Kraft Definition ist &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; im eindimensionalen Fall tatsächlich das Quadrat des (Pearson-)Korrelationskoeffizienten &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;. (M.a.W.: &lt;span class=&#34;math inline&#34;&gt;\(R^2= r^2\)&lt;/span&gt;.)&lt;/p&gt;
&lt;p&gt;In unserer Zusammenfassung des linearen Models findet sich dieser Wert auch. Und zwar unter dem Begriff:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Multiple R-squared:  0.4566, &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es gilt ja:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    R^2 = 1 - \frac{SS_E}{SS_T} = 1 - \frac{s^2_{\hat{e}_i}}{s^2_{y_i}} = 1 - \frac{1.0402829}{1.9144546} = 0.4566166
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der Wert&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## ..., Adjusted R-squared:  0.4544&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;erklärt sich daraus&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, dass das Bestimmheitsmaß um so größer wird je größer die Zahl der unabhängigen Variablen wird.
Und zwar &lt;em&gt;unabhöngig&lt;/em&gt; davon, ob weitere unabhängige Variablen wirklich einen Beitrag zur Erklärungskraft liefern.
Daher nutzt man besser das &lt;strong&gt;korrigierte Bestimmtheitsmaß&lt;/strong&gt; (engl.: &lt;em&gt;adjusted R-squared&lt;/em&gt;) &lt;span class=&#34;math inline&#34;&gt;\(\bar{R}^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \begin{align*}
        \bar{R}^2 &amp;amp;= 1- (1-R^2) \cdot \frac{n-1}{n-p-1}\\ 
                  &amp;amp;= R^2 - (1-R^2)  \cdot \frac{p}{n-p-1}
    \end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wobei &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; die Anzahl der unabhängigen Variablen im Modell darstellt.
In unserem Beispiel gilt daher:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \begin{align*}
        \bar{R}^2 &amp;amp;= 1 - (1-R^2)  \cdot \frac{n-1}{n-p-1} \\
                  &amp;amp;= 1 - (1- 0.4566166)  \cdot \frac{244-1}{244- 1- 1} \\
                  &amp;amp;= 0.4543712
    \end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vorsicht:&lt;/strong&gt; Das &lt;em&gt;korrigierte Bestimmtheitsmaß&lt;/em&gt; ist nicht mehr an das Intervall &lt;span class=&#34;math inline&#34;&gt;\([0; 1]\)&lt;/span&gt; gebunden!
Es kann negative Werte annehmen, ist in der Regel kleiner als das (unkorrigierte) Bestimmtheitsmaß und erreicht die obere Grenze (&lt;span class=&#34;math inline&#34;&gt;\(\bar{R}^2=1\)&lt;/span&gt;) genau dann, wenn &lt;span class=&#34;math inline&#34;&gt;\(R^2 = 1\)&lt;/span&gt; ist.&lt;/p&gt;
&lt;p&gt;Bei der &lt;strong&gt;Gesamtsignifikanz des Modells&lt;/strong&gt; (auch &lt;strong&gt;Overall-F-Test&lt;/strong&gt; genannt) wird geprüft, ob mindestens eine Variable einen Erklärungsgehalt für das Modell liefert.&lt;/p&gt;
&lt;p&gt;Falls diese Hypothese verworfen wird ist somit das Modell nutzlos.
Dieser Test lässt sich so interpretieren als würde man die gesamte Güte des Modells, also das &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; des Modells, testen.
Aus diesem Grund wird der F-Test der Gesamtsignifikanz des Modells auch als Anpassungsgüte-Test bezeichnet.
Die Nullhypothese des F-Test der Gesamtsignifikanz des Modells sagt aus, dass alle erklärenden Variablen keinen Einfluss auf die abhängige Variable haben.
Sowohl die abhängige Variable als auch die unabhängigen Variablen können binär (kategoriell) oder metrisch sein.
Der &lt;em&gt;Wald-Test&lt;/em&gt; kann dann die Hypothesen testen (ohne Einbezug des Achsenabschnittes):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    H_{0}\colon \beta _{1}=\beta _{2}=\ldots =\beta _{k}\;=\;0\Rightarrow R^{2}=0
\]&lt;/span&gt;
gegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    H_{1}:\beta _{j}\;\neq \;0\;\mathrm {f{\ddot {u}}r\;mindestens\;ein} \;j\in \{1,\ldots ,k\}\Rightarrow R^{2}\neq 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Teststatistik dieses Tests lautet&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
    F\;\;{\stackrel {H_{0}}{=}}{\frac {R^{2}}{1-R^{2}}} \cdot {\frac {n-p-1}{p}}\;\;{\stackrel {H_{0}}{\sim }}\;\;F(p,n-p)
\end{aligned}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle (n-p-1)\)&lt;/span&gt; Freiheitsgraden.
Überschreitet der empirische F-Wert einen kritischen F-Wert, der zu einem a priori festgelegten Signifikanzniveau &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, so verwirft man die Nullhypothese &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt;.
Das &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; ist dann ausreichend groß und mindestens ein Regressor trägt also vermutlich genügend viel Information zur Erklärung von &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; bei.
Es ist naheliegend bei hohen F-Werten die Nullhypothese zu verwerfen, da ein hohes Bestimmtheitsmaß zu einem hohen F-Wert führt.
Wenn der &lt;em&gt;Wald-Test&lt;/em&gt; für eine oder mehrere unabhängige Variablen die Nullhypothese ablehnt, dann kann man davon ausgehen, dass die zugehörigen Parameter ungleich Null sind, so dass die Variable(n) in das Modell mit einbezogen werden sollten.&lt;/p&gt;
&lt;p&gt;In unserem Beispiel ist&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    F={\frac {R^{2}}{1-R^{2}}} \cdot {\frac {n-p-1}{p}} = \frac{0.4566166}{1-0.4566166} \cdot \frac{244-1-1}{1} = 203.3577233
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;der Wert in der Zeile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;mit Parametern &lt;span class=&#34;math inline&#34;&gt;\(p=1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(n-p-1=242\)&lt;/span&gt; Freiheitsgraden.&lt;/p&gt;
&lt;p&gt;Der p-Wert von (numerisch) 0, liefert also ein hinreichendes Indiz dafür, dass der Rechnungsbetrag einen echten Beitrag liefert.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Parallelverschiebung&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Parallelverschiebung&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Shapiro-Wilk-Test&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Shapiro-Wilk-Test&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Bestimmtheitsmaß#Das_korrigierte_Bestimmtheitsmaß&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Bestimmtheitsmaß#Das_korrigierte_Bestimmtheitsmaß&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Prognose-, Konfidenz- und Fiduzialintervalle</title>
      <link>https://sefiroth.net/nab/post/prognose-konfidenz-und-fiduzialintervalle/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/prognose-konfidenz-und-fiduzialintervalle/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;*&lt;strong&gt;WORK IN PROGRESS&lt;/strong&gt;
Dieser Eintrag ist noch nicht fertig und wird in der Zukunft erweitert!&lt;/p&gt;
&lt;div id=&#34;konfidenzintervalle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Konfidenzintervalle&lt;/h2&gt;
&lt;div id=&#34;definition-von-konfidenzintervallen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Definition von Konfidenzintervallen&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Für unabhängig identisch verteilte Zufallsvariablen &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dotsc, X_n\)&lt;/span&gt; mit unbekanntem reellen Verteilungsparameter &lt;span class=&#34;math inline&#34;&gt;\(\vartheta\)&lt;/span&gt; kann unter bestimmten Umständen zwei Stichprobenfunktionen &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; angeben, so dass&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(U &amp;lt; \vartheta &amp;lt; V) \geq \gamma\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt, mit &lt;span class=&#34;math inline&#34;&gt;\(\gamma \in (0,1)\)&lt;/span&gt;.
Dann heißt das (stochastische) Intervall &lt;span class=&#34;math inline&#34;&gt;\([U, V]\)&lt;/span&gt; ein &lt;strong&gt;Konfidenzintervall&lt;/strong&gt; für &lt;span class=&#34;math inline&#34;&gt;\(\vartheta\)&lt;/span&gt; zum Konfidenzniveau &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; (auch: ein &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;-Konfidenzintervall&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Die Realisationen &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; von &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; bilden das &lt;strong&gt;Schätzintervall&lt;/strong&gt; &lt;span class=&#34;math inline&#34;&gt;\([u, v]\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Da die Realisationen &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; der Grenzen &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; keine Zufallsvariablen sind und &lt;span class=&#34;math inline&#34;&gt;\(\vartheta\)&lt;/span&gt; ein fixer Wert ist, kann man &lt;strong&gt;nicht&lt;/strong&gt; sagen, dass das Schätzintervall &lt;span class=&#34;math inline&#34;&gt;\([u, v]\)&lt;/span&gt; mit einer Wahrscheinlichkeit von &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; den unbekannten Parameter &lt;span class=&#34;math inline&#34;&gt;\(\vartheta\)&lt;/span&gt; enthält. Es bedeutet vielmehr, dass im Mittel ein Anteil von &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; aller so berechneten Schätzintervalle den unbekannten Parameter überdecken. Dem nicht widersprechend, kann –- wie bereits von Ronald Fisher festgestellt – in manchen Modellen die Qualität des Schätzintervalls von den Daten abhängen und sogar zu Antworten führen, die mit Blick auf die Daten unsinnig sind. Probleme mit solcher Post-Data-Inkohärenz führen zur Theorie der bedingten Inferenz. Ein weiteres Problem sind die Stichprobenfunktionen U und V an sich. Um diese zu finden werden oft Vereinfachungen getroffen, dadurch können systematische Fehler entstehen, oft es gibt mehrere Konfidenzintervalle (bei der Binomialverteilung z.B. nach Clopper-Pearson, Agresti-Coull oder Wald), welche oft unterschiedliche Werte liefern.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-beispiel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein Beispiel&lt;/h3&gt;
&lt;p&gt;Wir nehmen zunächst als Population &lt;span class=&#34;math inline&#34;&gt;\(N=1000\)&lt;/span&gt; normalverteilte Zufallszahlen mit dem Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\mu= 0\)&lt;/span&gt; und der Standardabweichung &lt;span class=&#34;math inline&#34;&gt;\(\sigma=2.0088\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Dazu das Histogramm der Population:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;histogram(pop, xlab=&amp;quot;Population&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-04-prognose-konfidenz-und-fiduzialintervalle_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Aus dieser Population ziehen wir eine Stichprobe &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; vom Umfang $n=$40 und erhalten die folgenden statistischen Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    min      Q1 median    Q3   max   mean    sd  n missing
##  -3.38 -0.9781 0.2042 1.546 4.002 0.1877 1.901 40       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir wollen nun den wahren Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\vartheta=\mu\)&lt;/span&gt; mit Hilfe der Stichprobe &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; schätzen. So ist es ja in der Realität auch, denn normalerweise haben wir die Daten über die Population nicht.&lt;/p&gt;
&lt;p&gt;Die Schätzfunktion für den Mittelwert lautet nun
&lt;span class=&#34;math display&#34;&gt;\[\bar{X} = \frac1n \sum_{i=1}^n X_i\]&lt;/span&gt;,
und damit die konkrete Punktschätzung
&lt;span class=&#34;math display&#34;&gt;\[\hat{\mu}=\bar{x}= \sum_{i=1}^n x_i\]&lt;/span&gt;
liefert den Wert &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}=\)&lt;/span&gt; 0.1877.&lt;/p&gt;
&lt;p&gt;In unserem Beispiel unterscheiden sich die beiden Werte um &lt;span class=&#34;math inline&#34;&gt;\(\mu - \hat{\mu}=\)&lt;/span&gt; -0.1877.&lt;/p&gt;
&lt;p&gt;Ein 95%-Konfidenzintervall nimmt nun den geschätzen Wert &lt;span class=&#34;math inline&#34;&gt;\(\hat{\mu}\)&lt;/span&gt; als Grundlage und gibt liefert ein Intervall mit der Eigentschaft, ausgehend von den konkreten Stichproben in 95% der Fälle den tatsächlichen Wert &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; zu umfassen. Es ist also
&lt;span class=&#34;math display&#34;&gt;\[\gamma = 0.95 = 1 - \alpha = 1 - 0.05, \quad \alpha = 0.05\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dazu werden die beiden Stichprobenfunktionen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[U=U(X_1, \dots, X_n)=\bar{X}-z_{\left(1-\frac{\alpha}{2}\right)}\cdot\frac{\sigma}{\sqrt{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[V=V(X_1, \dots, X_n)=\bar{X}-z_{\left(1-\frac{\alpha}{2}\right)}\cdot\frac{\sigma}{\sqrt{n}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit der &lt;em&gt;bekannten&lt;/em&gt; Standardabweichung &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; der &lt;em&gt;Population&lt;/em&gt; und der Stichprobengröße &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; nun mit der konkreten Realisation &lt;span class=&#34;math inline&#34;&gt;\(x_1, \dots, x_n\)&lt;/span&gt; der Stichprobe gefüttert und wir erhalten damit&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[u = \bar{x}-z_{\left(1-\frac{\alpha}{2}\right)}\cdot\frac{\sigma}{\sqrt{n}} = 0.1877-z_{\left(0.975\right)}\cdot\frac{2.0088}{\sqrt{40}}=-0.4348\]&lt;/span&gt;
und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[v = \bar{x}+z_{\left(1-\frac{\alpha}{2}\right)}\cdot\frac{\sigma}{\sqrt{n}} = 0.1877+z_{\left(0.975\right)}\cdot\frac{2.0088}{\sqrt{40}}=0.8102.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Realisation unseres 95%-Konfidenzintervall lautet nun also:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[[-0.4348; 0.8102]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Was hat es nun mit den ominösen 95% auf sich?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Das Konfidenzintervall ist ein stochastisches Intervall, d.h. die hier angegebenen Werte für &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; sind abhängig von der Realisation &lt;span class=&#34;math inline&#34;&gt;\(x_1, \dots, x_n\)&lt;/span&gt;, also der konkreten Stichprobe.&lt;/p&gt;
&lt;p&gt;Nehmen wir nun also einmal eine neue Stichprobe und berechnen erneut die Realisation unseres 95%-Konfidenzintervalls, so erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[[-0.7033; 0.5418]\]&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Interval coverage:&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     cover
## n     Low  Yes High
##   40 0.00 0.98 0.02&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please
## use `guide = &amp;quot;none&amp;quot;` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-04-prognose-konfidenz-und-fiduzialintervalle_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prognoseintervalle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prognoseintervalle&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;fuduzialintervalle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fuduzialintervalle&lt;/h2&gt;
&lt;p&gt;Quellen:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logik in der Statistik; Andrea Wiencierz, 7.10.2007 Link: &lt;a href=&#34;https://static.aminer.org/pdf/PDF/000/230/772/induktive_inferenz_und_mehrwertige_logik.pdf&#34; class=&#34;uri&#34;&gt;https://static.aminer.org/pdf/PDF/000/230/772/induktive_inferenz_und_mehrwertige_logik.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;vgl: &lt;a href=&#34;https://de.wikipedia.org/wiki/Konfidenzintervall&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Konfidenzintervall&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Konfidenzintervalle</title>
      <link>https://sefiroth.net/nab/post/konfidenzintervalle/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/konfidenzintervalle/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Stub!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Zentrales Schwankungsintervall</title>
      <link>https://sefiroth.net/nab/post/zentrales-schwankungsintervall/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/zentrales-schwankungsintervall/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Das &lt;strong&gt;zentrale Schwankungsintervall&lt;/strong&gt; sagt etwas über die Präzision der Lageschätzung eines Parameters (zum Beispiel eines Mittelwertes) aus. Das Schwankungsintervall schließt einen Bereich um den wahren Wert des Parameters in der Grundgesamtheit ein, der – vereinfacht gesprochen – mit einer zuvor festgelegten Sicherheitswahrscheinlichkeit den aus der Stichprobe geschätzten Parameter enthält.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;vgl: &lt;a href=&#34;https://de.wikipedia.org/wiki/Zentrales_Schwankungsintervall&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Zentrales_Schwankungsintervall&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Quartile, Quantile, Perzentile etc.</title>
      <link>https://sefiroth.net/nab/post/quartile-quantile-perzentile-etc/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/quartile-quantile-perzentile-etc/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;“Was hat das eigentlich mit den Quartilen, Quantilen und so weiter auf sich?”
Diese Frage kommt ab und zu in Vorlesungen zur Statistik vor. Dabei ist die Antwort recht einfach.&lt;/p&gt;
&lt;div id=&#34;quantile&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quantile&lt;/h2&gt;
&lt;div id=&#34;definitorische-antwort&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Definitorische Antwort&lt;/h3&gt;
&lt;p&gt;Für eine gegebene reelle Zufallsvariable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; heißt eine reelle Zahl &lt;span class=&#34;math inline&#34;&gt;\(x_p\)&lt;/span&gt; ein &lt;strong&gt;p-Quantil&lt;/strong&gt; (von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;), falls gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X \leq x_p) \leq p \quad \text{ und }\quad P(x_p \leq X) \geq 1-p.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;was-bedeutet-das-denn-nun-konkret&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was bedeutet das denn nun konkret?&lt;/h3&gt;
&lt;p&gt;Nun, ein Quantil ist ein Schwellenwert.
Ein bestimmter Anteil der Werte ist kleiner als das Quantil, der Rest ist größer.
Das 25-%-Quantil beispielsweise ist der Wert, für den gilt, dass 25 % aller Werte kleiner sind als dieser Wert.
Quantile formalisieren praktische Aussagen wie „25 % aller Frauen sind kleiner als 1,62 m“ –- wobei 1,62 m hier das 25-%-Quantil ist.&lt;/p&gt;
&lt;p&gt;Spezielle Quantile sind der &lt;em&gt;Median&lt;/em&gt;, die &lt;em&gt;Quartile&lt;/em&gt;, die &lt;em&gt;Quintile&lt;/em&gt;, die &lt;em&gt;Dezile&lt;/em&gt; und die &lt;em&gt;Perzentile&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;Wir betrachten dazu in den Bespielen die Datenreihe &lt;code&gt;dr&lt;/code&gt; an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Die Zahlen von 0 bis 600 
dr &amp;lt;- 0:600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;median&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Median&lt;/h3&gt;
&lt;p&gt;Der &lt;strong&gt;Median&lt;/strong&gt; (von lat. &lt;em&gt;Medium&lt;/em&gt; für „Mitte, Mittelpunkt“ abgeleiteter Begriff mit der Bedeutung “in der Mitte gelegen”) die das 50-%-Quantil. Der Wert, welcher die Datenreihe (bestenfalls) in zwei (etwa) gleich große Abschnitte trennt. Sehr oft schreibt man &lt;span class=&#34;math inline&#34;&gt;\(x_{med}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{50\%}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{Med}\)&lt;/span&gt; oder &lt;span class=&#34;math inline&#34;&gt;\(Q_2\)&lt;/span&gt; für den Median&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(dr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 300&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;terzile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Terzile&lt;/h3&gt;
&lt;p&gt;Als &lt;strong&gt;Terile&lt;/strong&gt; (von lat. &lt;em&gt;tertius&lt;/em&gt; “der Dritte”) werden die beiden Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=1/3\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=2/3\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in drei Abschnitte.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        0% 33.33333% 66.66667%      100% 
##         0       200       400       600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quartile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quartile&lt;/h3&gt;
&lt;p&gt;Die &lt;strong&gt;Quartile&lt;/strong&gt; (von lat. &lt;em&gt;quartus&lt;/em&gt; „der Vierte“) werden die Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=25\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=50\%\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=75\%\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in vier Abschnitte.
Dabei schreibt man oft: &lt;span class=&#34;math inline&#34;&gt;\(Q_1 = x_{0{,}25}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{Med} = Q_2 = x_{0{,}50}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Q_3 = x_{0{,}75}\)&lt;/span&gt; für die drei Quantile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr) # oder auch: quantile(dr, probs=seq(0, 1, 1/4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  25%  50%  75% 100% 
##    0  150  300  450  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quintile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quintile&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Quintile&lt;/strong&gt; (von lat. &lt;em&gt;quintus&lt;/em&gt; “der Fünfte”) werden die Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=20\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=40\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=60\%\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=80\%\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in fünf Abschnitte.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  20%  40%  60%  80% 100% 
##    0  120  240  360  480  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dezile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dezile&lt;/h3&gt;
&lt;p&gt;Die Quantile für vielfache von &lt;span class=&#34;math inline&#34;&gt;\(0{,}1\)&lt;/span&gt; also für &lt;span class=&#34;math inline&#34;&gt;\(p=0{,}1;0{,}2;\dots ;0{,}9\)&lt;/span&gt; werden &lt;strong&gt;Dezile&lt;/strong&gt; (von mittellateinisch &lt;em&gt;decimalis&lt;/em&gt;, zu lat. &lt;em&gt;decem&lt;/em&gt; „zehn“) genannt.
Dabei heißt das &lt;span class=&#34;math inline&#34;&gt;\(0{,}1\)&lt;/span&gt;-Quantil das erste Dezil, das &lt;span class=&#34;math inline&#34;&gt;\(0{,}2\)&lt;/span&gt;-Quantil das zweite Dezil usw.
Unterhalb des ersten Dezils liegen 10 % der Stichprobe, oberhalb entsprechend 90 % der Stichprobe.
Ebenso liegen 40 % der Stichprobe unterhalb des vierten Dezils und 60 % oberhalb.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/10))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
##    0   60  120  180  240  300  360  420  480  540  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;perzentile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Perzentile&lt;/h3&gt;
&lt;p&gt;Als &lt;strong&gt;Perzentile&lt;/strong&gt; (von lat.-ital. &lt;em&gt;per centum&lt;/em&gt; “von Hundert, Hundertstel”) werden die Quantile von &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle 0{,}01\)&lt;/span&gt; bis $ 0{,}99$ in Schritten von &lt;span class=&#34;math inline&#34;&gt;\(0{,}01\)&lt;/span&gt; bezeichnet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/100))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%   1%   2%   3%   4%   5%   6%   7%   8%   9%  10%  11%  12%  13%  14%  15% 
##    0    6   12   18   24   30   36   42   48   54   60   66   72   78   84   90 
##  16%  17%  18%  19%  20%  21%  22%  23%  24%  25%  26%  27%  28%  29%  30%  31% 
##   96  102  108  114  120  126  132  138  144  150  156  162  168  174  180  186 
##  32%  33%  34%  35%  36%  37%  38%  39%  40%  41%  42%  43%  44%  45%  46%  47% 
##  192  198  204  210  216  222  228  234  240  246  252  258  264  270  276  282 
##  48%  49%  50%  51%  52%  53%  54%  55%  56%  57%  58%  59%  60%  61%  62%  63% 
##  288  294  300  306  312  318  324  330  336  342  348  354  360  366  372  378 
##  64%  65%  66%  67%  68%  69%  70%  71%  72%  73%  74%  75%  76%  77%  78%  79% 
##  384  390  396  402  408  414  420  426  432  438  444  450  456  462  468  474 
##  80%  81%  82%  83%  84%  85%  86%  87%  88%  89%  90%  91%  92%  93%  94%  95% 
##  480  486  492  498  504  510  516  522  528  534  540  546  552  558  564  570 
##  96%  97%  98%  99% 100% 
##  576  582  588  594  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
