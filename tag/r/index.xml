<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | Norman&#39;s Academic Blog</title>
    <link>https://sefiroth.net/nab/tag/r/</link>
      <atom:link href="https://sefiroth.net/nab/tag/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>de-de</language><copyright>© in 2017-2021 by Norman Markgraf</copyright><lastBuildDate>Sun, 27 Jun 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://sefiroth.net/nab/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>R</title>
      <link>https://sefiroth.net/nab/tag/r/</link>
    </image>
    
    <item>
      <title>Datenjudo für Fragebögen </title>
      <link>https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/</link>
      <pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Ab und zu bekomme ich die Frage, wie man einen Fragebogen mit Likert-Scalen-Items auswerten kann.&lt;/p&gt;
&lt;p&gt;Dazu kann etwas gezieltes Datenjudo helfen. Wir schauen uns das folgende generierte Mini-Beispiel an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)  # Basis Paket
library(tibble)  # Eine modernere Variante der data.frames!
set.seed(2009)   # Reproduzierbarkeit

N &amp;lt;- 25  # Anzahl der Testzeileneinträge in den &amp;quot;testdaten&amp;quot;!

# Wir wollen eine Likert-Scale 
minLikert &amp;lt;- 1  # bis
maxLikert &amp;lt;- 6  # erstellen.

# Zum späteren Umrechnen der inversen Items:
maxInvItem &amp;lt;- maxLikert + 1

# Wir bauen uns eine Testumfrage mit zwei Itemserien 
# (AS1-AS6 und BS1-BS6) und N Beobachtungen.
# Die Items AS3, AS4  und BS1 und BS5 sind dabei 
# inverse Items, welche später umgerechnet werden:
testdaten &amp;lt;- tibble(
    ID = 1:N,
    # AS1-AS6 bilden ein Itemset:
    AS1 = sample(minLikert:maxLikert, N, replace = TRUE),
    AS2 = sample(minLikert:maxLikert, N, replace = TRUE),
    AS3 = sample(minLikert:maxLikert, N, replace = TRUE),
    AS4 = sample(minLikert:maxLikert, N, replace = TRUE),
    AS5 = sample(minLikert:maxLikert, N, replace = TRUE),
    AS6 = sample(minLikert:maxLikert, N, replace = TRUE),
    # BS1-BS5 bilden ein Itemset:
    BS1 = sample(minLikert:maxLikert, N, replace = TRUE),
    BS2 = sample(minLikert:maxLikert, N, replace = TRUE),
    BS3 = sample(minLikert:maxLikert, N, replace = TRUE),
    BS4 = sample(minLikert:maxLikert, N, replace = TRUE),
    BS5 = sample(minLikert:maxLikert, N, replace = TRUE),
    # Geschlecht als sex mit (1 für Frauen und 2 für Männer)
    sex = sample(1:2, N, replace = TRUE)
)

# Orinal testdaten einmal ausgeben:
head(testdaten)
#&amp;gt; # A tibble: 6 x 13
#&amp;gt;      ID   AS1   AS2   AS3   AS4   AS5   AS6   BS1   BS2   BS3   BS4   BS5   sex
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1     1     4     4     1     1     2     4     5     5     3     2     3     2
#&amp;gt; 2     2     2     1     2     2     5     6     4     5     2     2     6     1
#&amp;gt; 3     3     4     4     6     3     3     4     3     3     4     1     5     1
#&amp;gt; 4     4     2     6     1     4     5     4     6     4     5     1     3     1
#&amp;gt; 5     5     3     1     3     5     5     6     6     1     2     6     5     1
#&amp;gt; 6     6     6     4     1     3     6     6     4     6     5     3     3     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Spalten AS3, AS4 und BS1, BS5 waren inverse Items, die wir noch umrechnen müssen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Inverse Item umrechnen:
testdaten |&amp;gt;
    mutate(
        AS3 = maxInvItem - AS3,
        AS4 = maxInvItem - AS4,
        BS1 = maxInvItem - BS1,
        BS5 = maxInvItem - BS5
    ) -&amp;gt; testdaten_korrigiert 

# Die Daten mit den umgerechnetern inversen Items:
head(testdaten_korrigiert)
#&amp;gt; # A tibble: 6 x 13
#&amp;gt;      ID   AS1   AS2   AS3   AS4   AS5   AS6   BS1   BS2   BS3   BS4   BS5   sex
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt; 1     1     4     4     6     6     2     4     2     5     3     2     4     2
#&amp;gt; 2     2     2     1     5     5     5     6     3     5     2     2     1     1
#&amp;gt; 3     3     4     4     1     4     3     4     4     3     4     1     2     1
#&amp;gt; 4     4     2     6     6     3     5     4     1     4     5     1     4     1
#&amp;gt; 5     5     3     1     4     2     5     6     1     1     2     6     2     1
#&amp;gt; 6     6     6     4     6     4     6     6     3     6     5     3     4     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die jeweiligen Itemsets werden nun zur einem Wert (Gesamtscore)
zusammengefasst, in dem wir jeweils den Mittelwert von &lt;code&gt;AS1&lt;/code&gt;-&lt;code&gt;AS6&lt;/code&gt;
und &lt;code&gt;BS1&lt;/code&gt;-&lt;code&gt;BS5&lt;/code&gt; bildenund in &lt;code&gt;AS&lt;/code&gt; bzw. &lt;code&gt;BS&lt;/code&gt; speichern:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir fassen nun die AS1-AS6 und die BS1-BS5 zusammen 
# und bilden die jeweiligen Mittelwerte:
testdaten_korrigiert |&amp;gt;
    group_by(ID, sex) |&amp;gt;  # Damit wird für jede Zeile die Zusammenfassung gemacht!
    summarise(
        AS = mean(c(AS1, AS2, AS3, AS4, AS5, AS6)),
        BS = mean(c(BS1, BS2, BS3, BS4, BS5))
    ) -&amp;gt; testdaten_sum

# Ausgabe der Mittelwerte der AS und BS
head(testdaten_sum)
#&amp;gt; # A tibble: 6 x 4
#&amp;gt; # Groups:   ID [6]
#&amp;gt;      ID   sex    AS    BS
#&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1     1     2  4.33   3.2
#&amp;gt; 2     2     1  4      2.6
#&amp;gt; 3     3     1  3.33   2.8
#&amp;gt; 4     4     1  4.33   3  
#&amp;gt; 5     5     1  3.5    2.4
#&amp;gt; 6     6     1  5.33   4.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Datentabelle &lt;code&gt;testdaten_sum&lt;/code&gt; enthält nun die Spalten &lt;code&gt;AS&lt;/code&gt; und &lt;code&gt;BS&lt;/code&gt; mit den entsprechenden Mittelwerten der einzelnen Items &lt;code&gt;AS1&lt;/code&gt;-&lt;code&gt;AS6&lt;/code&gt; sowieso &lt;code&gt;BS1&lt;/code&gt;- &lt;code&gt;BS5&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Wir wollen nun die Ergebnisse als Boxplots anzeigen lassen. Dafür benennen wir die Geschlechter von 1,2 auf “Frau”, “Mann” um:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;testdaten_sum |&amp;gt;
    mutate(sex = factor(sex, levels = c(1, 2),
                             labels = c(&amp;quot;Frau&amp;quot;, &amp;quot;Mann&amp;quot;))
    ) -&amp;gt; testdaten_sex &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun können wir die Boxplots erstellen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Darstellung der Ergebnisse als Boxplot AS ~ sex:
gf_boxplot(AS ~ sex, data = testdaten_sex) %&amp;gt;%
    gf_labs(
        title = &amp;quot;Boxplot von AS nach Geschlechtern&amp;quot;,
        x = &amp;quot;Geschlechter&amp;quot;,
        y = &amp;quot;Item AS&amp;quot;
    ) |&amp;gt;
  gf_refine(
    scale_y_continuous(
      breaks = 1:6, 
      label = 1:6,
      limits = c(2.5, 4.5)  # Gibt den Bereich von 2.5 bis 4.5 aus!
    )  
  )

# Darstellung der Ergebnisse als Boxplot BS ~ sex:
gf_boxplot(BS ~ sex, data = testdaten_sex) %&amp;gt;%
    gf_labs(
        title = &amp;quot;Boxplot von BS nach Geschlechtern&amp;quot;,
        x = &amp;quot;Geschlechter&amp;quot;,
        y = &amp;quot;Item BS&amp;quot;
    ) |&amp;gt;
  gf_refine(
    scale_y_continuous(
      breaks = 1:6, 
      label = 1:6,
      limits = c(1, 6)  # Gibt den ganzen Bereich von 1 bis 6 aus!
    )  
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Kennzahlen dazu erhalten wir mit &lt;code&gt;favstats&lt;/code&gt;. Dabei wählen wir die ersten sechs Einträge (Variabelbezeichnung und Q0 bis Q4) aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(AS ~ sex, data = testdaten_sex)[1:6]
#&amp;gt;    sex      min       Q1   median       Q3      max
#&amp;gt; 1 Frau 2.166667 3.333333 3.666667 4.166667 5.333333
#&amp;gt; 2 Mann 3.666667 4.000000 4.333333 4.333333 4.500000
favstats(BS ~ sex, data = testdaten_sex)[1:6]
#&amp;gt;    sex min  Q1 median  Q3 max
#&amp;gt; 1 Frau 2.4 2.8    3.4 4.2 4.6
#&amp;gt; 2 Mann 2.6 3.2    3.3 3.8 4.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Unter der Verwendung des Pakets &lt;code&gt;likert&lt;/code&gt; (&lt;a href=&#34;https://github.com/jbryer/likert&#34; class=&#34;uri&#34;&gt;https://github.com/jbryer/likert&lt;/a&gt;) können wir die Ausgaben auch noch etwas schöner gestalten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(likert)

# Wir wählen nur den Itemset BS aus und speichern in in items2:
testdaten_korrigiert |&amp;gt;
  select(
    starts_with(&amp;quot;BS&amp;quot;)
  ) -&amp;gt; items2

# Leider mag likert tibbels nicht so gerne, daher:
items2 &amp;lt;- as.data.frame(items2)

# Wir geben den Items noch ein paar Buzzwords:
names(items2) &amp;lt;- c(&amp;quot;Gesundheit&amp;quot;, &amp;quot;Familie&amp;quot;, &amp;quot;Geld&amp;quot;, &amp;quot;Freunde&amp;quot;, &amp;quot;Langes Leben&amp;quot;)

# Vorbereitung:
l2 &amp;lt;- likert(items2, nlevels = 5)

# Zusammenfassung
summary(l2)
#&amp;gt;           Item      low   neutral     high     mean       sd
#&amp;gt; 3         Geld 28.57143 23.809524 47.61905 3.380952 1.359272
#&amp;gt; 5 Langes Leben 57.14286  4.761905 38.09524 2.619048 1.532194
#&amp;gt; 1   Gesundheit 38.09524 28.571429 33.33333 2.857143 1.492840
#&amp;gt; 2      Familie 38.09524 28.571429 33.33333 2.952381 1.499206
#&amp;gt; 4      Freunde 42.85714 23.809524 33.33333 2.857143 1.236354

# Graphische Ausgaben:
plot(l2)

plot(l2,&amp;quot;bar&amp;quot;)

plot(l2,&amp;quot;heat&amp;quot;)

plot(l2,&amp;quot;density&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-7-3.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/datenjudo-fur-fragebogen/index.de_files/figure-html/unnamed-chunk-7-4.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Voilà!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Interaktionseffekte leichter interpretieren durch Transformationen</title>
      <link>https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;einleitung&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Einleitung&lt;/h3&gt;
&lt;p&gt;Bei einer multiplen linearen Regression kann man den Einfluss einer unabhägigen Variable auf das Verhalten einer anderen unabhägigen Variable in Bezug auf die abhägige Variable mit modellieren.&lt;/p&gt;
&lt;p&gt;Wir wollen das einmal an dem Beispiel der folgenden Datentabelle &lt;a href=&#34;https://vincentarelbundock.github.io/Rdatasets/doc/AER/TeachingRatings.html&#34;&gt;&lt;em&gt;Impact of Beauty on Instructor’s Teaching Ratings&lt;/em&gt;&lt;/a&gt; und der Fragestellung in wie weit das Alter und das Geschlecht einen Einfluss auf das Evaluationsergebnis haben.&lt;/p&gt;
&lt;p&gt;Dazu stellen laden wir die Daten aus dem Internet:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
url &amp;lt;- paste0(&amp;quot;https://vincentarelbundock.github.io/Rdatasets/csv/AER/&amp;quot;,
              &amp;quot;TeachingRatings.csv&amp;quot;)
teacherratings &amp;lt;- read.csv(url)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und betrachten das Streudiagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(eval ~ age, color = ~gender, data = teacherratings)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-lineares-modell&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein lineares Modell&lt;/h3&gt;
&lt;p&gt;Ein klassisches lineares Modell sieht wie folgt aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erglm &amp;lt;- lm(eval ~ age + gender + age:gender, data = teacherratings)
coef(erglm)
#&amp;gt;    (Intercept)            age     gendermale age:gendermale 
#&amp;gt;     4.49018892    -0.01306572    -0.32104348     0.01109285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Doch was bedeuten diese Werte konkret:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;(Intercept) = 4.4901889: Gibt das (theoretische) Evaluationsergebnis für einer Frau im Alter von 0 Jahren an.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age = -0.0130657: Gibt an, um wie viele Punkte im Schnitt sich eine Frau pro Lebensjahr mehr verändert. (Da der Wert negativ ist, also verschlechtert.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;gendermale = -0.3210435: Gibt an, um wie viel sich das Startwert bei 0 Jahren verändert, wenn es ein Mann gewesen wäre. Wir kommen damit auf einen Startwert bei 0 Jahren für Männer von 4.1691454&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age:gendermale = 0.0110928: Gibt an um wie viel sich die Steigung ändert, wenn statt einer Frau ein Mann betrachtet wird. Statt einer Änderung um -0.0130657 bei Frauen beträgt sie bei Männern &lt;span class=&#34;math inline&#34;&gt;\(-0.0130657-0.0110928 = -0.0019729\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_female = c(coef(erglm)[1], coef(erglm)[2])
coef_male = c(
  coef(erglm)[1] + coef(erglm)[3],
  coef(erglm)[2] + coef(erglm)[4]
)
gf_point(eval ~ age, color = ~gender, data = teacherratings) %&amp;gt;%
  gf_coefline(coef = coef_female, color = ~&amp;quot;female&amp;quot;) %&amp;gt;%
  gf_coefline(coef = coef_male, color = ~&amp;quot;male&amp;quot;) 
  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können so die folgenden Modellgleichungen aufstellen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Für Frauen:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \widehat{eval}_{\text{female}} 
  &amp;amp; = 4.4901889 - 0.0130657 \cdot age \\
  &amp;amp;\approx 4.49 - 0.013 \cdot age
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Für Männer:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\widehat{eval}_{\text{male}} 
  &amp;amp;= 4.1691454 - 0.0019729 \cdot age\\
  &amp;amp;\approx 4.169 - 0.002 \cdot age
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;besserer-blick-durch-gute-transformation-der-daten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Besserer Blick durch gute Transformation der Daten&lt;/h3&gt;
&lt;p&gt;Spannender wäre es aber, wenn die y-Achenabschnitte nicht so weit ausserhalb unseres Betrachungsbereichs (29; 73) liegen würde.&lt;/p&gt;
&lt;p&gt;Wir zentrieren daher einmal unsere Altersangaben mit der Transformation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[age_i^\text{center} =  age_i - \overline{age}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Mittelwert bestimmen und speichern:
mean_age = mean( ~ age, data = teacherratings)

# Transformation durchführen:
teacherratings %&amp;gt;%
  mutate(
    age_center = age - mean_age
  ) -&amp;gt; teacherratings

# Das Ergebnis kurz zusammenfassen:
df_stats(~ age + age_center, min, mean, sd, max, 
         data = teacherratings)
#&amp;gt;     response       min         mean       sd      max
#&amp;gt; 1        age  29.00000 4.836501e+01 9.802742 73.00000
#&amp;gt; 2 age_center -19.36501 3.514033e-15 9.802742 24.63499&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das der Mittelwert bei den zentrierten Daten nicht exakt Null ist liegt an den numerischen Besonderheiten des Rechners. Kurz: Computer können gar nicht richitg rechnen und haben daher hier einen kleinen Rundungsfehler!&lt;/p&gt;
&lt;p&gt;Betrachten wir die gerundeten Werte, so ergibt sich das folgende, etwas übersichtlichere Bild:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir bauen uns gerundete Funktionen:
round_digits &amp;lt;- 3  # Anzahl der Nachkommastellen

mean_r &amp;lt;- function(x) round(mean(x), round_digits)
sd_r &amp;lt;- function(x) round(sd(x), round_digits)
min_r &amp;lt;- function(x) round(min(x), round_digits)
max_r &amp;lt;- function(x) round(max(x), round_digits)

# Wir benutzen nun die gerundeten Werte:
df_stats(~ age + age_center, min_r, mean_r, sd_r, max_r, 
         data = teacherratings)
#&amp;gt;     response   min_r mean_r  sd_r  max_r
#&amp;gt; 1        age  29.000 48.365 9.803 73.000
#&amp;gt; 2 age_center -19.365  0.000 9.803 24.635&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Im Mittel sind unsere Lehrer:innen also &lt;span class=&#34;math inline&#34;&gt;\(48.365\)&lt;/span&gt; alt, die Jüngsten mit 29 etwa &lt;span class=&#34;math inline&#34;&gt;\(19.365\)&lt;/span&gt; jünger und die Ältesten mit 73 etwa &lt;span class=&#34;math inline&#34;&gt;\(24.635\)&lt;/span&gt; älter als der Altersdurchschnitt.&lt;/p&gt;
&lt;p&gt;Ein Blick auf die Koeffizenten des linearen Modells bzgl. der zentrierten Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;erglm_c &amp;lt;- lm(eval ~ age_center + gender + age_center:gender, 
              data = teacherratings)
coef(erglm_c)
#&amp;gt;           (Intercept)            age_center            gendermale 
#&amp;gt;            3.85826543           -0.01306572            0.21546232 
#&amp;gt; age_center:gendermale 
#&amp;gt;            0.01109285&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das dazu passende Streudiagramm mit den Regressionsgeraden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef_c_female = c(coef(erglm_c)[1], coef(erglm_c)[2])
coef_c_male = c(
  coef(erglm_c)[1] + coef(erglm_c)[3],
  coef(erglm_c)[2] + coef(erglm_c)[4]
)
gf_point(eval ~ age_center, color = ~gender, 
         data = teacherratings) %&amp;gt;%
  gf_coefline(coef = coef_c_female, color = ~&amp;quot;female&amp;quot;) %&amp;gt;%
  gf_coefline(coef = coef_c_male, color = ~&amp;quot;male&amp;quot;) 
  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/interaktionseffekte-leichter-interpretieren-durch-transformationen/index.de_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Was bedeuten nun diese Werte konkret:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;(Intercept) = 3.8582654: Gibt das Evaluationsergebnis für einer Frau mit Durchschnittsalter (48) an.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age = -0.0130657: Gibt an, um wie viele Punkte im Schnitt sich eine Frau pro Lebensjahr mehr verändert.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;gendermale = -0.3210435: Gibt an, um wie viel sich das Evaluationsergebnis eines Mannes im Durchschnittsalter ändert gegenüber dem einer Frau. Für das Durchschnittalter liegen Männer im Schnitt bei 4.0737278&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;age:gendermale = 0.0110928: Gibt an, um wie viel sich die Steigung ändert, wenn statt einer Frau ein Mann betrachtet wird. Statt einer Änderung um -0.0130657 bei Frauen beträgt sie bei Männern &lt;span class=&#34;math inline&#34;&gt;\(-0.0130657-0.0110928 = -0.0019729\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Wir können daher die folgenden Modellgleichungen aufstellen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Für Frauen:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \widehat{eval}_{\text{female}} 
  &amp;amp; = 3.8582654 - 0.0130657 \cdot (age - 48.3650108) \\
  &amp;amp;\approx 3.858 - 0.013 \cdot (age - 48.365) 
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Für Männer:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\widehat{eval}_{\text{male}} 
  &amp;amp;= 4.0737278 - 0.0019729 \cdot (age - 48.3650108) \\
  &amp;amp;\approx 4.074 - 0.002 \cdot (age - 48.365)
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;zur-interpretation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zur Interpretation&lt;/h3&gt;
&lt;p&gt;Im durchschnittlichen Alter ist das erwartete Evaluationsergebnis bei Frauen (&lt;span class=&#34;math inline&#34;&gt;\(3.8582654\)&lt;/span&gt;) um rund &lt;span class=&#34;math inline&#34;&gt;\(0.215\)&lt;/span&gt; Punkte schlechter als bei Männern (&lt;span class=&#34;math inline&#34;&gt;\(4.0737278\)&lt;/span&gt;).
Mit jedem Lebensjahr sinkt dabei in beiden Fällen, also sowohl bei Frauen als auch bei Männern, das Evaluationsergbnis.
Bei den Frauen aber mit ca. &lt;span class=&#34;math inline&#34;&gt;\(-0.013\)&lt;/span&gt; deutlich stärker als mit ca. &lt;span class=&#34;math inline&#34;&gt;\(-0.002\)&lt;/span&gt; bei den Männern .&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fazit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Eine gute Transformation einiger Daten kann, dank der angepassten
Modellgleichungen, die Interpretation der Ergebnisse deutlich
vereinfachen!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nachtrag-und-danksagung&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nachtrag und Danksagung&lt;/h2&gt;
&lt;p&gt;Die Idee zu diesem Blog-Post verdanke ich dem Blog von &lt;em&gt;Prof. Dr. Sebastian Sauer&lt;/em&gt;. Hier der Link zum Orginal-Blog: &lt;a href=&#34;https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/&#34;&gt;https://data-se.netlify.app/2021/06/17/beispiel-zur-interpretation-des-interaktionseffekts/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Danke auch für die kritische Durchsicht und die hilfreichen Anmerkungen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reproduzierbarkeitsinformationen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproduzierbarkeitsinformationen&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt; 
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt; 
#&amp;gt; Package version:
#&amp;gt;   mosaic_1.8.3 xfun_0.24&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Regression mit studentisierten Daten</title>
      <link>https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/</link>
      <pubDate>Wed, 23 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Bei einer einfachen linearen Regression versuchen wir zu vorgegebenen Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1), \cdots (x_n, y_n)\)&lt;/span&gt; die Parameter einer
möglichst passenden Gerade &lt;span class=&#34;math inline&#34;&gt;\(g(x)=\beta_0 + \beta_1 \cdot x\)&lt;/span&gt; zu schätzen.&lt;/p&gt;
&lt;p&gt;Die Schätzung des y-Achsenabschnitts &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und der Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; erfolgt dabei algebraisch exakt mittels:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0 = \bar{y} - \hat\beta_1 \cdot \bar{x} \quad\text{und}\quad \hat\beta_1 = \frac{s_x}{s_y}\cdot r_{x,y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dabei sind &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt; die Mittelwerte und &lt;span class=&#34;math inline&#34;&gt;\(s_x\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(s_y\)&lt;/span&gt; die Standardabweichungen der Datenpunkte &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt;; darüberhinaus ist &lt;span class=&#34;math inline&#34;&gt;\(r_{x,y}\)&lt;/span&gt; der Korrelationskoeffizient der Datenpunkte.&lt;/p&gt;
&lt;p&gt;Beim studentisieren werden die Datenpunkte bzgl. des Mittelwertes zentriert und bzgl der Standardabweichung normiert:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x_i^{\text{stud}} = \frac{x_i-\bar{x}}{s_x} \quad\text{bzw.}\quad y_i^{\text{stud}} = \frac{y_i-\bar{y}}{s_y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Was passiert nun durch eine solche Studentisierung (oft auch z-Transformation genannt) mit den geschätzen Parametern?&lt;/p&gt;
&lt;p&gt;Die Mittelwerte &lt;span class=&#34;math inline&#34;&gt;\(\bar{x}^{stud}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}^{stud}\)&lt;/span&gt; werden zu Null. Die Standardabweichungen &lt;span class=&#34;math inline&#34;&gt;\(s_{x^{stud}}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(s_{y^stud}\)&lt;/span&gt; werden zur Eins:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\bar{x}^{stud}=0=\bar{y}^{stud} \qquad s_{x^{stud}}= 1 = s_{y^{stud}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der y-Achsenabschnitt wird nun durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0^{stud} 
= \bar{y}^{stud} - \hat\beta_1^{stud} \cdot \bar{x}^{stud}
= 0 - \hat\beta_1^{stud} \cdot 0 = 0\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und die Steigung durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta_1^{stud} 
= \frac{s_{x^{stud}}}{s_{y^{stud}}}\cdot r_{x^{stud},y^{stud}}
= \frac{1}{1}\cdot r_{x^{stud},y^{stud}} = r_{x^{stud},y^{stud}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;geschätzt.&lt;/p&gt;
&lt;p&gt;Für den Korrelationskoeffienten gilt nun
&lt;span class=&#34;math display&#34;&gt;\[
r_{x^{stud},y^{stud}} 
= \frac{s_{x^{stud},y^{stud}}}{s_{x^{stud}}\cdot_{y^{stud}}}
= \frac{s_{x^{stud},y^{stud}}}{1 \cdot 1}
= s_{x^{stud},y^{stud}}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Damit Schätzen wir unsere Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1^{stud}\)&lt;/span&gt; direkt aus der Kovarianz &lt;span class=&#34;math inline&#34;&gt;\(s_{x^{stud},y^{stud}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Damit gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1^{stud} = r_{x^{stud},y^{stud}} = s_{x^{stud},y^{stud}} \in [-1, 1]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In Worten zusammengefasst:
&lt;em&gt;Im studentisierten Fall ist&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;der y-Achsenabschnitt immer 0 und&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;die Steigung immer ein Wert zwischen -1 und 1&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;beispiel-mtcars--daten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Beispiel: &lt;code&gt;mtcars&lt;/code&gt;- Daten&lt;/h3&gt;
&lt;p&gt;Auf Grundlage der Datentabelle &lt;em&gt;mtcars&lt;/em&gt; wollen wir den linearer
Zusammenhang zwischen dem Verbrauch (in Meilen pro Gallone &lt;em&gt;mpg&lt;/em&gt;)
und der Leistung (Pferdestärke &lt;em&gt;hp&lt;/em&gt;) modellieren.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)

# Wir nehmen die Datentabelle &amp;#39;mtcars&amp;#39;:
mtcars %&amp;gt;%
  select(hp, mpg) -&amp;gt; dt

# Ein kurzer Blick aus die Daten:
df_stats( ~ hp + mpg, mean, sd, data = dt)
#&amp;gt;   response      mean        sd
#&amp;gt; 1       hp 146.68750 68.562868
#&amp;gt; 2      mpg  20.09062  6.026948

# Wir vergleichen den Verbrauch (mpg, miles per gallon) 
# mit den Pferdestärken (hp) mit Hilfe eines Streudiagramms.
# Dazu berechnen wir vorab die Mittelwerte
mean_hp &amp;lt;- mean(~ hp, data = dt)
mean_mpg &amp;lt;- mean(~ mpg, data = dt)

# und berechnen nun die Schätzwerte für die Regressionsgerade
beta_1 &amp;lt;- cov(mpg ~ hp, data = dt) / var(~ hp, data = dt)
beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp

# schliesslich zeichnen alles in das Streudiagramm ein:
gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, 
           color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1, intercept = ~beta_0, 
            color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988605 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Studentisieren wir nun die &lt;em&gt;mpg&lt;/em&gt; und &lt;em&gt;hp&lt;/em&gt; Werte. In &lt;strong&gt;R&lt;/strong&gt; können wir das mit der Funktion ‘zscore()’&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; wie folgt machen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dt %&amp;gt;%
  mutate(
    hp_stud = zscore(hp),
    mpg_stud = zscore(mpg)
  ) -&amp;gt; dt

# Ein kurzer Blick aus die Daten:
df_stats( ~ hp_stud + mpg_stud, mean, sd, data = dt)
#&amp;gt;   response         mean sd
#&amp;gt; 1  hp_stud 1.040834e-17  1
#&amp;gt; 2 mpg_stud 7.112366e-17  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Grund für die kleinen Abweichungen von der Null bei den Mittelwerten
sind unumgängliche Rundungsfehler, die der Computer macht!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir &amp;quot;berechnen&amp;quot; die Mittelwerte:
mean_hp_stud &amp;lt;- 0 # = mean(~ hp_stud, data = dt)
mean_mpg_stud &amp;lt;- 0 # = mean(~ mpg_stud, data = dt)

# Berechnen wir nun die Schätzwerte für die Regressionsgerade:
beta_1_stud &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt)
beta_0_stud &amp;lt;- 0 # = mean_mpg_stud - beta_1_stud * mean_hp_stud

# und zeichnen diese in unser Streudiagramm ein:
gf_point(mpg_stud ~ hp_stud, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg_stud, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp_stud, 
           color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg_stud ~ mean_hp_stud, 
           color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1_stud, intercept = ~beta_0_stud, 
            color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(-2,2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/regression-mit-studentisierten-daten/index.de_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade im studentisierten Problem lautet nun:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta^{stud}_0 + \hat\beta_1^{stud} \cdot x^{stud} \\ 
    &amp;amp;\approx 0 - 0.7761684 \cdot x^{stud} \\
    &amp;amp;\approx 0 -0.776 \cdot x^{stud} 
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;direkt-mit-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Direkt mit ‘R’&lt;/h3&gt;
&lt;p&gt;Wir erhalten unsere Ergebnisse natürlich auch direkt in R, ohne selber die Werte auszurechnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Ursprüngliches Modell:
erglm &amp;lt;- lm(mpg ~ hp, data = dt)
coef(erglm)
#&amp;gt; (Intercept)          hp 
#&amp;gt; 30.09886054 -0.06822828

# Studentisiertes Modell:
erglm_stud &amp;lt;- lm(mpg_stud ~ hp_stud, data = dt)
coef(erglm_stud)
#&amp;gt;   (Intercept)       hp_stud 
#&amp;gt; -3.149357e-17 -7.761684e-01&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;zurückrechnen-der-studentisierten-werte-in-das-ursprüngliche-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zurückrechnen der studentisierten Werte in das ursprüngliche Problem&lt;/h3&gt;
&lt;p&gt;Aus dem Ergebnis des studentisierten Modells können wir die Koeffizenten des ursprünglichen Modells wie folgt berechnen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1 = \hat\beta_1^{stud} \cdot \frac{s_y}{s_x}\]&lt;/span&gt;
und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0 = \bar{y} - \hat\beta_1 \cdot \bar{x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; geht das wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean_mpg &amp;lt;- mean( ~ mpg, data = dt)
sd_mpg &amp;lt;- sd( ~ mpg, data = dt)
mean_hp &amp;lt;- mean( ~ hp, data = dt)
sd_hp &amp;lt;- sd( ~ hp, data = dt)

(beta_1 &amp;lt;- beta_1_stud * sd_mpg / sd_hp)
#&amp;gt; [1] -0.06822828
(beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp)
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
### Fazit

...

## Reproduzierbarkeitsinformationen

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt;
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt;
#&amp;gt; Package version:
#&amp;gt; mosaic_1.8.3 tidyr_1.1.3 xfun_0.24
```&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Das “Cookbook” zur Datentabelle können Sie mit Hilfe von &lt;code&gt;help(&#34;mtcars&#34;)&lt;/code&gt; aufrufen!&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Sie können hier auch die Funktion &lt;code&gt;scale()&lt;/code&gt; verwenden!&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Über die Koeffizienten einer linearen Regression</title>
      <link>https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Bei einer &lt;em&gt;einfachen Regression&lt;/em&gt; versuchen wir zu gegebenen
Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1), ..., (x_n, y_n)\)&lt;/span&gt; eine &lt;em&gt;möglichst passende&lt;/em&gt; Funktion
&lt;span class=&#34;math inline&#34;&gt;\(g(x)\)&lt;/span&gt; zu finden, so dass
&lt;span class=&#34;math display&#34;&gt;\[y_i = g(x_i) + e_i\]&lt;/span&gt;
gilt. Dabei tolerieren wir eine (kleine) Abweichung &lt;span class=&#34;math inline&#34;&gt;\(e_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Bei einer &lt;em&gt;einfachen &lt;strong&gt;linearen&lt;/strong&gt; Regression&lt;/em&gt; gehen wir davon aus, dass die Datenpunkte (im wesentlichen) auf einer Geraden liegen. Mit &lt;span class=&#34;math inline&#34;&gt;\(g(x)=\beta_0 + \beta1 \cdot x\)&lt;/span&gt; ergibt sich dann für die Datenpunkte die Gleichung:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i = \beta_0 + \beta_1 \cdot x_i + e_i\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Unsere Aufgabe besteht nun darin die Parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (y-Achsenabschnitt) und &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; (Steigung) an Hand der &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; Datenpunkte zu schätzen.
Alle unsere Schätzungen kennzeichnen wir mit einem Dach (&lt;span class=&#34;math inline&#34;&gt;\(\hat{.}\)&lt;/span&gt;), um sie von den (in der Regel unbekannten) Parametern besser zu unterscheiden.&lt;/p&gt;
&lt;p&gt;Wir suchen somit nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta= \left(\hat\beta_0,\, \hat\beta_1\right)\)&lt;/span&gt;,
so dass die Gerade &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 + \hat\beta_1 \cdot x\)&lt;/span&gt; zu gegebenem &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;
eine möglichst gute Schätzung von &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; (genannt &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;) hat:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{y_i} = \hat\beta_0 + \hat\beta_1 \cdot x_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Abweichung &lt;span class=&#34;math inline&#34;&gt;\(\hat{e_i}\)&lt;/span&gt; unserer Schätzung &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt; von dem
gegebenen Wert &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; lässt sich schreiben als:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat{e_i} =  \hat{y_i} - y_i =  \hat\beta_0 + \hat\beta_1 \cdot x_i - y_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wenn wir diese Abweichung über alle &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; minimieren, finden wir unser &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Doch das wirft eine Frage auf:
&lt;em&gt;Wie genau messen wir die möglichst &lt;strong&gt;kleinste Abweichung&lt;/strong&gt; der &lt;span class=&#34;math inline&#34;&gt;\(\hat{e_i}\)&lt;/span&gt; konkret?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wir betrachten zunächst drei einfache Ideen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Betrag der Summe der Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Summe der absoluten Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Idee: &lt;em&gt;Summe der quadratischen Abweichungen&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Gewöhnlich nutzen wir die &lt;em&gt;quadratischen Abweichungen&lt;/em&gt;, weshalb
wir die drei Ideen ebenso in umgekehrter Reihenfolge betrachten wollen:&lt;/p&gt;
&lt;div id=&#34;idee-summe-der-quadratischen-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;3. Idee: Summe der quadratischen Abweichungen&lt;/h2&gt;
&lt;p&gt;Wir bezeichnen mit&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
QS &amp;amp;= QS(\hat\beta) = QS(\hat\beta_0, \hat\beta_1) \\
  &amp;amp;= \sum\limits_{i=1}^n \hat{e_i}^2 = \sum\limits_{i=1}^n \left(\hat{y_i} - y_i \right)^2 \\
  &amp;amp;= \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right)^2
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;die &lt;strong&gt;Q&lt;/strong&gt;uadrat-&lt;strong&gt;S&lt;/strong&gt;umme der Abweichungen.&lt;/p&gt;
&lt;p&gt;Gesucht wird &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta=\left(\hat\beta_0,\,\hat\beta_1\right)\)&lt;/span&gt;,
so das &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; minimiert wird.&lt;/p&gt;
&lt;p&gt;Dies ist ein Minimierungsproblem, bei dem wir zu mindestens eine (exakte)
mathematisch-algebraisch Lösung in Form eines stationären Punktes finden können.
Dazu berechnen wir die Nullstelle der ersten partiellen Ableitung von &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;div id=&#34;vorbemerkungen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vorbemerkungen&lt;/h3&gt;
&lt;p&gt;Wegen &lt;span class=&#34;math inline&#34;&gt;\(\bar{x} = \frac{1}{n} \sum\limits_{i=1}^n x_i\)&lt;/span&gt; ist &lt;span class=&#34;math inline&#34;&gt;\(n \cdot \bar{x} =\sum\limits_{i=1}^n x_i\)&lt;/span&gt; und analog &lt;span class=&#34;math inline&#34;&gt;\(n \cdot \bar{y} =\sum\limits_{i=1}^n y_i\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;schätzen-des-y-achenabschnitts-hatbeta_0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Schätzen des y-Achenabschnitts &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Es ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
 \frac{\partial}{\partial \hat\beta_0} \, QS &amp;amp;= 2 \cdot \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right) \cdot 1 \\
  &amp;amp;= 2 \cdot \left(\sum\limits_{i=1}^n \hat\beta_0 + \sum\limits_{i=1}^n\hat\beta_1 \cdot x_i - \sum\limits_{i=1}^n y_i\right) \\
  &amp;amp;= 2 \cdot \left( n \cdot \hat\beta_0 + \hat\beta_1\cdot\sum\limits_{i=1}^n x_i - \sum\limits_{i=1}^n y_i \right) \\
  &amp;amp;= 2 \cdot \left( n \cdot \hat\beta_0 + \hat\beta_1\cdot n \cdot \bar{x} - n \cdot\bar{y} \right) \\
  &amp;amp;= 2 \cdot n \cdot \left( \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y} \right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um stationäre Punkte zu ermitteln, müssen wir den Ausdruck nun gleich Null setzen und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  0 &amp;amp;= \frac{\partial}{\partial \hat\beta_0} \, QS \\
  &amp;amp;= 2 \cdot n \cdot \left( \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y} \right) \qquad | : (2 \cdot n) \\
  &amp;amp;= \hat\beta_0 + \hat\beta_1\cdot \bar{x} -\bar{y}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Stellen wir nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; um, erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat\beta_0 &amp;amp;= - \hat\beta_1\cdot\bar{x} + \bar{y} \\
  \hat\beta_0 &amp;amp;= \bar{y} - \hat\beta_1\cdot\bar{x}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; zu bestimmen, benötigen wir &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;schätzen-der-steigung-hatbeta_1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Schätzen der Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Es ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS &amp;amp;= 2 \cdot \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right) \cdot x_i \\
  &amp;amp;= 2 \cdot \left(\sum\limits_{i=1}^n \hat\beta_0 \cdot x_i + \sum\limits_{i=1}^n \hat\beta_1 \cdot x_i\cdot x_i- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_0 \cdot \sum\limits_{i=1}^n  x_i + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_0 \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir ersetzen nun &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; durch &lt;span class=&#34;math inline&#34;&gt;\(\bar{y} - \hat\beta_1\cdot \bar{x}\)&lt;/span&gt; und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS  &amp;amp;=
  2 \cdot \left(\hat\beta_0 \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(\left(\bar{y} - \hat\beta_1\cdot \bar{x}\right) \cdot n \cdot \bar{x} + \hat\beta_1 \cdot\sum\limits_{i=1}^n  x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - n \cdot \hat\beta_1 \cdot  \bar{x}^2  + \hat\beta_1 \cdot\sum\limits_{i=1}^n  x_i^2- \sum\limits_{i=1}^n y_i \cdot x_i\right) \\
  &amp;amp;= 2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - \sum\limits_{i=1}^n y_i \cdot x_i  + \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Mit Hilfe des &lt;a href=&#34;https://de.wikipedia.org/wiki/Verschiebungssatz_(Statistik)&#34;&gt;&lt;em&gt;Verschiebesatzes von Steiner&lt;/em&gt;&lt;/a&gt; (zweimal angewendet) erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \frac{\partial}{\partial \hat\beta_1} \, QS  
    &amp;amp;=2 \cdot \left(n \cdot\bar{y} \cdot \bar{x} - \sum\limits_{i=1}^n y_i \cdot x_i  + \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
    &amp;amp;=2 \cdot \left(- \left(\sum\limits_{i=1}^n y_i \cdot x_i - n \cdot \bar{y} \cdot \bar{x}   \right)+ \hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)\right) \\
    &amp;amp;=2 \cdot \left(\hat\beta_1 \cdot \left(\sum\limits_{i=1}^n  x_i^2- n \cdot  \bar{x}^2\right)- \left(\sum\limits_{i=1}^n y_i \cdot x_i - n \cdot \bar{y} \cdot \bar{x}   \right)\right) \\
    &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir setzen nun wieder den Ausdruck gleich Null:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
 0 &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right)  \qquad | : 2\\
   &amp;amp;= \hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})
 \end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Und stellen dann nach &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 
    &amp;amp;= \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y}) \\
  \hat\beta_1 
    &amp;amp;= \frac{\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\sum\limits_{i=1}^n(x_i-\bar{x})^2}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun Zähler und Nenner der rechten Seite mit &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\)&lt;/span&gt; erweitern
und erhalten so:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 
      &amp;amp;= \frac{\frac{1}{n} \cdot\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\frac{1}{n} \cdot\sum\limits_{i=1}^n  (x_i-\bar{x})^2} \\
      &amp;amp;= \frac{\sigma_{x,y}}{\sigma^2_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Oder aber wir erweitern mit &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n-1}\)&lt;/span&gt; und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 
      &amp;amp;= \frac{\frac{1}{n-1} \cdot\sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})}{\frac{1}{n-1} \cdot\sum\limits_{i=1}^n  (x_i-\bar{x})^2} \\
      &amp;amp;= \frac{s_{x,y}}{s^2_{x}}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Damit können wir zur Berechnung sowohl die Kovarianz der Grundgesamtheit &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{x,y}\)&lt;/span&gt; und die Varianz &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_x\)&lt;/span&gt; von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, als auch deren Schätzer &lt;span class=&#34;math inline&#34;&gt;\(s_{x,y}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(s^2_x\)&lt;/span&gt; verwendet werden!&lt;/p&gt;
&lt;p&gt;Diese Methode nennt sich &lt;strong&gt;Methode der kleinsten Quadrate&lt;/strong&gt;
(engl. &lt;em&gt;ordenary least square method&lt;/em&gt;) und wir sprechen
dann auch von den &lt;strong&gt;Kleinste-Quadrate-Schätzern&lt;/strong&gt;
(oder kurz &lt;strong&gt;KQ-Schätzer&lt;/strong&gt; bzw. &lt;strong&gt;OLS-Schätzer&lt;/strong&gt;) &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Erweitern wir den Ausdruck mit Standardabweichung &lt;span class=&#34;math inline&#34;&gt;\(\sigma_y\)&lt;/span&gt; bzw. &lt;span class=&#34;math inline&#34;&gt;\(s_y\)&lt;/span&gt;, so erhalten wir:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 &amp;amp;= \frac{\sigma_{x,y}}{\sigma^2_x} \cdot \frac{\sigma_y}{\sigma_y} = \frac{\sigma_{x,y}}{\sigma_x \cdot \sigma_x} \cdot \frac{\sigma_y}{\sigma_y} = \frac{\sigma_{x,y}}{\sigma_x \cdot \sigma_y} \cdot \frac{\sigma_y}{\sigma_x} \\
 &amp;amp;= \rho_{x,y} \cdot \frac{\sigma_y}{\sigma_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und analog für die Schätzer:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\hat\beta_1 &amp;amp;= \frac{s_{x,y}}{s^2_x} \cdot \frac{s_y}{s_y} 
  = \frac{s_{x,y}}{s_x \cdot s_x} \cdot \frac{s_y}{s_y}
  = \frac{s_{x,y}}{s_x \cdot s_y} \cdot \frac{s_y}{s_x} \\
 &amp;amp;= r_{x,y} \cdot \frac{s_y}{s_x} \\
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Steigung &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; hat somit eine direkte Beziehung mit dem &lt;em&gt;Korrelationskoeffizenten&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; (der Grundgesamtheit) bzw. &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; (der Stichprobe).&lt;/p&gt;
&lt;p&gt;Für eine Berechnung in &lt;strong&gt;R&lt;/strong&gt; heißt dies: wir können die Regressionskoeffizienten
&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt; direkt algebraisch ausrechnen, wenn wir&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;p&gt;die Standardabweichungen von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; und den Korrelationskoeffizienten oder&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;die Varianz von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und Kovarianz von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;haben.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-beispiel-in-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein Beispiel in R:&lt;/h3&gt;
&lt;p&gt;Auf Grundlage der Datentabelle &lt;em&gt;mtcars&lt;/em&gt; wollen wir Prüfen wie ein linearer
Zusammenhang zwischen dem Verbrauch (in Meilen pro Gallone &lt;em&gt;mpg&lt;/em&gt;) und der Leistung
(Pferdestärke &lt;em&gt;hp&lt;/em&gt;) modelliert werden kann.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)

# Wir nehmen die Datentabelle &amp;#39;mtcars&amp;#39;:
mtcars %&amp;gt;%
  select(hp, mpg) -&amp;gt; dt

# Ein kurzer Blick auf die Daten:
favstats(~ hp, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;      mean       sd
#&amp;gt;  146.6875 68.56287
favstats(~ mpg, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;      mean       sd
#&amp;gt;  20.09062 6.026948

# Wir vergleichen den Verbrauch (mpg, miles per gallon) 
# mit den Pferdestärken (hp) mit Hilfe eines Streudiagramms:
gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Berechnen wir zunächst die Mittelwerte von &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; (also ‘hp’) und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; (also ‘mpg’)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(mean_hp &amp;lt;- mean(~ hp, data = dt))
#&amp;gt; [1] 146.6875
(mean_mpg &amp;lt;- mean(~ mpg, data = dt))
#&amp;gt; [1] 20.09062&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und zeichnen die Punkt &lt;span class=&#34;math inline&#34;&gt;\((\bar{x}, \bar{y}) = (146.69, 20.09)\)&lt;/span&gt; in unser
Streudiagramm ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Berechnen wir nun die Schätzwerte für die Regressionsgerade&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(beta_1 &amp;lt;- cov(mpg ~ hp, data = dt) / var(~ hp, data = dt))
#&amp;gt; [1] -0.06822828
(beta_0 &amp;lt;- mean_mpg - beta_1 * mean_hp)
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und zeichnen diese in unser Streudiagramm ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg ~ hp, data = dt) %&amp;gt;%
  gf_hline(yintercept = ~ mean_mpg, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_vline(xintercept = ~ mean_hp, color = &amp;quot;grey60&amp;quot;, linetype = &amp;quot;dashed&amp;quot;) %&amp;gt;%
  gf_point(mean_mpg ~ mean_hp, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_abline(slope = ~ beta_1, intercept = ~beta_0, color = &amp;quot;dodgerblue&amp;quot;) %&amp;gt;%
  gf_lims(y = c(5,35))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988605 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;studentisieren-einmal-hin-und-einmal-zurück&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Studentisieren – einmal hin und einmal zurück&lt;/h3&gt;
&lt;p&gt;Was passiert eigentlich, wenn wir unsere &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; Werte studentisieren (aka standardisieren oder z-transformieren)?&lt;/p&gt;
&lt;p&gt;Zur Erinnerung, studentisieren geht so:
&lt;span class=&#34;math display&#34;&gt;\[x^{stud} = \frac{x - \bar{x}}{s_x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; können wir das mit der Funktion ‘zscore’ wie folgt machen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dt %&amp;gt;%
  mutate(
    hp_stud = zscore(hp),
    mpg_stud = zscore(mpg)
  ) -&amp;gt; dt&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Natürlich sind die Mittelwerte nun Null und die Standardabweichungen Eins:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(~ hp_stud, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;          mean sd
#&amp;gt;  1.040834e-17  1
favstats(~ mpg_stud, data=dt)[c(&amp;quot;mean&amp;quot;,&amp;quot;sd&amp;quot;)]
#&amp;gt;          mean sd
#&amp;gt;  7.112366e-17  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Der Grund für die kleinen Abweichungen von der Null bei den Mittelwerten
sind unumgängliche Rundungsfehler, die der Computer macht!&lt;/p&gt;
&lt;p&gt;Schauen wir uns nun das Streudiagramm an, zusammen mit dem Mittelpunkt &lt;span class=&#34;math inline&#34;&gt;\((0,0)\)&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(mpg_stud ~ hp_stud, data = dt) %&amp;gt;%
  gf_point(0 ~ 0, color = &amp;quot;red&amp;quot;, size = 5, alpha = 0.2) %&amp;gt;%
  gf_lims(y = c(-2, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;
Auch wenn die Skalierungen sich geändert haben, die Diagramme sind sehr ähnlich.&lt;/p&gt;
&lt;p&gt;Bestimmen wir die Koeffizienten der Regressionsgerade&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(beta_stud_1 &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt))
#&amp;gt; [1] -0.7761684
(beta_stud_0 &amp;lt;- 0 - beta_stud_1 * 0)
#&amp;gt; [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;und setzen sie in das Streudiagramm ein:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können das studentisierte Problem auch wieder auf unser ursprüngliches
zurück rechnen.&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade im studentisierten Problem lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta^{stud}_0 + \hat\beta_1^{stud} \cdot x^{stud} \\ 
          &amp;amp;\approx 0 -0.7761684 \cdot x^{stud} \\
          &amp;amp;\approx 0 -0.776 \cdot x^{stud}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Rechnen wir nun mittels der Formel
&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_1 = \hat\beta_1^{stud} \cdot \frac{s_y}{s_x}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;die Steigung um, so erhalten wir:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b1 &amp;lt;- beta_stud_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06822828&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und setzen wir das in unsere Gleichung zur Bestimmung von &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; ein:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b0 &amp;lt;- mean(dt$mpg) - b1 * mean(dt$hp))
#&amp;gt; [1] 30.09886&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so erhalten wir die Schätzwerte des ursprünglichen Problem.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-anderer-weg-um-die-regressionskoeffizenten-zu-bestimmen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein anderer Weg um die Regressionskoeffizenten zu bestimmen…&lt;/h3&gt;
&lt;p&gt;Gehen wir das Problem noch einmal neu an. Wir suchen &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta=(\hat\beta_0, \hat\beta_1)\)&lt;/span&gt; welches &lt;span class=&#34;math inline&#34;&gt;\(QS(\hat\beta) = QS(\hat\beta_0, \hat\beta_1) = \sum\limits_{i=1}^n \left(\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i \right)^2\)&lt;/span&gt; minimiert.&lt;/p&gt;
&lt;p&gt;Statt es direkt, wie oben durch Null setzen der partiellen Ableitungen, zu bestimmen, wählen wir nun einen mathematisch-&lt;em&gt;numerischen&lt;/em&gt; Ansatz und wollen &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta \in \mathbf{R}^2\)&lt;/span&gt; als &lt;em&gt;Optimierungsproblem&lt;/em&gt; mit Hilfe des &lt;em&gt;Gradientenverfahrens&lt;/em&gt; lösen.&lt;/p&gt;
&lt;p&gt;Beim Gradientenverfahren wird versucht, ausgehend von einem Startwert &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta^0 \in \mathbf{R}^2\)&lt;/span&gt;, gemäß der Iterationsvorschrift&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\beta^{k+1} = \hat\beta^{k} + \alpha^k \cdot d^k
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;für alle &lt;span class=&#34;math inline&#34;&gt;\(k=0,1, ...\)&lt;/span&gt; eine Näherungslösung für &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta\)&lt;/span&gt; zu finden.
Dabei ist &lt;span class=&#34;math inline&#34;&gt;\(\alpha^k &amp;gt; 0\)&lt;/span&gt; eine &lt;em&gt;positive Schrittweite&lt;/em&gt; und &lt;span class=&#34;math inline&#34;&gt;\(d^k\in\mathbf{R}^n\)&lt;/span&gt; eine &lt;em&gt;Abstiegsrichtung&lt;/em&gt;, welche wir in jedem Iterationsschritt &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; so bestimmen,
dass die Folge &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta^k\)&lt;/span&gt; zu einem stationären Punkt, unserer Näherungslösung, konvergiert.&lt;/p&gt;
&lt;p&gt;Im einfachsten Fall, dem &lt;strong&gt;Verfahren des steilsten Abstieges&lt;/strong&gt;, wird der
Abstiegsvektor &lt;span class=&#34;math inline&#34;&gt;\(d^k\)&lt;/span&gt; aus dem Gradienten &lt;span class=&#34;math inline&#34;&gt;\(\nabla QS\)&lt;/span&gt; wie folgt bestimmt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d^k = -\nabla QS\left(\hat\beta^k\right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wegen
&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_0} \, QS = 2 \cdot n \cdot \left(  \hat\beta_0 + \hat\beta_1\cdot\bar{x} - \bar{y} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_1} \, QS = 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y}) \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\nabla QS(\hat\beta) &amp;amp;= \nabla QS(\hat\beta_0, \hat\beta_1) \\
&amp;amp;= 2 \cdot \begin{pmatrix}
n \cdot(\hat\beta_0 + \hat\beta_1\cdot\bar{x} - \bar{y})  \\
\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})
\end{pmatrix}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir wollen hier von Anfang an mit den studentisierten Werten arbeiten, weil diese numerisch viele Vorteile haben.
Darum vereinfachen sich die beiden partiellen Ableitungen noch einmal zu:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\partial}{\partial \hat\beta_0} \, QS = 2 \cdot v
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;und&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\frac{\partial}{\partial \hat\beta_1} \, QS &amp;amp;= 2 \cdot \left(\hat\beta_1 \cdot \sum\limits_{i=1}^n(x_i-\bar{x})^2 - \sum\limits_{i=1}^n (x_i-\bar{x}) \cdot (y_i-\bar{y})\right) \\
 &amp;amp;= 2 \cdot (n-1) \left(\hat\beta_1 \cdot s^2_{x} - s_{x,y}\right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Somit gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\nabla QS(\hat\beta) &amp;amp;= \nabla QS(\hat\beta_0, \hat\beta_1) \\
&amp;amp;= 2 \cdot \begin{pmatrix}
n \cdot \hat\beta_0 \\
 (n-1) \left(\hat\beta_1 \cdot s^2_{x} - s_{x,y}\right) 
\end{pmatrix}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Um die Varianz und die Kovarianz nicht jedesmal neu zu berechnen, speichern
wir die Ergebnisse vorab. Ebenso, damit der Quellcode kürzer wird, speichern
wir in &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; die studentisierten Werte von &lt;span class=&#34;math inline&#34;&gt;\(hp\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(mpg\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Vorbereitungen 
var_x &amp;lt;- var(~ hp_stud, data = dt)
cov_xy &amp;lt;- cov(mpg_stud ~ hp_stud, data = dt)

n &amp;lt;- length(dt$hp_stud)

x &amp;lt;- dt$hp_stud
y &amp;lt;- dt$mpg_stud&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun erstellen wir die &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\nabla QS\)&lt;/span&gt; Funktionen:
Wir definieren diese Funktion wie folgt in &lt;strong&gt;R&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qs &amp;lt;- function(b_0, b_1) {
  sum((b_1 * x - y)**2)
}

nabla_qs &amp;lt;- function(b_0, b_1) {
  c(2 * n * b_0,
    2 * (n - 1) * (b_1 * var_x - cov_xy)
  )
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Schrittweite &lt;span class=&#34;math inline&#34;&gt;\(alpha\)&lt;/span&gt; bestimmen wir mit Hilfe der &lt;em&gt;Armijo-Bedingung&lt;/em&gt; und der &lt;em&gt;Backtracking Liniensuche&lt;/em&gt;:
Diese formalisiert das Konzept “genügend” in der geforderten Verringerung des Funktionswertes. Die Bedingung &lt;span class=&#34;math inline&#34;&gt;\(f(x^k + \alpha d^k) &amp;lt; f(x^k)\)&lt;/span&gt; wird modifiziert zu
&lt;span class=&#34;math display&#34;&gt;\[f(x^k + \alpha d^k) \leq f(x^k) + \sigma \alpha \left(\nabla f(x^k)\right)^T d^k,\]&lt;/span&gt;
mit &lt;span class=&#34;math inline&#34;&gt;\(\sigma\in (0,1)\)&lt;/span&gt;.
Die Armijo-Bedingung umgeht Konvergenzprobleme der einfachen Bedingung, indem sie fordert, dass die Verringerung zumindest proportional zur Schrittweite und zur Richtungsableitung &lt;span class=&#34;math inline&#34;&gt;\(\left(\nabla f(x^k)\right)^T d^k\)&lt;/span&gt; ist, mit Hilfe der Proportionalitätskonstante &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.
In der Praxis werden oft sehr kleine Werte verwendet, z.B. &lt;span class=&#34;math inline&#34;&gt;\(\sigma=0.0001\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Die &lt;em&gt;Backtracking-Liniensuche&lt;/em&gt; verringert die Schrittweite wiederholt um den
Faktor &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; (&lt;code&gt;rho&lt;/code&gt;) , bis die Armijo-Bedingung erfüllt ist.
Sie terminiert garantiert nach einer endlichen Anzahl von Schritten. Weshalb wir
sie hier einsetzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;alpha_k &amp;lt;- function(b_0, b_1, d_k, alpha = 1, sigma = 0.0001, rho = 0.5) {
  d_0 &amp;lt;- d_k[1]
  d_1 &amp;lt;- d_k[2]
  nabla &amp;lt;- nabla_qs(b_0, b_1)
  n_0 &amp;lt;- nabla[1]
  n_1 &amp;lt;- nabla[2]

  lhs &amp;lt;- qs(b_0 + alpha*d_0, b_1 + alpha*d_1)
  rhs &amp;lt;- qs(b_0, b_1) + sigma*alpha*(n_0*d_0 + n_1*d_1)

  while (lhs &amp;gt; rhs) {
    alpha &amp;lt;- rho * alpha
    lhs &amp;lt;- qs(b_0 + alpha*d_0, b_1 + alpha*d_1)
    rhs &amp;lt;- qs(b_0, b_1) + sigma*alpha*(n_0*d_0 + n_1*d_1)
  }
  return(alpha)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ein paar Einstellungen vorab:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# maximale Anzahl an Iterationen
max_iter &amp;lt;- 1000
iter &amp;lt;- 0

# Genauigkeit
eps &amp;lt;- 10**-6

# Startwerte
b_0 &amp;lt;- 0 
b_1 &amp;lt;- -1 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Für eine vorgegebene Genauigkeit &lt;span class=&#34;math inline&#34;&gt;\(eps=10^{-6}\)&lt;/span&gt;, den Startwerten &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0^0 = 0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1^0 = -1\)&lt;/span&gt; können wir somit das Verfahren starten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;while (TRUE) {
  iter &amp;lt;- iter + 1

  d_k &amp;lt;- -nabla_qs(b_0, b_1)

  ad_ &amp;lt;- alpha_k(b_0, b_1, d_k) * d_k

  x0 &amp;lt;- b_0 + ad_[1]
  x1 &amp;lt;- b_1 + ad_[2]

  if ((abs(b_0 - x0) &amp;lt; eps) &amp;amp; (abs(b_1 - x1) &amp;lt; eps) | (iter &amp;gt; max_iter)) {
    break
  }
  b_0 &amp;lt;- x0
  b_1 &amp;lt;- x1
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir haben in &lt;span class=&#34;math inline&#34;&gt;\(203\)&lt;/span&gt; Iterationsschritten das folgende Ergebnis für die Regressionskoeffizienten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat\beta_0^{stud} = 0 \qquad \hat\beta_1^{stud} = -0.7761689\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Betrachten wir die daraus erstellte Regressionsgerade:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Um die Regressionskoeffizienten für unser ursprüngliches Problem zu erhalten
müssen wir wie folgt zurück rechnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(b1 &amp;lt;- b_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06822832
(b0 &amp;lt;- mean(dt$mpg) -  b1 * mean(dt$hp))
#&amp;gt; [1] 30.09887&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die Geradengleichung für das ursprüngliches Problem lautet somit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988668 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-r-funktion-optim&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Die R Funktion &lt;code&gt;optim&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;In &lt;strong&gt;R&lt;/strong&gt; gibt es bessere Optimierungsmethoden, als die hier verwendete.
Zum Beispiel können wir die Funktion &lt;code&gt;optim&lt;/code&gt; verwenden.
Die Funktion &lt;code&gt;optim&lt;/code&gt; benötigt die zu optimierende &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; und
ggf. die Gradientenfunktion &lt;span class=&#34;math inline&#34;&gt;\(gf(x)\)&lt;/span&gt; sowie einen Startpunkt &lt;span class=&#34;math inline&#34;&gt;\(x^0\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f &amp;lt;- function(beta) {
  qs(beta[1], beta[2])
}

grf &amp;lt;- function(beta) {
  nabla_qs(beta[1], beta[2])
}

# Der eigentliche Aufruf von optim:
ergb &amp;lt;- optim(c(0,-0.5),f ,grf, method = &amp;quot;CG&amp;quot;)

# Auslesen der Schätzer aus dem Ergebnis:
(optim_beta_0 &amp;lt;- ergb$par[1])
#&amp;gt; [1] 0
(optim_beta_1 &amp;lt;- ergb$par[2])
#&amp;gt; [1] -0.7761683&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir erhalten somit für das studentisierte Problem die Gerade:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y}^{stud} &amp;amp;= \hat\beta_0^{stud} + \hat\beta_1^{stud} \cdot x^{stud} \\ 
          &amp;amp;\approx 0 -0.7761683 \cdot  x^{stud} \\
          &amp;amp;\approx 0 -0.776 \cdot  x^{stud}
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Für das ursprüngliche Problem rechnen wir mittels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;optim_b1 &amp;lt;- optim_beta_1 * sd(dt$mpg) / sd(dt$hp)
optim_b0 &amp;lt;- mean(dt$mpg) -  optim_b1 * mean(dt$hp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;um und erhalten:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 30.0988601 -0.0682283 \cdot x \\
          &amp;amp;\approx 30.099 -0.068 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;idee-summe-der-absoluten-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2. Idee: Summe der absoluten Abweichungen&lt;/h2&gt;
&lt;p&gt;Wir ändern nun die Abweichungsmessfunktion von der &lt;em&gt;Q&lt;/em&gt;uadrat-&lt;em&gt;S&lt;/em&gt;umme hin zu
den &lt;strong&gt;A&lt;/strong&gt;bsolut-&lt;em&gt;S&lt;/em&gt;ummen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[AS = AS(\hat\beta) = AS(\hat\beta_0, \hat\beta_1) = \sum_{i=1}^n |\hat{y}_i - y_i|\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Auch hier wollen wir mit den studentisierten Daten arbeiten und stellen
die Funktion der &lt;em&gt;A&lt;/em&gt;bsolut-&lt;em&gt;S&lt;/em&gt;ummen auf:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Absolute Abweichungssummen
as &amp;lt;- function(b_0, b_1) {
  return(sum(abs(b_0 + b_1 * x - y)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Danach konstruieren wir die zu optimierende Funktion &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Zu optimierende Funktion
f &amp;lt;- function(beta) {
  as(beta[1], beta[2])
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Diesmal nutzen wir &lt;code&gt;optim&lt;/code&gt; ohne eine Gradientenfunktion:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ergb &amp;lt;- optim(c(0,-1), f)

# Schätzer auslesen
(opti_as_beta_0 &amp;lt;- ergb$par[1])
#&amp;gt; [1] -0.1304518
(opti_as_beta_1 &amp;lt;- ergb$par[2])
#&amp;gt; [1] -0.6844911&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Schauen wir uns nun die so erhaltene Gerade im Vergleich mit der ‘normalen’ Regressionsgerade an:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In grün und gestrichelt sehen wir die Gerade aus der &lt;em&gt;Idee der quadratischen Abweichungssummen&lt;/em&gt;, in blau die aus der &lt;em&gt;Idee der absoluten Abweichungssummen&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Für unser ursprüngliches Problem rechnen wir um:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Umrechnen in die ursprüngliche Fragestellung
(as_b1 &amp;lt;- opti_as_beta_1 * sd(dt$mpg) / sd(dt$hp))
#&amp;gt; [1] -0.06016948
(as_b0 &amp;lt;- (mean(dt$mpg) - as_b1 * mean(dt$hp)) + opti_as_beta_0 * sd(dt$mpg))
#&amp;gt; [1] 28.13051&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und die dazu gehörige Darstellung:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/post/ueber-die-koeffizienten-einer-linearen-regression/index.de_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Funktionsvorschrift für die (blaue) Regressionsgerade lautet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
  \hat{y} &amp;amp;= \hat\beta_0 + \hat\beta_1 \cdot x \\ 
          &amp;amp;\approx 28.1305094 -0.0601695 \cdot x \\
          &amp;amp;\approx 28.131 -0.06 \cdot x
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Diese Methode nennt sich &lt;strong&gt;Median-Regression&lt;/strong&gt; und ein ein Spezialfall der &lt;strong&gt;Quantilsregression&lt;/strong&gt;, die sich u.a. mit dem R-Paket &lt;a href=&#34;https://cran.r-project.org/web/packages/quantreg/index.html&#34;&gt;&lt;em&gt;quantreg&lt;/em&gt;&lt;/a&gt;
unmittelbar umsetzen lässt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(quantreg)
ergmedianreg &amp;lt;- rq(mpg ~ hp, data = dt)
coef(ergmedianreg)
#&amp;gt; (Intercept)          hp 
#&amp;gt; 28.13050847 -0.06016949&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;idee-betrag-der-summe-der-abweichungen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;1. Idee: Betrag der Summe der Abweichungen&lt;/h2&gt;
&lt;p&gt;Wenn wir die Summe der Abweichungen &lt;span class=&#34;math inline&#34;&gt;\(\sum\limits_{i=1}^n \hat{e}_i\)&lt;/span&gt; minimieren
wollen, dann ist es sinnvoll den Betrag davon zu minimieren.
Wir suchen also die Schätzer &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1\)&lt;/span&gt;, so dass der Ausdruck&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\left| \sum_{i=1}^n \hat{e}_i \right| = \left| \sum_{i=1}^n (\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i) \right|
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;minimal ist.&lt;/p&gt;
&lt;p&gt;Wegen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}
\sum_{i=1}^n (\hat\beta_0 + \hat\beta_1 \cdot x_i - y_i)
&amp;amp;= \sum_{i=1}^n \hat\beta_0 + \sum_{i=1}^n \hat\beta_1 \cdot x_i - \sum_{i=1}^n y_i \\
&amp;amp;= n \cdot \hat\beta_0 + \hat\beta_1 \cdot \sum_{i=1}^n x_i - \sum_{i=1}^n y_i \\
&amp;amp;= n \cdot \hat\beta_0 + \hat\beta_1 \cdot n \cdot \bar{x} - n \cdot \bar{y} \\
&amp;amp;= n \cdot \left( \hat\beta_0 + \hat\beta_1 \cdot \bar{x} - \bar{y} \right) \\
&amp;amp;= n \cdot \left( \hat\beta_0 - \bar{y} + \hat\beta_1 \cdot \bar{x}  \right)
\end{aligned}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;können wir das absolute Minimum bei &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 - \bar{y} =0\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1 \cdot \bar{x}=0\)&lt;/span&gt; erreichen, was zur Lösung
&lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_0 =\bar{y}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat\beta_1 = 0\)&lt;/span&gt; führt.
Dies ist unser &lt;em&gt;Nullmodel&lt;/em&gt; in dem die &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; keinen Einfluss auf die &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; haben und
wir daher pauschal die &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; mit &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i=\bar{y}\)&lt;/span&gt;, also dem Mittelwert der &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; abschätzen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;zusammenfassung&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Zusammenfassung&lt;/h2&gt;
&lt;p&gt;Als Vergleich können wir uns die Quadratsumme &lt;span class=&#34;math inline&#34;&gt;\(QS\)&lt;/span&gt; und Absolutsumme &lt;span class=&#34;math inline&#34;&gt;\(AS\)&lt;/span&gt; der drei
Modelle einmal ansehen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quadratische Abweichungssummen
qs &amp;lt;- function(b_0, b_1) {
  sum(((b_0 + b_1 * dt$hp) - dt$mpg )**2)
}

# Absolute Abweichungssummen
as &amp;lt;- function(b_0, b_1) {
  sum(abs((b_0 + b_1 * dt$hp) - dt$mpg))
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Quadratsummen:
quad_sum &amp;lt;- c(qs(b0, b1), qs(as_b0, as_b1), qs(mean_mpg, 0))

# Absolutsummen:
abs_sum &amp;lt;- c(as(b0, b1), as(as_b0, as_b1), as(mean_mpg, 0))

tab &amp;lt;- tibble(
  sums = c(quad_sum, abs_sum),
  sum_type = rep(c(&amp;quot;quad&amp;quot;, &amp;quot;abs&amp;quot;), each = 3),
  methode = rep(c(&amp;quot;Idee 3&amp;quot;, &amp;quot;Idee 2&amp;quot;, &amp;quot;Idee 1&amp;quot;), 2)
)

pivot_wider(tab, names_from=sum_type, values_from=sums, names_sort=T)
#&amp;gt; # A tibble: 3 x 3
#&amp;gt;   methode   abs  quad
#&amp;gt;   &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1 Idee 3   93.0  448.
#&amp;gt; 2 Idee 2   87.3  477.
#&amp;gt; 3 Idee 1  151.  1126.&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;reproduzierbarkeitsinformationen&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Reproduzierbarkeitsinformationen&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; R version 4.1.0 (2021-05-18)
#&amp;gt; Platform: x86_64-apple-darwin17.0 (64-bit)
#&amp;gt; Running under: macOS Catalina 10.15.7
#&amp;gt; 
#&amp;gt; Locale: de_DE.UTF-8 / de_DE.UTF-8 / de_DE.UTF-8 / C / de_DE.UTF-8 / de_DE.UTF-8
#&amp;gt; 
#&amp;gt; Package version:
#&amp;gt;   mosaic_1.8.3  quantreg_5.86 tidyr_1.1.3   xfun_0.24&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Das “Cookbook” zur Datentabelle können Sie mit Hilfe von &lt;code&gt;help(&#34;mtcars&#34;)&lt;/code&gt; aufrufen!&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Korrigieren von Arbeiten mit Excel und R</title>
      <link>https://sefiroth.net/nab/post/korrigieren-von-arbeiten-mit-excel-und-r/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/korrigieren-von-arbeiten-mit-excel-und-r/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Das korrigieren von Arbeiten ist nicht gerade des Lehrenden liebste Tätigkeit. Vorallem, wenn man eine Mischung auf Multiple-Choice und Freitest Aufgaben zu korrigieren hat und leider keine gute technische Unterstützung vorfindet.&lt;/p&gt;
&lt;p&gt;Klar gibt es wunderschöne Lösungen mit R dazu, wie zum Beispiel &lt;a href=&#34;http://www.r-exams.org&#34; class=&#34;uri&#34;&gt;http://www.r-exams.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Aber zum Glück kann man den Ablauf auch “mit Bordmitteln” etwas verbessern.&lt;/p&gt;
&lt;p&gt;Wir bekommen eine Liste der Teilnehmer, in Form eine Excel- oder CSV-Datei, in die wir die Punkte eintragen können, die von der Hochschule digital verarbeitet wird. Diese Liste nehmen wir als Grundlage um den Ablauf etwas zu optimieren.&lt;/p&gt;
&lt;p&gt;In den Klausuren gibt es vier Sorten von Aufgabentypen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Multiple Choice mit genau einer Antwortmöglichkeit&lt;/li&gt;
&lt;li&gt;Multiple Choice mit mehr als einer Antwortmöglichkeit&lt;/li&gt;
&lt;li&gt;(Ganze) Zahlen als Antwort auf eine Frage&lt;/li&gt;
&lt;li&gt;Begründungen und/oder freie Textantworten&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Die ersten drei Aufgabentypen können sehr schön mit Hilfe einer Exceltabelle erfasst werden. Der vierte Aufgabentyp muss direkt bewertet werden und wird in so ebenfalls in die Exceltabelle eingegeben.&lt;/p&gt;
&lt;p&gt;Die erfassten Daten der Klausuren liegen zu Beginn der Auswertung in einer Exceldatei bereit, die in etwa wie folgt aussieht:&lt;/p&gt;
&lt;p&gt;&amp;lt; &amp;lt; &amp;lt; BILD EXCEL DATEI &amp;gt; &amp;gt; &amp;gt;&lt;/p&gt;
&lt;p&gt;Diese Datei wird unter dem Namen &lt;code&gt;Klausurteilnehmendenliste.xslx&lt;/code&gt; gespeichert.&lt;/p&gt;
&lt;p&gt;Die Auswertung geschieht dann mittels eines kleinen R-Skripts:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
library(readxl)

max.show &amp;lt;- 10

Aufgaben.Index &amp;lt;- 1:40
Aufgaben.Typ   &amp;lt;- rep(&amp;quot;MC&amp;quot;, 40)
for (idx in c(1, 9, 14, 36, 37, 38, 39, 40)){
    Aufgaben.Typ[idx] &amp;lt;- &amp;quot;nonMC&amp;quot;
}

Aufgaben.Punkte.max &amp;lt;- c( 8, 1, 1, 1, 2, 1, 2, 2, 3, 1, 
                          2, 1, 1, 3, 2, 1, 4, 2, 2, 2, 
                          2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 
                          1, 2, 1, 1, 1, 6, 4, 4, 6, 8)
Aufgaben.MC.richtig &amp;lt;- c(NA, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, NA, &amp;quot;B&amp;quot;,
                         &amp;quot;BD&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, NA, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;BC&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;,
                         &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;,  &amp;quot;2&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;,
                         &amp;quot;B&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, NA, NA, NA, NA, NA
                        )
if (sum(Aufgaben.Punkte.max) != 90) stop(&amp;quot;Gesamtpunktzahl ist nicht 90!&amp;quot;)

for (idx in 1:40) {
    if (Aufgaben.Typ[idx] == &amp;quot;MC&amp;quot;) {
        if (is.na(Aufgaben.MC.richtig[idx])) stop(paste(&amp;quot;MC Aufgabe&amp;quot;, idx, &amp;quot;ohne Musterlösung!&amp;quot;))
    } else {
        if (!is.na(Aufgaben.MC.richtig[idx])) stop(paste(&amp;quot;Nicht-MC Aufgabe&amp;quot;, idx, &amp;quot;mit Musterlösung!&amp;quot;))
    }
}

Aufgaben &amp;lt;- c( 531388,
                NA, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;,  NA, &amp;quot;B&amp;quot;,
                &amp;quot;BD&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;,  NA, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;,  &amp;quot;&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;,
                &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;2&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;,
                &amp;quot;A&amp;quot;, &amp;quot;E&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;C&amp;quot;, NA, NA, NA, NA, NA
                )

sumMC &amp;lt;- function(test) {
    summe &amp;lt;- 0
    for(idx in 1:40) {
        if (!is.na(test[idx+1]) &amp;amp;&amp;amp; (!(test[idx+1] == &amp;quot;/&amp;quot; ))) {
            if (Aufgaben.Typ[idx] == &amp;quot;MC&amp;quot;) {
                tmp &amp;lt;- length(Aufgaben.MC.richtig[idx])
                if (tmp &amp;gt; 1) {
                    pp &amp;lt;-  Aufgaben.Punkte.max[idx]/tmp
                    for(x in unlist(strsplit(Aufgaben.MC.richtig[idx], NULL))) {
                        if (toupper(x) %in% toupper(test[idx+1])) {
                            summe &amp;lt;- summe + pp
                        }
                    }
                } else {
                    if (toupper(test[idx+1]) == toupper(Aufgaben.MC.richtig[idx])) {
                        summe &amp;lt;- summe + Aufgaben.Punkte.max[idx]
                    }
                }
            } else {
                if (!is.na(test[idx+1])) {
                    summe &amp;lt;- summe + as.integer(test[idx+1])
                }
            }
        }
    }
    return(summe)
}

Klausurteilnehmendenliste &amp;lt;- read_excel(&amp;quot;Klausurteilnehmendenliste.xlsx&amp;quot;)
Klausurteilnehmendenliste &amp;lt;- Klausurteilnehmendenliste %&amp;gt;% select(c(-1,-2)) %&amp;gt;% mutate_all(toupper)

Punkte &amp;lt;- apply(Klausurteilnehmendenliste, 1, sumMC)
Klausurteilnehmendenliste &amp;lt;- cbind(Klausurteilnehmendenliste, Punkte)

head(select(Klausurteilnehmendenliste, c(1, &amp;quot;Punkte&amp;quot;)), max.show)
tail(select(Klausurteilnehmendenliste, c(1, &amp;quot;Punkte&amp;quot;)), max.show)

Klausurteilnehmendenliste %&amp;gt;%
    filter(Punkte &amp;gt; 10) %&amp;gt;%
    gf_counts(~ Punkte, data=.)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit den Zeilen&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Aufgaben.Typ   &amp;lt;- rep(&amp;quot;MC&amp;quot;, 40)
for (idx in c(1, 9, 14, 36, 37, 38, 39, 40)){
    Aufgaben.Typ[idx] &amp;lt;- &amp;quot;nonMC&amp;quot;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;werden zunächst 40 MC-Aufgaben angelegt und danach die Aufgaben 1, 9, 14, 36, 37, 38, 39 und 40 als nicht MC Aufgaben gekennzeichnet. Hier muss später die Punktzahl direkt eingegeben werden!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Aufgaben.Punkte.max &amp;lt;- c( 8, 1, 1, 1, 2, 1, 2, 2, 3, 1, 
                          2, 1, 1, 3, 2, 1, 4, 2, 2, 2, 
                          2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 
                          1, 2, 1, 1, 1, 6, 4, 4, 6, 8)
Aufgaben.MC.richtig &amp;lt;- c(NA, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, NA, &amp;quot;B&amp;quot;,
                         &amp;quot;BD&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, NA, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;BC&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;,
                         &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;,  &amp;quot;2&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;,
                         &amp;quot;B&amp;quot;, &amp;quot;F&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, NA, NA, NA, NA, NA
                        )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;Aufgaben.Punkte.max&lt;/code&gt; werden die maximal erreichbaren Punkte pro Aufgabe gespeichert. In &lt;code&gt;Aufgaben.MC.richtig&lt;/code&gt; sind alle &lt;em&gt;nicht MC&lt;/em&gt;-Aufgaben mit &lt;code&gt;NA&lt;/code&gt; gekennzeichnet. Die Lösungen werden als Zeichenkette (in Großbuchstaben) hinterlegt. Sollte eine MC-Aufgabe mehrere richtige Antworten haben, so schreibt man diese einfach hintereinander. So bedeutet “BD”, dass die Lösungen “B” und “D” richtig sind.&lt;/p&gt;
&lt;p&gt;Wird in den Lösungen für eine Aufgabe “/” eingetragen, so gilt diese Aufgabe als nicht bearbeitet und wird mit 0 Punkten bewertet.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Erste Schritte mit `vroom`</title>
      <link>https://sefiroth.net/nab/post/erste-schritte-mit-vroom/</link>
      <pubDate>Fri, 21 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/erste-schritte-mit-vroom/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Nach &lt;a href=&#34;https://readr.tidyverse.org&#34;&gt;&lt;code&gt;readr&lt;/code&gt;&lt;/a&gt; kommt &lt;a href=&#34;https://vroom.r-lib.org&#34;&gt;&lt;code&gt;vroom&lt;/code&gt;&lt;/a&gt;. In der Zwischenzeit liegt vroom in der Version 1.2.0 vor und daher habe ich mir ein paar Stunden Zeit gekommen um ein paar erste Experimente damit zu machen.&lt;/p&gt;
&lt;div id=&#34;erste-schritte-mit-vroom&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Erste Schritte mit vroom&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(vroom)

# URL für die Quelle von tips.csv:
url &amp;lt;- &amp;quot;https://goo.gl/whKjnl&amp;quot;

# Locale auf Deutsche Sprache, Dezimalkomma und Gruppierungspunkte setzen
mylocale &amp;lt;- locale(&amp;quot;de&amp;quot;, decimal_mark = &amp;quot;,&amp;quot;, grouping_mark = &amp;quot;.&amp;quot;)

# Spaltentypen ggf. vorgeben:
mycols &amp;lt;- cols(
            col_number(),  # total_bill
            col_number(),  # tip
            col_factor(),  # sex
            col_factor(),  # smoker
            col_factor(),  # day
            col_factor(),  # time
            col_integer()  # size
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Laden mit vroom, Spaltentypen erraten, Locale auf mylocale
tips.vroom &amp;lt;- vroom(url, locale = mylocale)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 244 Columns: 7&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &amp;quot;;&amp;quot;
## chr (4): sex, smoker, day, time
## dbl (3): total_bill, tip, size&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(tips.vroom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   total_bill   tip sex    smoker day   time    size
##        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;
## 1       17.0  1.01 Female No     Sun   Dinner     2
## 2       10.3  1.66 Male   No     Sun   Dinner     3
## 3       21.0  3.5  Male   No     Sun   Dinner     3
## 4       23.7  3.31 Male   No     Sun   Dinner     2
## 5       24.6  3.61 Female No     Sun   Dinner     4
## 6       25.3  4.71 Male   No     Sun   Dinner     4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(tips.vroom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [244 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ total_bill: num [1:244] 17 10.3 21 23.7 24.6 ...
##  $ tip       : num [1:244] 1.01 1.66 3.5 3.31 3.61 4.71 2 3.12 1.96 3.23 ...
##  $ sex       : chr [1:244] &amp;quot;Female&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; ...
##  $ smoker    : chr [1:244] &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; ...
##  $ day       : chr [1:244] &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; ...
##  $ time      : chr [1:244] &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; ...
##  $ size      : num [1:244] 2 3 3 2 4 4 2 4 2 2 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   total_bill = col_double(),
##   ..   tip = col_double(),
##   ..   sex = col_character(),
##   ..   smoker = col_character(),
##   ..   day = col_character(),
##   ..   time = col_character(),
##   ..   size = col_double(),
##   ..   .delim = &amp;quot;;&amp;quot;
##   .. )
##  - attr(*, &amp;quot;problems&amp;quot;)=&amp;lt;externalptr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(tips.vroom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 20632 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Laden mit vroom, Spaltentypen mycols, Locale auf mylocale
tips.vroom2 &amp;lt;- vroom(url, col_types = mycols, locale = mylocale)

head(tips.vroom2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   total_bill   tip sex    smoker day   time    size
##        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;
## 1       17.0  1.01 Female No     Sun   Dinner     2
## 2       10.3  1.66 Male   No     Sun   Dinner     3
## 3       21.0  3.5  Male   No     Sun   Dinner     3
## 4       23.7  3.31 Male   No     Sun   Dinner     2
## 5       24.6  3.61 Female No     Sun   Dinner     4
## 6       25.3  4.71 Male   No     Sun   Dinner     4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(tips.vroom2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [244 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ total_bill: num [1:244] 17 10.3 21 23.7 24.6 ...
##  $ tip       : num [1:244] 1.01 1.66 3.5 3.31 3.61 4.71 2 3.12 1.96 3.23 ...
##  $ sex       : Factor w/ 2 levels &amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;: 1 2 2 2 1 2 2 2 2 2 ...
##  $ smoker    : Factor w/ 2 levels &amp;quot;No&amp;quot;,&amp;quot;Yes&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ day       : Factor w/ 4 levels &amp;quot;Sun&amp;quot;,&amp;quot;Sat&amp;quot;,&amp;quot;Thur&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ time      : Factor w/ 2 levels &amp;quot;Dinner&amp;quot;,&amp;quot;Lunch&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ size      : int [1:244] 2 3 3 2 4 4 2 4 2 2 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   total_bill = col_number(),
##   ..   tip = col_number(),
##   ..   sex = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   smoker = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   day = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   time = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   size = col_integer(),
##   ..   .delim = &amp;quot;;&amp;quot;
##   .. )
##  - attr(*, &amp;quot;problems&amp;quot;)=&amp;lt;externalptr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(tips.vroom2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 19416 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Readr
library(readr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Registered S3 methods overwritten by &amp;#39;readr&amp;#39;:
##   method           from 
##   format.col_spec  vroom
##   print.col_spec   vroom
##   print.collector  vroom
##   print.date_names vroom
##   print.locale     vroom
##   str.col_spec     vroom&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attache Paket: &amp;#39;readr&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Die folgenden Objekte sind maskiert von &amp;#39;package:vroom&amp;#39;:
## 
##     as.col_spec, col_character, col_date, col_datetime, col_double,
##     col_factor, col_guess, col_integer, col_logical, col_number,
##     col_skip, col_time, cols, cols_condense, cols_only, date_names,
##     date_names_lang, date_names_langs, default_locale, fwf_cols,
##     fwf_empty, fwf_positions, fwf_widths, locale, output_column,
##     problems, spec&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips.readr &amp;lt;- readr::read_csv2(url)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Using &amp;#39;\&amp;#39;,\&amp;#39;&amp;#39; as decimal and &amp;#39;\&amp;#39;.\&amp;#39;&amp;#39; as grouping mark. Use `read_delim()` for more control.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   total_bill = col_double(),
##   tip = col_double(),
##   sex = col_character(),
##   smoker = col_character(),
##   day = col_character(),
##   time = col_character(),
##   size = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(tips.readr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   total_bill   tip sex    smoker day   time    size
##        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;
## 1       17.0  1.01 Female No     Sun   Dinner     2
## 2       10.3  1.66 Male   No     Sun   Dinner     3
## 3       21.0  3.5  Male   No     Sun   Dinner     3
## 4       23.7  3.31 Male   No     Sun   Dinner     2
## 5       24.6  3.61 Female No     Sun   Dinner     4
## 6       25.3  4.71 Male   No     Sun   Dinner     4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(tips.readr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [244 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ total_bill: num [1:244] 17 10.3 21 23.7 24.6 ...
##  $ tip       : num [1:244] 1.01 1.66 3.5 3.31 3.61 4.71 2 3.12 1.96 3.23 ...
##  $ sex       : chr [1:244] &amp;quot;Female&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; ...
##  $ smoker    : chr [1:244] &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; ...
##  $ day       : chr [1:244] &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; ...
##  $ time      : chr [1:244] &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; ...
##  $ size      : num [1:244] 2 3 3 2 4 4 2 4 2 2 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   total_bill = col_double(),
##   ..   tip = col_double(),
##   ..   sex = col_character(),
##   ..   smoker = col_character(),
##   ..   day = col_character(),
##   ..   time = col_character(),
##   ..   size = col_double()
##   .. )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(tips.readr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 20400 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Readr
tips.readr2 &amp;lt;- readr::read_csv2(url,
                                col_types = list(
                                col_double(),  # total_bill
                                col_double(),  # tip
                                col_factor(),  # sex
                                col_factor(),  # smoker
                                col_factor(),  # day
                                col_factor(),  # time
                                col_integer()  # size
                     )
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ℹ Using &amp;#39;\&amp;#39;,\&amp;#39;&amp;#39; as decimal and &amp;#39;\&amp;#39;.\&amp;#39;&amp;#39; as grouping mark. Use `read_delim()` for more control.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(tips.readr2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##   total_bill   tip sex    smoker day   time    size
##        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt;  &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;  &amp;lt;int&amp;gt;
## 1       17.0  1.01 Female No     Sun   Dinner     2
## 2       10.3  1.66 Male   No     Sun   Dinner     3
## 3       21.0  3.5  Male   No     Sun   Dinner     3
## 4       23.7  3.31 Male   No     Sun   Dinner     2
## 5       24.6  3.61 Female No     Sun   Dinner     4
## 6       25.3  4.71 Male   No     Sun   Dinner     4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(tips.readr2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## spec_tbl_df [244 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ total_bill: num [1:244] 17 10.3 21 23.7 24.6 ...
##  $ tip       : num [1:244] 1.01 1.66 3.5 3.31 3.61 4.71 2 3.12 1.96 3.23 ...
##  $ sex       : Factor w/ 2 levels &amp;quot;Female&amp;quot;,&amp;quot;Male&amp;quot;: 1 2 2 2 1 2 2 2 2 2 ...
##  $ smoker    : Factor w/ 2 levels &amp;quot;No&amp;quot;,&amp;quot;Yes&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ day       : Factor w/ 4 levels &amp;quot;Sun&amp;quot;,&amp;quot;Sat&amp;quot;,&amp;quot;Thur&amp;quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ time      : Factor w/ 2 levels &amp;quot;Dinner&amp;quot;,&amp;quot;Lunch&amp;quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ size      : int [1:244] 2 3 3 2 4 4 2 4 2 2 ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   total_bill = col_double(),
##   ..   tip = col_double(),
##   ..   sex = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   smoker = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   day = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   time = col_factor(levels = NULL, ordered = FALSE, include_na = FALSE),
##   ..   size = col_integer()
##   .. )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(tips.readr2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 19184 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Mit Bordmitteln von R
download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
tips.csv2 &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(tips.csv2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   total_bill  tip    sex smoker day   time size
## 1      16.99 1.01 Female     No Sun Dinner    2
## 2      10.34 1.66   Male     No Sun Dinner    3
## 3      21.01 3.50   Male     No Sun Dinner    3
## 4      23.68 3.31   Male     No Sun Dinner    2
## 5      24.59 3.61 Female     No Sun Dinner    4
## 6      25.29 4.71   Male     No Sun Dinner    4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(tips.csv2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    244 obs. of  7 variables:
##  $ total_bill: num  17 10.3 21 23.7 24.6 ...
##  $ tip       : num  1.01 1.66 3.5 3.31 3.61 4.71 2 3.12 1.96 3.23 ...
##  $ sex       : chr  &amp;quot;Female&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; &amp;quot;Male&amp;quot; ...
##  $ smoker    : chr  &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; &amp;quot;No&amp;quot; ...
##  $ day       : chr  &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; &amp;quot;Sun&amp;quot; ...
##  $ time      : chr  &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; &amp;quot;Dinner&amp;quot; ...
##  $ size      : int  2 3 3 2 4 4 2 4 2 2 ...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(tips.csv2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 14720 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Eine typische Frage von Studierenden</title>
      <link>https://sefiroth.net/nab/post/eine-typische-frage-von-studierenden/</link>
      <pubDate>Wed, 12 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/eine-typische-frage-von-studierenden/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Vor kurzem fand ich mal wieder eine Anfrage einer Studierenden in meinem Email Postfach. Die Frage lautete in etwa wie folgt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Guten Tag Herr Markgraf,&lt;/p&gt;
&lt;p&gt;ich würde gerne die Hypothese untersuchen: Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.
Dazu habe ich eine Variable “iphones.tagsüber.unbeachtet” mit 1x, 2x und 3x täglich als Ausprägungen und eine andere Variable “wetter.ist.gut”, die als Ausprägung “Ja” und “Nein” hat.
Welchen Test kann ich dazu zur Überprüfung einer Abhängigkeit nehmen?&lt;/p&gt;
&lt;p&gt;Vielen Dank im Voraus.&lt;/p&gt;
&lt;p&gt;MfG Monika Mustermann&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Natürlich ist diese Frage im Prinzip einfach zu beantworten, sogar von Leuten, die Statistik an einer Hochschule gehört haben. – Aber da ich ja auch sonst nichts zu tun habe, gebe ich gerne statistische Hilfestellung für Studierende.
Sicher, ich verdiene damit eigentlich mein Geld.
Also ist es nur natürlich, dass ich so etwas vollkommen unentgeldlich mache.
Und wieso sollten Studierende einfach mal ein Buch in die Hand nehmen und
selber nachdenken?
Es gibt vermutlich keine Bücher zu diesem Thema, denn es ist ganz sicher eine Geheimwissenschaft.
Und wieso sollte man dann also seine Betreuungsperson zu diesem Probem fragen?
Die hat ja auch so viel zu tun… – Egal.&lt;/p&gt;
&lt;p&gt;Was haben wir hier vorliegen? – Im einfachsten Fall sind es zwei kategoriale Variablen, und wir wollen sehen ob diese von einander (un-)abhängig sind.&lt;/p&gt;
&lt;p&gt;Mangels tatsächlicher Daten basteln wir uns einfach mal ein Beispiel:&lt;/p&gt;
&lt;div id=&#34;wir-bastlen-uns-ein-beispiel&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Wir bastlen uns ein Beispiel&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wie immer zuerst das Paket &amp;#39;mosaic&amp;#39; laden
library(mosaic)

# Einen beliebigen Startwert für den Zufallszahlengenerator
# für die Reproduzierbarkeit
set.seed(123)

# Anzahl der Vorfälle insgesamt
n &amp;lt;- 176

# Anzahl der Wiederholungen für die SBI-Methoden
loops &amp;lt;- 10000

# Erfinden eines Beispieldatensatzes
daten &amp;lt;- data.frame(
  iphones.tagsüber.unbeachtet = sample(rep(c(&amp;quot;1xtäglich&amp;quot;,&amp;quot;2xtäglich&amp;quot;,&amp;quot;3xtäglich&amp;quot;),n),n),
  wetter.ist.gut = sample(rep(c(&amp;quot;Ja&amp;quot;,&amp;quot;Nein&amp;quot;),n),n)
)

# Ausgabe der ersten Zeilen des Datensatzes
head(daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   iphones.tagsüber.unbeachtet wetter.ist.gut
## 1                   1xtäglich             Ja
## 2                   1xtäglich           Nein
## 3                   2xtäglich             Ja
## 4                   3xtäglich           Nein
## 5                   1xtäglich             Ja
## 6                   2xtäglich             Ja&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ein-blick-auf-kennzahlen-und-visualisierungsmöglichkeiten&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein Blick auf Kennzahlen und Visualisierungsmöglichkeiten&lt;/h3&gt;
&lt;p&gt;Man kann diese Daten als Kreuztabelle zusammenfassen und diese dann mit Hilfe eines Mosaikplots darstellen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet Ja Nein
##                   1xtäglich 29   33
##                   2xtäglich 34   26
##                   3xtäglich 27   27&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mosaicplot(wetter.ist.gut ~ iphones.tagsüber.unbeachtet, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Für später speichern wir die Kreuztabelle in obs.tab
obs.tab &amp;lt;- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;von-der-forschungsthese-zur-hypothese&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Von der Forschungsthese zur Hypothese&lt;/h3&gt;
&lt;p&gt;Um nun zwischen abhängig und unabhängig statistisch zu unterscheiden, sollte man sich die Null- und Alternativhypothese genau überlegen und &lt;em&gt;operationalisieren&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Ein Blick auf die (orginale) Forschungsthese: “Die reduzierte Abhängigkeit des Iphones tagsüber liegt am schönen Wetter.”&lt;/p&gt;
&lt;p&gt;Oh je, eine kausale Forschungsthese. Ein dezenter Hinweis auf das Werk von Judea Pearl und Dana Mackenzie &lt;a href=&#34;https://www.amazon.de/Book-Why-Science-Cause-Effect/dp/046509760X/ref=sr_1_1?adgrpid=70747374853&amp;amp;dchild=1&amp;amp;gclid=EAIaIQobChMIio7A5a-57gIVBKOyCh1zPAemEAAYAyAAEgKbXPD_BwE&amp;amp;hvadid=352621590167&amp;amp;hvdev=c&amp;amp;hvlocphy=9043910&amp;amp;hvnetw=g&amp;amp;hvqmt=b&amp;amp;hvrand=4305248996988708271&amp;amp;hvtargid=kwd-422343395170&amp;amp;hydadcr=16871_1724817&amp;amp;keywords=the+book+of+why+judea+pearl&amp;amp;qid=1611656438&amp;amp;sr=8-1&amp;amp;tag=googhydr08-21&#34;&gt;“The Book of Why!”&lt;/a&gt; muss an dieser Stelle sein. – Aber da wir keine kausale Modellierung machen wollen, müssen wir das Problem sinngetreu umformulieren:&lt;/p&gt;
&lt;p&gt;“Es besteht ein Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.”&lt;/p&gt;
&lt;p&gt;Warum diese neue Formulierung? – Nun, in der orginal Forschungsthese wird ein &lt;strong&gt;kausal&lt;/strong&gt; Zusammenhang geprüft. Da es sich vermutlich um eine Beobachtungstudie handelt können wir einen solchen Ursache-Wirkungs-Zusammenhang aber hier nicht so einfach prüfen. Wie das gehen könnte, dazu schaut man mal bei J.Pearl und D.Mackenzie (s.o.) nach.
Zwar kann man von außen sagen: “Wenn es einen Zusammenhang gibt, dann führt das schöne Wetter zur Nichtbeachtung.” mit klassischer Statistik können wir hier aber nur den Zusammenhang (und zwar ungerichtet!) testen.
Liegt dieser &lt;strong&gt;nicht&lt;/strong&gt; vor, so spricht erstmal auch nichts für einen kausalen Zusammenhang, aber ein Zusammenhang an sich spricht noch nicht für einen kausalen Zusammenhang!
(Korrelation ist ebeb &lt;strong&gt;nicht&lt;/strong&gt; Kausalität!)&lt;/p&gt;
&lt;p&gt;Aus der umformulierten Forschungsfrage können wir die Alternativ- und auch die Nullhypothese ableiten:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Alternativhypothese:&lt;/strong&gt; Es besteht ein Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nullhypothese:&lt;/strong&gt; Es besteht &lt;strong&gt;kein&lt;/strong&gt; Zusammenhang zwischen ‘schönem Wetter’ und dem ‘Iphone tagsüber unbeachtet’ lassen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wie-kann-man-nun-den-zusammenhang-messen-und-wie-sieht-kein-zusammenhang-dabei-aus&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wie kann man nun den Zusammenhang &lt;em&gt;messen&lt;/em&gt; und wie sieht &lt;em&gt;kein Zusammenhang&lt;/em&gt; dabei aus?&lt;/h2&gt;
&lt;p&gt;Um zu sehen ob unsere Werte keinen Zusammenhang haben, also rein zufällig sind, oder es einen inneren Zusammenhang gibt müssen wir die äußeren von den inneren Häufigkeiten trennen.&lt;/p&gt;
&lt;p&gt;Konkret heißt das, wir schauen uns an wie die Häufigkeiten oder auch Verteilung der einzelnen Variabeln ausssehen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## wetter.ist.gut
##   Ja Nein 
##   90   86&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tally(~ iphones.tagsüber.unbeachtet, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## iphones.tagsüber.unbeachtet
## 1xtäglich 2xtäglich 3xtäglich 
##        62        60        54&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;freiheitsgrade&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Freiheitsgrade&lt;/h4&gt;
&lt;p&gt;Die Werte innerhalb der Kreuztabelle oben werden im wesendlichen durch diese Werte bestimmt. Die außeren Werte sind also unsere Rahmenbedingungen. Dabei ist der Einfluss der sogenannten &lt;em&gt;Randhäufigkeiten&lt;/em&gt; (&lt;em&gt;Marginale Häufigkeit&lt;/em&gt;) nicht zu unterschätzen. Denn wenn wir diese als &lt;em&gt;fix&lt;/em&gt;/&lt;em&gt;gegeben&lt;/em&gt; ansehen, können wir nur mit den sechs Werten in der Mitte unserer Kreuztabelle &lt;em&gt;spielen&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Doch sind nicht alle sechs Werte wirklich frei wählbar. Denn um zum Beispiel die Summe 62 in der ersten Zeile zu erhalten haben wir ja die Summe von 29 und 33 gebildet.&lt;/p&gt;
&lt;p&gt;Ist nun der Rand, also 62, fest, so kann ich nicht &lt;em&gt;beide&lt;/em&gt; Summanden frei wählen, denn&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 = 29 + 33\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;impliziert ja, dass allgemein&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 = x + y\]&lt;/span&gt;
gelten muss und somit durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[x = 62 - y \qquad\text{ bzw. }\qquad y = 62 - x\]&lt;/span&gt;
immer maximal eine der Variabeln – &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; oder &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; – wirklich frei wählen kann.&lt;/p&gt;
&lt;p&gt;Da dies für jede Zeile, aber auch für jede Spalte gilt, denn z.B. ist die Summe der ersten Spalte gegeben durch&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[90 = 29 + 34 + 27,\]&lt;/span&gt;
sind von den sechs Werten in der Kreuztabelle in der Tat nur 2 Werte wirklich frei zu wählen.
Wir haben also ein Problem mit &lt;em&gt;2 Freiheitsgraden&lt;/em&gt;, man schreibt das kurz mit &lt;span class=&#34;math inline&#34;&gt;\(df=2\)&lt;/span&gt; (&lt;em&gt;df&lt;/em&gt; steht dabei für &lt;em&gt;degree of freedom&lt;/em&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unabhängigkeit-in-der-statistik&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Unabhängigkeit in der Statistik&lt;/h3&gt;
&lt;p&gt;Wir sagen, in der Statistik, dass ein gemeinsames Ereignis unabhängig ist wenn sich das Ereignis als Produkt der beiden Einzelereignisse berechnen lässt.
Seien &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; also zwei Ereignisse, dann gilt im Falle der Unabhängigkeit:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(A \cap B) = P(A) \cdot P(B)\]&lt;/span&gt;
Oder etwas informeller: &lt;em&gt;Die Wahrscheinlichkeit das beide Ereignisse eintreffen ist das Produkt der Wahrscheinlichkeiten, dass jeweils eines der beiden Ereignisse eintrifft.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Wir können diese Definition aus der Wahrscheinlichkeitstheorie an unser Problem adaptieren, in dem wir die Wahrscheinlichkeiten durch die relativen Häufigkeiten ersetzen.&lt;/p&gt;
&lt;p&gt;Der Wert für das gemeinsame Ereignis &lt;code&gt;iphone.tagsüber.unbeachtet = 1xtäglich&lt;/code&gt; und das &lt;code&gt;wetter.ist.gut=ja&lt;/code&gt; wird im Falle der Unabhägigkeit durch die beiden Randhäufigkeiten bestimmt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[62 \cdot 90 = 31.7045455\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun mit eine Kreuztabelle erstellen, wie sie seien müsste, falls wir tatsächlich &lt;em&gt;statitische Unabhängigkeit&lt;/em&gt; hätten. Wir nutzen dafür eine sehr allgemein gehaltene, aber selbst programmierte, Funktion &lt;code&gt;expectation.tab()&lt;/code&gt;, der wir eine Tabelle mit den Häufigkeiten der Beobachtungen geben und die uns dann die Tabelle liefert, wie sie aussehen würde, falls tatsächlich &lt;em&gt;statitische Unabhängigkeit&lt;/em&gt; herrschen würde.&lt;/p&gt;
&lt;p&gt;Die Tabelle mit den beobchteten Werten speichern wir in &lt;code&gt;obs.tab&lt;/code&gt;, die der erwarteten Werte in &lt;code&gt;exp.tab&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expectation.tab &amp;lt;- function(tab.obs) {
  ret &amp;lt;- tab.obs
  max.i &amp;lt;- dim(tab.obs)[1]
  max.j &amp;lt;- dim(tab.obs)[2]
  
  # Randhäufigkeiten 
  x &amp;lt;- rep(0, max.i)
  for (i in 0:max.i) x[i] = sum(tab.obs[i,])

  y &amp;lt;- rep(0, max.j)
  for (j in 0:max.j) y[j] = sum(tab.obs[,j])

  # Anzahl aller Beobachtungen
  n = sum(tab.obs)
  
  for (i in 0:max.i) {
    for (j in 0:max.j) {
       ret[i,j] &amp;lt;- (x[i] * y[j] / n)
    }
  }

  ret
}

# Kreuztabelle der beobachtete Werte
obs.tab &amp;lt;- tally(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)

# Kreuztabelle der erwarteten Werte auf Grundlage der beobachteten Werte
exp.tab &amp;lt;- expectation.tab(obs.tab)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Schauen wir uns die beiden Tabellen kurz an. Zuerst die der beobachteten Werte:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obs.tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet Ja Nein
##                   1xtäglich 29   33
##                   2xtäglich 34   26
##                   3xtäglich 27   27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dann die der erwarteten Werte:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exp.tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            wetter.ist.gut
## iphones.tagsüber.unbeachtet       Ja     Nein
##                   1xtäglich 31.70455 30.29545
##                   2xtäglich 30.68182 29.31818
##                   3xtäglich 27.61364 26.38636&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;was-können-wir-nun-messen&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was können wir nun messen?&lt;/h3&gt;
&lt;p&gt;Unsicherheit und Zufall spielen eine große Rolle. Wir können also nicht erwarten, dass die Werte für die Kreuztabelle in der Realität genau getroffen werden. (Vorallem, weil wir hier ja mit Nachkommastellen arbeiten!) Aber wir können versuchen den Abstand zu diesen Werten zu messen. Je weiter weg die Werte in der Kreuztabelle von den theoretischen Werten liegen, um so unwarscheinlicher ist es, dass die Werte zufällig aus einer unabhängigen Population gezogen wurden. D.h. wir könnten uns für eine Abhägigkeit aussprechen.&lt;/p&gt;
&lt;div id=&#34;messen-mit-dem-absolutabstand&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Messen mit dem Absolutabstand?&lt;/h4&gt;
&lt;p&gt;Man könnte nun auf die Idee kommen die Abstände an jeder Stelle zu messen und den absoluten Abstand zu summieren:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(abs(obs.tab - exp.tab))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13.27273&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nur was sagt dieser Wert aus? – Ist das ein kleiner Abstand oder ein großer?&lt;/p&gt;
&lt;p&gt;Wir brauchen Referenzwerte zur Orientierung. Eine Idee lautet: &lt;strong&gt;Permutationstest&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sind die Werte unabhängig von einander, dann spielt die konkrete Zuordnung keine Rolle, sondern nur die Anzahl der Ereignisse an sich. Ordnen wir nun zufällig einem &lt;code&gt;iphones.tagsüber.unbeachtet&lt;/code&gt;-Wert einen beliebigen &lt;code&gt;wetter.ist.gut&lt;/code&gt;-Wert zu, dann besteht kein Zusammenhang mehr zwischen den Werten. Dies machen wir mittels &lt;code&gt;iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Wir simulieren so den Zustand, dass es keine Abhängigkeit zwischen den Werten gibt.&lt;/p&gt;
&lt;p&gt;Dabei messen wir den Abstand zwischen den Abstand zwischen den beobachteten Werten und den Werten, die wir erwarten würden, falls Unabhägigkeit vorliegen würde. Dafür nutzen wir die selbsterstellte Funktioen &lt;code&gt;diffabsobsexp&lt;/code&gt;, welche die Summe der absoluten Abweichungen berechnet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffabsobsexp}(obs, exp) = \sum\limits_i \left|obs_i - exp_i\right|\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen das ganze mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, die wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der absoluten Differenz zwischen
# beobachteten und erwarteten Werte
diffabsobsexp &amp;lt;- function(obs, exp) {
  sum(abs(obs - exp))
}

# Absolute Abweichung der gemessenen Werte
obs.abs &amp;lt;- diffabsobsexp(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffabsobsexp(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_histogram(~ diffabsobsexp, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert, also die relative Fläche rechts von der roten Linie in unseren Histogramm, abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffabsobsexp &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5714&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Absolute Abweichungen (oder auch &lt;em&gt;absolute Fehler&lt;/em&gt;) haben die Tendenz bei großen Zahlen auch große Abweichungswerte zu liefern und bei kleinen Werten eher kleine Abweichungswerte.
Das kann man als Markel ansehen.
Daher arbeitet man vielleicht lieber mit relativen Abweichungen (oder auch &lt;em&gt;relativen Fehlern&lt;/em&gt;).
Dabei setzt man die absolute Abweichung jedesmal in Bezug auf den erwarteten Wert.
Die dazu passenden Funktion haben wir unten mit &lt;code&gt;diffabsobsexprel&lt;/code&gt; implementiert.
Dabei ist:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffabsobsexprel}(obs, exp) = \sum\limits_i \frac{\left|obs_i - exp_i\right|}{exp_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen das ganze mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der korrigierten absoluten 
# Differenz zwischen beobachteten und erwarteten Werten
diffabsobsexprel &amp;lt;- function(obs, exp) {
  sum((abs(obs - exp))/exp)
}

# Absolute Abweichung der gemessenen Werte -- korrigiert
obs.abs &amp;lt;- diffabsobsexprel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffabsobsexprel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_dhistogram(~ diffabsobsexprel, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Auch hier können wir den p-Wert abschätzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffabsobsexprel &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Ist der absolute Abstand überhaupt gut gewählt? – Wäre nicht eher der quadratische Abstand angebracht?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Ein Vorteil des quadratischen Abstand ist es, dass er kleine Abstände kleiner und große Abstände größer bewertet, als der absolute Abstand. Außerdem hat er mathematisch einige Vorteile. Wir messen nun den quadratischen Abstande mit der Funktion
&lt;code&gt;diffquad&lt;/code&gt;, die wie folgt arbeitet:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffquad}(obs, exp) = \sum\limits_i \left(obs_i - exp_i\right)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir Wiederholen dies nun mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquad &amp;lt;- function(obs, exp) {
  sum((obs - exp)^2)
}

# Quadratische Abweichung der gemessenen Werte
obs.abs &amp;lt;- diffquad(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffquad(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_dhistogram(~ diffquad, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffquad &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5389&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie beim absoluten Abstand werden hier die Größe der Werte ausser acht gelassen und vielleicht fühlen wir uns etwas wohler, wenn wir statt des quadratischen Abstands den relativen quadratischen Abstand benutzen:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{diffquadrel}(obs, exp) = \sum\limits_i \frac{\left(obs_i - exp_i\right)^2}{exp_i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Dies wiederholen wir nun mit Hilfe von &lt;code&gt;do(loops)&lt;/code&gt; genau &lt;code&gt;loops&lt;/code&gt;&lt;span class=&#34;math inline&#34;&gt;\(=10^{4}\)&lt;/span&gt; mal, geben dann das Histogramm aus und tragen als rote Linie den Wert ein, den wir bei unseren beobachteten Daten tatsächliche gemessen haben:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Funktion zur Berechnung der korrigierten quadratischen 
# Differenz zwischen beobachteten und erwarteten Werten
diffquadrel &amp;lt;- function(obs, exp) {
  sum(((obs - exp)^2)/exp)
}

# Quadratische Abweichung der gemessenen Werte -- korrigiert
obs.abs &amp;lt;- diffquadrel(obs.tab, exp.tab)

# Erzeugen der Nullverteilung
NullVert  &amp;lt;- do(loops) * diffquadrel(tally(iphones.tagsüber.unbeachtet ~ shuffle(wetter.ist.gut), data = daten), exp.tab)
gf_histogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data = NullVert) %&amp;gt;%
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Den Wert 1.2344597, den wir mit Hilfe der relativen quadratischen Abweichung berechnet haben, nennen wir auch &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt; Wert.&lt;/p&gt;
&lt;p&gt;Wir können nun den p-Wert abschätzen mit:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop( ~ diffquadrel &amp;gt;= obs.abs, data = NullVert)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.5599&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An Hand der p-Werte können wir nun über die Nullhypothese entscheiden:&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;was-sagt-die-klassische-statistik&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was sagt die klassische Statistik?&lt;/h3&gt;
&lt;p&gt;In der klassischen Statistik könnte man hier den &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-Unabhängigkeitstest anwenden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xchisq.test(iphones.tagsüber.unbeachtet ~ wetter.ist.gut, data = daten)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s Chi-squared test
## 
## data:  x
## X-squared = 1.2345, df = 2, p-value = 0.5394
## 
##    29       33   
## (31.70)  (30.30) 
## [0.231]  [0.241] 
## &amp;lt;-0.48&amp;gt;  &amp;lt; 0.49&amp;gt; 
##    
##    34       26   
## (30.68)  (29.32) 
## [0.359]  [0.376] 
## &amp;lt; 0.60&amp;gt;  &amp;lt;-0.61&amp;gt; 
##    
##    27       27   
## (27.61)  (26.39) 
## [0.014]  [0.014] 
## &amp;lt;-0.12&amp;gt;  &amp;lt; 0.12&amp;gt; 
##    
## key:
##  observed
##  (expected)
##  [contribution to X-squared]
##  &amp;lt;Pearson residual&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vergleichen wir nun die beiden Ansätze, SBI auf der einen und der klassische Ansatz auf der anderern Seite, einmal in einem Diagramm. Das (Dichte-)Histogramm sind die Daten aus der Nullverteilung für die quadratische, korrigierte Differenz. Die rote Linie ist der gemessene Abweichungswert. Die schwarze Linie ist der Graph der &lt;span class=&#34;math inline&#34;&gt;\(\chi^2\)&lt;/span&gt;-Verteilung mit zwei Freiheitsgraden:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_dhistogram(~ diffquadrel, binwidth = 0.5, center = 0.25, data = NullVert) %&amp;gt;%
  gf_fun(dchisq(x, df=2) ~ x, xlim = c(0:20), color = &amp;quot;blue&amp;quot;) %&amp;gt;% 
  gf_vline(xintercept = ~ obs.abs, color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Aber es gibt auch den (exakten) Fisher-Test:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fisher.test(obs.tab, alternative = &amp;quot;greater&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Fisher&amp;#39;s Exact Test for Count Data
## 
## data:  obs.tab
## p-value = 0.5609
## alternative hypothesis: greater&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;fazit&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fazit&lt;/h3&gt;
&lt;p&gt;Wir können die p-Werte der einzelnen Tests nun gegenüber stellen:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Scale for &amp;#39;y&amp;#39; is already present. Adding another scale for &amp;#39;y&amp;#39;, which will
## replace the existing scale.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-02-12-eine-typische-frage-von-studierenden_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Gewöhnlich haben wir ein Signifikanznivau von &lt;span class=&#34;math inline&#34;&gt;\(5\% = 0{,}05\)&lt;/span&gt; angenommen.
Die rote Linie zeigt diese Grenze.
Liegt der Balken links vor dieser Linie, so sprechen wir davon, dass der
gemessene Wert selten bei unabhänigen Daten vorliegt und würden uns gegen die
Nullhypothese und damit quasi für die Alternativhypothese entscheiden.
Liegt der Balken recht der roten Linie, so haben wir übliche Werte für
unabhängige Daten und keinen Grund gefunden, der gegen die Nullhypothese
spricht.
Warum wir sie dann, auf Grundlage unserer Daten, auch nicht ablehnen können.&lt;/p&gt;
&lt;p&gt;Bleibt Sie Frage, gibt es Situationen in denen die Entscheidung über die
Nullhypothese bei den einzelen betrachteten Verfahren unterschiedlichen ist?
Und wenn ja, wann und wieoft?&lt;/p&gt;
&lt;p&gt;Diese Fragen sind nicht Thema dieses Beitrags, aber vielleicht habe ich Zeit
und betrachte das später einmal.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Warum das Nachrechnen von Veröffentlichungen so wichtig ist</title>
      <link>https://sefiroth.net/nab/post/warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist/</link>
      <pubDate>Mon, 27 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Im Internet fand ich vor kurzem einen sehr interessanten &lt;a href=&#34;http://www.stefanbartz.de/dateien/Vorsicht-bei-der-sigma-Regel.pdf&#34;&gt;Text&lt;/a&gt; von &lt;a href=&#34;http://www.stefanbartz.de&#34;&gt;Stefan Bart&lt;/a&gt;. Eine Aufgabe daraus fand meine besondere Aufmerksamkeit.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;HSB gesucht (Grundgesamtheit mit &lt;span class=&#34;math inline&#34;&gt;\(H_0 \rightarrow\)&lt;/span&gt; Stichprobe)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Es soll die Nullhypothese, dass die 500 Mädchen und 500 Jungen der Schule gleich intelligent sind, getestet werden.
Dazu werden 200 zufällige Junge-Mädchen-Paare gebildet.
Bei 112 davon hatte der Junge einen höheren IQ. Ist die Abweichung vom Mittelwert signifikant?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Als Lösungen wurden vorgeschlagen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;em&gt;grobe Näherung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[x \in [n \cdot p_0 \pm \sqrt{n}\,] = [200 \cdot 0{,}5 \pm \sqrt{200}\,] \approx [85{,}85786; 114{,}1421] \approx [85; 115]\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;bessere Näherung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned}x \in \left[n \cdot p_0 \pm \Phi(0{,}975) \sqrt{n \cdot p_0 (1-p_0)}\,\right] &amp;amp;\approx \left[n \cdot p_0 \pm 1{,}96 \cdot \sqrt{n \cdot p_0 \cdot(1-p_0)} \,\right] \\ &amp;amp;\approx \left[200 \cdot 0{,}5 \pm 1.959964 \cdot \sqrt{200 \cdot 0{,}5 \cdot (1-0{,}5)}\,\right] \\ &amp;amp;\approx \left[86{,}14096; 113{,}859\right] \\&amp;amp;\approx \left[86; 114\right]\end{aligned}\]&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;exakte Lösung&lt;/em&gt;:
&lt;span class=&#34;math display&#34;&gt;\[x \in [89; 111]\]&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Auf Grundlage dieser drei Lösungen wurde dann entschieden, ob die Abweichung signifikant ist, also 112 im oder eben nicht im berechneten Intervall liegt. &lt;em&gt;Ergebnis:&lt;/em&gt; a), b) liefern nicht signifikante und c) ein signifikantes Ergebnis.&lt;/p&gt;
&lt;p&gt;Die Frage bleibt, was in der Aufgabenstellung mit “200 zufällige Junge-Mädchen-Paaren” gemeint ist.&lt;/p&gt;
&lt;p&gt;Bekannterweise kann man diesen Satz interpretieren:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Eine &lt;em&gt;uneingeschränkte Zufallsstichprobe&lt;/em&gt; erhält man z. B. bei einem &lt;em&gt;Ziehen ohne Zurücklegen&lt;/em&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Hypergeometrische Verteilung).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Eine &lt;em&gt;einfache Zufallsstichprobe&lt;/em&gt; z. B. bei einem &lt;em&gt;Ziehen mit Zurücklegen&lt;/em&gt; (&lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; Binomialverteilung).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Rechnet man mit Hilfe von &lt;em&gt;R&lt;/em&gt; die exakte Lösung nach, so erhält man:&lt;/p&gt;
&lt;p&gt;Für die Binomialverteilung (die “bessere Näherung”):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pl &amp;lt;- 0.025 # 2,5% als untere Grenze
pr &amp;lt;- 0.975 # 97,5% als obere Grenze

iu &amp;lt;- qbinom(pl, 200, prob=0.5)
io &amp;lt;- qbinom(pr, 200, prob=0.5)
c(iu, io) # Ausgabe des (HSB-)Intervalls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  86 114&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Für die Hypergeometischeverteilung (hier “exakte Lösung” genannt) müssen wir die zwei Gruppen (500 Jungen und 500 Mädchen) jeweils als ein mögliches Paar ansehen. Es gibt somit insgesamt 500 solcher Paare, da jeder Junge und jedes Mädchen in nur einem Paar vorkommen können. – Sehr wohl aber 500! solcher Möglichen Paar-Reihen.&lt;/p&gt;
&lt;p&gt;Betrachten wir nun jedes Paar nur einmal, dann ziehen wir aus der Menge der Paare also eine &lt;em&gt;Stichprobe ohne Zurücklegen&lt;/em&gt;, also eine &lt;em&gt;uneingeschränkte Zufallsstichprobe&lt;/em&gt;.
Zum bestimmen der Quantiele und damit des HSB benötigen wir dann die &lt;em&gt;hypergeometrische Verteilung&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Oh ja, diese Annahme ist sehr verwirrend, logisch nicht ganz einzusehen und einfach von Mathematik-Lehrenden gemacht worden, damit man die Hypergeometrischeverteilung hier anwenden kann. Alleine schon die Annahme, dass zwei Personen immer einen unterschiedlichen IQ haben müssen … – Egal!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- 250 # Anzahl der Paare mit besseren Mädchen
n &amp;lt;- 250 # Anzahl der Paare mit besseren Jungen
k &amp;lt;- 200 # Umfang des Stichprobe
pl &amp;lt;- 0.025 # 2,5% als untere Grenze
pr &amp;lt;- 0.975 # 97,5% als obere Grenze

iu &amp;lt;- qhyper(pl, m, n, k) # Linke/untere Intervallgrenze
io &amp;lt;- qhyper(pr, m, n, k) # Rechte/obere Intervallgrenze
c(iu, io) # Ausgabe des (HSB-)Intervalls&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  89 111&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;R&lt;/strong&gt; liefert aus &lt;em&gt;exakte Lösung&lt;/em&gt; das Intervall &lt;span class=&#34;math inline&#34;&gt;\([89; 111]\)&lt;/span&gt;. Schauen wir einmal genauer hin:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- 250 # Anzahl der Paare mit besseren Mädchen
n &amp;lt;- 250 # Anzahl der Paare mit besseren Jungen
k &amp;lt;- 200 # Umfang des Stichprobe

p &amp;lt;- dhyper(0:k, m, n, k)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Werte für die linke/untere Intervallgrenzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Werte für die linke/untere Intervallgrenzen:
sum(p[0:89])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01782071&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p[0:90])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02755396&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Werte für die rechte/untere Intervallgrenzen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Werte für die rechte/untere Intervallgrenzen:
sum(p[0:111])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.972446&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p[0:112])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9821793&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie wird nun gerundet? – Im Text heißt es:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Werden 2,5% und 97,5% nicht genau getroffen, wird hier nicht […] nach außen / .  , sondern in beiden Fällen nach rechts . gerundet;
d.h. man nimmt diejenigen Werte in das zu bestimmende Intervall auf, bei denen 2,5% bzw. 97,5% zum ersten Mal
übertroffen werden. Somit verbleiben weniger als 2,5% der Histogrammfläche am linken bzw. rechten Rand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;ein-paar-überlegungen-zum-lösen-der-aufgabe-mit-sbi&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Ein paar Überlegungen zum Lösen der Aufgabe mit SBI&lt;/h3&gt;
&lt;p&gt;Eigentlich haben wir es mit drei Fällen je Paar zu tun:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} &amp;gt; IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} &amp;lt; IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(IQ_{Junge} = IQ_{Mädchen}\)&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tatsächlich spielt hier welches Mädchen und welcher Junge im Paar sind eine entscheidende Rolle.&lt;/p&gt;
&lt;p&gt;Simulieren wir nun einmal, dass unsere beiden Gruppe im wesendlichen (und im Mittel) gleich intelligent sind, was wir durch einen gleich mittlenem IQ von 100 und einer Standardabweichung von 15 modellieren wollen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Wir laden zuerst das Paket `mosaic`
library(mosaic)

# Zur Reproduzierbarkeit
set.seed(2009)

# IQs für Jungen und Mädchen normalverteilt mit den Parametern mu=100 und sigma=15

# 1. Fassung, aber hier ist F_iq_junger = F_iq_maedchen
#iq_jungen &amp;lt;- rnorm(500, mean=100, sd=15)
#iq_maedchen &amp;lt;- rnorm(500, mean=100, sd=15)

# 2. Fassung
#iq &amp;lt;- rnorm(500, mean=100, sd=15)
#iq_jungen &amp;lt;- iq
#iq_maedchen &amp;lt;- iq

# 3. Fassung
iq_jungen &amp;lt;- rnorm(500, mean=100, sd=15)
iq_maedchen &amp;lt;- rnorm(499, mean=100, sd=15)
iq_maedchen &amp;lt;- c(iq_maedchen, mean(iq_jungen)+499*(mean(iq_jungen)-mean(iq_maedchen)))

# Ein Blick auf die beinden Datenreihen
length(iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(iq_jungen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 99.22318&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(iq_jungen)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 99.22318&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Bilden wir nun die Paare:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paare &amp;lt;- data.frame(jungen = iq_jungen, maedchen = iq_maedchen)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und schauen uns nun einmal an, wie oft – bei zufälliger Auswahl von 200 Paarungen – es vorkommen kann, dass Jungen in den Paarungen einen höheren IQ haben als Mädchen. Das wäre dann dem Zufall geschuldet und nicht der übermässigen Intelligenz der Jungen. (Da nach Vereinbarung beide Gruppen gleich intelligent waren!)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;NullVerteilung &amp;lt;- do(5000) * count( ~ sample(jungen, 200) - sample(maedchen, 200) &amp;gt; 0, data=paare)
gf_bar( ~ n_TRUE, data=NullVerteilung)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2020-01-27-warum-das-nachrechnen-von-veroeffentlichungen-so-wichtig-ist_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Das HSB für diesen Fall wäre dann:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(hsb &amp;lt;- quantile( ~ n_TRUE, prob=c(0.025, 0.975), data=NullVerteilung))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  2.5% 97.5% 
##    83   107&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Anders formuliert, der zu erwartende Hauptstreubereich ist das Intervall &lt;span class=&#34;math inline&#34;&gt;\([83, 107]\)&lt;/span&gt;!&lt;/p&gt;
&lt;p&gt;Die 112 Paare in denen die Jungen einen höheren IQ haben, sind also nicht zu erwarten. (Also &lt;em&gt;signifikant!&lt;/em&gt;)&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Die ersten Schritte zur Prognose mitteles linearer Regression</title>
      <link>https://sefiroth.net/nab/post/die-ersten-schritte-zur-prognose-mitteles-linearer-regression/</link>
      <pubDate>Wed, 18 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/die-ersten-schritte-zur-prognose-mitteles-linearer-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Prognosen sind ein wichtiger Bestandteil von Data Science und ist durchaus nicht nur auf moderne Ansätze, wie Neuronale Netze, deep lerning etc. begrenzt. Auch die gute, alte Regression kann ein sehr sinnvolles Mittel sein solche Prognosen zu erstellen.&lt;/p&gt;
&lt;p&gt;Um ein wenig die Ideen hinter Prognosen zu beleuchten wollen wir uns an Prognosen mit dem &lt;strong&gt;tipping&lt;/strong&gt;-Daten heranwagen.&lt;/p&gt;
&lt;div id=&#34;einlesen-der-tipping-daten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Einlesen der tipping-Daten&lt;/h2&gt;
&lt;p&gt;Zuerst laden wir die notwenidgen Pakete:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Falls die &lt;strong&gt;tipping&lt;/strong&gt;-Daten noch nicht im Verzeichnis liegen, laden wir sie aus dem Internet nach:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if (!file.exists(&amp;quot;tips.csv&amp;quot;)) {
  download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun laden wir die &lt;strong&gt;tipping&lt;/strong&gt;-Daten in den Speicher in den Datenrahmen &lt;code&gt;tips&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir werfen einen ersten Blick auf die &lt;strong&gt;tipping&lt;/strong&gt;-Daten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inspect(tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## categorical variables:  
##     name     class levels   n missing
## 1    sex character      2 244       0
## 2 smoker character      2 244       0
## 3    day character      4 244       0
## 4   time character      2 244       0
##                                    distribution
## 1 Male (64.3%), Female (35.7%)                 
## 2 No (61.9%), Yes (38.1%)                      
## 3 Sat (35.7%), Sun (31.1%), Thur (25.4%) ...   
## 4 Dinner (72.1%), Lunch (27.9%)                
## 
## quantitative variables:  
##            name   class  min      Q1 median      Q3   max      mean        sd
## ...1 total_bill numeric 3.07 13.3475 17.795 24.1275 50.81 19.785943 8.9024120
## ...2        tip numeric 1.00  2.0000  2.900  3.5625 10.00  2.998279 1.3836382
## ...3       size integer 1.00  2.0000  2.000  3.0000  6.00  2.569672 0.9510998
##        n missing
## ...1 244       0
## ...2 244       0
## ...3 244       0&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;vorbereiten-der-test-trainings--und-auswertungesdaten&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vorbereiten der Test-/Trainings- und Auswertungesdaten&lt;/h2&gt;
&lt;p&gt;Zunächst schränken wir die &lt;strong&gt;tipping&lt;/strong&gt;-Daten auf die Variabeln “total_bill”, “sex”, “smoker”, “day”, “time”, “size” ein und speichern das Ergebnis wieder in &lt;code&gt;tips&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tips %&amp;gt;%
    select(c(&amp;quot;total_bill&amp;quot;, &amp;quot;sex&amp;quot;, &amp;quot;smoker&amp;quot;, &amp;quot;day&amp;quot;, &amp;quot;time&amp;quot;, &amp;quot;size&amp;quot;)) -&amp;gt; tips&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ziel ist es, den Rechnungsbetrag (“total_bill”) auf Grundlage der Variabeln “sex”, “smoker”, “day”, “time” und/oder “size” vorherzusagen.&lt;/p&gt;
&lt;p&gt;Wir teilen den tipping-Datensatz auf in eine Trainingsdatensatz (“tipstrain”), einem Testdatensatz (“tipstest”) und einem Prüfdatensatz (“tipspruef”).
Der Trainingsdatensatz sollte rund zweidrittel der Daten die wir haben umfassen.
Der Testdatensatz die restlich ca. eindrittel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;trainings_anteil = 2/3

# n.train ist ein Index für alle Werte, 
# die wir im Trainingsdatensatz haben wollen:
x.train &amp;lt;- sample(1:nrow(tips), floor(trainings_anteil*nrow(tips)))

# Trainingsdatensatz erstellen:
tipstrain &amp;lt;- slice(tips, x.train)

# Prüfdatensatz erstellen, also alles was 
# nicht in den Trainingsdatensatz gekommen ist:
tipspruef &amp;lt;- slice(tips, -(x.train))

# Der Testdatensatz ist der Prüfdatensatz 
# ohne die Variable total_bill:
tipspruef %&amp;gt;% 
    select(-total_bill) -&amp;gt; tipstest&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit dem Tainingsdatensatz versuchen wir nun ein Prognosemodell zu erstellen, um aus den Testdatensatz eine Prognose für “total_bill” zu erstellen.&lt;/p&gt;
&lt;p&gt;Das Prognose-Modell wird ausschließlich auf Grundlage des Trainingsdatensatzes erstellt. Am Ende wollen wir unser Modell dann aber mit Hilfe des Prüfdatensatzes bewertet.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;die-datenlage&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Die Datenlage&lt;/h2&gt;
&lt;p&gt;Ein (paar) Blick(e) auf unsere Trainingsdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(total_bill ~ jitter(size), color=~time, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-18-die-ersten-schritte-zur-prognose-mitteles-linearer-regression_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_point(total_bill ~ day | time, color = ~ sex, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2019-12-18-die-ersten-schritte-zur-prognose-mitteles-linearer-regression_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prognosemodel-nullmodell&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prognosemodel: Nullmodell&lt;/h2&gt;
&lt;div id=&#34;aufstellen-des-nullmodel-aka-regression-mit-der-achse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aufstellen des Nullmodel aka Regression mit der Achse&lt;/h3&gt;
&lt;p&gt;Wir erstellen das Nullmodell wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lm.null &amp;lt;- lm( total_bill ~ 1, data=tipstrain)
summary(lm.null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = total_bill ~ 1, data = tipstrain)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -13.159  -6.989  -2.429   4.171  30.401 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  20.4086     0.7311   27.91   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 9.306 on 161 degrees of freedom&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das Nullmodell sagt in jedem Fall den Rechnungsbetrag vorher als den Mittelwert der Trainingsdaten!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(~ total_bill, data=tipstrain)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 20.40864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nun bestimmten wir mit Hilfe des Nullmodells “lm.null” eine Vorhersage für die Testdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict.null &amp;lt;- predict(lm.null, newdata=tipstest)
head(predict.null)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        1        2        3        4        5        6 
## 20.40864 20.40864 20.40864 20.40864 20.40864 20.40864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wie gesagt, das Nullmodell liefert als Prognose immer den Mittelwert der Trainingsdaten zurück,
das mathematische Nullmodell lautet also:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\widehat{total\_bill_i} = 20.408642  \]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;auswertung-des-nullmodells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Auswertung des Nullmodells&lt;/h3&gt;
&lt;p&gt;Zur Auswertung Nutzen wir den &lt;em&gt;mittleren Absolutabstand&lt;/em&gt; zwischen der Vorhersage und den Prüfdaten:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;maa.null &amp;lt;-sum( abs( tipspruef$total_bill - predict.null))
maa.null&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 544.772&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;prognosemodell-lineare-regression-gegen-size-als-metrischer-wert&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prognosemodell: Lineare Regression gegen “size” als metrischer Wert&lt;/h2&gt;
&lt;div id=&#34;aufstellen-des-modells&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aufstellen des Modells&lt;/h3&gt;
&lt;/div&gt;
&lt;div id=&#34;auswertung-des-regressionsmodell&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Auswertung des Regressionsmodell&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Der Angriff der Riesenschlangen.</title>
      <link>https://sefiroth.net/nab/post/der-angriff-der-riesenschlangen/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/der-angriff-der-riesenschlangen/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Klingt ja bedrohlich, aber es ist wirklich Möglich &lt;a href=&#34;https://www.r-project.org&#34;&gt;R&lt;/a&gt; und &lt;a href=&#34;https://www.python.org&#34;&gt;Python&lt;/a&gt; sinnvoll zu kombinieren. Nicht nur in den Anwendungen, sondern auch beim Erstellen von Skripten mit &lt;a href=&#34;https://rmarkdown.rstudio.com&#34;&gt;R markdown&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Zu Beginn des letzten Semesters hatte ich die Idee in der Vorlesung “&lt;em&gt;Mathematischen Grundlagen der Wirtschaftsinformatik&lt;/em&gt;” ein paar der Begriffe der Mengenlehre denen daraus abgeleiteten Begriffen der abstrakten Datentypen gegenüberzustellen. So gibt es die Idee der &lt;em&gt;Menge&lt;/em&gt; u.a. in &lt;em&gt;Python&lt;/em&gt; als &lt;em&gt;set&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Wie aber kann man solche Python-Fragmente in ein R markdown Sktipr einbauen? - Kann man &lt;em&gt;R markdown&lt;/em&gt; überhaupt mit &lt;em&gt;Python&lt;/em&gt; zusammen bringen? - Ein wenig suchen im Internet und ein paar Stunden später hatte ich es geschaft. Dank einer Netzpython…&lt;/p&gt;
&lt;div id=&#34;die-netzpython-als-bindeglied-zwischen-r-und-python&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Die Netzpython als Bindeglied zwischen R und Python&lt;/h2&gt;
&lt;p&gt;Eine Netzpython (engl. &lt;a href=&#34;https://en.wikipedia.org/wiki/Reticulated_python&#34;&gt;reticulated python&lt;/a&gt;) stand Pate für den Namen des &lt;em&gt;R&lt;/em&gt; Paketes &lt;a href=&#34;https://rstudio.github.io/reticulate/index.html&#34;&gt;&lt;code&gt;reticulate&lt;/code&gt;&lt;/a&gt;, welches &lt;em&gt;R&lt;/em&gt; und &lt;em&gt;Python&lt;/em&gt; miteinander verbindet. So ist es möglich &lt;em&gt;Python&lt;/em&gt;-Befehle direkt in ein &lt;em&gt;R markdown&lt;/em&gt; Skript ausführen zulassen, diese Fragmente adequat durchzustellen – ganz wie &lt;em&gt;R Skripte&lt;/em&gt; – und sogar Daten zwoschen &lt;em&gt;R&lt;/em&gt; und &lt;em&gt;Python&lt;/em&gt; hin und her (aus) zu tauschen.&lt;/p&gt;
&lt;p&gt;Nach der Installation mittels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;reticulate&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;bedarf es aber durch aus noch einiger Anpassungen, bis alles zur Zufriedenheit funktioniert.&lt;/p&gt;
&lt;p&gt;Standardmässig sucht die Netzpython nach ihrem Gefährten mit der Hilfe des Befehls &lt;code&gt;Sys.which(&#34;python&#34;)&lt;/code&gt;, welcher bei mir leider zu einer vollkommen alten, aber noch benutzen, &lt;em&gt;Python&lt;/em&gt; Version führte. Möchte man eine ganz bestimmte &lt;em&gt;Python&lt;/em&gt; Version haben, so hilft einem der Befehl &lt;code&gt;use_python()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_python(&amp;quot;/usr/local/bin/python&amp;quot;)  # Pfad zum Python-Befehl der benutz werden soll.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es werden auch &lt;a href=&#34;https://realpython.com/python-virtual-environments-a-primer/&#34;&gt;virtuelle Umgebungen&lt;/a&gt; unterstützt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_virtualenv(&amp;quot;myenv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Und auch eine ganz andere Schlangenart kann benutzt werden, &lt;a href=&#34;https://www.anaconda.com/what-is-anaconda/&#34;&gt;Anacondas&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_condaenv(&amp;quot;mycondaenv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;der-einbau-in-ein-r-markdown-dokument&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Der Einbau in ein R markdown Dokument&lt;/h2&gt;
&lt;p&gt;Einen &lt;em&gt;Python&lt;/em&gt; Quellcode in ein &lt;em&gt;R markdown&lt;/em&gt; einzubauen ist dann wieder sehr einfach. Man ändert einfach ein &lt;em&gt;r&lt;/em&gt; in &lt;em&gt;python&lt;/em&gt; im Codeblock und schon steht einem der &lt;em&gt;knitr-Chunk&lt;/em&gt; als &lt;em&gt;Python&lt;/em&gt; Quelle zur Verfügung.&lt;/p&gt;
Sp liefert der &lt;em&gt;knitr-Chunk&lt;/em&gt;
&lt;pre&gt;&lt;code&gt;```{python}
# Etwas Python gefällig?
def quadrat(x):
    return x**2
    
print(quadrat(2))
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in einem &lt;em&gt;R markdown&lt;/em&gt;, dann die Ausgabe:&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Etwas Python geföllig?
def quadrat(x):
    return x**2
    
print(quadrat(2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Das war es aber noch lange nicht. &lt;em&gt;R&lt;/em&gt; und &lt;em&gt;Python&lt;/em&gt; können nämlich nicht nur nebeneinander, sondern auch miteinander!&lt;/p&gt;
&lt;p&gt;Dazu dann aber mehr in einem späteren Blog-Eintrag.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Auch R markdown Dateien sollten sich an Regeln halten</title>
      <link>https://sefiroth.net/nab/post/auch-r-markdown-dateien-sollten-sich-an-regeln-halten/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/auch-r-markdown-dateien-sollten-sich-an-regeln-halten/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Jede Programmiersprache hat Regeln.
Neben dem Regelwerk welches durch den Syntax einer Sprache festgelegt wird, gib es aber noch Regeln über die Form in der man den Quelltext schreibt.
Diese sogenannte &lt;em&gt;Stilregeln&lt;/em&gt; (engl. &lt;em&gt;style guides&lt;/em&gt;) sind von Programmieren aufgestellte Regeln um ein einheitliches “Schriftbild” des Quelltextes zu erhalten.
Das Ziel der &lt;em&gt;Stilregeln&lt;/em&gt; ist es, den Quelltext lesbarer zu gestallten, um leichter Änderungen einzupflegen oder um unnötiges zu vermeiden.&lt;/p&gt;
&lt;p&gt;Eine Programmiersprache wie &lt;em&gt;Python&lt;/em&gt; zum Beispiel hat mit &lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP8&lt;/a&gt; einen eigenen Standard wie ein &lt;em&gt;Python&lt;/em&gt; Programm geschrieben seien sollte.
Dazu gibt es auch gleich das passenden Prüfprogramm (früher &lt;code&gt;pep8&lt;/code&gt;, neuerdings &lt;a href=&#34;https://github.com/PyCQA/pycodestyle&#34;&gt;&lt;code&gt;pycodestyle&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Schreibt man ein &lt;em&gt;R markdown&lt;/em&gt; Text mag man vielleicht nicht daran denken, dass so eine Idee auch hier sehr sinnvoll ist.
Neben den gängigen Style-Guides für den &lt;em&gt;R&lt;/em&gt; Quellcode (z. B.: &lt;a href=&#34;https://google.github.io/styleguide/Rguide.xml&#34;&gt;Google’s R Style Guide&lt;/a&gt;, &lt;a href=&#34;http://adv-r.had.co.nz/Style.html&#34;&gt;Hadley Wickham’s Advanced R - Style guide&lt;/a&gt;, &lt;a href=&#34;http://jef.works/R-style-guide/&#34;&gt;jef.works R Style Guide&lt;/a&gt;, &lt;a href=&#34;https://csgillespie.wordpress.com/2010/11/23/r-style-guide/&#34;&gt;R Style Guide&lt;/a&gt; oder &lt;a href=&#34;https://github.com/rdatsci/PackagesInfo/wiki/R-Style-Guide&#34;&gt;R-Style-Guide&lt;/a&gt;) gibt es aber kaum Regeln (z. B.: &lt;a href=&#34;https://holtzy.github.io/Pimp-my-rmd/&#34;&gt;Pimp my Rmd&lt;/a&gt;) für die Gestaltung von &lt;em&gt;R markdown&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;stil-regeln-für-gutes-r-markdown-ein-erster-vorschlag&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Stil-Regeln für gutes &lt;em&gt;R markdown&lt;/em&gt;, ein erster Vorschlag&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Keine unnützen Zeichen am Ende von Textzeilen. / &lt;em&gt;No whitespaces at the end of a line&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Eine Textzeile sollte mit einem ‘echtem’ Zeichen enden und nicht mit einem ‘unsichtbarem’ Zeichen.
Das heisst: Leerzeichen, Tabs, harte Leerzeichen etc. gehören nicht ans Ende einer Zeile.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zwei Leerzeilen vor einer jeden Kopfzeile. / &lt;em&gt;Two blank lines before every header&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Um die Inhalte auch klar voneinander trennen zu können sollte man vor der Kopfzeile zwei Leerzeilen eingefügt werden.
Statt&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Das ist eine Kopfzeile auf der 1. Ebene
## Das is eine Kopfzeile auf der 2. Ebene
Das hier ist einfacher Text&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;sollte es so gegliedert sein:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;

# Das ist eine Kopfzeile auf der 1. Ebene


## Das is eine Kopfzeile auf der 2. Ebene

Das hier ist einfacher Text&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vor und nach Aufzählungen sollte immer eine Leerzeile stehen. / &lt;em&gt;One blank line before and after itemizations or enumerations&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Statt&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Das ist eine Liste:
- Ein Punkt
- Ein anderer Punkt
Und hier geht der Text weiter.
1. Der erste Punkt.
2. Der zweite Punkt.
Und wieder mal ein Text.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;sollte es so gegliedert sein:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Das ist eine Liste:

- Ein Punkt
- Ein anderer Punkt

Und hier geht der Text weiter.

1. Der erste Punkt.
2. Der zweite Punkt.

Und wieder mal ein Text.&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vor und nach Codeblöcken sollte immer eine Leerzeile stehen. / &lt;em&gt;One blank line before and after a codeblock&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Statt&lt;/p&gt;
&lt;pre&gt;
Etwas Text vorher
```{r}&lt;code&gt;1+1
```&lt;/code&gt;und danach.
&lt;/pre&gt;
&lt;p&gt;sollte man es besser wie folgt gliedern:&lt;/p&gt;
&lt;pre&gt;
Etwas Text vorher

```{r}&lt;code&gt;1+1
```&lt;/code&gt; und danach.
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Keine anderen Sprachen als &lt;em&gt;R markdown&lt;/em&gt; für Inhalte oder Design nutzen. / &lt;em&gt;Use no other languages to create content or design, other than (R) markdown.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Keine anderen Sprachen, insbesondere LaTeX, um besondere Effekte zu erzielen. Dafür sollten (native) DIV oder SPAN Abschnitte benutzt werden und entsprechend durch spätere (Filter-)Programme umgesetzt werden. So ist es immer möglich Design-Ideen für alle möglichen Zielsprachen zu erhalten.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;rmdstylechecker-ein-erster-style-checker-für-r-markdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;RmdStyleChecker, ein erster Style Checker für &lt;em&gt;R markdown&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Die ersten drei Punkte der Liste habe ich zu Testzwecken in einem kleinen Projekt mit Hilfe von &lt;em&gt;Python&lt;/em&gt; implementiert.
Den &lt;em&gt;Python&lt;/em&gt;-Quelltext findet man unter &lt;a href=&#34;https://github.com/NMarkgraf/RmdStyleChecker&#34;&gt;RmdStyleChecker&lt;/a&gt;. Er läuft unter &lt;em&gt;Python&lt;/em&gt; 3.5+.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ein wenig schneller zur simulierten Nullverteilung</title>
      <link>https://sefiroth.net/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/</link>
      <pubDate>Wed, 02 May 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/ein-wenig-schneller-zur-simulierten-nullverteilung/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/htmlwidgets/htmlwidgets.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/jquery/jquery.min.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/d3/d3.min.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/profvis.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/profvis.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis/scroll.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/highlight/textmate.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/highlight/highlight.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/profvis-binding/profvis.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Ein Nullhypothesentest ist schnell geschrieben.
Will man den approximativen Weg gehen, so hilft &lt;strong&gt;R&lt;/strong&gt; einem mit entsprechenden Tests mit einfachen Befehlen.
Nimmt man &lt;strong&gt;MOSAIC&lt;/strong&gt; dazu, so bekommt man u.a. für den Test auf Anteils- oder Mittelwerte sogar einen sehr einfachen, weil einheitlichen, Syntax.&lt;/p&gt;
&lt;div id=&#34;zwei-beispiele-für-approximative-hypothesentests-mit-mosaic&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Zwei Beispiele für approximative Hypothesentests mit MOSAIC&lt;/h3&gt;
&lt;p&gt;Laden wir unsere Testdaten, die &lt;strong&gt;tipping&lt;/strong&gt; Daten wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)
set.seed(2009)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dann erstellen wir zwei Forschungsfragen:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Ist der mittlere Frauenanteil unter der Bezahler*innen zu den Zeitpunkten Lunch und Dinner gleich?&lt;/li&gt;
&lt;li&gt;Ist der mittlere Rechnungsbetrag zu den Zeitpunkten Lunch und Dinner gleich?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Im ersten Fall ist die Hypothese schnell geschrieben:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0 : \pi_{\text{Lunch}} = \pi_{\text{Dinner}} \quad\text{vs.}\quad H_1 : \pi_{\text{Lunch}} \neq \pi_{\text{Dinner}}
\]&lt;/span&gt;
Der approximative Test mit R und MOSAIC lautet nun:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.test(sex ~ time, success = &amp;quot;Female&amp;quot;, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  2-sample test for equality of proportions with continuity correction
## 
## data:  tally(sex ~ time)
## X-squared = 9.3438, df = 1, p-value = 0.002237
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.36602563 -0.07247705
## sample estimates:
##    prop 1    prop 2 
## 0.2954545 0.5147059&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ähnlich sieht es für den zweiten Fall aus. Die Hypothese lautet hier:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0 : \mu_{Lunch} = \mu_{Dinner} \quad\text{vs.}\quad H_1 : \mu_{Lunch} \neq \mu_{Dinner}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der dazugehörige Test lautet dann:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t.test(total_bill ~ time, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Welch Two Sample t-test
## 
## data:  total_bill by time
## t = 3.123, df = 143.29, p-value = 0.002167
## alternative hypothesis: true difference in means between group Dinner and group Lunch is not equal to 0
## 95 percent confidence interval:
##  1.331877 5.925088
## sample estimates:
## mean in group Dinner  mean in group Lunch 
##             20.79716             17.16868&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;simulation-der-nullverteilung-mit-mosaic&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulation der Nullverteilung mit MOSAIC&lt;/h2&gt;
&lt;p&gt;Ein anderer Weg ist es die Stichprobe selber zu nutzen um daraus eine Verteilung der Nullhypothese (die Nullverteilung) ableiten zu können.
Im ersten Fall schaut man sich die Anteilsunterschiede an, wenn man die (potentielle) Abhängigkeit von der Tageszeit (Lunch und Dinner) künstlich “abschaltet”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2009)
NullVtlgAntwert &amp;lt;- do(10000) * diffprop(sex ~ shuffle(time),
    success = &amp;quot;Female&amp;quot;, data = tips)
gf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Schaut man sich nun die Lage der Anteilsdifferenz der Stichprobe &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi=0.2192513\)&lt;/span&gt; in Bezug auf diese Nullverteilung geometrisch an, so kann man schon einen ersten Eindruck erlangen, ob die Nullhypothese abzulehnen ist oder nicht:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diffpropdach &amp;lt;- diffprop(sex ~ time, success = &amp;quot;Female&amp;quot;, data = tips)
gf_histogram(~diffprop, nint = 25, data = NullVtlgAntwert) +
    geom_vline(xintercept = diffpropdach, color = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Offenbar ist &lt;span class=&#34;math inline&#34;&gt;\(\hat\pi\)&lt;/span&gt; kein sehr häufiges Ereignis.&lt;/p&gt;
&lt;p&gt;Der &lt;em&gt;p-Wert&lt;/em&gt; ist ebenfalls leicht zu ermitteln:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pvalue_aw &amp;lt;- prop(~abs(diffprop) &amp;gt;= abs(diffpropdach), data = NullVtlgAntwert)
pvalue_aw&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.0018&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Mit einem Anteilswert (p-Wert) von 0.0018 zweigen wir wie selten das Ereignis unter der &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; ist.&lt;/p&gt;
&lt;p&gt;Ähnlich sieht die Situation im zweien Fall aus. Mit Hilfe weniger Befehle erzeugen wir die Nullverteilung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2009)
NullVtlgMittelwert &amp;lt;- do(10000) * diffmean(total_bill ~ shuffle(time),
    data = tips)
gf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Und können im Anschluss die Mittelwertsdifferenz der Stichprobe geometrisch einordnen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;diffmeandach &amp;lt;- diffmean(total_bill ~ time, data = tips)
gf_histogram(~diffmean, nint = 25, data = NullVtlgMittelwert) +
    geom_vline(xintercept = diffmeandach, color = &amp;quot;blue&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Auch den &lt;em&gt;p-Wert&lt;/em&gt; können wir wieder leicht bestimmen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pvalue_mw &amp;lt;- prop(~abs(diffmean) &amp;gt;= abs(diffmeandach), data = NullVtlgMittelwert)
pvalue_mw&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## prop_TRUE 
##    0.0047&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;das-problem-zeit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Das Problem – Zeit&lt;/h2&gt;
&lt;p&gt;Das Problem bei der Simulation ist die Zeit, die &lt;strong&gt;R&lt;/strong&gt; braucht um die Nullverteilungen zu generieren.
Das liegt im wesentlichen an Mosaic.
Mit den Routinen aus &lt;a href=&#34;https://github.com/NMarkgraf/FastSimNullDistR&#34;&gt;FastSimNullDistR&lt;/a&gt; lassen sich die Nullverteilungen deutlich schneller berechnen.
Ein Vergleich:&lt;/p&gt;
&lt;div id=&#34;htmlwidget-1&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-1&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,6,6,6,6,6,6,6,7,7,7,7,7,7,7,8,8,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,15,15,15,15,15,15,15,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,18,18,18,18,18,18,19,19,19,19,19,20,20,20,20,20,20,21,21,21,21,21,21,21,22,22,22,22,22,22,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,25,25,25,26,26,26,26,26,26,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,34,34,34,34,34,35,35,35,35,35,35,35,35,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,39,39,39,39,39,39,39,40,40,40,40,40,40,40,41,41,42,42,42,42,42,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,46,46,46,46,46,46,47,47,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,50,50,50,50,50,50,50,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,54,54,54,54,54,54,55,55,55,55,55,55,55,56,56,56,56,56,56,56,56,56,56,57,57,57,57,57,57,57,57,58,58,58,58,58,59,59,59,59,59,59,59,60,60,60,60,60,60,60,60,60,60,61,61,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,63,63,63,63,63,63,64,64,65,65,65,65,65,65,65,65,65,65,66,66,66,66,66,66,66,67,67,67,67,67,67,67,67,68,68,68,68,68,68,69,69,69,69,69,69,69,69,69,69,69,70,70,70,71,71,71,71,71,71,71,72,72,72,72,72,72,72,73,73,73,73,74,74,74,74,74,74,74,74,74,75,75,75,75,75,75,75,76,76,76,76,76,76,76,77,77,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,79,79,79,80,80,80,80,80,80,80,80,80,80,81,81,81,81,81,81,81,81,81,82,82,82,82,82,82,83,83,83,83,83,83,83,84,84,84,84,84,84,84,84,85,85,85,85,86,86,86,86,86,86,86,87,87,87,87,87,87,88,88,88,88,88,88,88,88,88,88,88,88,88,89,89,89,89,89,89,89,89,90,90,90,90,90,90,90,90,91,91,91,91,92,92,93,93,93,93,93,93,93,93,93,93,93,94,94,94,94,94,94,94,94,94,95,95,95,95,95,95,95,95,96,96,96,96,96,96,96,96,97,97,97,97,97,97,97,98,98,98,98,98,99,99,99,99,99,99,100,100,100,100,100,100,100,100,100,101,101,102,102,102,102,102,102,102,103,103,103,103,103,103,103,104,104,104,104,104,104,105,105,105,105,105,105,105,105,106,106,106,106,106,106,106,106,106,106,107,107,107,107,107,107,107,108,108,108,108,108,108,108,109,109,109,109,109,110,110,110,110,110,110,110,111,111,111,111,111,111,111,111,112,112,112,112,112,112,112,113,113,113,113,113,113,113,114,114,114,114,115,115,116,116,116,116,116,116,116,117,117,117,117,117,117,117,117,117,117,118,118,119,119,119,119,119,119,119,119,120,120,120,120,120,120,121,121,121,121,121,121,121,121,122,122,122,122,122,123,123,124,124,124,124,124,124,124,124,124,124,124,125,125,125,125,125,125,125,125,125,126,126,126,126,126,126,126,126,127,127,127,127,127,127,128,128,128,128,128,129,129,129,129,129,129,129,130,130,130,130,130,130,130,130,130,130,130,131,131,131,131,131,131,131,131,131,131,132,132,132,132,132,132,133,133,133,133,133,133,133,134,134,134,134,134,134,134,134,134,135,135,135,135,135,135,135,135,136,136,136,136,136,136,136,137,137,137,137,137,137,137,137,137,137,137,137,138,138,138,138,139,139,139,139,139,139,139,139,139,139,139,140,140,140,140,140,140,140,140,141,141,141,141,141,141,142,142,142,142,142,142,142,142,143,143,143,143,143,143,143,143,143,144,144,145,145,145,145,145,145,145,145,145,146,146,146,146,146,146,146,146,146,147,147,147,147,147,147,147,147,148,148,148,148,148,148,148,148,148,149,149,149,150,150,150,150,150,150,150,150,150,151,151,151,151,151,151,152,152,152,152,152,152,152,152,152,152,153,153,153,153,153,153,153,153,153,153,154,154,154,154,154,154,154,154,154,154,155,155,155,155,155,155,155,155,155,156,156,156,156,156,156,156,157,157,157,157,157,157,157,157,158,158,158,158,158,158,158,158,159,159,159,159,160,160,160,160,160,160,160,160,160,160,160,161,161,161,161,161,161,161,161,162,162,162,162,162,162,162,163,163,163,163,163,163,164,164,164,164,164,165,165,165,165,165,165,165,166,166,166,166,166,166,166,166,166,166,167,167,167,167,167,167,167,168,168,168,168,168,168,169,169,169,169,169,169,169,170,170,170,170,170,170,170,171,171,171,171,171,171,171,172,172,172,172,172,172,172,172,173,173,173,173,173,173,174,174,174,174,174,174,174,175,175,175,175,175,175,175,175,175,175,175,176,176,176,176,176,176,176,176,176,176,177,177,177,177,177,177,177,177,178,178,178,178,178,178,178,179,179,179,179,179,179,180,180,180,180,180,180,181,181,181,181,181,181,181,181,182,182,182,182,182,183,183,183,183,183,183,183,183,184,184,184,184,184,184,185,185,185,185,185,185,185,185,185,185,186,186,186,186,186,186,186,187,187,187,187,187,187,187,187,188,188,188,188,188,188,189,189,189,189,189,189,190,190,190,190,190,190,190,190,190,191,191,191,191,191,191,191,191,191,191,191,192,192,192,192,192,192,192,192,192,193,193,193,193,193,193,193,193,194,194,194,194,194,194,194,194,194,194,194,195,195,195,195,195,195,195,195,195,195,196,196,197,197,197,197,197,197,197,197,198,198,198,198,198,198,198,199,199,199,199,199,199,199,199,199,200,200,200,200,200,200,200,200,201,201,201,201,201,201,202,202,202,202,202,202,202,202,202,202,202,202,202,203,203,203,203,203,203,203,203,203,203,203,203,204,204,204,204,204,204,204,204,205,205,205,205,205,205,205,206,206,206,206,206,206,207,207,207,207,207,207,207,208,208,208,208,209,209,209,209,209,209,209,209,210,210,210,210,210,210,210,210,210,210,210,210,210,210,211,211,211,211,211,211,211,211,211,211,212,212,212,212,212,212,212,212,212,212,212,212,213,213,213,213,213,213,214,214,214,215,215,215,216,216,216,216,216,217,217,218,218,218,218,218,218,218,218,218,218,218,218,219,219,219,219,219,219,219,220,220,220,220,220,221,221,221,221,221,221,221,221,222,222,222,222,222,222,222,222,222,222,222,223,223,223,223,223,223,223,223,223,224,224,224,224,224,224,224,225,225,225,225,225,225,225,226,226,226,226,226,226,227,227,227,227,227,227,228,228,228,228,228,228,228,228,228,228,228,228,229,229,229,229,229,229,229,229,229,229,230,230,230,230,230,231,231,231,232,232,232,232,232,232,233,233,233,233,233,234,234,234,234,234,234,235,235,236,236,236,236,236,236,236,237,237,237,237,237,237,237,237,238,238,238,238,238,238,238,238,238,238,238,238,238,238,239,239,239,239,239,239,239,239,240,240,240,240,240,240,240,240,240,240,240,240,240,240,241,241,241,242,242,242,242,242,242,243,243,243,243,243,244,244,244,244,244,244,244,245,245,245,245,245,245,245,245,245,245,246,246,246,247,247,247,247,247,247,247,247,248,248,248,248,248,248,249,249,249,249,249,249,249,250,250,250,250,250,250,251,251,251,251,252,252,252,252,252,252,252,252,252,252,252,252,253,253,254,254,254,254,254,254,255,255,255,255,255,255,255,256,256,256,256,257,257,257,257,257,257,257,257,257,257,257,258,258,258,258,258,258,258,258,258,258,258,259,259,259,259,259,260,260,260,260,260,261,261,261,261,261,261,261,261,262,262,263,263,263,263,263,263,263,264,264,264,264,264,265,265,265,265,265,265,265,265,265,266,266,266,266,266,266,266,266,267,267,267,267,267,267,267,267,268,268,268,268,268,268,268,268,269,269,270,270,270,270,270,270,270,270,270,270,270,270,270,271,271,271,271,271,271,271,271,271,271,271,271,271,272,272,272,272,272,272,272,272,273,273,273,273,274,274,274,274,274,274,274,274,274,274,275,275,275,275,275,275,276,276,276,276,276,277,277,278,278,279,279,279,279,279,279,279,279,279,279,280,280,280,280,280,280,280,281,281,281,281,281,281,281,282,282,283,283,283,283,283,283,283,283,283,283,283,283,284,284,284,284,284,284,285,285,285,285,285,285,285,285,286,286,286,286,286,286,286,287,287,287,287,287,287,287,288,288,288,288,288,288,288,288,288,288,288,289,289,289,289,290,290,290,290,290,290,290,291,291,291,291,291,291,291,291,292,292,292,292,292,292,293,293,293,293,293,293,293,293,294,294,294,294,294,294,294,294,294,294,294,294,295,295,295,295,295,295,295,295,296,296,296,296,296,297,297,297,297,297,297,297,297,298,298,298,298,299,299,300,300,301,301,301,301,301,301,302,302,302,302,302,302,302,303,303,303,303,303,303,303,303,303,304,304,304,304,304,304,304,305,305,305,305,305,306,306,306,306,306,306,306,306,306,307,307,307,307,307,307,307,307,308,308,308,308,308,308,308,308,308,309,309,309,309,309,309,310,310,310,311,311,311,311,311,311,311,312,312,312,312,313,313,313,313,313,314,314,314,314,314,314,314,314,315,315,315,316,316,316,316,316,316,316,317,317,317,317,317,317,317,318,318,318,318,318,318,319,319,320,320,320,320,320,320,320,320,320,321,321,321,321,321,321,321,321,322,322,322,322,322,322,322,322,323,323,323,323,323,323,323,324,324,325,325,325,325,325,326,326,326,326,326,326,326,327,327,327,327,327,328,328,329,329,329,330,330,330,330,330,330,331,331,331,331,331,331,331,331,332,332,332,332,332,333,333,333,333,333,334,334,334,334,334,334,334,334,334,334,335,335,335,335,335,335,335,336,336,336,336,336,336,336,336,336,336,336,337,337,338,338,338,338,338,339,339,339,339,339,340,340,341,341,341,341,341,341,342,342,343,343,343,343,343,343,343,343,343,343,343,343,343,344,344,344,344,344,344,344,344,345,345,345,345,346,346,346,346,346,346,346,347,347,347,347,347,347,347,348,348,348,348,348,349,349,349,349,349,349,349,349,350,350,350,350,350,350,350,350,351,351,351,351,352,352,352,352,352,352,352,352,352,352,353,353,353,353,353,353,353,353,353,353,353,353,353,354,354,354,354,354,354,354,355,355,355,355,355,355,355,355,356,356,356,356,357,357,357,357,357,357,358,358,358,358,358,358,359,359,359,359,359,359,360,360,360,360,360,360,360,360,361,361,361,361,361,361,361,362,362,362,362,362,362,362,362,362,362,363,363,363,363,363,363,363,364,364,364,364,364,364,364,364,364,364,364,364,364,365,365,365,365,365,365,365,365,365,365,366,366,366,366,366,366,366,366,367,367,367,367,367,367,368,368,368,368,368,368,368,369,369,369,369,369,370,370,370,370,370,370,370,370,371,371,372,372,372,372,372,373,373,373,373,373,373,373,373,374,374,374,374,374,374,374,374,374,375,375,375,375,375,375,375,376,376,376,376,377,377,377,377,377,378,378,378,378,378,378,378,378,379,379,379,379,379,379,379,379,379,380,380,380,380,380,381,381,381,381,381,381,381,381,381,381,381,382,382,382,382,382,382,382,382,382,382,383,383,383,383,383,383,383,383,384,384,384,384,384,384,384,385,385,386,386,386,386,386,386,387,387,387,387,387,387,387,388,388,388,388,388,388,388,389,389,389,389,389,389,389,390,390,390,390,390,390,390,390,391,391,391,391,391,391,391,392,392,392,392,392,392,392,393,393,393,394,394,394,394,394,394,394,394,394,394,395,395,395,395,395,396,396,396,396,396,396,396,396,396,396,397,397,397,397,397,397,397,398,398,398,398,398,398,398,398,398,398,398,399,399,399,399,399,399,399,399,399,399,399,400,400,400,400,400,400,400,401,401,401,401,401,401,401,401,401,401,401,401,401,401,402,402,402,402,402,402,402,403,403,403,403,403,403,404,404,404,404,405,405,405,405,405,405,405,405,406,406,406,406,406,406,406,407,407,407,407,407,407,408,408,408,408,408,408,408,409,409,409,409,409,409,409,409,409,410,410,411,411,411,411,411,411,411,412,412,412,412,412,412,412,412,412,412,412,413,413,413,413,413,413,413,413,413,413,414,414,414,414,414,414,414,414,415,415,415,415,415,415,415,416,416,416,416,416,416,417,417,417,417,417,417,417,417,418,418,419,419,419,419,419,419,420,420,420,420,420,420,420,420,421,421,421,422,422,422,422,422,422,422,422,422,422,423,423,423,423,423,423,423,423,424,424,424,424,424,424,424,425,425,425,425,425,426,426,426,426,426,426,426,427,427,427,427,427,428,428,428,428,428,428,429,429,429,429,429,429,429,429,429,430,430,430,430,430,430,430,431,431,431,431,431,431,431,431,431,431,432,432,432,432,432,432,433,433,433,433,433,433,433,433,433,433,434,434,434,434,434,434,434,435,435,435,435,435,435,435,436,436,436,437,437,437,437,437,437,438,438,438,438,438,438,439,439,440,440,440,440,440,440,440,440,440,441,441,441,441,441,441,441,441,442,442,442,442,442,442,442,442,442,442,443,443,443,443,443,443,444,444,444,444,444,444,444,444,444,444,444,444,444,444,445,445,445,445,445,445,445,446,446,446,446,447,447,447,447,447,447,447,448,448,448,448,448,448,448,449,449,449,449,449,449,449,449,450,450,450,450,450,450,450,451,451,452,452,453,453,453,453,453,453,453,453,454,454,454,454,454,454,454,454,455,455,455,455,455,455,455,456,456,456,456,456,456,456,456,457,457,457,457,457,457,457,457,457,457,457,458,458,458,458,458,458,459,459,459,459,459,459,459,459,459,459,459,459,459,459,460,460,460,460,460,460,460,461,461,461,461,461,462,462,462,462,462,462,462,462,463,463,463,463,463,463,463,464,464,464,464,464,465,465,465,465,465,465,465,466,466,466,466,467,467,467,467,467,467,467,468,468,469,469,469,469,469,469,469,469,470,470,471,471,471,471,471,472,472,472,472,472,472,473,473,474,474,474,474,474,475,475,475,475,475,475,476,476,476,476,476,476,476,476,477,477,477,477,478,478,478,478,478,478,479,479,479,479,479,479,479,479,479,479,480,480,480,480,480,480,480,481,481,481,481,481,481,481,482,482,483,483,483,484,484,485,485,485,485,485,485,485,486,486,486,486,486,486,486,486,487,487,487,487,487,488,488,488,488,488,489,489,489,489,489,490,490,490,491,491,491,491,491,491,491,492,492,492,492,492,492,492,492,492,492,493,493,493,493,493,493,493,493,494,494,494,494,494,494,494,494,495,495,495,495,495,495,495,495,495,496,496,496,496,496,496,497,497,497,497,497,497,497,497,497,497,498,498,498,498,499,499,499,499,499,499,500,500,500,500,500,500,500,500,500,501,501,501,501,502,502,502,502,502,503,503,503,503,503,503,503,503,504,504,504,504,504,504,504,504,504,505,505,505,505,506,506,506,506,506,507,507,508,508,509,509,509,509,509,509,509,509,510,510,510,510,510,510,510,510,510,510,511,511,511,511,511,511,511,511,511,511,511,511,512,512,512,512,512,513,513,513,513,513,513,513,513,513,513,513,513,513,514,514,514,514,514,514,514,514,514,514,515,515,515,515,515,516,516,517,517,517,517,517,517,517,518,518,518,518,518,518,519,519,519,519,519,519,519,520,520,520,520,520,521,521,521,521,521,521,521,522,522,522,522,522,522,522,522,523,523,523,523,524,524,525,525,525,525,525,525,525,525,526,526,526,526,526,526,527,527,527,527,527,527,527,527,528,528,528,528,528,528,528,529,529,529,529,529,529,529,529,529,529,529,529,530,530,530,530,530,530,530,531,531,531,531,531,531,531,531,531,531,531,532,532,532,533,533,534,534,534,534,534,534,535,535,536,536,536,536,536,536,536,537,537,537,537,537,537,537,537,537,537,537,537,538,538,538,538,538,539,539,539,539,539,539,539,539,540,540,540,540,540,541,541,541,541,541,542,542,542,542,542,542,542,543,543,543,543,543,544,544,544,544,544,544,544,544,545,545,546,546,546,546,546,546,546,546,547,547,547,547,547,548,548,548,548,548,548,548,549,549,549,550,550,550,550,550,550,551,551,551,551,551,551,551,552,552,552,552,552,552,552,552,553,553,553,553,554,554,554,554,554,554,554,554,555,555,555,555,555,555,555,555,555,555,555,556,556,556,556,556,556,556,556,556,556,557,557,557,558,558,558,558,558,558,558,559,559,559,559,559,559,559,559,559,559,560,560,560,560,560,560,560,560,560,560,560,560,560,561,561,562,562,562,562,562,562,562,562,562,562,562,563,563,563,563,563,563,563,564,564,564,564,564,564,564,564,564,564,564,564,564,565,565,565,566,566,566,566,566,566,567,567,567,567,567,567,567,568,568,568,568,568,569,569,569,569,570,570,570,570,570,570,570,570,570,570,570,570,571,571,571,571,571,571,571,572,572,572,572,572,572,572,572,572,572,572,572,573,573,573,573,573,573,574,574,574,574,574,574,575,575,576,576,576,576,576,576,576,576,577,577,577,577,577,577,578,578,578,578,578,578,578,578,578,578,579,579,579,579,579,579,579,579,579,579,579,579,580,580,580,580,580,580,581,581,581,581,581,581,581,581,582,582,582,582,582,582,582,582,582,582,583,583,583,583,583,584,584,585,585,585,585,585,585,585,586,586,586,586,586,586,586,586,587,587,587,587,587,587,587,587,588,588,588,588,588,588,588,588,588,588,588,589,589,589,589,589,589,589,589,590,590,590,590,590,591,591,592,592,593,593,593,593,593,593,593,593,594,594,594,594,594,594,594,594],&#34;depth&#34;:[10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,3,2,1,3,2,1,5,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,2,1,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,2,1,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,5,4,3,2,1,2,1,6,5,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,2,1,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,3,2,1,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,2,1,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,3,2,1,2,1,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;$&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&lt;-&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;~&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;force&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.data.frame&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;utils::tail&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;dim&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;all&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;utils::tail&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical2factor&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim.data.frame&#34;,&#34;ncol&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;logical2factor&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;~&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;tabulate&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;tabulate&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dimnames&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.ordered&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;(&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaicCore::tally&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical2factor&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;caller_env&#34;,&#34;rlang::eval_tidy&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;environment&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;utils::tail&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.function&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.call&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical2factor&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;caller_env&#34;,&#34;rlang::eval_tidy&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dim.data.frame&#34;,&#34;ncol&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.call&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;force&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;any&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;logical&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;startsWith&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinTwoFrames&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.na&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;logical2factor.data.frame&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.list&#34;,&#34;local&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[.table&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;dimnames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;~&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaicCore::tally&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;colSums&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;is.function&#34;,&#34;local&#34;,&#34;integer&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;tail.default&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;checkHT&#34;,&#34;tail.default&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;force&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;max&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;environment&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;utils::tail&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;[[&lt;-&#34;,&#34;mosaic_formula_q&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;list.names&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;seq.int&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.row_names_info&#34;,&#34;data.frame&#34;,&#34;joinTwoFrames&#34;,&#34;joinFrames&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;table&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;.External&#34;,&#34;local&#34;,&#34;is.list&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;evalFormula&#34;,&#34;mosaic_tally.formula&#34;,&#34;prop&#34;,&#34;diffprop&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;memalloc&#34;:[27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,27.9101638793945,28.5200729370117,28.5200729370117,28.5200729370117,28.5200729370117,28.5200729370117,28.5200729370117,28.5200729370117,28.5200729370117,29.1329956054688,29.1329956054688,29.1329956054688,29.1329956054688,29.1329956054688,29.1329956054688,29.1329956054688,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,29.9777374267578,30.5727233886719,30.5727233886719,30.5727233886719,30.5727233886719,30.5727233886719,31.2377014160156,31.2377014160156,31.2377014160156,31.2377014160156,31.2377014160156,31.2377014160156,31.2377014160156,32.0650787353516,32.0650787353516,32.0650787353516,32.0650787353516,32.0650787353516,32.0650787353516,32.0650787353516,32.6524429321289,32.6524429321289,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,33.6149826049805,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,34.2112274169922,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,35.4130325317383,36.0227432250977,36.0227432250977,36.0227432250977,36.0227432250977,36.0227432250977,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,36.6196670532227,37.2273712158203,37.2273712158203,37.2273712158203,37.8158264160156,37.8158264160156,37.8158264160156,37.8158264160156,37.8158264160156,37.8158264160156,37.8158264160156,27.6099166870117,27.6099166870117,27.6099166870117,27.6099166870117,27.6099166870117,27.6099166870117,27.6099166870117,28.2103271484375,28.2103271484375,28.2103271484375,28.2103271484375,28.2103271484375,28.2103271484375,28.2103271484375,28.2103271484375,28.9047470092773,28.9047470092773,28.9047470092773,28.9047470092773,28.9047470092773,28.9047470092773,29.7800674438477,29.7800674438477,29.7800674438477,29.7800674438477,29.7800674438477,30.3831558227539,30.3831558227539,30.3831558227539,30.3831558227539,30.3831558227539,30.3831558227539,31.1824798583984,31.1824798583984,31.1824798583984,31.1824798583984,31.1824798583984,31.1824798583984,31.1824798583984,31.8119735717773,31.8119735717773,31.8119735717773,31.8119735717773,31.8119735717773,31.8119735717773,32.9020309448242,32.9020309448242,32.9020309448242,32.9020309448242,32.9020309448242,32.9020309448242,32.9020309448242,32.9020309448242,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,33.5027465820312,34.5936126708984,34.5936126708984,34.5936126708984,35.1832275390625,35.1832275390625,35.1832275390625,35.1832275390625,35.1832275390625,35.1832275390625,35.8218688964844,35.8218688964844,35.8218688964844,35.8218688964844,35.8218688964844,35.8218688964844,35.8218688964844,36.5701904296875,36.5701904296875,36.5701904296875,36.5701904296875,36.5701904296875,36.5701904296875,36.5701904296875,36.5701904296875,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,37.1816101074219,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,27.5602340698242,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,28.1630554199219,29.1690292358398,29.1690292358398,29.1690292358398,29.1690292358398,29.1690292358398,29.1690292358398,29.1690292358398,29.1690292358398,29.7788696289062,29.7788696289062,29.7788696289062,29.7788696289062,29.7788696289062,29.7788696289062,29.7788696289062,29.7788696289062,30.3905944824219,30.3905944824219,30.3905944824219,30.3905944824219,30.3905944824219,31.2239227294922,31.2239227294922,31.2239227294922,31.2239227294922,31.2239227294922,31.2239227294922,31.2239227294922,31.2239227294922,31.9402008056641,31.9402008056641,31.9402008056641,31.9402008056641,31.9402008056641,31.9402008056641,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,32.5378265380859,33.2804489135742,33.2804489135742,33.2804489135742,33.2804489135742,33.2804489135742,33.2804489135742,33.9790573120117,33.9790573120117,33.9790573120117,33.9790573120117,33.9790573120117,33.9790573120117,33.9790573120117,35.1796340942383,35.1796340942383,35.1796340942383,35.1796340942383,35.1796340942383,35.1796340942383,35.1796340942383,35.9917755126953,35.9917755126953,36.5975952148438,36.5975952148438,36.5975952148438,36.5975952148438,36.5975952148438,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,37.5368881225586,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.3264999389648,27.9378051757812,27.9378051757812,27.9378051757812,27.9378051757812,27.9378051757812,27.9378051757812,27.9378051757812,28.5686645507812,28.5686645507812,28.5686645507812,28.5686645507812,28.5686645507812,28.5686645507812,29.1799850463867,29.1799850463867,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,30.4037399291992,31.629768371582,31.629768371582,31.629768371582,31.629768371582,31.629768371582,31.629768371582,31.629768371582,32.7086029052734,32.7086029052734,32.7086029052734,32.7086029052734,32.7086029052734,32.7086029052734,32.7086029052734,33.3213500976562,33.3213500976562,33.3213500976562,33.3213500976562,33.3213500976562,33.3213500976562,33.3213500976562,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,34.2853851318359,35.0008392333984,35.0008392333984,35.0008392333984,35.0008392333984,35.0008392333984,35.0008392333984,35.0008392333984,35.0008392333984,35.7712554931641,35.7712554931641,35.7712554931641,35.7712554931641,35.7712554931641,35.7712554931641,36.6624221801758,36.6624221801758,36.6624221801758,36.6624221801758,36.6624221801758,36.6624221801758,36.6624221801758,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.2611846923828,37.849609375,37.849609375,37.849609375,37.849609375,37.849609375,37.849609375,37.849609375,37.849609375,27.6692733764648,27.6692733764648,27.6692733764648,27.6692733764648,27.6692733764648,28.3465728759766,28.3465728759766,28.3465728759766,28.3465728759766,28.3465728759766,28.3465728759766,28.3465728759766,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.2505874633789,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,29.8611526489258,30.5596008300781,30.5596008300781,30.5596008300781,30.5596008300781,30.5596008300781,30.5596008300781,30.5596008300781,31.6968154907227,31.6968154907227,31.6968154907227,31.6968154907227,31.6968154907227,31.6968154907227,32.7623138427734,32.7623138427734,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,33.3632583618164,34.5853805541992,34.5853805541992,34.5853805541992,34.5853805541992,34.5853805541992,34.5853805541992,34.5853805541992,35.2859115600586,35.2859115600586,35.2859115600586,35.2859115600586,35.2859115600586,35.2859115600586,35.2859115600586,35.2859115600586,36.5015411376953,36.5015411376953,36.5015411376953,36.5015411376953,36.5015411376953,36.5015411376953,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.2268218994141,37.8661956787109,37.8661956787109,37.8661956787109,27.9080810546875,27.9080810546875,27.9080810546875,27.9080810546875,27.9080810546875,27.9080810546875,27.9080810546875,28.5171890258789,28.5171890258789,28.5171890258789,28.5171890258789,28.5171890258789,28.5171890258789,28.5171890258789,29.2402267456055,29.2402267456055,29.2402267456055,29.2402267456055,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,29.8333129882812,30.4404373168945,30.4404373168945,30.4404373168945,30.4404373168945,30.4404373168945,30.4404373168945,30.4404373168945,31.3867416381836,31.3867416381836,31.3867416381836,31.3867416381836,31.3867416381836,31.3867416381836,31.3867416381836,31.9719924926758,31.9719924926758,31.9719924926758,31.9719924926758,31.9719924926758,31.9719924926758,31.9719924926758,31.9719924926758,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,32.7896194458008,33.4037857055664,33.4037857055664,33.4037857055664,33.4037857055664,33.4037857055664,33.4037857055664,33.4037857055664,33.4037857055664,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,34.4106750488281,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,35.2391586303711,36.4618682861328,36.4618682861328,36.4618682861328,36.4618682861328,36.4618682861328,36.4618682861328,37.164421081543,37.164421081543,37.164421081543,37.164421081543,37.164421081543,37.164421081543,37.164421081543,37.7813491821289,37.7813491821289,37.7813491821289,37.7813491821289,37.7813491821289,37.7813491821289,37.7813491821289,37.7813491821289,27.2070770263672,27.2070770263672,27.2070770263672,27.2070770263672,27.9259872436523,27.9259872436523,27.9259872436523,27.9259872436523,27.9259872436523,27.9259872436523,27.9259872436523,28.6704177856445,28.6704177856445,28.6704177856445,28.6704177856445,28.6704177856445,28.6704177856445,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,29.7158966064453,30.9331893920898,30.9331893920898,30.9331893920898,30.9331893920898,30.9331893920898,30.9331893920898,30.9331893920898,30.9331893920898,31.5849151611328,31.5849151611328,31.5849151611328,31.5849151611328,31.5849151611328,31.5849151611328,31.5849151611328,31.5849151611328,32.1962814331055,32.1962814331055,32.1962814331055,32.1962814331055,32.7715225219727,32.7715225219727,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.3380584716797,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,33.8744430541992,34.403938293457,34.403938293457,34.403938293457,34.403938293457,34.403938293457,34.403938293457,34.403938293457,34.403938293457,34.9687957763672,34.9687957763672,34.9687957763672,34.9687957763672,34.9687957763672,34.9687957763672,34.9687957763672,34.9687957763672,35.5291748046875,35.5291748046875,35.5291748046875,35.5291748046875,35.5291748046875,35.5291748046875,35.5291748046875,36.0905609130859,36.0905609130859,36.0905609130859,36.0905609130859,36.0905609130859,36.6488647460938,36.6488647460938,36.6488647460938,36.6488647460938,36.6488647460938,36.6488647460938,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,37.4629058837891,27.2996826171875,27.2996826171875,27.9434051513672,27.9434051513672,27.9434051513672,27.9434051513672,27.9434051513672,27.9434051513672,27.9434051513672,28.542594909668,28.542594909668,28.542594909668,28.542594909668,28.542594909668,28.542594909668,28.542594909668,29.4344711303711,29.4344711303711,29.4344711303711,29.4344711303711,29.4344711303711,29.4344711303711,30.1502914428711,30.1502914428711,30.1502914428711,30.1502914428711,30.1502914428711,30.1502914428711,30.1502914428711,30.1502914428711,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,30.8037261962891,31.631103515625,31.631103515625,31.631103515625,31.631103515625,31.631103515625,31.631103515625,31.631103515625,32.5966796875,32.5966796875,32.5966796875,32.5966796875,32.5966796875,32.5966796875,32.5966796875,33.4016876220703,33.4016876220703,33.4016876220703,33.4016876220703,33.4016876220703,33.9963531494141,33.9963531494141,33.9963531494141,33.9963531494141,33.9963531494141,33.9963531494141,33.9963531494141,34.7263717651367,34.7263717651367,34.7263717651367,34.7263717651367,34.7263717651367,34.7263717651367,34.7263717651367,34.7263717651367,35.458869934082,35.458869934082,35.458869934082,35.458869934082,35.458869934082,35.458869934082,35.458869934082,36.0955352783203,36.0955352783203,36.0955352783203,36.0955352783203,36.0955352783203,36.0955352783203,36.0955352783203,36.9694366455078,36.9694366455078,36.9694366455078,36.9694366455078,37.5548858642578,37.5548858642578,27.3267517089844,27.3267517089844,27.3267517089844,27.3267517089844,27.3267517089844,27.3267517089844,27.3267517089844,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.0182189941406,28.8618240356445,28.8618240356445,29.8871154785156,29.8871154785156,29.8871154785156,29.8871154785156,29.8871154785156,29.8871154785156,29.8871154785156,29.8871154785156,30.4970169067383,30.4970169067383,30.4970169067383,30.4970169067383,30.4970169067383,30.4970169067383,31.4167938232422,31.4167938232422,31.4167938232422,31.4167938232422,31.4167938232422,31.4167938232422,31.4167938232422,31.4167938232422,32.0058212280273,32.0058212280273,32.0058212280273,32.0058212280273,32.0058212280273,32.6862106323242,32.6862106323242,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,33.447265625,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.0224151611328,34.8028717041016,34.8028717041016,34.8028717041016,34.8028717041016,34.8028717041016,34.8028717041016,34.8028717041016,34.8028717041016,35.3795471191406,35.3795471191406,35.3795471191406,35.3795471191406,35.3795471191406,35.3795471191406,35.9797973632812,35.9797973632812,35.9797973632812,35.9797973632812,35.9797973632812,36.5442733764648,36.5442733764648,36.5442733764648,36.5442733764648,36.5442733764648,36.5442733764648,36.5442733764648,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.155517578125,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,37.7771911621094,27.5744552612305,27.5744552612305,27.5744552612305,27.5744552612305,27.5744552612305,27.5744552612305,28.1936798095703,28.1936798095703,28.1936798095703,28.1936798095703,28.1936798095703,28.1936798095703,28.1936798095703,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,28.8048782348633,29.4017639160156,29.4017639160156,29.4017639160156,29.4017639160156,29.4017639160156,29.4017639160156,29.4017639160156,29.4017639160156,30.0464401245117,30.0464401245117,30.0464401245117,30.0464401245117,30.0464401245117,30.0464401245117,30.0464401245117,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,30.6417541503906,31.2505493164062,31.2505493164062,31.2505493164062,31.2505493164062,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.0999755859375,32.7120971679688,32.7120971679688,32.7120971679688,32.7120971679688,32.7120971679688,32.7120971679688,32.7120971679688,32.7120971679688,33.3283309936523,33.3283309936523,33.3283309936523,33.3283309936523,33.3283309936523,33.3283309936523,34.1891937255859,34.1891937255859,34.1891937255859,34.1891937255859,34.1891937255859,34.1891937255859,34.1891937255859,34.1891937255859,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,34.7583312988281,35.3362197875977,35.3362197875977,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.1848754882812,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,36.8260879516602,37.5415191650391,37.5415191650391,37.5415191650391,37.5415191650391,37.5415191650391,37.5415191650391,37.5415191650391,37.5415191650391,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.3659973144531,27.9987640380859,27.9987640380859,27.9987640380859,28.722770690918,28.722770690918,28.722770690918,28.722770690918,28.722770690918,28.722770690918,28.722770690918,28.722770690918,28.722770690918,29.3906860351562,29.3906860351562,29.3906860351562,29.3906860351562,29.3906860351562,29.3906860351562,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,30.3817977905273,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,31.1994323730469,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.0401382446289,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,32.9937896728516,33.6621704101562,33.6621704101562,33.6621704101562,33.6621704101562,33.6621704101562,33.6621704101562,33.6621704101562,34.3634796142578,34.3634796142578,34.3634796142578,34.3634796142578,34.3634796142578,34.3634796142578,34.3634796142578,34.3634796142578,35.1949462890625,35.1949462890625,35.1949462890625,35.1949462890625,35.1949462890625,35.1949462890625,35.1949462890625,35.1949462890625,35.9628448486328,35.9628448486328,35.9628448486328,35.9628448486328,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,36.5491943359375,37.1933135986328,37.1933135986328,37.1933135986328,37.1933135986328,37.1933135986328,37.1933135986328,37.1933135986328,37.1933135986328,37.8023529052734,37.8023529052734,37.8023529052734,37.8023529052734,37.8023529052734,37.8023529052734,37.8023529052734,27.6654739379883,27.6654739379883,27.6654739379883,27.6654739379883,27.6654739379883,27.6654739379883,28.2592315673828,28.2592315673828,28.2592315673828,28.2592315673828,28.2592315673828,29.476318359375,29.476318359375,29.476318359375,29.476318359375,29.476318359375,29.476318359375,29.476318359375,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.0855560302734,30.6890487670898,30.6890487670898,30.6890487670898,30.6890487670898,30.6890487670898,30.6890487670898,30.6890487670898,31.9103775024414,31.9103775024414,31.9103775024414,31.9103775024414,31.9103775024414,31.9103775024414,32.5445251464844,32.5445251464844,32.5445251464844,32.5445251464844,32.5445251464844,32.5445251464844,32.5445251464844,33.397346496582,33.397346496582,33.397346496582,33.397346496582,33.397346496582,33.397346496582,33.397346496582,33.9712295532227,33.9712295532227,33.9712295532227,33.9712295532227,33.9712295532227,33.9712295532227,33.9712295532227,34.725959777832,34.725959777832,34.725959777832,34.725959777832,34.725959777832,34.725959777832,34.725959777832,34.725959777832,35.3645324707031,35.3645324707031,35.3645324707031,35.3645324707031,35.3645324707031,35.3645324707031,35.9372406005859,35.9372406005859,35.9372406005859,35.9372406005859,35.9372406005859,35.9372406005859,35.9372406005859,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,36.6841659545898,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,37.3407135009766,27.3058700561523,27.3058700561523,27.3058700561523,27.3058700561523,27.3058700561523,27.3058700561523,27.3058700561523,27.3058700561523,27.990104675293,27.990104675293,27.990104675293,27.990104675293,27.990104675293,27.990104675293,27.990104675293,28.5855178833008,28.5855178833008,28.5855178833008,28.5855178833008,28.5855178833008,28.5855178833008,29.1895294189453,29.1895294189453,29.1895294189453,29.1895294189453,29.1895294189453,29.1895294189453,29.8010330200195,29.8010330200195,29.8010330200195,29.8010330200195,29.8010330200195,29.8010330200195,29.8010330200195,29.8010330200195,30.9631652832031,30.9631652832031,30.9631652832031,30.9631652832031,30.9631652832031,31.5380096435547,31.5380096435547,31.5380096435547,31.5380096435547,31.5380096435547,31.5380096435547,31.5380096435547,31.5380096435547,32.3408126831055,32.3408126831055,32.3408126831055,32.3408126831055,32.3408126831055,32.3408126831055,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,33.1215744018555,34.0508270263672,34.0508270263672,34.0508270263672,34.0508270263672,34.0508270263672,34.0508270263672,34.0508270263672,34.6544418334961,34.6544418334961,34.6544418334961,34.6544418334961,34.6544418334961,34.6544418334961,34.6544418334961,34.6544418334961,35.2594299316406,35.2594299316406,35.2594299316406,35.2594299316406,35.2594299316406,35.2594299316406,35.8470993041992,35.8470993041992,35.8470993041992,35.8470993041992,35.8470993041992,35.8470993041992,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,36.4379348754883,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,37.6211624145508,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,27.4727096557617,28.4618682861328,28.4618682861328,28.4618682861328,28.4618682861328,28.4618682861328,28.4618682861328,28.4618682861328,28.4618682861328,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.1761856079102,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,29.7873001098633,30.3893966674805,30.3893966674805,31.0879745483398,31.0879745483398,31.0879745483398,31.0879745483398,31.0879745483398,31.0879745483398,31.0879745483398,31.0879745483398,31.7606964111328,31.7606964111328,31.7606964111328,31.7606964111328,31.7606964111328,31.7606964111328,31.7606964111328,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.358283996582,32.9405136108398,32.9405136108398,32.9405136108398,32.9405136108398,32.9405136108398,32.9405136108398,32.9405136108398,32.9405136108398,34.0815200805664,34.0815200805664,34.0815200805664,34.0815200805664,34.0815200805664,34.0815200805664,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,34.7644958496094,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,35.4647827148438,36.0367660522461,36.0367660522461,36.0367660522461,36.0367660522461,36.0367660522461,36.0367660522461,36.0367660522461,36.0367660522461,36.6052856445312,36.6052856445312,36.6052856445312,36.6052856445312,36.6052856445312,36.6052856445312,36.6052856445312,37.1746444702148,37.1746444702148,37.1746444702148,37.1746444702148,37.1746444702148,37.1746444702148,37.8301086425781,37.8301086425781,37.8301086425781,37.8301086425781,37.8301086425781,37.8301086425781,37.8301086425781,27.6154708862305,27.6154708862305,27.6154708862305,27.6154708862305,28.3234786987305,28.3234786987305,28.3234786987305,28.3234786987305,28.3234786987305,28.3234786987305,28.3234786987305,28.3234786987305,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.0662307739258,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,29.8110046386719,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,30.4993591308594,31.1097030639648,31.1097030639648,31.1097030639648,31.1097030639648,31.1097030639648,31.1097030639648,31.8527221679688,31.8527221679688,31.8527221679688,32.4216537475586,32.4216537475586,32.4216537475586,32.9832916259766,32.9832916259766,32.9832916259766,32.9832916259766,32.9832916259766,33.7834396362305,33.7834396362305,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,34.6129684448242,35.355712890625,35.355712890625,35.355712890625,35.355712890625,35.355712890625,35.355712890625,35.355712890625,35.9345703125,35.9345703125,35.9345703125,35.9345703125,35.9345703125,36.5537567138672,36.5537567138672,36.5537567138672,36.5537567138672,36.5537567138672,36.5537567138672,36.5537567138672,36.5537567138672,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.1521759033203,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,37.7660369873047,27.6525192260742,27.6525192260742,27.6525192260742,27.6525192260742,27.6525192260742,27.6525192260742,27.6525192260742,28.4457550048828,28.4457550048828,28.4457550048828,28.4457550048828,28.4457550048828,28.4457550048828,28.4457550048828,29.1135406494141,29.1135406494141,29.1135406494141,29.1135406494141,29.1135406494141,29.1135406494141,29.7143249511719,29.7143249511719,29.7143249511719,29.7143249511719,29.7143249511719,29.7143249511719,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,30.3244094848633,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.2886962890625,31.880500793457,31.880500793457,31.880500793457,31.880500793457,31.880500793457,32.3777313232422,32.3777313232422,32.3777313232422,33.2351837158203,33.2351837158203,33.2351837158203,33.2351837158203,33.2351837158203,33.2351837158203,34.1374893188477,34.1374893188477,34.1374893188477,34.1374893188477,34.1374893188477,34.9073638916016,34.9073638916016,34.9073638916016,34.9073638916016,34.9073638916016,34.9073638916016,35.53564453125,35.53564453125,36.2170867919922,36.2170867919922,36.2170867919922,36.2170867919922,36.2170867919922,36.2170867919922,36.2170867919922,37.411018371582,37.411018371582,37.411018371582,37.411018371582,37.411018371582,37.411018371582,37.411018371582,37.411018371582,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,37.8621520996094,27.8412857055664,27.8412857055664,27.8412857055664,27.8412857055664,27.8412857055664,27.8412857055664,27.8412857055664,27.8412857055664,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,28.4515075683594,29.0943145751953,29.0943145751953,29.0943145751953,29.9443130493164,29.9443130493164,29.9443130493164,29.9443130493164,29.9443130493164,29.9443130493164,30.8438262939453,30.8438262939453,30.8438262939453,30.8438262939453,30.8438262939453,31.6644821166992,31.6644821166992,31.6644821166992,31.6644821166992,31.6644821166992,31.6644821166992,31.6644821166992,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.2508773803711,32.8572463989258,32.8572463989258,32.8572463989258,33.488639831543,33.488639831543,33.488639831543,33.488639831543,33.488639831543,33.488639831543,33.488639831543,33.488639831543,34.3959503173828,34.3959503173828,34.3959503173828,34.3959503173828,34.3959503173828,34.3959503173828,35.152717590332,35.152717590332,35.152717590332,35.152717590332,35.152717590332,35.152717590332,35.152717590332,35.857536315918,35.857536315918,35.857536315918,35.857536315918,35.857536315918,35.857536315918,36.8396224975586,36.8396224975586,36.8396224975586,36.8396224975586,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,35.6913604736328,28.3548736572266,28.3548736572266,29.0732574462891,29.0732574462891,29.0732574462891,29.0732574462891,29.0732574462891,29.0732574462891,30.1678924560547,30.1678924560547,30.1678924560547,30.1678924560547,30.1678924560547,30.1678924560547,30.1678924560547,30.8044662475586,30.8044662475586,30.8044662475586,30.8044662475586,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,31.4222259521484,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,32.5712509155273,33.2307739257812,33.2307739257812,33.2307739257812,33.2307739257812,33.2307739257812,33.87060546875,33.87060546875,33.87060546875,33.87060546875,33.87060546875,34.5289306640625,34.5289306640625,34.5289306640625,34.5289306640625,34.5289306640625,34.5289306640625,34.5289306640625,34.5289306640625,35.2250595092773,35.2250595092773,35.9268341064453,35.9268341064453,35.9268341064453,35.9268341064453,35.9268341064453,35.9268341064453,35.9268341064453,36.6188278198242,36.6188278198242,36.6188278198242,36.6188278198242,36.6188278198242,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.1993789672852,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,37.8671264648438,27.8119277954102,27.8119277954102,27.8119277954102,27.8119277954102,27.8119277954102,27.8119277954102,27.8119277954102,27.8119277954102,28.4233322143555,28.4233322143555,28.4233322143555,28.4233322143555,28.4233322143555,28.4233322143555,28.4233322143555,28.4233322143555,29.0811614990234,29.0811614990234,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,29.8960037231445,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,30.6073455810547,31.8195343017578,31.8195343017578,31.8195343017578,31.8195343017578,31.8195343017578,31.8195343017578,31.8195343017578,31.8195343017578,32.6491622924805,32.6491622924805,32.6491622924805,32.6491622924805,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,33.8468399047852,35.0371398925781,35.0371398925781,35.0371398925781,35.0371398925781,35.0371398925781,35.0371398925781,35.7154235839844,35.7154235839844,35.7154235839844,35.7154235839844,35.7154235839844,36.3411331176758,36.3411331176758,36.9227523803711,36.9227523803711,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,37.5125427246094,27.356819152832,27.356819152832,27.356819152832,27.356819152832,27.356819152832,27.356819152832,27.356819152832,28.0316314697266,28.0316314697266,28.0316314697266,28.0316314697266,28.0316314697266,28.0316314697266,28.0316314697266,28.9601287841797,28.9601287841797,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,29.5614166259766,30.1878356933594,30.1878356933594,30.1878356933594,30.1878356933594,30.1878356933594,30.1878356933594,31.2207489013672,31.2207489013672,31.2207489013672,31.2207489013672,31.2207489013672,31.2207489013672,31.2207489013672,31.2207489013672,31.908088684082,31.908088684082,31.908088684082,31.908088684082,31.908088684082,31.908088684082,31.908088684082,32.901741027832,32.901741027832,32.901741027832,32.901741027832,32.901741027832,32.901741027832,32.901741027832,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,33.6428985595703,34.3260345458984,34.3260345458984,34.3260345458984,34.3260345458984,34.9015731811523,34.9015731811523,34.9015731811523,34.9015731811523,34.9015731811523,34.9015731811523,34.9015731811523,35.5319595336914,35.5319595336914,35.5319595336914,35.5319595336914,35.5319595336914,35.5319595336914,35.5319595336914,35.5319595336914,36.1447448730469,36.1447448730469,36.1447448730469,36.1447448730469,36.1447448730469,36.1447448730469,36.8221664428711,36.8221664428711,36.8221664428711,36.8221664428711,36.8221664428711,36.8221664428711,36.8221664428711,36.8221664428711,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,37.798454284668,27.6884689331055,27.6884689331055,27.6884689331055,27.6884689331055,27.6884689331055,27.6884689331055,27.6884689331055,27.6884689331055,28.3514862060547,28.3514862060547,28.3514862060547,28.3514862060547,28.3514862060547,29.4952239990234,29.4952239990234,29.4952239990234,29.4952239990234,29.4952239990234,29.4952239990234,29.4952239990234,29.4952239990234,30.3992614746094,30.3992614746094,30.3992614746094,30.3992614746094,31.0191116333008,31.0191116333008,31.6395034790039,31.6395034790039,32.2373199462891,32.2373199462891,32.2373199462891,32.2373199462891,32.2373199462891,32.2373199462891,32.8120269775391,32.8120269775391,32.8120269775391,32.8120269775391,32.8120269775391,32.8120269775391,32.8120269775391,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,33.4067230224609,34.604606628418,34.604606628418,34.604606628418,34.604606628418,34.604606628418,34.604606628418,34.604606628418,35.2062606811523,35.2062606811523,35.2062606811523,35.2062606811523,35.2062606811523,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.1930770874023,36.8034973144531,36.8034973144531,36.8034973144531,36.8034973144531,36.8034973144531,36.8034973144531,36.8034973144531,36.8034973144531,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.3890914916992,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,37.8675003051758,27.8437423706055,27.8437423706055,27.8437423706055,28.4448394775391,28.4448394775391,28.4448394775391,28.4448394775391,28.4448394775391,28.4448394775391,28.4448394775391,29.0697021484375,29.0697021484375,29.0697021484375,29.0697021484375,29.7446746826172,29.7446746826172,29.7446746826172,29.7446746826172,29.7446746826172,30.3441162109375,30.3441162109375,30.3441162109375,30.3441162109375,30.3441162109375,30.3441162109375,30.3441162109375,30.3441162109375,30.9514770507812,30.9514770507812,30.9514770507812,31.5387725830078,31.5387725830078,31.5387725830078,31.5387725830078,31.5387725830078,31.5387725830078,31.5387725830078,32.2523345947266,32.2523345947266,32.2523345947266,32.2523345947266,32.2523345947266,32.2523345947266,32.2523345947266,33.1022338867188,33.1022338867188,33.1022338867188,33.1022338867188,33.1022338867188,33.1022338867188,33.7155380249023,33.7155380249023,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,34.3208770751953,35.0833358764648,35.0833358764648,35.0833358764648,35.0833358764648,35.0833358764648,35.0833358764648,35.0833358764648,35.0833358764648,36.0472640991211,36.0472640991211,36.0472640991211,36.0472640991211,36.0472640991211,36.0472640991211,36.0472640991211,36.0472640991211,36.6172103881836,36.6172103881836,36.6172103881836,36.6172103881836,36.6172103881836,36.6172103881836,36.6172103881836,37.2127532958984,37.2127532958984,27.6562576293945,27.6562576293945,27.6562576293945,27.6562576293945,27.6562576293945,28.2635803222656,28.2635803222656,28.2635803222656,28.2635803222656,28.2635803222656,28.2635803222656,28.2635803222656,29.0047225952148,29.0047225952148,29.0047225952148,29.0047225952148,29.0047225952148,29.5919494628906,29.5919494628906,30.281867980957,30.281867980957,30.281867980957,31.474723815918,31.474723815918,31.474723815918,31.474723815918,31.474723815918,31.474723815918,32.0851516723633,32.0851516723633,32.0851516723633,32.0851516723633,32.0851516723633,32.0851516723633,32.0851516723633,32.0851516723633,33.293571472168,33.293571472168,33.293571472168,33.293571472168,33.293571472168,33.9500885009766,33.9500885009766,33.9500885009766,33.9500885009766,33.9500885009766,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,34.5360488891602,35.1327514648438,35.1327514648438,35.1327514648438,35.1327514648438,35.1327514648438,35.1327514648438,35.1327514648438,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.0569534301758,36.9415817260742,36.9415817260742,37.8220443725586,37.8220443725586,37.8220443725586,37.8220443725586,37.8220443725586,27.7250213623047,27.7250213623047,27.7250213623047,27.7250213623047,27.7250213623047,28.3548812866211,28.3548812866211,28.9851150512695,28.9851150512695,28.9851150512695,28.9851150512695,28.9851150512695,28.9851150512695,30.0932006835938,30.0932006835938,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.3175201416016,31.9888229370117,31.9888229370117,31.9888229370117,31.9888229370117,31.9888229370117,31.9888229370117,31.9888229370117,31.9888229370117,32.5825424194336,32.5825424194336,32.5825424194336,32.5825424194336,33.170051574707,33.170051574707,33.170051574707,33.170051574707,33.170051574707,33.170051574707,33.170051574707,33.8157730102539,33.8157730102539,33.8157730102539,33.8157730102539,33.8157730102539,33.8157730102539,33.8157730102539,34.3974456787109,34.3974456787109,34.3974456787109,34.3974456787109,34.3974456787109,34.9957885742188,34.9957885742188,34.9957885742188,34.9957885742188,34.9957885742188,34.9957885742188,34.9957885742188,34.9957885742188,36.1881332397461,36.1881332397461,36.1881332397461,36.1881332397461,36.1881332397461,36.1881332397461,36.1881332397461,36.1881332397461,37.133659362793,37.133659362793,37.133659362793,37.133659362793,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,37.7092208862305,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,27.6318588256836,28.2431564331055,28.2431564331055,28.2431564331055,28.2431564331055,28.2431564331055,28.2431564331055,28.2431564331055,28.8537445068359,28.8537445068359,28.8537445068359,28.8537445068359,28.8537445068359,28.8537445068359,28.8537445068359,28.8537445068359,29.465705871582,29.465705871582,29.465705871582,29.465705871582,30.0676193237305,30.0676193237305,30.0676193237305,30.0676193237305,30.0676193237305,30.0676193237305,31.2809143066406,31.2809143066406,31.2809143066406,31.2809143066406,31.2809143066406,31.2809143066406,31.9675445556641,31.9675445556641,31.9675445556641,31.9675445556641,31.9675445556641,31.9675445556641,32.7986221313477,32.7986221313477,32.7986221313477,32.7986221313477,32.7986221313477,32.7986221313477,32.7986221313477,32.7986221313477,33.9978179931641,33.9978179931641,33.9978179931641,33.9978179931641,33.9978179931641,33.9978179931641,33.9978179931641,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,34.601448059082,35.2010803222656,35.2010803222656,35.2010803222656,35.2010803222656,35.2010803222656,35.2010803222656,35.2010803222656,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,36.1213684082031,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.0372772216797,37.7133712768555,37.7133712768555,37.7133712768555,37.7133712768555,37.7133712768555,37.7133712768555,37.7133712768555,37.7133712768555,27.7117614746094,27.7117614746094,27.7117614746094,27.7117614746094,27.7117614746094,27.7117614746094,28.9180450439453,28.9180450439453,28.9180450439453,28.9180450439453,28.9180450439453,28.9180450439453,28.9180450439453,29.5271987915039,29.5271987915039,29.5271987915039,29.5271987915039,29.5271987915039,30.7490463256836,30.7490463256836,30.7490463256836,30.7490463256836,30.7490463256836,30.7490463256836,30.7490463256836,30.7490463256836,31.3598022460938,31.3598022460938,32.5722427368164,32.5722427368164,32.5722427368164,32.5722427368164,32.5722427368164,33.1857681274414,33.1857681274414,33.1857681274414,33.1857681274414,33.1857681274414,33.1857681274414,33.1857681274414,33.1857681274414,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,33.7837829589844,34.3824234008789,34.3824234008789,34.3824234008789,34.3824234008789,34.3824234008789,34.3824234008789,34.3824234008789,35.151252746582,35.151252746582,35.151252746582,35.151252746582,35.7653274536133,35.7653274536133,35.7653274536133,35.7653274536133,35.7653274536133,36.3489456176758,36.3489456176758,36.3489456176758,36.3489456176758,36.3489456176758,36.3489456176758,36.3489456176758,36.3489456176758,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,37.0945281982422,27.5256958007812,27.5256958007812,27.5256958007812,27.5256958007812,27.5256958007812,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.1257019042969,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,28.7427520751953,29.9231414794922,29.9231414794922,29.9231414794922,29.9231414794922,29.9231414794922,29.9231414794922,29.9231414794922,29.9231414794922,30.8878555297852,30.8878555297852,30.8878555297852,30.8878555297852,30.8878555297852,30.8878555297852,30.8878555297852,31.7564392089844,31.7564392089844,32.6876525878906,32.6876525878906,32.6876525878906,32.6876525878906,32.6876525878906,32.6876525878906,33.423698425293,33.423698425293,33.423698425293,33.423698425293,33.423698425293,33.423698425293,33.423698425293,34.021110534668,34.021110534668,34.021110534668,34.021110534668,34.021110534668,34.021110534668,34.021110534668,34.7066116333008,34.7066116333008,34.7066116333008,34.7066116333008,34.7066116333008,34.7066116333008,34.7066116333008,35.3776702880859,35.3776702880859,35.3776702880859,35.3776702880859,35.3776702880859,35.3776702880859,35.3776702880859,35.3776702880859,36.0553207397461,36.0553207397461,36.0553207397461,36.0553207397461,36.0553207397461,36.0553207397461,36.0553207397461,36.9384689331055,36.9384689331055,36.9384689331055,36.9384689331055,36.9384689331055,36.9384689331055,36.9384689331055,37.8892440795898,37.8892440795898,37.8892440795898,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,27.814094543457,28.7969818115234,28.7969818115234,28.7969818115234,28.7969818115234,28.7969818115234,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.2577438354492,29.7544097900391,29.7544097900391,29.7544097900391,29.7544097900391,29.7544097900391,29.7544097900391,29.7544097900391,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,30.3517913818359,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,31.5663681030273,32.2376937866211,32.2376937866211,32.2376937866211,32.2376937866211,32.2376937866211,32.2376937866211,32.2376937866211,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,33.401985168457,34.0277633666992,34.0277633666992,34.0277633666992,34.0277633666992,34.0277633666992,34.0277633666992,34.0277633666992,34.7466812133789,34.7466812133789,34.7466812133789,34.7466812133789,34.7466812133789,34.7466812133789,35.5127334594727,35.5127334594727,35.5127334594727,35.5127334594727,36.3772354125977,36.3772354125977,36.3772354125977,36.3772354125977,36.3772354125977,36.3772354125977,36.3772354125977,36.3772354125977,36.9619903564453,36.9619903564453,36.9619903564453,36.9619903564453,36.9619903564453,36.9619903564453,36.9619903564453,27.3972396850586,27.3972396850586,27.3972396850586,27.3972396850586,27.3972396850586,27.3972396850586,28.567253112793,28.567253112793,28.567253112793,28.567253112793,28.567253112793,28.567253112793,28.567253112793,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.2046813964844,29.8027801513672,29.8027801513672,31.0128479003906,31.0128479003906,31.0128479003906,31.0128479003906,31.0128479003906,31.0128479003906,31.0128479003906,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.2121047973633,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,32.8091201782227,33.9935531616211,33.9935531616211,33.9935531616211,33.9935531616211,33.9935531616211,33.9935531616211,33.9935531616211,33.9935531616211,34.5873947143555,34.5873947143555,34.5873947143555,34.5873947143555,34.5873947143555,34.5873947143555,34.5873947143555,35.7576904296875,35.7576904296875,35.7576904296875,35.7576904296875,35.7576904296875,35.7576904296875,36.6193923950195,36.6193923950195,36.6193923950195,36.6193923950195,36.6193923950195,36.6193923950195,36.6193923950195,36.6193923950195,37.4157791137695,37.4157791137695,27.8747024536133,27.8747024536133,27.8747024536133,27.8747024536133,27.8747024536133,27.8747024536133,29.0879364013672,29.0879364013672,29.0879364013672,29.0879364013672,29.0879364013672,29.0879364013672,29.0879364013672,29.0879364013672,29.7995452880859,29.7995452880859,29.7995452880859,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,30.9137420654297,31.5254898071289,31.5254898071289,31.5254898071289,31.5254898071289,31.5254898071289,31.5254898071289,31.5254898071289,31.5254898071289,32.1418304443359,32.1418304443359,32.1418304443359,32.1418304443359,32.1418304443359,32.1418304443359,32.1418304443359,32.7411727905273,32.7411727905273,32.7411727905273,32.7411727905273,32.7411727905273,33.3316879272461,33.3316879272461,33.3316879272461,33.3316879272461,33.3316879272461,33.3316879272461,33.3316879272461,33.9251403808594,33.9251403808594,33.9251403808594,33.9251403808594,33.9251403808594,34.5064697265625,34.5064697265625,34.5064697265625,34.5064697265625,34.5064697265625,34.5064697265625,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.0991363525391,35.7241973876953,35.7241973876953,35.7241973876953,35.7241973876953,35.7241973876953,35.7241973876953,35.7241973876953,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.3354187011719,36.9351577758789,36.9351577758789,36.9351577758789,36.9351577758789,36.9351577758789,36.9351577758789,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,37.6531219482422,27.517333984375,27.517333984375,27.517333984375,27.517333984375,27.517333984375,27.517333984375,27.517333984375,28.7141799926758,28.7141799926758,28.7141799926758,28.7141799926758,28.7141799926758,28.7141799926758,28.7141799926758,29.2666397094727,29.2666397094727,29.2666397094727,29.9234313964844,29.9234313964844,29.9234313964844,29.9234313964844,29.9234313964844,29.9234313964844,30.5122680664062,30.5122680664062,30.5122680664062,30.5122680664062,30.5122680664062,30.5122680664062,31.2963714599609,31.2963714599609,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.0556030273438,32.7255630493164,32.7255630493164,32.7255630493164,32.7255630493164,32.7255630493164,32.7255630493164,32.7255630493164,32.7255630493164,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,33.4411697387695,34.2033004760742,34.2033004760742,34.2033004760742,34.2033004760742,34.2033004760742,34.2033004760742,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,34.7946319580078,35.3949890136719,35.3949890136719,35.3949890136719,35.3949890136719,35.3949890136719,35.3949890136719,35.3949890136719,36.5823822021484,36.5823822021484,36.5823822021484,36.5823822021484,37.7745666503906,37.7745666503906,37.7745666503906,37.7745666503906,37.7745666503906,37.7745666503906,37.7745666503906,27.6484069824219,27.6484069824219,27.6484069824219,27.6484069824219,27.6484069824219,27.6484069824219,27.6484069824219,28.3092575073242,28.3092575073242,28.3092575073242,28.3092575073242,28.3092575073242,28.3092575073242,28.3092575073242,28.3092575073242,28.9607009887695,28.9607009887695,28.9607009887695,28.9607009887695,28.9607009887695,28.9607009887695,28.9607009887695,29.6157302856445,29.6157302856445,30.2058029174805,30.2058029174805,30.8170318603516,30.8170318603516,30.8170318603516,30.8170318603516,30.8170318603516,30.8170318603516,30.8170318603516,30.8170318603516,31.762939453125,31.762939453125,31.762939453125,31.762939453125,31.762939453125,31.762939453125,31.762939453125,31.762939453125,32.3368911743164,32.3368911743164,32.3368911743164,32.3368911743164,32.3368911743164,32.3368911743164,32.3368911743164,32.9224853515625,32.9224853515625,32.9224853515625,32.9224853515625,32.9224853515625,32.9224853515625,32.9224853515625,32.9224853515625,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,33.5171432495117,34.4370422363281,34.4370422363281,34.4370422363281,34.4370422363281,34.4370422363281,34.4370422363281,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.1006927490234,35.9372100830078,35.9372100830078,35.9372100830078,35.9372100830078,35.9372100830078,35.9372100830078,35.9372100830078,36.5151290893555,36.5151290893555,36.5151290893555,36.5151290893555,36.5151290893555,37.6877059936523,37.6877059936523,37.6877059936523,37.6877059936523,37.6877059936523,37.6877059936523,37.6877059936523,37.6877059936523,27.5172882080078,27.5172882080078,27.5172882080078,27.5172882080078,27.5172882080078,27.5172882080078,27.5172882080078,28.5250473022461,28.5250473022461,28.5250473022461,28.5250473022461,28.5250473022461,29.1932678222656,29.1932678222656,29.1932678222656,29.1932678222656,29.1932678222656,29.1932678222656,29.1932678222656,30.2984466552734,30.2984466552734,30.2984466552734,30.2984466552734,30.9317398071289,30.9317398071289,30.9317398071289,30.9317398071289,30.9317398071289,30.9317398071289,30.9317398071289,31.8191299438477,31.8191299438477,32.4146728515625,32.4146728515625,32.4146728515625,32.4146728515625,32.4146728515625,32.4146728515625,32.4146728515625,32.4146728515625,33.0556259155273,33.0556259155273,33.7145309448242,33.7145309448242,33.7145309448242,33.7145309448242,33.7145309448242,34.4766540527344,34.4766540527344,34.4766540527344,34.4766540527344,34.4766540527344,34.4766540527344,35.2442092895508,35.2442092895508,35.831413269043,35.831413269043,35.831413269043,35.831413269043,35.831413269043,36.4714660644531,36.4714660644531,36.4714660644531,36.4714660644531,36.4714660644531,36.4714660644531,37.1463088989258,37.1463088989258,37.1463088989258,37.1463088989258,37.1463088989258,37.1463088989258,37.1463088989258,37.1463088989258,37.7816543579102,37.7816543579102,37.7816543579102,37.7816543579102,27.8318634033203,27.8318634033203,27.8318634033203,27.8318634033203,27.8318634033203,27.8318634033203,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,28.4371109008789,29.297737121582,29.297737121582,29.297737121582,29.297737121582,29.297737121582,29.297737121582,29.297737121582,29.9760131835938,29.9760131835938,29.9760131835938,29.9760131835938,29.9760131835938,29.9760131835938,29.9760131835938,30.6106033325195,30.6106033325195,31.2208862304688,31.2208862304688,31.2208862304688,32.4228439331055,32.4228439331055,33.6337280273438,33.6337280273438,33.6337280273438,33.6337280273438,33.6337280273438,33.6337280273438,33.6337280273438,34.3010711669922,34.3010711669922,34.3010711669922,34.3010711669922,34.3010711669922,34.3010711669922,34.3010711669922,34.3010711669922,34.8963394165039,34.8963394165039,34.8963394165039,34.8963394165039,34.8963394165039,35.9865646362305,35.9865646362305,35.9865646362305,35.9865646362305,35.9865646362305,36.5881500244141,36.5881500244141,36.5881500244141,36.5881500244141,36.5881500244141,37.3919448852539,37.3919448852539,37.3919448852539,27.8637313842773,27.8637313842773,27.8637313842773,27.8637313842773,27.8637313842773,27.8637313842773,27.8637313842773,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,28.4889984130859,29.698616027832,29.698616027832,29.698616027832,29.698616027832,29.698616027832,29.698616027832,29.698616027832,29.698616027832,30.54248046875,30.54248046875,30.54248046875,30.54248046875,30.54248046875,30.54248046875,30.54248046875,30.54248046875,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.2759017944336,31.8711090087891,31.8711090087891,31.8711090087891,31.8711090087891,31.8711090087891,31.8711090087891,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,32.6851577758789,33.2826690673828,33.2826690673828,33.2826690673828,33.2826690673828,33.8705978393555,33.8705978393555,33.8705978393555,33.8705978393555,33.8705978393555,33.8705978393555,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.0534515380859,35.6454544067383,35.6454544067383,35.6454544067383,35.6454544067383,36.2522354125977,36.2522354125977,36.2522354125977,36.2522354125977,36.2522354125977,36.8344955444336,36.8344955444336,36.8344955444336,36.8344955444336,36.8344955444336,36.8344955444336,36.8344955444336,36.8344955444336,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,37.4469680786133,27.6003036499023,27.6003036499023,27.6003036499023,27.6003036499023,28.2068557739258,28.2068557739258,28.2068557739258,28.2068557739258,28.2068557739258,28.8102874755859,28.8102874755859,30.0397644042969,30.0397644042969,30.639533996582,30.639533996582,30.639533996582,30.639533996582,30.639533996582,30.639533996582,30.639533996582,30.639533996582,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.2504272460938,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,31.9799423217773,32.5811157226562,32.5811157226562,32.5811157226562,32.5811157226562,32.5811157226562,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.1727447509766,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,33.8312149047852,34.9183578491211,34.9183578491211,34.9183578491211,34.9183578491211,34.9183578491211,35.5654754638672,35.5654754638672,36.140495300293,36.140495300293,36.140495300293,36.140495300293,36.140495300293,36.140495300293,36.140495300293,36.7220077514648,36.7220077514648,36.7220077514648,36.7220077514648,36.7220077514648,36.7220077514648,37.4516906738281,37.4516906738281,37.4516906738281,37.4516906738281,37.4516906738281,37.4516906738281,37.4516906738281,27.486572265625,27.486572265625,27.486572265625,27.486572265625,27.486572265625,28.1674270629883,28.1674270629883,28.1674270629883,28.1674270629883,28.1674270629883,28.1674270629883,28.1674270629883,29.0119323730469,29.0119323730469,29.0119323730469,29.0119323730469,29.0119323730469,29.0119323730469,29.0119323730469,29.0119323730469,29.7540588378906,29.7540588378906,29.7540588378906,29.7540588378906,30.7167510986328,30.7167510986328,31.3183441162109,31.3183441162109,31.3183441162109,31.3183441162109,31.3183441162109,31.3183441162109,31.3183441162109,31.3183441162109,31.9260711669922,31.9260711669922,31.9260711669922,31.9260711669922,31.9260711669922,31.9260711669922,33.037971496582,33.037971496582,33.037971496582,33.037971496582,33.037971496582,33.037971496582,33.037971496582,33.037971496582,33.6262893676758,33.6262893676758,33.6262893676758,33.6262893676758,33.6262893676758,33.6262893676758,33.6262893676758,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,34.3645172119141,35.0573043823242,35.0573043823242,35.0573043823242,35.0573043823242,35.0573043823242,35.0573043823242,35.0573043823242,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,35.81103515625,36.4061508178711,36.4061508178711,36.4061508178711,37.2557144165039,37.2557144165039,37.8500518798828,37.8500518798828,37.8500518798828,37.8500518798828,37.8500518798828,37.8500518798828,27.9769439697266,27.9769439697266,28.7631759643555,28.7631759643555,28.7631759643555,28.7631759643555,28.7631759643555,28.7631759643555,28.7631759643555,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.3897247314453,29.9949035644531,29.9949035644531,29.9949035644531,29.9949035644531,29.9949035644531,30.7047500610352,30.7047500610352,30.7047500610352,30.7047500610352,30.7047500610352,30.7047500610352,30.7047500610352,30.7047500610352,31.3881530761719,31.3881530761719,31.3881530761719,31.3881530761719,31.3881530761719,32.4734573364258,32.4734573364258,32.4734573364258,32.4734573364258,32.4734573364258,33.6768341064453,33.6768341064453,33.6768341064453,33.6768341064453,33.6768341064453,33.6768341064453,33.6768341064453,34.4586486816406,34.4586486816406,34.4586486816406,34.4586486816406,34.4586486816406,35.152229309082,35.152229309082,35.152229309082,35.152229309082,35.152229309082,35.152229309082,35.152229309082,35.152229309082,35.7385101318359,35.7385101318359,36.482048034668,36.482048034668,36.482048034668,36.482048034668,36.482048034668,36.482048034668,36.482048034668,36.482048034668,37.0602264404297,37.0602264404297,37.0602264404297,37.0602264404297,37.0602264404297,37.7904663085938,37.7904663085938,37.7904663085938,37.7904663085938,37.7904663085938,37.7904663085938,37.7904663085938,28.2798767089844,28.2798767089844,28.2798767089844,28.8781661987305,28.8781661987305,28.8781661987305,28.8781661987305,28.8781661987305,28.8781661987305,29.4718551635742,29.4718551635742,29.4718551635742,29.4718551635742,29.4718551635742,29.4718551635742,29.4718551635742,30.0770874023438,30.0770874023438,30.0770874023438,30.0770874023438,30.0770874023438,30.0770874023438,30.0770874023438,30.0770874023438,30.7165145874023,30.7165145874023,30.7165145874023,30.7165145874023,31.3043975830078,31.3043975830078,31.3043975830078,31.3043975830078,31.3043975830078,31.3043975830078,31.3043975830078,31.3043975830078,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.1656875610352,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,32.8375015258789,34.0425872802734,34.0425872802734,34.0425872802734,34.7442474365234,34.7442474365234,34.7442474365234,34.7442474365234,34.7442474365234,34.7442474365234,34.7442474365234,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.3287887573242,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,35.9719390869141,36.5867691040039,36.5867691040039,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,37.2575149536133,27.5933227539062,27.5933227539062,27.5933227539062,27.5933227539062,27.5933227539062,27.5933227539062,27.5933227539062,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,28.814826965332,29.7743911743164,29.7743911743164,29.7743911743164,30.6378326416016,30.6378326416016,30.6378326416016,30.6378326416016,30.6378326416016,30.6378326416016,31.3516464233398,31.3516464233398,31.3516464233398,31.3516464233398,31.3516464233398,31.3516464233398,31.3516464233398,31.9615020751953,31.9615020751953,31.9615020751953,31.9615020751953,31.9615020751953,32.619255065918,32.619255065918,32.619255065918,32.619255065918,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,33.2786178588867,34.0480117797852,34.0480117797852,34.0480117797852,34.0480117797852,34.0480117797852,34.0480117797852,34.0480117797852,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,34.6464080810547,35.2465972900391,35.2465972900391,35.2465972900391,35.2465972900391,35.2465972900391,35.2465972900391,35.9297637939453,35.9297637939453,35.9297637939453,35.9297637939453,35.9297637939453,35.9297637939453,37.128288269043,37.128288269043,37.8453598022461,37.8453598022461,37.8453598022461,37.8453598022461,37.8453598022461,37.8453598022461,37.8453598022461,37.8453598022461,28.2114486694336,28.2114486694336,28.2114486694336,28.2114486694336,28.2114486694336,28.2114486694336,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,28.8199234008789,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,29.42236328125,30.0289840698242,30.0289840698242,30.0289840698242,30.0289840698242,30.0289840698242,30.0289840698242,30.6300277709961,30.6300277709961,30.6300277709961,30.6300277709961,30.6300277709961,30.6300277709961,30.6300277709961,30.6300277709961,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,31.8430938720703,32.5422592163086,32.5422592163086,32.5422592163086,32.5422592163086,32.5422592163086,33.3541870117188,33.3541870117188,34.262336730957,34.262336730957,34.262336730957,34.262336730957,34.262336730957,34.262336730957,34.262336730957,34.8621292114258,34.8621292114258,34.8621292114258,34.8621292114258,34.8621292114258,34.8621292114258,34.8621292114258,34.8621292114258,35.6188125610352,35.6188125610352,35.6188125610352,35.6188125610352,35.6188125610352,35.6188125610352,35.6188125610352,35.6188125610352,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,36.56396484375,37.7382354736328,37.7382354736328,37.7382354736328,37.7382354736328,37.7382354736328,37.7382354736328,37.7382354736328,37.7382354736328,27.6393508911133,27.6393508911133,27.6393508911133,27.6393508911133,27.6393508911133,28.4367370605469,28.4367370605469,29.195198059082,29.195198059082,30.0249710083008,30.0249710083008,30.0249710083008,30.0249710083008,30.0249710083008,30.0249710083008,30.0249710083008,30.0249710083008,30.636344909668,30.636344909668,30.636344909668,30.636344909668,30.636344909668,30.636344909668,30.636344909668,30.636344909668],&#34;meminc&#34;:[0,0,0,0,0,0,0,0,0,0,0.609909057617188,0,0,0,0,0,0,0,0.612922668457031,0,0,0,0,0,0,0.844741821289062,0,0,0,0,0,0,0,0,0,0.594985961914062,0,0,0,0,0.66497802734375,0,0,0,0,0,0,0.827377319335938,0,0,0,0,0,0,0.587364196777344,0,0.962539672851562,0,0,0,0,0,0,0,0,0,0,0.596244812011719,0,0,0,0,0,0,0,0,0,0,0,0,1.20180511474609,0,0,0,0,0,0,0,0,0.609710693359375,0,0,0,0,0.596923828125,0,0,0,0,0,0,0,0,0,0,0,0.607704162597656,0,0,0.588455200195312,0,0,0,0,0,0,-10.2059097290039,0,0,0,0,0,0,0.600410461425781,0,0,0,0,0,0,0,0.694419860839844,0,0,0,0,0,0.875320434570312,0,0,0,0,0.60308837890625,0,0,0,0,0,0.799324035644531,0,0,0,0,0,0,0.629493713378906,0,0,0,0,0,1.09005737304688,0,0,0,0,0,0,0,0.600715637207031,0,0,0,0,0,0,0,0,0,1.09086608886719,0,0,0.589614868164062,0,0,0,0,0,0.638641357421875,0,0,0,0,0,0,0.748321533203125,0,0,0,0,0,0,0,0.611419677734375,0,0,0,0,0,0,0,0,0,-9.62137603759766,0,0,0,0,0,0,0,0,0,0.602821350097656,0,0,0,0,0,0,0,0,0,0,1.00597381591797,0,0,0,0,0,0,0,0.609840393066406,0,0,0,0,0,0,0,0.611724853515625,0,0,0,0,0.833328247070312,0,0,0,0,0,0,0,0.716278076171875,0,0,0,0,0,0.597625732421875,0,0,0,0,0,0,0,0,0,0,0.742622375488281,0,0,0,0,0,0.6986083984375,0,0,0,0,0,0,1.20057678222656,0,0,0,0,0,0,0.812141418457031,0,0.605819702148438,0,0,0,0,0.939292907714844,0,0,0,0,0,0,0,0,-10.2103881835938,0,0,0,0,0,0,0,0,0,0,0,0,0,0.611305236816406,0,0,0,0,0,0,0.630859375,0,0,0,0,0,0.611320495605469,0,1.2237548828125,0,0,0,0,0,0,0,0,0,1.22602844238281,0,0,0,0,0,0,1.07883453369141,0,0,0,0,0,0,0.612747192382812,0,0,0,0,0,0,0.964035034179688,0,0,0,0,0,0,0,0,0,0.7154541015625,0,0,0,0,0,0,0,0.770416259765625,0,0,0,0,0,0.891166687011719,0,0,0,0,0,0,0.598762512207031,0,0,0,0,0,0,0,0,0,0.588424682617188,0,0,0,0,0,0,0,-10.1803359985352,0,0,0,0,0.677299499511719,0,0,0,0,0,0,0.904014587402344,0,0,0,0,0,0,0,0,0,0.610565185546875,0,0,0,0,0,0,0,0,0,0.698448181152344,0,0,0,0,0,0,1.13721466064453,0,0,0,0,0,1.06549835205078,0,0.600944519042969,0,0,0,0,0,0,0,0,0,1.22212219238281,0,0,0,0,0,0,0.700531005859375,0,0,0,0,0,0,0,1.21562957763672,0,0,0,0,0,0.72528076171875,0,0,0,0,0,0,0,0,0,0,0.639373779296875,0,0,-9.95811462402344,0,0,0,0,0,0,0.609107971191406,0,0,0,0,0,0,0.723037719726562,0,0,0,0.593086242675781,0,0,0,0,0,0,0,0,0.607124328613281,0,0,0,0,0,0,0.946304321289062,0,0,0,0,0,0,0.585250854492188,0,0,0,0,0,0,0,0.817626953125,0,0,0,0,0,0,0,0,0,0.614166259765625,0,0,0,0,0,0,0,1.00688934326172,0,0,0,0,0,0,0,0,0,0.828483581542969,0,0,0,0,0,0,0,0,1.22270965576172,0,0,0,0,0,0.702552795410156,0,0,0,0,0,0,0.616928100585938,0,0,0,0,0,0,0,-10.5742721557617,0,0,0,0.718910217285156,0,0,0,0,0,0,0.744430541992188,0,0,0,0,0,1.04547882080078,0,0,0,0,0,0,0,0,0,0,0,0,1.21729278564453,0,0,0,0,0,0,0,0.651725769042969,0,0,0,0,0,0,0,0.611366271972656,0,0,0,0.575241088867188,0,0.566535949707031,0,0,0,0,0,0,0,0,0,0,0.536384582519531,0,0,0,0,0,0,0,0,0.529495239257812,0,0,0,0,0,0,0,0.564857482910156,0,0,0,0,0,0,0,0.560379028320312,0,0,0,0,0,0,0.561386108398438,0,0,0,0,0.558303833007812,0,0,0,0,0,0.814041137695312,0,0,0,0,0,0,0,0,-10.1632232666016,0,0.643722534179688,0,0,0,0,0,0,0.599189758300781,0,0,0,0,0,0,0.891876220703125,0,0,0,0,0,0.7158203125,0,0,0,0,0,0,0,0.653434753417969,0,0,0,0,0,0,0,0,0,0.827377319335938,0,0,0,0,0,0,0.965576171875,0,0,0,0,0,0,0.805007934570312,0,0,0,0,0.59466552734375,0,0,0,0,0,0,0.730018615722656,0,0,0,0,0,0,0,0.732498168945312,0,0,0,0,0,0,0.636665344238281,0,0,0,0,0,0,0.8739013671875,0,0,0,0.58544921875,0,-10.2281341552734,0,0,0,0,0,0,0.69146728515625,0,0,0,0,0,0,0,0,0,0.843605041503906,0,1.02529144287109,0,0,0,0,0,0,0,0.609901428222656,0,0,0,0,0,0.919776916503906,0,0,0,0,0,0,0,0.589027404785156,0,0,0,0,0.680389404296875,0,0.761054992675781,0,0,0,0,0,0,0,0,0,0,0.575149536132812,0,0,0,0,0,0,0,0,0.78045654296875,0,0,0,0,0,0,0,0.576675415039062,0,0,0,0,0,0.600250244140625,0,0,0,0,0.564476013183594,0,0,0,0,0,0,0.611244201660156,0,0,0,0,0,0,0,0,0,0,0.621673583984375,0,0,0,0,0,0,0,0,0,-10.2027359008789,0,0,0,0,0,0.619224548339844,0,0,0,0,0,0,0.611198425292969,0,0,0,0,0,0,0,0,0.596885681152344,0,0,0,0,0,0,0,0.644676208496094,0,0,0,0,0,0,0.595314025878906,0,0,0,0,0,0,0,0,0,0,0,0.608795166015625,0,0,0,0.84942626953125,0,0,0,0,0,0,0,0,0,0,0.61212158203125,0,0,0,0,0,0,0,0.616233825683594,0,0,0,0,0,0.860862731933594,0,0,0,0,0,0,0,0.569137573242188,0,0,0,0,0,0,0,0,0.577888488769531,0,0.848655700683594,0,0,0,0,0,0,0,0,0.641212463378906,0,0,0,0,0,0,0,0,0.715431213378906,0,0,0,0,0,0,0,-10.1755218505859,0,0,0,0,0,0,0,0,0.632766723632812,0,0,0.724006652832031,0,0,0,0,0,0,0,0,0.667915344238281,0,0,0,0,0,0.991111755371094,0,0,0,0,0,0,0,0,0,0.817634582519531,0,0,0,0,0,0,0,0,0,0.840705871582031,0,0,0,0,0,0,0,0,0,0.953651428222656,0,0,0,0,0,0,0,0,0.668380737304688,0,0,0,0,0,0,0.701309204101562,0,0,0,0,0,0,0,0.831466674804688,0,0,0,0,0,0,0,0.767898559570312,0,0,0,0.586349487304688,0,0,0,0,0,0,0,0,0,0,0.644119262695312,0,0,0,0,0,0,0,0.609039306640625,0,0,0,0,0,0,-10.1368789672852,0,0,0,0,0,0.593757629394531,0,0,0,0,1.21708679199219,0,0,0,0,0,0,0.609237670898438,0,0,0,0,0,0,0,0,0,0.603492736816406,0,0,0,0,0,0,1.22132873535156,0,0,0,0,0,0.634147644042969,0,0,0,0,0,0,0.852821350097656,0,0,0,0,0,0,0.573883056640625,0,0,0,0,0,0,0.754730224609375,0,0,0,0,0,0,0,0.638572692871094,0,0,0,0,0,0.572708129882812,0,0,0,0,0,0,0.746925354003906,0,0,0,0,0,0,0,0,0,0,0.656547546386719,0,0,0,0,0,0,0,0,0,-10.0348434448242,0,0,0,0,0,0,0,0.684234619140625,0,0,0,0,0,0,0.595413208007812,0,0,0,0,0,0.604011535644531,0,0,0,0,0,0.611503601074219,0,0,0,0,0,0,0,1.16213226318359,0,0,0,0,0.574844360351562,0,0,0,0,0,0,0,0.802803039550781,0,0,0,0,0,0.78076171875,0,0,0,0,0,0,0,0,0,0.929252624511719,0,0,0,0,0,0,0.603614807128906,0,0,0,0,0,0,0,0.604988098144531,0,0,0,0,0,0.587669372558594,0,0,0,0,0,0.590835571289062,0,0,0,0,0,0,0,0,1.1832275390625,0,0,0,0,0,0,0,0,0,0,-10.1484527587891,0,0,0,0,0,0,0,0,0.989158630371094,0,0,0,0,0,0,0,0.714317321777344,0,0,0,0,0,0,0,0,0,0,0.611114501953125,0,0,0,0,0,0,0,0,0,0.602096557617188,0,0.698577880859375,0,0,0,0,0,0,0,0.672721862792969,0,0,0,0,0,0,0.597587585449219,0,0,0,0,0,0,0,0,0.582229614257812,0,0,0,0,0,0,0,1.14100646972656,0,0,0,0,0,0.682975769042969,0,0,0,0,0,0,0,0,0,0,0,0,0.700286865234375,0,0,0,0,0,0,0,0,0,0,0,0.571983337402344,0,0,0,0,0,0,0,0.568519592285156,0,0,0,0,0,0,0.569358825683594,0,0,0,0,0,0.655464172363281,0,0,0,0,0,0,-10.2146377563477,0,0,0,0.7080078125,0,0,0,0,0,0,0,0.742752075195312,0,0,0,0,0,0,0,0,0,0,0,0,0,0.744773864746094,0,0,0,0,0,0,0,0,0,0.6883544921875,0,0,0,0,0,0,0,0,0,0,0,0.610343933105469,0,0,0,0,0,0.743019104003906,0,0,0.568931579589844,0,0,0.561637878417969,0,0,0,0,0.800148010253906,0,0.82952880859375,0,0,0,0,0,0,0,0,0,0,0,0.742744445800781,0,0,0,0,0,0,0.578857421875,0,0,0,0,0.619186401367188,0,0,0,0,0,0,0,0.598419189453125,0,0,0,0,0,0,0,0,0,0,0.613861083984375,0,0,0,0,0,0,0,0,-10.1135177612305,0,0,0,0,0,0,0.793235778808594,0,0,0,0,0,0,0.66778564453125,0,0,0,0,0,0.600784301757812,0,0,0,0,0,0.610084533691406,0,0,0,0,0,0,0,0,0,0,0,0.964286804199219,0,0,0,0,0,0,0,0,0,0.591804504394531,0,0,0,0,0.497230529785156,0,0,0.857452392578125,0,0,0,0,0,0.902305603027344,0,0,0,0,0.769874572753906,0,0,0,0,0,0.628280639648438,0,0.681442260742188,0,0,0,0,0,0,1.19393157958984,0,0,0,0,0,0,0,0.451133728027344,0,0,0,0,0,0,0,0,0,0,0,0,0,-10.020866394043,0,0,0,0,0,0,0,0.610221862792969,0,0,0,0,0,0,0,0,0,0,0,0,0,0.642807006835938,0,0,0.849998474121094,0,0,0,0,0,0.899513244628906,0,0,0,0,0.820655822753906,0,0,0,0,0,0,0.586395263671875,0,0,0,0,0,0,0,0,0,0.606369018554688,0,0,0.631393432617188,0,0,0,0,0,0,0,0.907310485839844,0,0,0,0,0,0.756767272949219,0,0,0,0,0,0,0.704818725585938,0,0,0,0,0,0.982086181640625,0,0,0,-1.14826202392578,0,0,0,0,0,0,0,0,0,0,0,-7.33648681640625,0,0.7183837890625,0,0,0,0,0,1.09463500976562,0,0,0,0,0,0,0.636573791503906,0,0,0,0.617759704589844,0,0,0,0,0,0,0,0,0,0,1.14902496337891,0,0,0,0,0,0,0,0,0,0,0.659523010253906,0,0,0,0,0.63983154296875,0,0,0,0,0.6583251953125,0,0,0,0,0,0,0,0.696128845214844,0,0.701774597167969,0,0,0,0,0,0,0.691993713378906,0,0,0,0,0.580551147460938,0,0,0,0,0,0,0,0,0.667747497558594,0,0,0,0,0,0,0,-10.0551986694336,0,0,0,0,0,0,0,0.611404418945312,0,0,0,0,0,0,0,0.657829284667969,0,0.814842224121094,0,0,0,0,0,0,0,0,0,0,0,0,0.711341857910156,0,0,0,0,0,0,0,0,0,0,0,0,1.21218872070312,0,0,0,0,0,0,0,0.829627990722656,0,0,0,1.19767761230469,0,0,0,0,0,0,0,0,0,1.19029998779297,0,0,0,0,0,0.67828369140625,0,0,0,0,0.625709533691406,0,0.581619262695312,0,0.589790344238281,0,0,0,0,0,0,0,0,0,-10.1557235717773,0,0,0,0,0,0,0.674812316894531,0,0,0,0,0,0,0.928497314453125,0,0.601287841796875,0,0,0,0,0,0,0,0,0,0,0,0.626419067382812,0,0,0,0,0,1.03291320800781,0,0,0,0,0,0,0,0.687339782714844,0,0,0,0,0,0,0.99365234375,0,0,0,0,0,0,0.741157531738281,0,0,0,0,0,0,0,0,0,0,0.683135986328125,0,0,0,0.575538635253906,0,0,0,0,0,0,0.630386352539062,0,0,0,0,0,0,0,0.612785339355469,0,0,0,0,0,0.677421569824219,0,0,0,0,0,0,0,0.976287841796875,0,0,0,0,0,0,0,0,0,0,0,-10.1099853515625,0,0,0,0,0,0,0,0.663017272949219,0,0,0,0,1.14373779296875,0,0,0,0,0,0,0,0.904037475585938,0,0,0,0.619850158691406,0,0.620391845703125,0,0.597816467285156,0,0,0,0,0,0.57470703125,0,0,0,0,0,0,0.594696044921875,0,0,0,0,0,0,0,0,1.19788360595703,0,0,0,0,0,0,0.601654052734375,0,0,0,0,0.98681640625,0,0,0,0,0,0,0,0,0.610420227050781,0,0,0,0,0,0,0,0.585594177246094,0,0,0,0,0,0,0,0,0.478408813476562,0,0,0,0,0,-10.0237579345703,0,0,0.601097106933594,0,0,0,0,0,0,0.624862670898438,0,0,0,0.674972534179688,0,0,0,0,0.599441528320312,0,0,0,0,0,0,0,0.60736083984375,0,0,0.587295532226562,0,0,0,0,0,0,0.71356201171875,0,0,0,0,0,0,0.849899291992188,0,0,0,0,0,0.613304138183594,0,0.605339050292969,0,0,0,0,0,0,0,0,0.762458801269531,0,0,0,0,0,0,0,0.96392822265625,0,0,0,0,0,0,0,0.5699462890625,0,0,0,0,0,0,0.595542907714844,0,-9.55649566650391,0,0,0,0,0.607322692871094,0,0,0,0,0,0,0.741142272949219,0,0,0,0,0.587226867675781,0,0.689918518066406,0,0,1.19285583496094,0,0,0,0,0,0.610427856445312,0,0,0,0,0,0,0,1.20841979980469,0,0,0,0,0.656517028808594,0,0,0,0,0.585960388183594,0,0,0,0,0,0,0,0,0,0.596702575683594,0,0,0,0,0,0,0.924201965332031,0,0,0,0,0,0,0,0,0,0,0.884628295898438,0,0.880462646484375,0,0,0,0,-10.0970230102539,0,0,0,0,0.629859924316406,0,0.630233764648438,0,0,0,0,0,1.10808563232422,0,1.22431945800781,0,0,0,0,0,0,0,0,0,0,0,0,0.671302795410156,0,0,0,0,0,0,0,0.593719482421875,0,0,0,0.587509155273438,0,0,0,0,0,0,0.645721435546875,0,0,0,0,0,0,0.581672668457031,0,0,0,0,0.598342895507812,0,0,0,0,0,0,0,1.19234466552734,0,0,0,0,0,0,0,0.945526123046875,0,0,0,0.5755615234375,0,0,0,0,0,0,0,0,0,-10.0773620605469,0,0,0,0,0,0,0,0,0,0,0,0,0.611297607421875,0,0,0,0,0,0,0.610588073730469,0,0,0,0,0,0,0,0.611961364746094,0,0,0,0.601913452148438,0,0,0,0,0,1.21329498291016,0,0,0,0,0,0.686630249023438,0,0,0,0,0,0.831077575683594,0,0,0,0,0,0,0,1.19919586181641,0,0,0,0,0,0,0.603630065917969,0,0,0,0,0,0,0,0,0,0.599632263183594,0,0,0,0,0,0,0.9202880859375,0,0,0,0,0,0,0,0,0,0,0,0,0.915908813476562,0,0,0,0,0,0,0,0,0,0.676094055175781,0,0,0,0,0,0,0,-10.0016098022461,0,0,0,0,0,1.20628356933594,0,0,0,0,0,0,0.609153747558594,0,0,0,0,1.22184753417969,0,0,0,0,0,0,0,0.610755920410156,0,1.21244049072266,0,0,0,0,0.613525390625,0,0,0,0,0,0,0,0.598014831542969,0,0,0,0,0,0,0,0,0.598640441894531,0,0,0,0,0,0,0.768829345703125,0,0,0,0.61407470703125,0,0,0,0,0.5836181640625,0,0,0,0,0,0,0,0.745582580566406,0,0,0,0,0,0,0,0,-9.56883239746094,0,0,0,0,0.600006103515625,0,0,0,0,0,0,0,0,0,0,0.617050170898438,0,0,0,0,0,0,0,0,0,1.18038940429688,0,0,0,0,0,0,0,0.964714050292969,0,0,0,0,0,0,0.868583679199219,0,0.93121337890625,0,0,0,0,0,0.736045837402344,0,0,0,0,0,0,0.597412109375,0,0,0,0,0,0,0.685501098632812,0,0,0,0,0,0,0.671058654785156,0,0,0,0,0,0,0,0.677650451660156,0,0,0,0,0,0,0.883148193359375,0,0,0,0,0,0,0.950775146484375,0,0,-10.0751495361328,0,0,0,0,0,0,0,0,0,0.982887268066406,0,0,0,0,0.460762023925781,0,0,0,0,0,0,0,0,0,0.496665954589844,0,0,0,0,0,0,0.597381591796875,0,0,0,0,0,0,0,0,0,0,1.21457672119141,0,0,0,0,0,0,0,0,0,0,0.67132568359375,0,0,0,0,0,0,1.16429138183594,0,0,0,0,0,0,0,0,0,0,0,0,0,0.625778198242188,0,0,0,0,0,0,0.718917846679688,0,0,0,0,0,0.76605224609375,0,0,0,0.864501953125,0,0,0,0,0,0,0,0.584754943847656,0,0,0,0,0,0,-9.56475067138672,0,0,0,0,0,1.17001342773438,0,0,0,0,0,0,0.637428283691406,0,0,0,0,0,0,0,0,0.598098754882812,0,1.21006774902344,0,0,0,0,0,0,1.19925689697266,0,0,0,0,0,0,0,0,0,0,0.597015380859375,0,0,0,0,0,0,0,0,0,1.18443298339844,0,0,0,0,0,0,0,0.593841552734375,0,0,0,0,0,0,1.17029571533203,0,0,0,0,0,0.861701965332031,0,0,0,0,0,0,0,0.79638671875,0,-9.54107666015625,0,0,0,0,0,1.21323394775391,0,0,0,0,0,0,0,0.71160888671875,0,0,1.11419677734375,0,0,0,0,0,0,0,0,0,0.611747741699219,0,0,0,0,0,0,0,0.616340637207031,0,0,0,0,0,0,0.599342346191406,0,0,0,0,0.59051513671875,0,0,0,0,0,0,0.593452453613281,0,0,0,0,0.581329345703125,0,0,0,0,0,0.592666625976562,0,0,0,0,0,0,0,0,0.62506103515625,0,0,0,0,0,0,0.611221313476562,0,0,0,0,0,0,0,0,0,0.599739074707031,0,0,0,0,0,0.717964172363281,0,0,0,0,0,0,0,0,0,-10.1357879638672,0,0,0,0,0,0,1.19684600830078,0,0,0,0,0,0,0.552459716796875,0,0,0.656791687011719,0,0,0,0,0,0.588836669921875,0,0,0,0,0,0.784103393554688,0,0.759231567382812,0,0,0,0,0,0,0,0,0.669960021972656,0,0,0,0,0,0,0,0.715606689453125,0,0,0,0,0,0,0,0,0,0.762130737304688,0,0,0,0,0,0.591331481933594,0,0,0,0,0,0,0,0,0,0,0,0,0,0.600357055664062,0,0,0,0,0,0,1.18739318847656,0,0,0,1.19218444824219,0,0,0,0,0,0,-10.1261596679688,0,0,0,0,0,0,0.660850524902344,0,0,0,0,0,0,0,0.651443481445312,0,0,0,0,0,0,0.655029296875,0,0.590072631835938,0,0.611228942871094,0,0,0,0,0,0,0,0.945907592773438,0,0,0,0,0,0,0,0.573951721191406,0,0,0,0,0,0,0.585594177246094,0,0,0,0,0,0,0,0.594657897949219,0,0,0,0,0,0,0,0,0,0,0.919898986816406,0,0,0,0,0,0.663650512695312,0,0,0,0,0,0,0,0,0,0,0,0,0,0.836517333984375,0,0,0,0,0,0,0.577919006347656,0,0,0,0,1.17257690429688,0,0,0,0,0,0,0,-10.1704177856445,0,0,0,0,0,0,1.00775909423828,0,0,0,0,0.668220520019531,0,0,0,0,0,0,1.10517883300781,0,0,0,0.633293151855469,0,0,0,0,0,0,0.88739013671875,0,0.595542907714844,0,0,0,0,0,0,0,0.640953063964844,0,0.658905029296875,0,0,0,0,0.762123107910156,0,0,0,0,0,0.767555236816406,0,0.587203979492188,0,0,0,0,0.640052795410156,0,0,0,0,0,0.674842834472656,0,0,0,0,0,0,0,0.635345458984375,0,0,0,-9.94979095458984,0,0,0,0,0,0.605247497558594,0,0,0,0,0,0,0,0,0,0.860626220703125,0,0,0,0,0,0,0.678276062011719,0,0,0,0,0,0,0.634590148925781,0,0.610282897949219,0,0,1.20195770263672,0,1.21088409423828,0,0,0,0,0,0,0.667343139648438,0,0,0,0,0,0,0,0.595268249511719,0,0,0,0,1.09022521972656,0,0,0,0,0.601585388183594,0,0,0,0,0.803794860839844,0,0,-9.52821350097656,0,0,0,0,0,0,0.625267028808594,0,0,0,0,0,0,0,0,0,1.20961761474609,0,0,0,0,0,0,0,0.843864440917969,0,0,0,0,0,0,0,0.733421325683594,0,0,0,0,0,0,0,0,0.595207214355469,0,0,0,0,0,0.814048767089844,0,0,0,0,0,0,0,0,0,0.597511291503906,0,0,0,0.587928771972656,0,0,0,0,0,1.18285369873047,0,0,0,0,0,0,0,0,0.592002868652344,0,0,0,0.606781005859375,0,0,0,0,0.582260131835938,0,0,0,0,0,0,0,0.612472534179688,0,0,0,0,0,0,0,0,-9.84666442871094,0,0,0,0.606552124023438,0,0,0,0,0.603431701660156,0,1.22947692871094,0,0.599769592285156,0,0,0,0,0,0,0,0.610893249511719,0,0,0,0,0,0,0,0,0,0.729515075683594,0,0,0,0,0,0,0,0,0,0,0,0.601173400878906,0,0,0,0,0.591629028320312,0,0,0,0,0,0,0,0,0,0,0,0,0.658470153808594,0,0,0,0,0,0,0,0,0,1.08714294433594,0,0,0,0,0.647117614746094,0,0.575019836425781,0,0,0,0,0,0,0.581512451171875,0,0,0,0,0,0.729682922363281,0,0,0,0,0,0,-9.96511840820312,0,0,0,0,0.680854797363281,0,0,0,0,0,0,0.844505310058594,0,0,0,0,0,0,0,0.74212646484375,0,0,0,0.962692260742188,0,0.601593017578125,0,0,0,0,0,0,0,0.60772705078125,0,0,0,0,0,1.11190032958984,0,0,0,0,0,0,0,0.58831787109375,0,0,0,0,0,0,0.738227844238281,0,0,0,0,0,0,0,0,0,0,0,0.692787170410156,0,0,0,0,0,0,0.753730773925781,0,0,0,0,0,0,0,0,0,0,0.595115661621094,0,0,0.849563598632812,0,0.594337463378906,0,0,0,0,0,-9.87310791015625,0,0.786231994628906,0,0,0,0,0,0,0.626548767089844,0,0,0,0,0,0,0,0,0,0,0,0.605178833007812,0,0,0,0,0.709846496582031,0,0,0,0,0,0,0,0.683403015136719,0,0,0,0,1.08530426025391,0,0,0,0,1.20337677001953,0,0,0,0,0,0,0.781814575195312,0,0,0,0,0.693580627441406,0,0,0,0,0,0,0,0.586280822753906,0,0.743537902832031,0,0,0,0,0,0,0,0.578178405761719,0,0,0,0,0.730239868164062,0,0,0,0,0,0,-9.51058959960938,0,0,0.598289489746094,0,0,0,0,0,0.59368896484375,0,0,0,0,0,0,0.605232238769531,0,0,0,0,0,0,0,0.639427185058594,0,0,0,0.587882995605469,0,0,0,0,0,0,0,0.861289978027344,0,0,0,0,0,0,0,0,0,0,0.67181396484375,0,0,0,0,0,0,0,0,0,1.20508575439453,0,0,0.70166015625,0,0,0,0,0,0,0.584541320800781,0,0,0,0,0,0,0,0,0,0.643150329589844,0,0,0,0,0,0,0,0,0,0,0,0,0.614830017089844,0,0.670745849609375,0,0,0,0,0,0,0,0,0,0,-9.66419219970703,0,0,0,0,0,0,1.22150421142578,0,0,0,0,0,0,0,0,0,0,0,0,0.959564208984375,0,0,0.863441467285156,0,0,0,0,0,0.713813781738281,0,0,0,0,0,0,0.609855651855469,0,0,0,0,0.657752990722656,0,0,0,0.65936279296875,0,0,0,0,0,0,0,0,0,0,0,0.769393920898438,0,0,0,0,0,0,0.598396301269531,0,0,0,0,0,0,0,0,0,0,0,0.600189208984375,0,0,0,0,0,0.68316650390625,0,0,0,0,0,1.19852447509766,0,0.717071533203125,0,0,0,0,0,0,0,-9.6339111328125,0,0,0,0,0,0.608474731445312,0,0,0,0,0,0,0,0,0,0.602439880371094,0,0,0,0,0,0,0,0,0,0,0,0.606620788574219,0,0,0,0,0,0.601043701171875,0,0,0,0,0,0,0,1.21306610107422,0,0,0,0,0,0,0,0,0,0.699165344238281,0,0,0,0,0.811927795410156,0,0.908149719238281,0,0,0,0,0,0,0.59979248046875,0,0,0,0,0,0,0,0.756683349609375,0,0,0,0,0,0,0,0.945152282714844,0,0,0,0,0,0,0,0,0,0,1.17427062988281,0,0,0,0,0,0,0,-10.0988845825195,0,0,0,0,0.797386169433594,0,0.758460998535156,0,0.82977294921875,0,0,0,0,0,0,0,0.611373901367188,0,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//RtmpyrO71H/file11ae4cc9f3f1.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-2&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-2&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14],&#34;depth&#34;:[13,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;lapply&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;findLocalsList1&#34;,&#34;findLocalsList&#34;,&#34;funEnv&#34;,&#34;make.functionContext&#34;,&#34;cmpfun&#34;,&#34;compiler:::tryCmpfun&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRProp&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null],&#34;memalloc&#34;:[28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,28.3796691894531,31.1854553222656,31.1854553222656,31.1854553222656,31.1854553222656,31.1854553222656,31.1854553222656,31.1854553222656,31.1854553222656,36.8465423583984,36.8465423583984,36.8465423583984,36.8465423583984,36.8465423583984,36.8465423583984,36.8465423583984,42.614143371582,42.614143371582,42.614143371582,42.614143371582,42.614143371582,42.614143371582,42.614143371582,42.614143371582,48.2350692749023,48.2350692749023,48.2350692749023,48.2350692749023,48.2350692749023,48.2350692749023,48.2350692749023,48.2350692749023,55.0683517456055,55.0683517456055,55.0683517456055,55.0683517456055,55.0683517456055,55.0683517456055,55.0683517456055,55.0683517456055,62.9347152709961,62.9347152709961,62.9347152709961,62.9347152709961,62.9347152709961,62.9347152709961,62.9347152709961,62.9347152709961,31.0472183227539,31.0472183227539,31.0472183227539,31.0472183227539,31.0472183227539,31.0472183227539,31.0472183227539,31.0472183227539,37.5025329589844,37.5025329589844,37.5025329589844,37.5025329589844,37.5025329589844,37.5025329589844,44.6674499511719,44.6674499511719,44.6674499511719,44.6674499511719,44.6674499511719,44.6674499511719,44.6674499511719,44.6674499511719,51.0702590942383,51.0702590942383,51.0702590942383,51.0702590942383,51.0702590942383,51.0702590942383,51.0702590942383,51.0702590942383,56.6027297973633,56.6027297973633,56.6027297973633,56.6027297973633,56.6027297973633,56.6027297973633,56.6027297973633,56.6027297973633,62.5353393554688,62.5353393554688,62.5353393554688,62.5353393554688,62.5353393554688,62.5353393554688,62.5353393554688,33.0220947265625,33.0220947265625,33.0220947265625,33.0220947265625,33.0220947265625,33.0220947265625,33.0220947265625,33.0220947265625],&#34;meminc&#34;:[0,0,0,0,0,0,0,0,0,0,0,0,0,2.8057861328125,0,0,0,0,0,0,0,5.66108703613281,0,0,0,0,0,0,5.76760101318359,0,0,0,0,0,0,0,5.62092590332031,0,0,0,0,0,0,0,6.83328247070312,0,0,0,0,0,0,0,7.86636352539062,0,0,0,0,0,0,0,-31.8874969482422,0,0,0,0,0,0,0,6.45531463623047,0,0,0,0,0,7.1649169921875,0,0,0,0,0,0,0,6.40280914306641,0,0,0,0,0,0,0,5.532470703125,0,0,0,0,0,0,0,5.93260955810547,0,0,0,0,0,0,-29.5132446289062,0,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[{&#34;filename&#34;:&#34;&lt;expr&gt;&#34;,&#34;content&#34;:&#34;set.seed(2009)\nprofvis({\n    NullDistFSNDR_aw &lt;- fastSimNullDistRProp(sex ~ time, success=\&#34;Female\&#34;, data=tips)\n})&#34;,&#34;normpath&#34;:&#34;&lt;expr&gt;&#34;}],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//RtmpyrO71H/file11ae10f3035f.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-3&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-3&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,7,7,7,7,7,7,7,7,7,7,7,8,8,8,9,9,9,9,9,10,10,10,10,10,10,10,10,11,11,11,12,12,12,12,12,12,12,12,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,26,26,26,26,26,27,27,27,27,27,27,27,27,28,28,28,29,29,29,29,29,29,29,30,30,30,30,31,31,31,31,31,32,32,32,32,32,32,32,32,33,33,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,37,37,37,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,45,45,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,48,48,49,49,49,49,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,52,52,53,53,53,53,53,53,53,54,54,54,54,54,54,54,55,55,55,55,55,55,55,55,55,55,55,55,56,56,56,56,56,57,57,57,57,57,58,58,58,58,58,59,59,59,59,59,60,60,60,61,61,61,61,61,61,61,61,62,62,62,62,62,62,62,63,63,63,63,63,63,63,63,64,64,64,64,64,64,64,64,64,64,64,64,65,65,66,66,66,66,66,66,66,67,67,67,67,67,67,67,68,68,68,68,68,68,68,68,68,69,69,69,69,69,69,69,69,69,69,70,70,70,70,70,70,70,70,70,70,70,70,70,70,71,71,71,71,71,71,71,71,71,71,71,71,71,72,72,72,72,72,72,72,73,73,73,73,73,73,73,73,73,73,74,74,74,74,74,74,74,75,75,75,75,75,75,75,76,76,76,76,76,76,77,77,77,77,77,77,78,78,78,78,78,78,78,78,78,78,79,79,79,79,79,80,80,80,80,80,80,80,81,81,81,81,81,82,82,83,83,83,83,83,83,83,84,84,84,84,84,84,85,85,85,85,85,85,85,86,86,86,86,86,86,86,86,86,86,86,86,86,87,87,87,87,87,87,88,88,88,88,88,88,88,88,88,88,89,89,89,89,89,89,90,90,90,90,90,90,90,90,90,90,91,91,91,91,91,91,92,92,92,92,92,92,92,92,93,93,93,93,93,93,93,94,94,95,95,95,95,95,95,95,96,96,96,96,96,96,96,97,97,97,97,97,98,98,98,98,98,98,98,98,98,98,99,99,99,99,99,99,99,99,100,100,100,100,100,101,101,101,101,101,101,101,102,102,102,102,102,102,102,102,102,102,103,103,103,103,103,103,103,104,104,104,104,104,104,104,105,105,105,105,105,106,106,106,106,106,106,106,107,107,107,107,107,107,107,108,108,108,108,108,108,108,108,108,108,109,109,109,109,109,109,110,110,110,110,110,110,110,110,110,110,110,111,111,112,112,112,112,112,112,113,113,113,113,113,113,113,114,114,114,114,114,114,114,114,114,114,115,115,115,115,115,115,115,115,115,115,115,116,116,116,116,116,116,116,117,117,118,118,118,118,118,119,119,120,120,120,120,120,120,120,120,120,120,120,121,121,121,121,121,121,121,121,122,122,122,122,122,122,122,123,123,123,123,123,123,123,123,123,123,123,124,124,124,124,124,124,124,124,124,124,125,125,125,125,125,126,126,126,126,126,126,126,126,127,127,127,127,127,127,127,127,128,128,128,128,128,129,129,129,129,129,129,129,129,129,130,130,130,130,131,131,132,132,132,132,132,133,133,133,133,133,134,134,134,134,134,134,135,135,135,135,135,135,135,135,135,135,135,136,136,136,136,136,136,136,137,137,137,137,137,137,137,137,138,138,138,138,138,138,139,139,139,140,140,140,140,140,141,141,141,141,141,141,141,141,142,142,142,142,142,142,143,143,143,143,143,143,143,143,144,144,144,144,144,144,144,145,145,145,145,145,145,145,145,146,146,146,146,146,146,147,147,148,148,148,148,148,148,148,149,149,149,149,149,149,149,149,149,149,150,150,150,150,150,151,151,151,151,151,151,151,151,151,151,152,152,152,152,152,152,153,153,153,153,153,153,153,153,154,154,154,154,154,154,154,154,155,155,155,155,155,155,155,155,156,156,156,156,156,156,156,156,156,156,157,157,157,157,157,157,157,157,158,158,158,158,158,158,158,158,158,158,158,159,159,159,159,159,159,159,159,160,160,160,160,160,160,160,160,160,160,160,161,161,161,161,161,161,161,161,162,162,163,163,163,163,163,163,163,164,164,164,164,164,164,165,165,165,165,165,165,165,165,165,165,165,166,166,166,166,166,166,167,167,167,167,167,168,168,168,168,168,169,169,169,169,169,169,169,169,169,169,169,169,170,170,171,171,171,171,171,171,171,172,172,172,172,172,172,172,172,172,172,172,172,173,173,173,173,173,173,173,174,174,174,174,174,174,174,174,175,175,175,175,175,176,176,176,177,177,177,177,177,178,178,178,178,179,179,179,179,179,179,179,179,179,180,180,180,180,180,181,181,181,181,181,182,182,182,182,183,183,184,184,184,184,184,184,184,185,185,185,185,185,185,185,185,186,186,186,186,186,186,186,186,187,187,187,187,187,187,187,187,188,188,189,189,189,189,189,189,190,190,190,190,190,190,190,190,191,191,191,191,191,191,191,192,192,192,192,192,192,193,193,193,193,193,193,193,194,194,194,194,194,194,194,194,194,194,195,195,195,195,195,195,195,195,195,195,195,195,196,196,196,196,196,196,196,196,196,196,196,197,197,197,197,197,197,197,197,198,198,198,198,198,198,198,198,199,199,199,199,199,199,199,199,199,199,199,199,200,200,200,200,200,201,201,201,201,201,202,202,202,203,203,203,203,204,204,204,204,204,204,204,204,204,204,205,205,205,205,206,206,206,206,206,206,206,206,207,207,207,207,207,207,207,208,208,208,208,209,209,209,209,209,210,210,210,210,210,210,211,211,211,211,211,211,211,212,212,212,212,212,212,212,213,213,213,213,213,213,213,213,214,214,214,214,214,214,214,214,214,215,215,215,215,216,216,216,216,216,216,216,217,217,217,217,217,217,217,217,217,217,218,218,218,218,218,219,219,219,219,219,219,220,220,220,220,220,221,221,221,221,221,221,221,221,221,221,222,222,222,222,222,222,222,223,223,223,223,223,224,224,224,224,224,224,224,224,224,224,224,224,225,225,225,225,225,225,225,225,225,226,226,226,226,226,226,227,227,227,227,227,227,227,227,228,228,228,228,228,228,228,228,228,228,228,229,229,229,229,230,230,230,230,230,230,230,230,230,230,230,231,231,231,231,231,231,231,231,232,232,232,232,232,232,232,232,232,233,233,233,233,234,234,234,234,234,234,234,234,234,234,235,235,235,235,235,235,235,235,235,235,235,236,236,236,236,236,236,236,237,237,237,237,237,237,237,237,237,238,238,238,238,238,238,239,239,239,239,239,239,239,239,240,240,240,240,240,240,240,240,241,241,241,241,241,241,241,241,241,242,242,242,242,242,242,242,242,242,242,242,242,243,243,243,243,243,243,243,243,243,244,244,244,244,244,244,244,244,244,245,245,245,245,245,246,246,246,246,246,246,246,247,247,247,247,247,248,248,248,248,248,249,249,249,249,249,249,250,250,250,250,250,251,251,251,251,251,251,252,252,252,252,252,253,253,253,253,253,253,253,253,253,253,253,253,253,254,254,254,254,254,254,254,255,255,255,255,255,255,255,255,255,256,256,256,256,256,257,257,257,257,257,257,257,257,257,257,257,258,258,258,258,258,258,258,258,259,259,259,259,260,260,260,260,260,260,260,260,260,260,260,261,261,261,261,261,261,261,261,261,262,262,262,262,262,262,262,262,263,263,264,264,264,264,264,264,264,264,264,265,265,265,265,265,265,265,265,266,266,266,266,266,266,267,267,267,267,267,267,267,267,268,268,268,268,269,269,269,269,269,269,269,269,269,269,270,270,270,270,270,271,271,271,271,271,271,272,272,272,272,272,272,272,272,272,272,272,273,273,273,273,273,273,273,273,274,274,274,275,275,275,275,275,276,276,276,276,276,276,276,276,277,277,277,277,277,277,277,277,278,278,279,279,279,279,279,279,279,279,280,280,280,280,280,280,281,281,281,281,281,281,281,282,282,282,282,282,282,282,282,283,283,283,283,283,284,284,284,284,284,284,284,285,285,285,285,285,285,286,286,286,286,286,286,287,287,287,287,287,287,287,287,287,287,287,287,288,288,288,288,288,288,288,288,289,289,289,289,289,289,289,289,290,290,290,290,290,290,290,291,291,292,292,292,292,292,292,292,292,293,293,293,293,293,293,293,294,294,294,294,294,295,295,295,295,295,295,295,295,296,296,296,296,296,296,296,297,297,297,297,297,297,297,297,297,297,298,298,298,298,298,298,298,298,299,299,299,299,299,299,299,299,299,300,300,300,300,300,300,301,301,301,301,301,301,301,302,302,302,302,302,303,303,303,303,303,303,303,303,303,304,304,304,304,305,305,305,305,305,306,306,306,306,306,307,307,307,307,307,307,307,308,308,308,308,308,308,308,309,309,309,309,309,309,309,309,309,310,310,310,310,310,310,310,311,311,311,311,311,311,311,311,311,311,311,312,312,312,312,312,312,312,312,313,313,313,313,313,313,313,313,314,314,314,314,314,314,314,314,314,314,314,314,315,315,315,315,315,315,315,316,316,316,316,316,316,316,316,316,317,317,317,317,317,317,317,317,318,318,318,318,318,319,319,319,319,319,319,319,319,319,319,320,320,320,320,320,320,320,320,320,320,321,321,321,321,321,321,321,321,322,322,323,323,323,323,323,324,324,324,324,324,324,324,325,325,325,325,325,326,326,326,326,326,326,326,326,327,327,327,327,327,327,327,328,328,328,328,328,328,328,328,329,329,329,329,329,329,330,330,331,331,331,331,331,331,331,332,332,332,332,333,333,333,333,333,333,333,333,333,333,334,334,334,334,334,335,335,336,336,336,336,336,337,337,337,337,337,337,337,337,338,338,338,338,338,338,338,338,338,339,339,339,339,339,339,339,339,339,339,340,340,340,340,340,340,340,340,341,341,341,341,341,342,342,342,342,342,342,342,342,342,343,343,343,343,343,343,344,344,344,344,344,344,344,344,345,345,345,345,345,345,345,345,346,346,346,346,346,346,346,346,346,346,346,346,346,347,347,347,347,347,347,347,347,347,348,348,348,348,348,348,348,348,349,349,349,349,349,349,349,349,349,350,350,350,350,350,350,350,350,350,351,351,352,352,352,352,352,352,352,352,352,352,353,353,353,353,353,353,353,353,353,353,354,354,354,354,354,354,355,355,355,355,355,355,356,356,356,356,356,356,357,357,357,357,357,357,358,358,358,358,358,358,359,359,359,359,359,359,360,360,360,360,360,360,361,361,361,361,361,361,362,362,363,363,363,363,363,363,363,363,363,363,363,364,364,364,364,364,364,364,365,365,365,365,366,366,366,366,366,366,366,366,366,366,366,367,367,367,367,367,367,367,368,368,368,368,368,368,369,369,369,369,369,370,370,370,370,370,371,371,371,371,371,371,371,372,372,372,372,372,372,373,373,374,374,374,374,374,374,374,374,375,375,375,375,375,375,375,375,376,376,376,376,376,376,376,377,377,377,377,377,377,377,377,377,378,378,378,378,378,379,379,379,379,379,380,380,380,380,380,380,380,381,381,381,381,381,382,382,382,382,382,382,382,382,382,383,383,383,383,383,384,384,384,384,384,384,384,384,385,385,385,385,385,385,385,386,386,386,386,387,387,388,388,388,388,388,389,389,389,389,390,390,391,391,391,391,391,391,392,392,392,392,392,392,392,392,393,393,393,393,393,393,394,394,394,394,394,394,394,394,394,395,395,395,396,396,396,396,396,396,396,396,396,396,396,397,397,398,398,398,398,398,398,398,398,399,399,399,399,399,399,399,400,400,400,400,400,400,400,400,400,401,401,401,401,401,401,401,401,401,401,402,402,402,402,403,403,404,404,404,404,404,404,404,404,404,404,404,404,404,405,405,405,405,405,405,405,405,405,405,405,405,406,406,406,406,406,406,406,406,406,406,406,407,407,407,407,407,407,407,407,407,408,408,408,408,408,408,408,408,408,408,408,409,409,409,409,409,410,410,410,410,410,410,410,410,411,411,411,411,411,411,411,412,412,412,412,412,412,412,412,412,412,413,413,413,413,413,413,413,413,413,413,414,414,414,414,414,414,414,415,415,415,415,415,415,415,415,415,415,415,416,416,416,416,416,416,416,417,417,417,417,417,417,417,417,417,417,418,418,419,419,419,419,419,419,419,420,420,420,420,420,420,421,421,421,421,421,421,421,421,421,422,422,422,422,422,422,422,422,422,422,422,423,423,423,423,423,423,423,423,423,424,424,425,425,425,425,425,425,425,426,426,426,426,426,427,427,427,427,427,427,428,428,428,428,428,428,428,428,429,429,429,429,429,429,430,430,430,430,430,430,430,430,430,430,431,431,431,431,431,431,431,432,432,432,432,432,432,432,432,432,432,433,433,433,433,433,433,433,433,433,433,433,434,434,435,435,435,435,436,436,436,436,436,436,436,436,437,437,438,438,438,438,438,438,438,438,438,438,438,438,438,439,439,439,439,439,439,439,439,439,439,440,440,440,440,441,441,441,441,441,441,441,441,441,441,441,442,442,442,442,442,442,442,442,443,443,444,444,444,444,444,445,445,445,445,445,445,445,445,446,446,446,446,446,446,446,446,446,446,446,447,447,447,447,447,447,447,447,447,447,447,447,448,448,448,448,448,448,448,448,448,449,449,449,449,449,449,449,450,450,450,450,450,450,450,451,451,451,451,451,451,451,452,452,452,452,452,452,453,453,453,453,453,453,453,453,454,454,454,454,454,455,455,455,455,455,455,455,456,456,456,456,456,456,456,456,456,456,457,457,457,457,457,458,458,458,458,458,458,458,459,459,459,459,459,459,459,459,460,460,460,460,460,461,461,461,461,461,461,461,461,461,461,462,462,462,462,462,462,462,462,462,462,463,463,463,463,463,463,464,464,464,464,464,464,464,464,464,464,464,464,465,465,465,465,465,465,465,465,466,466,466,466,466,466,466,466,466,467,467,467,467,467,468,468,468,468,468,468,468,468,469,469,469,469,469,470,470,470,470,470,470,470,470,470,470,470,471,471,471,471,471,471,471,472,472,472,472,472,472,472,472,472,472,473,473,473,473,473,474,474,475,475,475,475,475,475,476,476,476,476,476,476,476,476,476,477,477,477,477,478,478,478,478,478,478,478,478,478,479,479,479,479,479,480,480,480,480,480,480,481,481,481,481,481,482,482,482,482,482,482,482,482,482,483,483,483,483,483,484,484,484,484,484,484,484,484,485,485,485,486,486,486,486,486,486,486,486,487,487,488,488,488,488,488,488,489,489,489,489,489,489,489,489,490,490,490,490,490,490,490,491,491,491,491,491,491,491,491,491,491,492,492,492,492,492,492,492,492,492,492,492,493,493,493,493,493,493,493,494,494,494,494,494,495,495,495,495,495,495,495,496,496,496,496,496,496,496,497,497,497,497,497,497,498,498,498,498,498,498,498,499,499,499,499,499,499,499,499,499,500,500,500,500,500,500,501,501,501,501,501,501,501,502,502,502,502,502,502,503,503,503,503,503,503,503,503,503,503,504,504,505,505,505,505,505,505,505,505,505,505,506,506,506,506,506,506,506,506,507,507,507,507,507,508,508,508,508,508,508,509,509,509,509,509,509,510,510,510,510,510,510,510,511,511,511,511,511,511,511,512,512,512,512,512,512,512,512,513,513,514,514,514,514,514,514,514,514,514,515,515,515,515,515,515,516,516,516,516,517,517,517,517,517,517,517,517,517,518,518,518,518,518,518,518,518,518,518,518,519,519,519,519,519,519,519,520,520,520,520,520,520,520,521,521,522,522,522,522,522,522,522,522,523,523,523,523,523,523,524,524,524,524,524,524,524,524,525,525,525,525,525,526,526,527,527,527,527,527,527,527,527,528,528,528,528,529,529,529,529,529,529,529,529,530,530,530,530,530,530,530,531,531,531,531,532,532,532,532,532,532,532,532,532,533,533,533,533,533,533,533,533,533,533,534,534,535,535,535,535,535,535,535,535,535,536,536,537,537,537,537,538,538,538,538,538,539,539,539,539,540,540,540,540,540,541,541,541,541,541,542,542,542,542,542,542,542,543,543,543,543,543,543,543,543,543,543,543,543,543,543,544,544,544,544,544,544,544,544,544,545,545,545,545,545,545,545,545,546,546,546,546,546,546,546,547,547,547,547,548,548,548,548,548,548,548,548,548,548,548,549,549,549,549,549,549,550,550,550,550,550,550,550,550,551,551,551,551,551,551,551,551,551,551,551,552,552,552,552,552,552,552,552,552,553,553,554,554,554,554,554,554,555,555,555,555,555,555,555,555,556,556,556,556,556,556,556,557,557,557,557,557,557,558,558,558,558,558,559,559,559,559,559,559,560,560,560,560,560,560,560,561,561,561,561,561,561,562,562,562,562,562,563,563,563,563,563,563,563,564,564,564,564,564,564,565,565,565,565,565,565,565,566,566,566,566,566,566,566,566,567,567,567,567,567,567,567,567,568,568,568,568,568,569,569,569,569,569,569,569,569,569,570,570,570,570,570,570,570,570,570,570,570,571,571,571,571,571,571,571,572,572,572,572,572,572,572,572,572],&#34;depth&#34;:[4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,3,2,1,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,4,3,2,1,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,2,1,5,4,3,2,1,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,2,1,4,3,2,1,8,7,6,5,4,3,2,1,2,1,13,12,11,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,12,11,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,5,4,3,2,1,8,7,6,5,4,3,2,1,3,2,1,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,10,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,2,1,8,7,6,5,4,3,2,1,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,9,8,7,6,5,4,3,2,1,10,9,8,7,6,5,4,3,2,1,2,1,9,8,7,6,5,4,3,2,1,2,1,4,3,2,1,5,4,3,2,1,4,3,2,1,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,14,13,12,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1,2,1,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,5,4,3,2,1,7,6,5,4,3,2,1,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,5,4,3,2,1,9,8,7,6,5,4,3,2,1,11,10,9,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,9,8,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;NextMethod&#34;,&#34;[.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;rlang::enexpr&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;attributes&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;is.numeric&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;is.na&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&lt;-&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;alist&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;~&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;attributes&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;dim.data.frame&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::joinFrames&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;diff.default&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.call&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;getOption&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;getOption&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.na&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;enexpr&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::eval_tidy&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition.parsedFormula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;levels&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;getOption&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.integer&#34;,&#34;local&#34;,&#34;length&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;rownames&lt;-&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.subset2&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;$&#34;,&#34;rhs.parsedFormula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;rlang::enexpr&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;formals&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;dim.data.frame&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste0&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.data.frame&#34;,&#34;rownames&lt;-&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;row.names&lt;-.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External2&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.frame&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rlang::is_formula&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unlist&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.External&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;eval&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;enexpr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;mean.default&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;cull&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.vector&#34;,&#34;as.data.frame.character&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;as.data.frame&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parent.frame&#34;,&#34;caller_env&#34;,&#34;rlang::eval_tidy&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;*&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;[&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.character&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sample&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list.default&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;condition&#34;,&#34;condition.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;rhs_or_expr&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;anyNA&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.set_row_names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;dim&#34;,&#34;ncol&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;local&#34;,&#34;make.unique&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;unique.default&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;names&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;length&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;split&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;.subset2&#34;,&#34;local&#34;,&#34;length&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;sample.default&#34;,&#34;shuffle&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;c&#34;,&#34;local&#34;,&#34;order&#34;,&#34;factor&#34;,&#34;as.factor&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;any&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;grep&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;pmatch&#34;,&#34;.deparseOpts&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;deparse1&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;mode&#34;,&#34;deparse&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;do.call&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.parent&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.fun&#34;,&#34;vapply&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;GC&gt;&#34;,&#34;structure&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;is.matrix&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;deparse&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;alist&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;gsub&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;[[.data.frame&#34;,&#34;interaction&#34;,&#34;split.default&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;%in%&#34;,&#34;[.data.frame&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;match.arg&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;&lt;Anonymous&gt;&#34;,&#34;FUN&#34;,&#34;lapply&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;parse.formula&#34;,&#34;rhs.formula&#34;,&#34;mosaicCore::mosaic_formula_q&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;as.list&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;paste&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;sys.function&#34;,&#34;match.arg&#34;,&#34;order&#34;,&#34;make.names&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;lhs.parsedFormula&#34;,&#34;lhs.formula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;,&#34;structure&#34;,&#34;as.data.frame.numeric&#34;,&#34;data.frame&#34;,&#34;evalSubFormula&#34;,&#34;mosaicCore::evalFormula&#34;,&#34;maggregate&#34;,&#34;mean_&#34;,&#34;diffmean&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;linenum&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],&#34;memalloc&#34;:[28.9154052734375,28.9154052734375,28.9154052734375,28.9154052734375,29.6049652099609,29.6049652099609,29.6049652099609,29.6049652099609,29.6049652099609,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.1325378417969,30.6638031005859,30.6638031005859,30.6638031005859,30.6638031005859,30.6638031005859,30.6638031005859,30.6638031005859,31.3674011230469,31.3674011230469,31.3674011230469,31.3674011230469,31.3674011230469,31.3674011230469,31.3674011230469,32.1290283203125,32.1290283203125,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,32.6079025268555,33.1935272216797,33.1935272216797,33.1935272216797,34.1318054199219,34.1318054199219,34.1318054199219,34.1318054199219,34.1318054199219,34.6768035888672,34.6768035888672,34.6768035888672,34.6768035888672,34.6768035888672,34.6768035888672,34.6768035888672,34.6768035888672,35.2383880615234,35.2383880615234,35.2383880615234,35.7067108154297,35.7067108154297,35.7067108154297,35.7067108154297,35.7067108154297,35.7067108154297,35.7067108154297,35.7067108154297,36.2475128173828,36.2475128173828,36.2475128173828,36.2475128173828,36.2475128173828,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,28.2996978759766,29.0002899169922,29.0002899169922,29.0002899169922,29.0002899169922,29.0002899169922,29.0002899169922,29.0002899169922,29.5012664794922,29.5012664794922,29.5012664794922,29.5012664794922,29.5012664794922,29.5012664794922,29.5012664794922,30.273567199707,30.273567199707,30.273567199707,30.273567199707,30.273567199707,30.273567199707,30.273567199707,30.273567199707,31.2267837524414,31.2267837524414,31.2267837524414,31.2267837524414,31.2267837524414,31.2267837524414,31.2267837524414,31.7775650024414,31.7775650024414,31.7775650024414,31.7775650024414,31.7775650024414,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,32.3670196533203,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.3368377685547,33.8268508911133,33.8268508911133,33.8268508911133,33.8268508911133,33.8268508911133,33.8268508911133,33.8268508911133,33.8268508911133,34.7309951782227,34.7309951782227,34.7309951782227,34.7309951782227,34.7309951782227,34.7309951782227,34.7309951782227,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.2154388427734,35.7035751342773,35.7035751342773,35.7035751342773,35.7035751342773,35.7035751342773,35.7035751342773,35.7035751342773,35.7035751342773,36.571418762207,36.571418762207,36.571418762207,36.571418762207,36.571418762207,29.2045211791992,29.2045211791992,29.2045211791992,29.2045211791992,29.2045211791992,29.2045211791992,29.2045211791992,29.2045211791992,29.8821258544922,29.8821258544922,29.8821258544922,30.4869079589844,30.4869079589844,30.4869079589844,30.4869079589844,30.4869079589844,30.4869079589844,30.4869079589844,31.020263671875,31.020263671875,31.020263671875,31.020263671875,31.6451187133789,31.6451187133789,31.6451187133789,31.6451187133789,31.6451187133789,32.1685791015625,32.1685791015625,32.1685791015625,32.1685791015625,32.1685791015625,32.1685791015625,32.1685791015625,32.1685791015625,32.7050552368164,32.7050552368164,33.4036102294922,33.4036102294922,33.4036102294922,33.4036102294922,33.4036102294922,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,33.8873825073242,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,34.8668365478516,35.8490982055664,35.8490982055664,35.8490982055664,33.5781631469727,33.5781631469727,33.5781631469727,33.5781631469727,33.5781631469727,33.5781631469727,33.5781631469727,33.5781631469727,29.2387619018555,29.2387619018555,29.2387619018555,29.2387619018555,29.2387619018555,29.2387619018555,29.2387619018555,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.1856460571289,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,30.6710510253906,31.1586074829102,31.1586074829102,31.1586074829102,31.1586074829102,31.1586074829102,31.1586074829102,31.1586074829102,31.1586074829102,31.8293838500977,31.8293838500977,31.8293838500977,31.8293838500977,31.8293838500977,31.8293838500977,31.8293838500977,32.3307647705078,32.3307647705078,32.3307647705078,32.3307647705078,32.3307647705078,32.3307647705078,32.3307647705078,32.3307647705078,32.8227767944336,32.8227767944336,33.3046646118164,33.3046646118164,33.3046646118164,33.3046646118164,33.3046646118164,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,33.8819961547852,34.4410629272461,34.4410629272461,35.1096801757812,35.1096801757812,35.1096801757812,35.1096801757812,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.0947570800781,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,36.5802612304688,29.1226196289062,29.1226196289062,29.8616180419922,29.8616180419922,29.8616180419922,29.8616180419922,29.8616180419922,29.8616180419922,29.8616180419922,30.3480987548828,30.3480987548828,30.3480987548828,30.3480987548828,30.3480987548828,30.3480987548828,30.3480987548828,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,30.8381423950195,31.3358535766602,31.3358535766602,31.3358535766602,31.3358535766602,31.3358535766602,31.9381103515625,31.9381103515625,31.9381103515625,31.9381103515625,31.9381103515625,32.4194946289062,32.4194946289062,32.4194946289062,32.4194946289062,32.4194946289062,33.4011688232422,33.4011688232422,33.4011688232422,33.4011688232422,33.4011688232422,33.9993515014648,33.9993515014648,33.9993515014648,34.8156127929688,34.8156127929688,34.8156127929688,34.8156127929688,34.8156127929688,34.8156127929688,34.8156127929688,34.8156127929688,35.3259811401367,35.3259811401367,35.3259811401367,35.3259811401367,35.3259811401367,35.3259811401367,35.3259811401367,36.2542953491211,36.2542953491211,36.2542953491211,36.2542953491211,36.2542953491211,36.2542953491211,36.2542953491211,36.2542953491211,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.235954284668,28.4031982421875,28.4031982421875,29.0033493041992,29.0033493041992,29.0033493041992,29.0033493041992,29.0033493041992,29.0033493041992,29.0033493041992,30.0068511962891,30.0068511962891,30.0068511962891,30.0068511962891,30.0068511962891,30.0068511962891,30.0068511962891,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,30.9997787475586,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,31.993537902832,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,32.9632263183594,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,33.9019317626953,34.8432464599609,34.8432464599609,34.8432464599609,34.8432464599609,34.8432464599609,34.8432464599609,34.8432464599609,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.3110580444336,35.7450790405273,35.7450790405273,35.7450790405273,35.7450790405273,35.7450790405273,35.7450790405273,35.7450790405273,36.1786651611328,36.1786651611328,36.1786651611328,36.1786651611328,36.1786651611328,36.1786651611328,36.1786651611328,28.4959564208984,28.4959564208984,28.4959564208984,28.4959564208984,28.4959564208984,28.4959564208984,28.9962921142578,28.9962921142578,28.9962921142578,28.9962921142578,28.9962921142578,28.9962921142578,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.4728088378906,29.9678039550781,29.9678039550781,29.9678039550781,29.9678039550781,29.9678039550781,30.6807250976562,30.6807250976562,30.6807250976562,30.6807250976562,30.6807250976562,30.6807250976562,30.6807250976562,31.3208618164062,31.3208618164062,31.3208618164062,31.3208618164062,31.3208618164062,31.8113708496094,31.8113708496094,32.3477249145508,32.3477249145508,32.3477249145508,32.3477249145508,32.3477249145508,32.3477249145508,32.3477249145508,32.9392471313477,32.9392471313477,32.9392471313477,32.9392471313477,32.9392471313477,32.9392471313477,33.4247665405273,33.4247665405273,33.4247665405273,33.4247665405273,33.4247665405273,33.4247665405273,33.4247665405273,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,33.9294662475586,34.4137496948242,34.4137496948242,34.4137496948242,34.4137496948242,34.4137496948242,34.4137496948242,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.2558746337891,35.7705688476562,35.7705688476562,35.7705688476562,35.7705688476562,35.7705688476562,35.7705688476562,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,36.2436370849609,28.3204193115234,28.3204193115234,28.3204193115234,28.3204193115234,28.3204193115234,28.3204193115234,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,28.8076858520508,29.5436096191406,29.5436096191406,29.5436096191406,29.5436096191406,29.5436096191406,29.5436096191406,29.5436096191406,30.5379028320312,30.5379028320312,31.5392303466797,31.5392303466797,31.5392303466797,31.5392303466797,31.5392303466797,31.5392303466797,31.5392303466797,32.2097015380859,32.2097015380859,32.2097015380859,32.2097015380859,32.2097015380859,32.2097015380859,32.2097015380859,33.0126266479492,33.0126266479492,33.0126266479492,33.0126266479492,33.0126266479492,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,33.9894790649414,34.9740753173828,34.9740753173828,34.9740753173828,34.9740753173828,34.9740753173828,34.9740753173828,34.9740753173828,34.9740753173828,35.9604721069336,35.9604721069336,35.9604721069336,35.9604721069336,35.9604721069336,28.3704605102539,28.3704605102539,28.3704605102539,28.3704605102539,28.3704605102539,28.3704605102539,28.3704605102539,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.3324966430664,29.8890991210938,29.8890991210938,29.8890991210938,29.8890991210938,29.8890991210938,29.8890991210938,29.8890991210938,30.5695495605469,30.5695495605469,30.5695495605469,30.5695495605469,30.5695495605469,30.5695495605469,30.5695495605469,31.5705184936523,31.5705184936523,31.5705184936523,31.5705184936523,31.5705184936523,32.1761856079102,32.1761856079102,32.1761856079102,32.1761856079102,32.1761856079102,32.1761856079102,32.1761856079102,32.6529388427734,32.6529388427734,32.6529388427734,32.6529388427734,32.6529388427734,32.6529388427734,32.6529388427734,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,33.6225662231445,34.4419479370117,34.4419479370117,34.4419479370117,34.4419479370117,34.4419479370117,34.4419479370117,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,35.0767211914062,36.0473327636719,36.0473327636719,36.5318222045898,36.5318222045898,36.5318222045898,36.5318222045898,36.5318222045898,36.5318222045898,29.0647659301758,29.0647659301758,29.0647659301758,29.0647659301758,29.0647659301758,29.0647659301758,29.0647659301758,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.0538330078125,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,30.5451278686523,31.1059875488281,31.1059875488281,31.1059875488281,31.1059875488281,31.1059875488281,31.1059875488281,31.1059875488281,31.5851593017578,31.5851593017578,32.1912384033203,32.1912384033203,32.1912384033203,32.1912384033203,32.1912384033203,33.1726684570312,33.1726684570312,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,33.6615371704102,34.1415100097656,34.1415100097656,34.1415100097656,34.1415100097656,34.1415100097656,34.1415100097656,34.1415100097656,34.1415100097656,34.7699127197266,34.7699127197266,34.7699127197266,34.7699127197266,34.7699127197266,34.7699127197266,34.7699127197266,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.3166885375977,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,35.87548828125,36.4697265625,36.4697265625,36.4697265625,36.4697265625,36.4697265625,28.5030059814453,28.5030059814453,28.5030059814453,28.5030059814453,28.5030059814453,28.5030059814453,28.5030059814453,28.5030059814453,29.1070785522461,29.1070785522461,29.1070785522461,29.1070785522461,29.1070785522461,29.1070785522461,29.1070785522461,29.1070785522461,29.6392974853516,29.6392974853516,29.6392974853516,29.6392974853516,29.6392974853516,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.3616409301758,30.8928680419922,30.8928680419922,30.8928680419922,30.8928680419922,31.3880157470703,31.3880157470703,32.0517501831055,32.0517501831055,32.0517501831055,32.0517501831055,32.0517501831055,32.597541809082,32.597541809082,32.597541809082,32.597541809082,32.597541809082,33.3306274414062,33.3306274414062,33.3306274414062,33.3306274414062,33.3306274414062,33.3306274414062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,33.8198852539062,34.8039855957031,34.8039855957031,34.8039855957031,34.8039855957031,34.8039855957031,34.8039855957031,34.8039855957031,35.6145935058594,35.6145935058594,35.6145935058594,35.6145935058594,35.6145935058594,35.6145935058594,35.6145935058594,35.6145935058594,36.0942153930664,36.0942153930664,36.0942153930664,36.0942153930664,36.0942153930664,36.0942153930664,36.5804443359375,36.5804443359375,36.5804443359375,28.9113388061523,28.9113388061523,28.9113388061523,28.9113388061523,28.9113388061523,29.5176086425781,29.5176086425781,29.5176086425781,29.5176086425781,29.5176086425781,29.5176086425781,29.5176086425781,29.5176086425781,30.018310546875,30.018310546875,30.018310546875,30.018310546875,30.018310546875,30.018310546875,30.5385894775391,30.5385894775391,30.5385894775391,30.5385894775391,30.5385894775391,30.5385894775391,30.5385894775391,30.5385894775391,31.0300827026367,31.0300827026367,31.0300827026367,31.0300827026367,31.0300827026367,31.0300827026367,31.0300827026367,31.5427398681641,31.5427398681641,31.5427398681641,31.5427398681641,31.5427398681641,31.5427398681641,31.5427398681641,31.5427398681641,32.0280227661133,32.0280227661133,32.0280227661133,32.0280227661133,32.0280227661133,32.0280227661133,32.5979156494141,32.5979156494141,33.1300811767578,33.1300811767578,33.1300811767578,33.1300811767578,33.1300811767578,33.1300811767578,33.1300811767578,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,33.6215133666992,34.083366394043,34.083366394043,34.083366394043,34.083366394043,34.083366394043,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,34.5604553222656,35.1155242919922,35.1155242919922,35.1155242919922,35.1155242919922,35.1155242919922,35.1155242919922,35.6554183959961,35.6554183959961,35.6554183959961,35.6554183959961,35.6554183959961,35.6554183959961,35.6554183959961,35.6554183959961,36.3002471923828,36.3002471923828,36.3002471923828,36.3002471923828,36.3002471923828,36.3002471923828,36.3002471923828,36.3002471923828,28.8284683227539,28.8284683227539,28.8284683227539,28.8284683227539,28.8284683227539,28.8284683227539,28.8284683227539,28.8284683227539,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,29.6677169799805,30.3034133911133,30.3034133911133,30.3034133911133,30.3034133911133,30.3034133911133,30.3034133911133,30.3034133911133,30.3034133911133,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.0211029052734,31.5754013061523,31.5754013061523,31.5754013061523,31.5754013061523,31.5754013061523,31.5754013061523,31.5754013061523,31.5754013061523,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.0603866577148,32.6207122802734,32.6207122802734,32.6207122802734,32.6207122802734,32.6207122802734,32.6207122802734,32.6207122802734,32.6207122802734,33.3509979248047,33.3509979248047,33.8211288452148,33.8211288452148,33.8211288452148,33.8211288452148,33.8211288452148,33.8211288452148,33.8211288452148,34.3421096801758,34.3421096801758,34.3421096801758,34.3421096801758,34.3421096801758,34.3421096801758,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,34.8763580322266,35.4626007080078,35.4626007080078,35.4626007080078,35.4626007080078,35.4626007080078,35.4626007080078,36.3105773925781,36.3105773925781,36.3105773925781,36.3105773925781,36.3105773925781,28.3860321044922,28.3860321044922,28.3860321044922,28.3860321044922,28.3860321044922,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,29.0195236206055,30.0196762084961,30.0196762084961,31.0197296142578,31.0197296142578,31.0197296142578,31.0197296142578,31.0197296142578,31.0197296142578,31.0197296142578,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,31.7661666870117,32.3252487182617,32.3252487182617,32.3252487182617,32.3252487182617,32.3252487182617,32.3252487182617,32.3252487182617,32.8183517456055,32.8183517456055,32.8183517456055,32.8183517456055,32.8183517456055,32.8183517456055,32.8183517456055,32.8183517456055,33.3018646240234,33.3018646240234,33.3018646240234,33.3018646240234,33.3018646240234,33.9489669799805,33.9489669799805,33.9489669799805,34.4429092407227,34.4429092407227,34.4429092407227,34.4429092407227,34.4429092407227,34.9324188232422,34.9324188232422,34.9324188232422,34.9324188232422,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,35.4676666259766,36.0173492431641,36.0173492431641,36.0173492431641,36.0173492431641,36.0173492431641,36.4893341064453,36.4893341064453,36.4893341064453,36.4893341064453,36.4893341064453,28.648307800293,28.648307800293,28.648307800293,28.648307800293,29.2851867675781,29.2851867675781,30.2789916992188,30.2789916992188,30.2789916992188,30.2789916992188,30.2789916992188,30.2789916992188,30.2789916992188,30.822395324707,30.822395324707,30.822395324707,30.822395324707,30.822395324707,30.822395324707,30.822395324707,30.822395324707,31.3134384155273,31.3134384155273,31.3134384155273,31.3134384155273,31.3134384155273,31.3134384155273,31.3134384155273,31.3134384155273,31.7871170043945,31.7871170043945,31.7871170043945,31.7871170043945,31.7871170043945,31.7871170043945,31.7871170043945,31.7871170043945,32.7540283203125,32.7540283203125,33.6768035888672,33.6768035888672,33.6768035888672,33.6768035888672,33.6768035888672,33.6768035888672,34.1667404174805,34.1667404174805,34.1667404174805,34.1667404174805,34.1667404174805,34.1667404174805,34.1667404174805,34.1667404174805,34.6823806762695,34.6823806762695,34.6823806762695,34.6823806762695,34.6823806762695,34.6823806762695,34.6823806762695,35.3335266113281,35.3335266113281,35.3335266113281,35.3335266113281,35.3335266113281,35.3335266113281,36.0051116943359,36.0051116943359,36.0051116943359,36.0051116943359,36.0051116943359,36.0051116943359,36.0051116943359,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,36.590576171875,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.1747589111328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,29.6679229736328,30.2727966308594,30.2727966308594,30.2727966308594,30.2727966308594,30.2727966308594,30.2727966308594,30.2727966308594,30.2727966308594,30.7741622924805,30.7741622924805,30.7741622924805,30.7741622924805,30.7741622924805,30.7741622924805,30.7741622924805,30.7741622924805,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,31.4113998413086,32.1083297729492,32.1083297729492,32.1083297729492,32.1083297729492,32.1083297729492,32.6310043334961,32.6310043334961,32.6310043334961,32.6310043334961,32.6310043334961,33.1807250976562,33.1807250976562,33.1807250976562,33.7509689331055,33.7509689331055,33.7509689331055,33.7509689331055,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,34.5451431274414,35.2455978393555,35.2455978393555,35.2455978393555,35.2455978393555,35.7305374145508,35.7305374145508,35.7305374145508,35.7305374145508,35.7305374145508,35.7305374145508,35.7305374145508,35.7305374145508,36.2063598632812,36.2063598632812,36.2063598632812,36.2063598632812,36.2063598632812,36.2063598632812,36.2063598632812,36.6003112792969,36.6003112792969,36.6003112792969,36.6003112792969,28.7435760498047,28.7435760498047,28.7435760498047,28.7435760498047,28.7435760498047,29.2330932617188,29.2330932617188,29.2330932617188,29.2330932617188,29.2330932617188,29.2330932617188,29.9447250366211,29.9447250366211,29.9447250366211,29.9447250366211,29.9447250366211,29.9447250366211,29.9447250366211,30.9270706176758,30.9270706176758,30.9270706176758,30.9270706176758,30.9270706176758,30.9270706176758,30.9270706176758,31.4240264892578,31.4240264892578,31.4240264892578,31.4240264892578,31.4240264892578,31.4240264892578,31.4240264892578,31.4240264892578,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,31.9024505615234,32.7316284179688,32.7316284179688,32.7316284179688,32.7316284179688,33.4105453491211,33.4105453491211,33.4105453491211,33.4105453491211,33.4105453491211,33.4105453491211,33.4105453491211,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.1911468505859,34.6755981445312,34.6755981445312,34.6755981445312,34.6755981445312,34.6755981445312,35.1485443115234,35.1485443115234,35.1485443115234,35.1485443115234,35.1485443115234,35.1485443115234,35.6267852783203,35.6267852783203,35.6267852783203,35.6267852783203,35.6267852783203,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,36.5110626220703,28.6853408813477,28.6853408813477,28.6853408813477,28.6853408813477,28.6853408813477,28.6853408813477,28.6853408813477,29.2134552001953,29.2134552001953,29.2134552001953,29.2134552001953,29.2134552001953,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,29.6879348754883,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.1713027954102,30.6571350097656,30.6571350097656,30.6571350097656,30.6571350097656,30.6571350097656,30.6571350097656,31.1940460205078,31.1940460205078,31.1940460205078,31.1940460205078,31.1940460205078,31.1940460205078,31.1940460205078,31.1940460205078,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,32.1025924682617,33.0388793945312,33.0388793945312,33.0388793945312,33.0388793945312,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.5096664428711,33.9826965332031,33.9826965332031,33.9826965332031,33.9826965332031,33.9826965332031,33.9826965332031,33.9826965332031,33.9826965332031,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.4669570922852,34.9464645385742,34.9464645385742,34.9464645385742,34.9464645385742,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.4198684692383,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,35.9081954956055,36.5968856811523,36.5968856811523,36.5968856811523,36.5968856811523,36.5968856811523,36.5968856811523,36.5968856811523,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,28.6987152099609,29.1831207275391,29.1831207275391,29.1831207275391,29.1831207275391,29.1831207275391,29.1831207275391,30.1241683959961,30.1241683959961,30.1241683959961,30.1241683959961,30.1241683959961,30.1241683959961,30.1241683959961,30.1241683959961,31.0963897705078,31.0963897705078,31.0963897705078,31.0963897705078,31.0963897705078,31.0963897705078,31.0963897705078,31.0963897705078,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,31.5860595703125,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.1508255004883,32.809700012207,32.809700012207,32.809700012207,32.809700012207,32.809700012207,32.809700012207,32.809700012207,32.809700012207,32.809700012207,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.3631286621094,33.845947265625,33.845947265625,33.845947265625,33.845947265625,33.845947265625,34.3460235595703,34.3460235595703,34.3460235595703,34.3460235595703,34.3460235595703,34.3460235595703,34.3460235595703,35.1148986816406,35.1148986816406,35.1148986816406,35.1148986816406,35.1148986816406,35.5962677001953,35.5962677001953,35.5962677001953,35.5962677001953,35.5962677001953,36.1558380126953,36.1558380126953,36.1558380126953,36.1558380126953,36.1558380126953,36.1558380126953,36.5948791503906,36.5948791503906,36.5948791503906,36.5948791503906,36.5948791503906,29.1196517944336,29.1196517944336,29.1196517944336,29.1196517944336,29.1196517944336,29.1196517944336,29.6060943603516,29.6060943603516,29.6060943603516,29.6060943603516,29.6060943603516,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.0934066772461,30.5776443481445,30.5776443481445,30.5776443481445,30.5776443481445,30.5776443481445,30.5776443481445,30.5776443481445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,31.5483474731445,32.0318298339844,32.0318298339844,32.0318298339844,32.0318298339844,32.0318298339844,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.4926834106445,32.9561462402344,32.9561462402344,32.9561462402344,32.9561462402344,32.9561462402344,32.9561462402344,32.9561462402344,32.9561462402344,33.8806076049805,33.8806076049805,33.8806076049805,33.8806076049805,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.3514709472656,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,34.7895126342773,35.1995620727539,35.1995620727539,35.1995620727539,35.1995620727539,35.1995620727539,35.1995620727539,35.1995620727539,35.1995620727539,35.6896667480469,35.6896667480469,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,36.1802978515625,28.6277008056641,28.6277008056641,28.6277008056641,28.6277008056641,28.6277008056641,28.6277008056641,28.6277008056641,28.6277008056641,29.1587677001953,29.1587677001953,29.1587677001953,29.1587677001953,29.1587677001953,29.1587677001953,29.6318435668945,29.6318435668945,29.6318435668945,29.6318435668945,29.6318435668945,29.6318435668945,29.6318435668945,29.6318435668945,30.1294479370117,30.1294479370117,30.1294479370117,30.1294479370117,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,30.6220092773438,31.087890625,31.087890625,31.087890625,31.087890625,31.087890625,31.6078414916992,31.6078414916992,31.6078414916992,31.6078414916992,31.6078414916992,31.6078414916992,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.3155670166016,32.7941360473633,32.7941360473633,32.7941360473633,32.7941360473633,32.7941360473633,32.7941360473633,32.7941360473633,32.7941360473633,33.3473892211914,33.3473892211914,33.3473892211914,33.8704376220703,33.8704376220703,33.8704376220703,33.8704376220703,33.8704376220703,34.3462524414062,34.3462524414062,34.3462524414062,34.3462524414062,34.3462524414062,34.3462524414062,34.3462524414062,34.3462524414062,34.9941787719727,34.9941787719727,34.9941787719727,34.9941787719727,34.9941787719727,34.9941787719727,34.9941787719727,34.9941787719727,35.4756240844727,35.4756240844727,35.9801177978516,35.9801177978516,35.9801177978516,35.9801177978516,35.9801177978516,35.9801177978516,35.9801177978516,35.9801177978516,36.6026229858398,36.6026229858398,36.6026229858398,36.6026229858398,36.6026229858398,36.6026229858398,28.7657089233398,28.7657089233398,28.7657089233398,28.7657089233398,28.7657089233398,28.7657089233398,28.7657089233398,29.2863082885742,29.2863082885742,29.2863082885742,29.2863082885742,29.2863082885742,29.2863082885742,29.2863082885742,29.2863082885742,30.2090606689453,30.2090606689453,30.2090606689453,30.2090606689453,30.2090606689453,31.0166854858398,31.0166854858398,31.0166854858398,31.0166854858398,31.0166854858398,31.0166854858398,31.0166854858398,31.4843902587891,31.4843902587891,31.4843902587891,31.4843902587891,31.4843902587891,31.4843902587891,31.9872283935547,31.9872283935547,31.9872283935547,31.9872283935547,31.9872283935547,31.9872283935547,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.4716567993164,32.9913711547852,32.9913711547852,32.9913711547852,32.9913711547852,32.9913711547852,32.9913711547852,32.9913711547852,32.9913711547852,33.464714050293,33.464714050293,33.464714050293,33.464714050293,33.464714050293,33.464714050293,33.464714050293,33.464714050293,34.0837936401367,34.0837936401367,34.0837936401367,34.0837936401367,34.0837936401367,34.0837936401367,34.0837936401367,34.7431182861328,34.7431182861328,35.2187194824219,35.2187194824219,35.2187194824219,35.2187194824219,35.2187194824219,35.2187194824219,35.2187194824219,35.2187194824219,35.642448425293,35.642448425293,35.642448425293,35.642448425293,35.642448425293,35.642448425293,35.642448425293,36.0947341918945,36.0947341918945,36.0947341918945,36.0947341918945,36.0947341918945,36.5135040283203,36.5135040283203,36.5135040283203,36.5135040283203,36.5135040283203,36.5135040283203,36.5135040283203,36.5135040283203,28.5375137329102,28.5375137329102,28.5375137329102,28.5375137329102,28.5375137329102,28.5375137329102,28.5375137329102,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,28.9176406860352,29.3006896972656,29.3006896972656,29.3006896972656,29.3006896972656,29.3006896972656,29.3006896972656,29.3006896972656,29.3006896972656,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,29.6570358276367,30.1538009643555,30.1538009643555,30.1538009643555,30.1538009643555,30.1538009643555,30.1538009643555,30.6299057006836,30.6299057006836,30.6299057006836,30.6299057006836,30.6299057006836,30.6299057006836,30.6299057006836,31.1233596801758,31.1233596801758,31.1233596801758,31.1233596801758,31.1233596801758,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,31.6451950073242,32.6032867431641,32.6032867431641,32.6032867431641,32.6032867431641,33.5717391967773,33.5717391967773,33.5717391967773,33.5717391967773,33.5717391967773,34.2176818847656,34.2176818847656,34.2176818847656,34.2176818847656,34.2176818847656,34.7068328857422,34.7068328857422,34.7068328857422,34.7068328857422,34.7068328857422,34.7068328857422,34.7068328857422,35.2473526000977,35.2473526000977,35.2473526000977,35.2473526000977,35.2473526000977,35.2473526000977,35.2473526000977,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,35.7238922119141,36.2368774414062,36.2368774414062,36.2368774414062,36.2368774414062,36.2368774414062,36.2368774414062,36.2368774414062,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,28.3811950683594,29.2686080932617,29.2686080932617,29.2686080932617,29.2686080932617,29.2686080932617,29.2686080932617,29.2686080932617,29.2686080932617,30.0237579345703,30.0237579345703,30.0237579345703,30.0237579345703,30.0237579345703,30.0237579345703,30.0237579345703,30.0237579345703,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,30.5483169555664,31.4850234985352,31.4850234985352,31.4850234985352,31.4850234985352,31.4850234985352,31.4850234985352,31.4850234985352,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.4051284790039,32.940299987793,32.940299987793,32.940299987793,32.940299987793,32.940299987793,32.940299987793,32.940299987793,32.940299987793,33.4251098632812,33.4251098632812,33.4251098632812,33.4251098632812,33.4251098632812,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,33.9001235961914,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.3875350952148,34.8726501464844,34.8726501464844,34.8726501464844,34.8726501464844,34.8726501464844,34.8726501464844,34.8726501464844,34.8726501464844,35.3638000488281,35.3638000488281,36.3118591308594,36.3118591308594,36.3118591308594,36.3118591308594,36.3118591308594,28.4877319335938,28.4877319335938,28.4877319335938,28.4877319335938,28.4877319335938,28.4877319335938,28.4877319335938,28.994255065918,28.994255065918,28.994255065918,28.994255065918,28.994255065918,29.5113906860352,29.5113906860352,29.5113906860352,29.5113906860352,29.5113906860352,29.5113906860352,29.5113906860352,29.5113906860352,30.3659210205078,30.3659210205078,30.3659210205078,30.3659210205078,30.3659210205078,30.3659210205078,30.3659210205078,30.8415679931641,30.8415679931641,30.8415679931641,30.8415679931641,30.8415679931641,30.8415679931641,30.8415679931641,30.8415679931641,31.3783187866211,31.3783187866211,31.3783187866211,31.3783187866211,31.3783187866211,31.3783187866211,31.8602981567383,31.8602981567383,32.3392181396484,32.3392181396484,32.3392181396484,32.3392181396484,32.3392181396484,32.3392181396484,32.3392181396484,32.8141937255859,32.8141937255859,32.8141937255859,32.8141937255859,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,33.5649337768555,34.2536087036133,34.2536087036133,34.2536087036133,34.2536087036133,34.2536087036133,34.7647171020508,34.7647171020508,35.5479583740234,35.5479583740234,35.5479583740234,35.5479583740234,35.5479583740234,36.0349197387695,36.0349197387695,36.0349197387695,36.0349197387695,36.0349197387695,36.0349197387695,36.0349197387695,36.0349197387695,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,36.5232391357422,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,28.5827102661133,29.1667633056641,29.1667633056641,29.1667633056641,29.1667633056641,29.1667633056641,29.1667633056641,29.1667633056641,29.1667633056641,29.7151718139648,29.7151718139648,29.7151718139648,29.7151718139648,29.7151718139648,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.2768783569336,30.7764739990234,30.7764739990234,30.7764739990234,30.7764739990234,30.7764739990234,30.7764739990234,31.3012390136719,31.3012390136719,31.3012390136719,31.3012390136719,31.3012390136719,31.3012390136719,31.3012390136719,31.3012390136719,31.8332061767578,31.8332061767578,31.8332061767578,31.8332061767578,31.8332061767578,31.8332061767578,31.8332061767578,31.8332061767578,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.4480056762695,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,32.9209976196289,33.4410400390625,33.4410400390625,33.4410400390625,33.4410400390625,33.4410400390625,33.4410400390625,33.4410400390625,33.4410400390625,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,33.9633560180664,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,34.4817123413086,35.0497589111328,35.0497589111328,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,35.5230178833008,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.1027069091797,36.5856170654297,36.5856170654297,36.5856170654297,36.5856170654297,36.5856170654297,36.5856170654297,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,36.6262817382812,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.2727737426758,28.770881652832,28.770881652832,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,29.3320541381836,30.0134887695312,30.0134887695312,30.0134887695312,30.0134887695312,30.0134887695312,30.0134887695312,30.0134887695312,30.6249160766602,30.6249160766602,30.6249160766602,30.6249160766602,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.142333984375,31.6235656738281,31.6235656738281,31.6235656738281,31.6235656738281,31.6235656738281,31.6235656738281,31.6235656738281,32.0996780395508,32.0996780395508,32.0996780395508,32.0996780395508,32.0996780395508,32.0996780395508,32.6613998413086,32.6613998413086,32.6613998413086,32.6613998413086,32.6613998413086,33.1506118774414,33.1506118774414,33.1506118774414,33.1506118774414,33.1506118774414,33.7180709838867,33.7180709838867,33.7180709838867,33.7180709838867,33.7180709838867,33.7180709838867,33.7180709838867,34.2230911254883,34.2230911254883,34.2230911254883,34.2230911254883,34.2230911254883,34.2230911254883,34.7092742919922,34.7092742919922,35.3256988525391,35.3256988525391,35.3256988525391,35.3256988525391,35.3256988525391,35.3256988525391,35.3256988525391,35.3256988525391,35.8623733520508,35.8623733520508,35.8623733520508,35.8623733520508,35.8623733520508,35.8623733520508,35.8623733520508,35.8623733520508,36.3232345581055,36.3232345581055,36.3232345581055,36.3232345581055,36.3232345581055,36.3232345581055,36.3232345581055,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,28.3834686279297,29.0817794799805,29.0817794799805,29.0817794799805,29.0817794799805,29.0817794799805,29.583381652832,29.583381652832,29.583381652832,29.583381652832,29.583381652832,30.4227905273438,30.4227905273438,30.4227905273438,30.4227905273438,30.4227905273438,30.4227905273438,30.4227905273438,30.9256439208984,30.9256439208984,30.9256439208984,30.9256439208984,30.9256439208984,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.4802017211914,31.9684600830078,31.9684600830078,31.9684600830078,31.9684600830078,31.9684600830078,32.5389251708984,32.5389251708984,32.5389251708984,32.5389251708984,32.5389251708984,32.5389251708984,32.5389251708984,32.5389251708984,33.2015151977539,33.2015151977539,33.2015151977539,33.2015151977539,33.2015151977539,33.2015151977539,33.2015151977539,33.673225402832,33.673225402832,33.673225402832,33.673225402832,34.4794769287109,34.4794769287109,35.0597915649414,35.0597915649414,35.0597915649414,35.0597915649414,35.0597915649414,35.5522384643555,35.5522384643555,35.5522384643555,35.5522384643555,36.0751419067383,36.0751419067383,36.556999206543,36.556999206543,36.556999206543,36.556999206543,36.556999206543,36.556999206543,28.7653732299805,28.7653732299805,28.7653732299805,28.7653732299805,28.7653732299805,28.7653732299805,28.7653732299805,28.7653732299805,29.261604309082,29.261604309082,29.261604309082,29.261604309082,29.261604309082,29.261604309082,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,29.7536163330078,30.275032043457,30.275032043457,30.275032043457,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,30.7750854492188,31.2541809082031,31.2541809082031,31.7445602416992,31.7445602416992,31.7445602416992,31.7445602416992,31.7445602416992,31.7445602416992,31.7445602416992,31.7445602416992,32.3626022338867,32.3626022338867,32.3626022338867,32.3626022338867,32.3626022338867,32.3626022338867,32.3626022338867,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,32.9135360717773,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,33.5011596679688,34.1364822387695,34.1364822387695,34.1364822387695,34.1364822387695,34.9747924804688,34.9747924804688,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,35.6350326538086,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,36.3162536621094,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.3944778442383,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,28.9652786254883,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,29.4551849365234,30.017822265625,30.017822265625,30.017822265625,30.017822265625,30.017822265625,30.4966201782227,30.4966201782227,30.4966201782227,30.4966201782227,30.4966201782227,30.4966201782227,30.4966201782227,30.4966201782227,30.9923858642578,30.9923858642578,30.9923858642578,30.9923858642578,30.9923858642578,30.9923858642578,30.9923858642578,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,31.4841995239258,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,32.3485412597656,33.0371017456055,33.0371017456055,33.0371017456055,33.0371017456055,33.0371017456055,33.0371017456055,33.0371017456055,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,33.6116409301758,34.1177597045898,34.1177597045898,34.1177597045898,34.1177597045898,34.1177597045898,34.1177597045898,34.1177597045898,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,34.6509246826172,35.1226959228516,35.1226959228516,35.6582717895508,35.6582717895508,35.6582717895508,35.6582717895508,35.6582717895508,35.6582717895508,35.6582717895508,36.2411270141602,36.2411270141602,36.2411270141602,36.2411270141602,36.2411270141602,36.2411270141602,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,28.2987365722656,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.2403717041016,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,29.8548126220703,30.3385543823242,30.3385543823242,30.9805679321289,30.9805679321289,30.9805679321289,30.9805679321289,30.9805679321289,30.9805679321289,30.9805679321289,31.5327377319336,31.5327377319336,31.5327377319336,31.5327377319336,31.5327377319336,32.0358352661133,32.0358352661133,32.0358352661133,32.0358352661133,32.0358352661133,32.0358352661133,32.6058959960938,32.6058959960938,32.6058959960938,32.6058959960938,32.6058959960938,32.6058959960938,32.6058959960938,32.6058959960938,33.0901718139648,33.0901718139648,33.0901718139648,33.0901718139648,33.0901718139648,33.0901718139648,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,33.607780456543,34.0960922241211,34.0960922241211,34.0960922241211,34.0960922241211,34.0960922241211,34.0960922241211,34.0960922241211,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,34.7475891113281,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.3242797851562,35.8031539916992,35.8031539916992,36.3052444458008,36.3052444458008,36.3052444458008,36.3052444458008,28.5363464355469,28.5363464355469,28.5363464355469,28.5363464355469,28.5363464355469,28.5363464355469,28.5363464355469,28.5363464355469,29.0582656860352,29.0582656860352,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,29.5622329711914,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.0432815551758,30.5316772460938,30.5316772460938,30.5316772460938,30.5316772460938,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.0561676025391,31.6192779541016,31.6192779541016,31.6192779541016,31.6192779541016,31.6192779541016,31.6192779541016,31.6192779541016,31.6192779541016,32.1688385009766,32.1688385009766,32.7087249755859,32.7087249755859,32.7087249755859,32.7087249755859,32.7087249755859,33.4869537353516,33.4869537353516,33.4869537353516,33.4869537353516,33.4869537353516,33.4869537353516,33.4869537353516,33.4869537353516,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.0670700073242,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,34.5685653686523,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.0455627441406,35.6001815795898,35.6001815795898,35.6001815795898,35.6001815795898,35.6001815795898,35.6001815795898,35.6001815795898,36.19580078125,36.19580078125,36.19580078125,36.19580078125,36.19580078125,36.19580078125,36.19580078125,28.3144149780273,28.3144149780273,28.3144149780273,28.3144149780273,28.3144149780273,28.3144149780273,28.3144149780273,28.8125152587891,28.8125152587891,28.8125152587891,28.8125152587891,28.8125152587891,28.8125152587891,29.3583450317383,29.3583450317383,29.3583450317383,29.3583450317383,29.3583450317383,29.3583450317383,29.3583450317383,29.3583450317383,30.0314025878906,30.0314025878906,30.0314025878906,30.0314025878906,30.0314025878906,30.6226577758789,30.6226577758789,30.6226577758789,30.6226577758789,30.6226577758789,30.6226577758789,30.6226577758789,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.0998992919922,31.6405334472656,31.6405334472656,31.6405334472656,31.6405334472656,31.6405334472656,32.1696014404297,32.1696014404297,32.1696014404297,32.1696014404297,32.1696014404297,32.1696014404297,32.1696014404297,32.7363433837891,32.7363433837891,32.7363433837891,32.7363433837891,32.7363433837891,32.7363433837891,32.7363433837891,32.7363433837891,33.2142486572266,33.2142486572266,33.2142486572266,33.2142486572266,33.2142486572266,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,33.7233963012695,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.2947311401367,34.8013610839844,34.8013610839844,34.8013610839844,34.8013610839844,34.8013610839844,34.8013610839844,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,35.6580963134766,36.1613616943359,36.1613616943359,36.1613616943359,36.1613616943359,36.1613616943359,36.1613616943359,36.1613616943359,36.1613616943359,36.572883605957,36.572883605957,36.572883605957,36.572883605957,36.572883605957,36.572883605957,36.572883605957,36.572883605957,36.572883605957,28.9093780517578,28.9093780517578,28.9093780517578,28.9093780517578,28.9093780517578,29.3663177490234,29.3663177490234,29.3663177490234,29.3663177490234,29.3663177490234,29.3663177490234,29.3663177490234,29.3663177490234,29.8699188232422,29.8699188232422,29.8699188232422,29.8699188232422,29.8699188232422,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.4382247924805,30.9311447143555,30.9311447143555,30.9311447143555,30.9311447143555,30.9311447143555,30.9311447143555,30.9311447143555,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.4257049560547,31.9148712158203,31.9148712158203,31.9148712158203,31.9148712158203,31.9148712158203,32.5368499755859,32.5368499755859,33.0767364501953,33.0767364501953,33.0767364501953,33.0767364501953,33.0767364501953,33.0767364501953,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,33.6881866455078,34.2078475952148,34.2078475952148,34.2078475952148,34.2078475952148,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,34.6938934326172,35.2484588623047,35.2484588623047,35.2484588623047,35.2484588623047,35.2484588623047,35.7366333007812,35.7366333007812,35.7366333007812,35.7366333007812,35.7366333007812,35.7366333007812,36.2876892089844,36.2876892089844,36.2876892089844,36.2876892089844,36.2876892089844,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.3663940429688,28.9462738037109,28.9462738037109,28.9462738037109,28.9462738037109,28.9462738037109,29.4530029296875,29.4530029296875,29.4530029296875,29.4530029296875,29.4530029296875,29.4530029296875,29.4530029296875,29.4530029296875,29.9944000244141,29.9944000244141,29.9944000244141,30.5035400390625,30.5035400390625,30.5035400390625,30.5035400390625,30.5035400390625,30.5035400390625,30.5035400390625,30.5035400390625,31.1114349365234,31.1114349365234,31.6147003173828,31.6147003173828,31.6147003173828,31.6147003173828,31.6147003173828,31.6147003173828,32.1964797973633,32.1964797973633,32.1964797973633,32.1964797973633,32.1964797973633,32.1964797973633,32.1964797973633,32.1964797973633,32.701904296875,32.701904296875,32.701904296875,32.701904296875,32.701904296875,32.701904296875,32.701904296875,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.1759414672852,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,33.6441268920898,34.1842498779297,34.1842498779297,34.1842498779297,34.1842498779297,34.1842498779297,34.1842498779297,34.1842498779297,35.1836624145508,35.1836624145508,35.1836624145508,35.1836624145508,35.1836624145508,36.1399230957031,36.1399230957031,36.1399230957031,36.1399230957031,36.1399230957031,36.1399230957031,36.1399230957031,36.5829772949219,36.5829772949219,36.5829772949219,36.5829772949219,36.5829772949219,36.5829772949219,36.5829772949219,28.8449401855469,28.8449401855469,28.8449401855469,28.8449401855469,28.8449401855469,28.8449401855469,29.7814254760742,29.7814254760742,29.7814254760742,29.7814254760742,29.7814254760742,29.7814254760742,29.7814254760742,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.2625045776367,30.7587127685547,30.7587127685547,30.7587127685547,30.7587127685547,30.7587127685547,30.7587127685547,31.6029815673828,31.6029815673828,31.6029815673828,31.6029815673828,31.6029815673828,31.6029815673828,31.6029815673828,32.1001129150391,32.1001129150391,32.1001129150391,32.1001129150391,32.1001129150391,32.1001129150391,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,32.6916961669922,33.276481628418,33.276481628418,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,33.8599319458008,34.8547668457031,34.8547668457031,34.8547668457031,34.8547668457031,34.8547668457031,34.8547668457031,34.8547668457031,34.8547668457031,35.3537292480469,35.3537292480469,35.3537292480469,35.3537292480469,35.3537292480469,35.8729705810547,35.8729705810547,35.8729705810547,35.8729705810547,35.8729705810547,35.8729705810547,36.3594589233398,36.3594589233398,36.3594589233398,36.3594589233398,36.3594589233398,36.3594589233398,28.5893630981445,28.5893630981445,28.5893630981445,28.5893630981445,28.5893630981445,28.5893630981445,28.5893630981445,29.293327331543,29.293327331543,29.293327331543,29.293327331543,29.293327331543,29.293327331543,29.293327331543,29.78076171875,29.78076171875,29.78076171875,29.78076171875,29.78076171875,29.78076171875,29.78076171875,29.78076171875,30.2705764770508,30.2705764770508,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,30.8756484985352,31.4065322875977,31.4065322875977,31.4065322875977,31.4065322875977,31.4065322875977,31.4065322875977,31.9747314453125,31.9747314453125,31.9747314453125,31.9747314453125,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,32.4642028808594,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.2719497680664,33.7494506835938,33.7494506835938,33.7494506835938,33.7494506835938,33.7494506835938,33.7494506835938,33.7494506835938,34.4911727905273,34.4911727905273,34.4911727905273,34.4911727905273,34.4911727905273,34.4911727905273,34.4911727905273,34.9777221679688,34.9777221679688,35.4645690917969,35.4645690917969,35.4645690917969,35.4645690917969,35.4645690917969,35.4645690917969,35.4645690917969,35.4645690917969,35.9621276855469,35.9621276855469,35.9621276855469,35.9621276855469,35.9621276855469,35.9621276855469,36.4496765136719,36.4496765136719,36.4496765136719,36.4496765136719,36.4496765136719,36.4496765136719,36.4496765136719,36.4496765136719,28.5575103759766,28.5575103759766,28.5575103759766,28.5575103759766,28.5575103759766,29.0268249511719,29.0268249511719,29.5115509033203,29.5115509033203,29.5115509033203,29.5115509033203,29.5115509033203,29.5115509033203,29.5115509033203,29.5115509033203,30.0477905273438,30.0477905273438,30.0477905273438,30.0477905273438,30.8100662231445,30.8100662231445,30.8100662231445,30.8100662231445,30.8100662231445,30.8100662231445,30.8100662231445,30.8100662231445,31.7876205444336,31.7876205444336,31.7876205444336,31.7876205444336,31.7876205444336,31.7876205444336,31.7876205444336,32.4745330810547,32.4745330810547,32.4745330810547,32.4745330810547,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.0372009277344,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,33.5167617797852,34.0386352539062,34.0386352539062,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,34.5281600952148,35.0142440795898,35.0142440795898,35.4967498779297,35.4967498779297,35.4967498779297,35.4967498779297,36.1337966918945,36.1337966918945,36.1337966918945,36.1337966918945,36.1337966918945,28.5814895629883,28.5814895629883,28.5814895629883,28.5814895629883,29.4182586669922,29.4182586669922,29.4182586669922,29.4182586669922,29.4182586669922,29.8887634277344,29.8887634277344,29.8887634277344,29.8887634277344,29.8887634277344,30.561882019043,30.561882019043,30.561882019043,30.561882019043,30.561882019043,30.561882019043,30.561882019043,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.1003494262695,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,31.6728363037109,32.2343597412109,32.2343597412109,32.2343597412109,32.2343597412109,32.2343597412109,32.2343597412109,32.2343597412109,32.2343597412109,32.7367782592773,32.7367782592773,32.7367782592773,32.7367782592773,32.7367782592773,32.7367782592773,32.7367782592773,33.4432678222656,33.4432678222656,33.4432678222656,33.4432678222656,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,33.9524765014648,34.736213684082,34.736213684082,34.736213684082,34.736213684082,34.736213684082,34.736213684082,35.2706146240234,35.2706146240234,35.2706146240234,35.2706146240234,35.2706146240234,35.2706146240234,35.2706146240234,35.2706146240234,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.243034362793,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,36.5975494384766,29.1008911132812,29.1008911132812,29.8389358520508,29.8389358520508,29.8389358520508,29.8389358520508,29.8389358520508,29.8389358520508,30.3823699951172,30.3823699951172,30.3823699951172,30.3823699951172,30.3823699951172,30.3823699951172,30.3823699951172,30.3823699951172,30.9765167236328,30.9765167236328,30.9765167236328,30.9765167236328,30.9765167236328,30.9765167236328,30.9765167236328,31.4556198120117,31.4556198120117,31.4556198120117,31.4556198120117,31.4556198120117,31.4556198120117,31.9837493896484,31.9837493896484,31.9837493896484,31.9837493896484,31.9837493896484,32.6218185424805,32.6218185424805,32.6218185424805,32.6218185424805,32.6218185424805,32.6218185424805,33.3787841796875,33.3787841796875,33.3787841796875,33.3787841796875,33.3787841796875,33.3787841796875,33.3787841796875,34.0490036010742,34.0490036010742,34.0490036010742,34.0490036010742,34.0490036010742,34.0490036010742,34.6023483276367,34.6023483276367,34.6023483276367,34.6023483276367,34.6023483276367,35.1671905517578,35.1671905517578,35.1671905517578,35.1671905517578,35.1671905517578,35.1671905517578,35.1671905517578,35.6724700927734,35.6724700927734,35.6724700927734,35.6724700927734,35.6724700927734,35.6724700927734,36.2501373291016,36.2501373291016,36.2501373291016,36.2501373291016,36.2501373291016,36.2501373291016,36.2501373291016,28.4546661376953,28.4546661376953,28.4546661376953,28.4546661376953,28.4546661376953,28.4546661376953,28.4546661376953,28.4546661376953,29.2733688354492,29.2733688354492,29.2733688354492,29.2733688354492,29.2733688354492,29.2733688354492,29.2733688354492,29.2733688354492,29.9912185668945,29.9912185668945,29.9912185668945,29.9912185668945,29.9912185668945,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,30.5469436645508,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.0390396118164,31.5052795410156,31.5052795410156,31.5052795410156,31.5052795410156,31.5052795410156,31.5052795410156,31.5052795410156,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859,32.1774749755859],&#34;meminc&#34;:[0,0,0,0,0.689559936523438,0,0,0,0,0.527572631835938,0,0,0,0,0,0,0,0,0,0,0.531265258789062,0,0,0,0,0,0,0.703598022460938,0,0,0,0,0,0,0.761627197265625,0,0.478874206542969,0,0,0,0,0,0,0,0,0,0,0.585624694824219,0,0,0.938278198242188,0,0,0,0,0.544998168945312,0,0,0,0,0,0,0,0.56158447265625,0,0,0.46832275390625,0,0,0,0,0,0,0,0.540802001953125,0,0,0,0,-7.94781494140625,0,0,0,0,0,0,0,0,0,0,0.700592041015625,0,0,0,0,0,0,0.5009765625,0,0,0,0,0,0,0.772300720214844,0,0,0,0,0,0,0,0.953216552734375,0,0,0,0,0,0,0.55078125,0,0,0,0,0.589454650878906,0,0,0,0,0,0,0,0,0,0,0.969818115234375,0,0,0,0,0,0,0,0,0,0,0,0.490013122558594,0,0,0,0,0,0,0,0.904144287109375,0,0,0,0,0,0,0.484443664550781,0,0,0,0,0,0,0,0,0,0,0.488136291503906,0,0,0,0,0,0,0,0.867843627929688,0,0,0,0,-7.36689758300781,0,0,0,0,0,0,0,0.677604675292969,0,0,0.604782104492188,0,0,0,0,0,0,0.533355712890625,0,0,0,0.624855041503906,0,0,0,0,0.523460388183594,0,0,0,0,0,0,0,0.536476135253906,0,0.698554992675781,0,0,0,0,0.483772277832031,0,0,0,0,0,0,0,0,0,0.979454040527344,0,0,0,0,0,0,0,0,0,0.982261657714844,0,0,-2.27093505859375,0,0,0,0,0,0,0,-4.33940124511719,0,0,0,0,0,0,0.946884155273438,0,0,0,0,0,0,0,0,0.485404968261719,0,0,0,0,0,0,0,0,0,0,0.487556457519531,0,0,0,0,0,0,0,0.6707763671875,0,0,0,0,0,0,0.501380920410156,0,0,0,0,0,0,0,0.492012023925781,0,0.481887817382812,0,0,0,0,0.57733154296875,0,0,0,0,0,0,0,0,0,0.559066772460938,0,0.668617248535156,0,0,0,0.985076904296875,0,0,0,0,0,0,0,0,0,0.485504150390625,0,0,0,0,0,0,0,0,0,-7.4576416015625,0,0.738998413085938,0,0,0,0,0,0,0.486480712890625,0,0,0,0,0,0,0.490043640136719,0,0,0,0,0,0,0,0,0,0,0,0.497711181640625,0,0,0,0,0.602256774902344,0,0,0,0,0.48138427734375,0,0,0,0,0.981674194335938,0,0,0,0,0.598182678222656,0,0,0.816261291503906,0,0,0,0,0,0,0,0.510368347167969,0,0,0,0,0,0,0.928314208984375,0,0,0,0,0,0,0,-8.01834106445312,0,0,0,0,0,0,0,0,0,0,0,0.167243957519531,0,0.600151062011719,0,0,0,0,0,0,1.00350189208984,0,0,0,0,0,0,0.992927551269531,0,0,0,0,0,0,0,0,0.993759155273438,0,0,0,0,0,0,0,0,0,0.969688415527344,0,0,0,0,0,0,0,0,0,0,0,0,0,0.938705444335938,0,0,0,0,0,0,0,0,0,0,0,0,0.941314697265625,0,0,0,0,0,0,0.467811584472656,0,0,0,0,0,0,0,0,0,0.43402099609375,0,0,0,0,0,0,0.433586120605469,0,0,0,0,0,0,-7.68270874023438,0,0,0,0,0,0.500335693359375,0,0,0,0,0,0.476516723632812,0,0,0,0,0,0,0,0,0,0.4949951171875,0,0,0,0,0.712921142578125,0,0,0,0,0,0,0.64013671875,0,0,0,0,0.490509033203125,0,0.536354064941406,0,0,0,0,0,0,0.591522216796875,0,0,0,0,0,0.485519409179688,0,0,0,0,0,0,0.50469970703125,0,0,0,0,0,0,0,0,0,0,0,0,0.484283447265625,0,0,0,0,0,0.842124938964844,0,0,0,0,0,0,0,0,0,0.514694213867188,0,0,0,0,0,0.473068237304688,0,0,0,0,0,0,0,0,0,-7.9232177734375,0,0,0,0,0,0.487266540527344,0,0,0,0,0,0,0,0.735923767089844,0,0,0,0,0,0,0.994293212890625,0,1.00132751464844,0,0,0,0,0,0,0.67047119140625,0,0,0,0,0,0,0.802925109863281,0,0,0,0,0.976852416992188,0,0,0,0,0,0,0,0,0,0.984596252441406,0,0,0,0,0,0,0,0.986396789550781,0,0,0,0,-7.59001159667969,0,0,0,0,0,0,0.9620361328125,0,0,0,0,0,0,0,0,0,0.556602478027344,0,0,0,0,0,0,0.680450439453125,0,0,0,0,0,0,1.00096893310547,0,0,0,0,0.605667114257812,0,0,0,0,0,0,0.476753234863281,0,0,0,0,0,0,0.969627380371094,0,0,0,0,0,0,0,0,0,0.819381713867188,0,0,0,0,0,0.634773254394531,0,0,0,0,0,0,0,0,0,0,0.970611572265625,0,0.484489440917969,0,0,0,0,0,-7.46705627441406,0,0,0,0,0,0,0.989067077636719,0,0,0,0,0,0,0,0,0,0.491294860839844,0,0,0,0,0,0,0,0,0,0,0.560859680175781,0,0,0,0,0,0,0.479171752929688,0,0.6060791015625,0,0,0,0,0.981430053710938,0,0.488868713378906,0,0,0,0,0,0,0,0,0,0,0.479972839355469,0,0,0,0,0,0,0,0.628402709960938,0,0,0,0,0,0,0.546775817871094,0,0,0,0,0,0,0,0,0,0,0.558799743652344,0,0,0,0,0,0,0,0,0,0.59423828125,0,0,0,0,-7.96672058105469,0,0,0,0,0,0,0,0.604072570800781,0,0,0,0,0,0,0,0.532218933105469,0,0,0,0,0.722343444824219,0,0,0,0,0,0,0,0,0.531227111816406,0,0,0,0.495147705078125,0,0.663734436035156,0,0,0,0,0.545791625976562,0,0,0,0,0.733085632324219,0,0,0,0,0,0.4892578125,0,0,0,0,0,0,0,0,0,0,0.984100341796875,0,0,0,0,0,0,0.81060791015625,0,0,0,0,0,0,0,0.479621887207031,0,0,0,0,0,0.486228942871094,0,0,-7.66910552978516,0,0,0,0,0.606269836425781,0,0,0,0,0,0,0,0.500701904296875,0,0,0,0,0,0.520278930664062,0,0,0,0,0,0,0,0.491493225097656,0,0,0,0,0,0,0.512657165527344,0,0,0,0,0,0,0,0.485282897949219,0,0,0,0,0,0.569892883300781,0,0.53216552734375,0,0,0,0,0,0,0.491432189941406,0,0,0,0,0,0,0,0,0,0.46185302734375,0,0,0,0,0.477088928222656,0,0,0,0,0,0,0,0,0,0.555068969726562,0,0,0,0,0,0.539894104003906,0,0,0,0,0,0,0,0.644828796386719,0,0,0,0,0,0,0,-7.47177886962891,0,0,0,0,0,0,0,0.839248657226562,0,0,0,0,0,0,0,0,0,0.635696411132812,0,0,0,0,0,0,0,0.717689514160156,0,0,0,0,0,0,0,0,0,0,0.554298400878906,0,0,0,0,0,0,0,0.4849853515625,0,0,0,0,0,0,0,0,0,0,0.560325622558594,0,0,0,0,0,0,0,0.73028564453125,0,0.470130920410156,0,0,0,0,0,0,0.520980834960938,0,0,0,0,0,0.534248352050781,0,0,0,0,0,0,0,0,0,0,0.58624267578125,0,0,0,0,0,0.847976684570312,0,0,0,0,-7.92454528808594,0,0,0,0,0.633491516113281,0,0,0,0,0,0,0,0,0,0,0,1.00015258789062,0,1.00005340576172,0,0,0,0,0,0,0.746437072753906,0,0,0,0,0,0,0,0,0,0,0,0.55908203125,0,0,0,0,0,0,0.49310302734375,0,0,0,0,0,0,0,0.483512878417969,0,0,0,0,0.647102355957031,0,0,0.493942260742188,0,0,0,0,0.489509582519531,0,0,0,0.535247802734375,0,0,0,0,0,0,0,0,0.5496826171875,0,0,0,0,0.47198486328125,0,0,0,0,-7.84102630615234,0,0,0,0.636878967285156,0,0.993804931640625,0,0,0,0,0,0,0.543403625488281,0,0,0,0,0,0,0,0.491043090820312,0,0,0,0,0,0,0,0.473678588867188,0,0,0,0,0,0,0,0.966911315917969,0,0.922775268554688,0,0,0,0,0,0.489936828613281,0,0,0,0,0,0,0,0.515640258789062,0,0,0,0,0,0,0.651145935058594,0,0,0,0,0,0.671585083007812,0,0,0,0,0,0,0.585464477539062,0,0,0,0,0,0,0,0,0,-7.41581726074219,0,0,0,0,0,0,0,0,0,0,0,0.4931640625,0,0,0,0,0,0,0,0,0,0,0.604873657226562,0,0,0,0,0,0,0,0.501365661621094,0,0,0,0,0,0,0,0.637237548828125,0,0,0,0,0,0,0,0,0,0,0,0.696929931640625,0,0,0,0,0.522674560546875,0,0,0,0,0.549720764160156,0,0,0.570243835449219,0,0,0,0.794174194335938,0,0,0,0,0,0,0,0,0,0.700454711914062,0,0,0,0.484939575195312,0,0,0,0,0,0,0,0.475822448730469,0,0,0,0,0,0,0.393951416015625,0,0,0,-7.85673522949219,0,0,0,0,0.489517211914062,0,0,0,0,0,0.711631774902344,0,0,0,0,0,0,0.982345581054688,0,0,0,0,0,0,0.496955871582031,0,0,0,0,0,0,0,0.478424072265625,0,0,0,0,0,0,0,0,0.829177856445312,0,0,0,0.678916931152344,0,0,0,0,0,0,0.780601501464844,0,0,0,0,0,0,0,0,0,0.484451293945312,0,0,0,0,0.472946166992188,0,0,0,0,0,0.478240966796875,0,0,0,0,0.88427734375,0,0,0,0,0,0,0,0,0,-7.82572174072266,0,0,0,0,0,0,0.528114318847656,0,0,0,0,0.474479675292969,0,0,0,0,0,0,0,0,0,0,0,0.483367919921875,0,0,0,0,0,0,0,0,0.485832214355469,0,0,0,0,0,0.536911010742188,0,0,0,0,0,0,0,0.908546447753906,0,0,0,0,0,0,0,0,0,0,0.936286926269531,0,0,0,0.470787048339844,0,0,0,0,0,0,0,0,0,0,0.473030090332031,0,0,0,0,0,0,0,0.484260559082031,0,0,0,0,0,0,0,0,0.479507446289062,0,0,0,0.473403930664062,0,0,0,0,0,0,0,0,0,0.488327026367188,0,0,0,0,0,0,0,0,0,0,0.688690185546875,0,0,0,0,0,0,-7.89817047119141,0,0,0,0,0,0,0,0,0.484405517578125,0,0,0,0,0,0.941047668457031,0,0,0,0,0,0,0,0.972221374511719,0,0,0,0,0,0,0,0.489669799804688,0,0,0,0,0,0,0,0,0.564765930175781,0,0,0,0,0,0,0,0,0,0,0,0.65887451171875,0,0,0,0,0,0,0,0,0.553428649902344,0,0,0,0,0,0,0,0,0.482818603515625,0,0,0,0,0.500076293945312,0,0,0,0,0,0,0.768875122070312,0,0,0,0,0.481369018554688,0,0,0,0,0.5595703125,0,0,0,0,0,0.439041137695312,0,0,0,0,-7.47522735595703,0,0,0,0,0,0.486442565917969,0,0,0,0,0.487312316894531,0,0,0,0,0,0,0,0,0,0,0,0,0.484237670898438,0,0,0,0,0,0,0.970703125,0,0,0,0,0,0,0,0,0.483482360839844,0,0,0,0,0.460853576660156,0,0,0,0,0,0,0,0,0,0,0.463462829589844,0,0,0,0,0,0,0,0.924461364746094,0,0,0,0.470863342285156,0,0,0,0,0,0,0,0,0,0,0.438041687011719,0,0,0,0,0,0,0,0,0.410049438476562,0,0,0,0,0,0,0,0.490104675292969,0,0.490631103515625,0,0,0,0,0,0,0,0,-7.55259704589844,0,0,0,0,0,0,0,0.53106689453125,0,0,0,0,0,0.473075866699219,0,0,0,0,0,0,0,0.497604370117188,0,0,0,0.492561340332031,0,0,0,0,0,0,0,0,0,0.46588134765625,0,0,0,0,0.519950866699219,0,0,0,0,0,0.707725524902344,0,0,0,0,0,0,0,0,0,0,0.478569030761719,0,0,0,0,0,0,0,0.553253173828125,0,0,0.523048400878906,0,0,0,0,0.475814819335938,0,0,0,0,0,0,0,0.647926330566406,0,0,0,0,0,0,0,0.4814453125,0,0.504493713378906,0,0,0,0,0,0,0,0.622505187988281,0,0,0,0,0,-7.8369140625,0,0,0,0,0,0,0.520599365234375,0,0,0,0,0,0,0,0.922752380371094,0,0,0,0,0.807624816894531,0,0,0,0,0,0,0.467704772949219,0,0,0,0,0,0.502838134765625,0,0,0,0,0,0.484428405761719,0,0,0,0,0,0,0,0,0,0,0,0.51971435546875,0,0,0,0,0,0,0,0.473342895507812,0,0,0,0,0,0,0,0.61907958984375,0,0,0,0,0,0,0.659324645996094,0,0.475601196289062,0,0,0,0,0,0,0,0.423728942871094,0,0,0,0,0,0,0.452285766601562,0,0,0,0,0.418769836425781,0,0,0,0,0,0,0,-7.97599029541016,0,0,0,0,0,0,0.380126953125,0,0,0,0,0,0,0,0,0,0.383049011230469,0,0,0,0,0,0,0,0.356346130371094,0,0,0,0,0,0,0,0,0.49676513671875,0,0,0,0,0,0.476104736328125,0,0,0,0,0,0,0.493453979492188,0,0,0,0,0.521835327148438,0,0,0,0,0,0,0,0,0.958091735839844,0,0,0,0.968452453613281,0,0,0,0,0.645942687988281,0,0,0,0,0.489151000976562,0,0,0,0,0,0,0.540519714355469,0,0,0,0,0,0,0.476539611816406,0,0,0,0,0,0,0,0,0.512985229492188,0,0,0,0,0,0,-7.85568237304688,0,0,0,0,0,0,0,0,0,0,0.887413024902344,0,0,0,0,0,0,0,0.755149841308594,0,0,0,0,0,0,0,0.524559020996094,0,0,0,0,0,0,0,0,0,0,0,0.93670654296875,0,0,0,0,0,0,0.92010498046875,0,0,0,0,0,0,0,0,0.535171508789062,0,0,0,0,0,0,0,0.484809875488281,0,0,0,0,0.475013732910156,0,0,0,0,0,0,0,0,0,0.487411499023438,0,0,0,0,0,0,0,0,0,0.485115051269531,0,0,0,0,0,0,0,0.49114990234375,0,0.94805908203125,0,0,0,0,-7.82412719726562,0,0,0,0,0,0,0.506523132324219,0,0,0,0,0.517135620117188,0,0,0,0,0,0,0,0.854530334472656,0,0,0,0,0,0,0.47564697265625,0,0,0,0,0,0,0,0.536750793457031,0,0,0,0,0,0.481979370117188,0,0.478919982910156,0,0,0,0,0,0,0.4749755859375,0,0,0,0.750740051269531,0,0,0,0,0,0,0,0,0,0.688674926757812,0,0,0,0,0.5111083984375,0,0.783241271972656,0,0,0,0,0.486961364746094,0,0,0,0,0,0,0,0.488319396972656,0,0,0,0,0,0,0,0,-7.94052886962891,0,0,0,0,0,0,0,0,0,0.584053039550781,0,0,0,0,0,0,0,0.548408508300781,0,0,0,0,0.56170654296875,0,0,0,0,0,0,0,0,0.499595642089844,0,0,0,0,0,0.524765014648438,0,0,0,0,0,0,0,0.531967163085938,0,0,0,0,0,0,0,0.614799499511719,0,0,0,0,0,0,0,0,0,0,0,0,0.472991943359375,0,0,0,0,0,0,0,0,0.520042419433594,0,0,0,0,0,0,0,0.522315979003906,0,0,0,0,0,0,0,0,0.518356323242188,0,0,0,0,0,0,0,0,0.568046569824219,0,0.473258972167969,0,0,0,0,0,0,0,0,0,0.579689025878906,0,0,0,0,0,0,0,0,0,0.48291015625,0,0,0,0,0,0.0406646728515625,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-8.35350799560547,0,0,0,0,0,0,0,0,0,0,0,0.49810791015625,0,0.561172485351562,0,0,0,0,0,0,0,0,0,0,0.681434631347656,0,0,0,0,0,0,0.611427307128906,0,0,0,0.517417907714844,0,0,0,0,0,0,0,0,0,0,0.481231689453125,0,0,0,0,0,0,0.476112365722656,0,0,0,0,0,0.561721801757812,0,0,0,0,0.489212036132812,0,0,0,0,0.567459106445312,0,0,0,0,0,0,0.505020141601562,0,0,0,0,0,0.486183166503906,0,0.616424560546875,0,0,0,0,0,0,0,0.536674499511719,0,0,0,0,0,0,0,0.460861206054688,0,0,0,0,0,0,-7.93976593017578,0,0,0,0,0,0,0,0,0.698310852050781,0,0,0,0,0.501602172851562,0,0,0,0,0.839408874511719,0,0,0,0,0,0,0.502853393554688,0,0,0,0,0.554557800292969,0,0,0,0,0,0,0,0,0.488258361816406,0,0,0,0,0.570465087890625,0,0,0,0,0,0,0,0.662590026855469,0,0,0,0,0,0,0.471710205078125,0,0,0,0.806251525878906,0,0.580314636230469,0,0,0,0,0.492446899414062,0,0,0,0.522903442382812,0,0.481857299804688,0,0,0,0,0,-7.7916259765625,0,0,0,0,0,0,0,0.496231079101562,0,0,0,0,0,0.492012023925781,0,0,0,0,0,0,0,0,0.521415710449219,0,0,0.500053405761719,0,0,0,0,0,0,0,0,0,0,0.479095458984375,0,0.490379333496094,0,0,0,0,0,0,0,0.6180419921875,0,0,0,0,0,0,0.550933837890625,0,0,0,0,0,0,0,0,0.587623596191406,0,0,0,0,0,0,0,0,0,0.635322570800781,0,0,0,0.838310241699219,0,0.660240173339844,0,0,0,0,0,0,0,0,0,0,0,0,0.681221008300781,0,0,0,0,0,0,0,0,0,0,0,-7.92177581787109,0,0,0,0,0,0,0,0,0,0,0.57080078125,0,0,0,0,0,0,0,0,0.489906311035156,0,0,0,0,0,0,0,0,0,0,0.562637329101562,0,0,0,0,0.478797912597656,0,0,0,0,0,0,0,0.495765686035156,0,0,0,0,0,0,0.491813659667969,0,0,0,0,0,0,0,0,0,0.864341735839844,0,0,0,0,0,0,0,0,0,0.688560485839844,0,0,0,0,0,0,0.574539184570312,0,0,0,0,0,0,0,0,0,0,0.506118774414062,0,0,0,0,0,0,0.533164978027344,0,0,0,0,0,0,0,0,0,0.471771240234375,0,0.535575866699219,0,0,0,0,0,0,0.582855224609375,0,0,0,0,0,-7.94239044189453,0,0,0,0,0,0,0,0,0.941635131835938,0,0,0,0,0,0,0,0,0,0,0.61444091796875,0,0,0,0,0,0,0,0,0.483741760253906,0,0.642013549804688,0,0,0,0,0,0,0.552169799804688,0,0,0,0,0.503097534179688,0,0,0,0,0,0.570060729980469,0,0,0,0,0,0,0,0.484275817871094,0,0,0,0,0,0.517608642578125,0,0,0,0,0,0,0,0,0,0.488311767578125,0,0,0,0,0,0,0.651496887207031,0,0,0,0,0,0,0,0,0,0.576690673828125,0,0,0,0,0,0,0,0,0,0,0.478874206542969,0,0.502090454101562,0,0,0,-7.76889801025391,0,0,0,0,0,0,0,0.521919250488281,0,0.50396728515625,0,0,0,0,0,0,0,0,0,0,0,0,0.481048583984375,0,0,0,0,0,0,0,0,0,0.488395690917969,0,0,0,0.524490356445312,0,0,0,0,0,0,0,0,0,0,0.5631103515625,0,0,0,0,0,0,0,0.549560546875,0,0.539886474609375,0,0,0,0,0.778228759765625,0,0,0,0,0,0,0,0.580116271972656,0,0,0,0,0,0,0,0,0,0,0.501495361328125,0,0,0,0,0,0,0,0,0,0,0,0.476997375488281,0,0,0,0,0,0,0,0,0.554618835449219,0,0,0,0,0,0,0.595619201660156,0,0,0,0,0,0,-7.88138580322266,0,0,0,0,0,0,0.498100280761719,0,0,0,0,0,0.545829772949219,0,0,0,0,0,0,0,0.673057556152344,0,0,0,0,0.591255187988281,0,0,0,0,0,0,0.477241516113281,0,0,0,0,0,0,0,0,0,0.540634155273438,0,0,0,0,0.529067993164062,0,0,0,0,0,0,0.566741943359375,0,0,0,0,0,0,0,0.4779052734375,0,0,0,0,0.509147644042969,0,0,0,0,0,0,0,0,0,0.571334838867188,0,0,0,0,0,0,0,0,0,0.506629943847656,0,0,0,0,0,0.856735229492188,0,0,0,0,0,0,0,0,0,0,0,0.503265380859375,0,0,0,0,0,0,0,0.411521911621094,0,0,0,0,0,0,0,0,-7.66350555419922,0,0,0,0,0.456939697265625,0,0,0,0,0,0,0,0.50360107421875,0,0,0,0,0.568305969238281,0,0,0,0,0,0,0,0,0,0,0.492919921875,0,0,0,0,0,0,0.494560241699219,0,0,0,0,0,0,0,0,0,0.489166259765625,0,0,0,0,0.621978759765625,0,0.539886474609375,0,0,0,0,0,0.6114501953125,0,0,0,0,0,0,0,0,0.519660949707031,0,0,0,0.486045837402344,0,0,0,0,0,0,0,0,0.5545654296875,0,0,0,0,0.488174438476562,0,0,0,0,0,0.551055908203125,0,0,0,0,-7.92129516601562,0,0,0,0,0,0,0,0,0.579879760742188,0,0,0,0,0.506729125976562,0,0,0,0,0,0,0,0.541397094726562,0,0,0.509140014648438,0,0,0,0,0,0,0,0.607894897460938,0,0.503265380859375,0,0,0,0,0,0.581779479980469,0,0,0,0,0,0,0,0.505424499511719,0,0,0,0,0,0,0.474037170410156,0,0,0,0,0,0,0,0,0,0.468185424804688,0,0,0,0,0,0,0,0,0,0,0.540122985839844,0,0,0,0,0,0,0.999412536621094,0,0,0,0,0.956260681152344,0,0,0,0,0,0,0.44305419921875,0,0,0,0,0,0,-7.738037109375,0,0,0,0,0,0.936485290527344,0,0,0,0,0,0,0.4810791015625,0,0,0,0,0,0,0,0,0.496208190917969,0,0,0,0,0,0.844268798828125,0,0,0,0,0,0,0.49713134765625,0,0,0,0,0,0.591583251953125,0,0,0,0,0,0,0,0,0,0.584785461425781,0,0.583450317382812,0,0,0,0,0,0,0,0,0,0.994834899902344,0,0,0,0,0,0,0,0.49896240234375,0,0,0,0,0.519241333007812,0,0,0,0,0,0.486488342285156,0,0,0,0,0,-7.77009582519531,0,0,0,0,0,0,0.703964233398438,0,0,0,0,0,0,0.487434387207031,0,0,0,0,0,0,0,0.489814758300781,0,0.605072021484375,0,0,0,0,0,0,0,0,0.5308837890625,0,0,0,0,0,0.568199157714844,0,0,0,0.489471435546875,0,0,0,0,0,0,0,0,0.807746887207031,0,0,0,0,0,0,0,0,0,0,0.477500915527344,0,0,0,0,0,0,0.741722106933594,0,0,0,0,0,0,0.486549377441406,0,0.486846923828125,0,0,0,0,0,0,0,0.49755859375,0,0,0,0,0,0.487548828125,0,0,0,0,0,0,0,-7.89216613769531,0,0,0,0,0.469314575195312,0,0.484725952148438,0,0,0,0,0,0,0,0.536239624023438,0,0,0,0.762275695800781,0,0,0,0,0,0,0,0.977554321289062,0,0,0,0,0,0,0.686912536621094,0,0,0,0.562667846679688,0,0,0,0,0,0,0,0,0.479560852050781,0,0,0,0,0,0,0,0,0,0.521873474121094,0,0.489524841308594,0,0,0,0,0,0,0,0,0.486083984375,0,0.482505798339844,0,0,0,0.637046813964844,0,0,0,0,-7.55230712890625,0,0,0,0.836769104003906,0,0,0,0,0.470504760742188,0,0,0,0,0.673118591308594,0,0,0,0,0,0,0.538467407226562,0,0,0,0,0,0,0,0,0,0,0,0,0,0.572486877441406,0,0,0,0,0,0,0,0,0.5615234375,0,0,0,0,0,0,0,0.502418518066406,0,0,0,0,0,0,0.706489562988281,0,0,0,0.509208679199219,0,0,0,0,0,0,0,0,0,0,0.783737182617188,0,0,0,0,0,0.534400939941406,0,0,0,0,0,0,0,0.972419738769531,0,0,0,0,0,0,0,0,0,0,0.354515075683594,0,0,0,0,0,0,0,0,-7.49665832519531,0,0.738044738769531,0,0,0,0,0,0.543434143066406,0,0,0,0,0,0,0,0.594146728515625,0,0,0,0,0,0,0.479103088378906,0,0,0,0,0,0.528129577636719,0,0,0,0,0.638069152832031,0,0,0,0,0,0.756965637207031,0,0,0,0,0,0,0.670219421386719,0,0,0,0,0,0.5533447265625,0,0,0,0,0.564842224121094,0,0,0,0,0,0,0.505279541015625,0,0,0,0,0,0.577667236328125,0,0,0,0,0,0,-7.79547119140625,0,0,0,0,0,0,0,0.818702697753906,0,0,0,0,0,0,0,0.717849731445312,0,0,0,0,0.55572509765625,0,0,0,0,0,0,0,0,0.492095947265625,0,0,0,0,0,0,0,0,0,0,0.466239929199219,0,0,0,0,0,0,0.672195434570312,0,0,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//RtmpyrO71H/file11ae472e70f2.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;div id=&#34;htmlwidget-4&#34; style=&#34;width:100%;height:600px;&#34; class=&#34;profvis html-widget&#34;&gt;&lt;/div&gt;
&lt;script type=&#34;application/json&#34; data-for=&#34;htmlwidget-4&#34;&gt;{&#34;x&#34;:{&#34;message&#34;:{&#34;prof&#34;:{&#34;time&#34;:[1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12],&#34;depth&#34;:[8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1,8,7,6,5,4,3,2,1,7,6,5,4,3,2,1],&#34;label&#34;:[&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sample.int&#34;,&#34;base::sample&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;,&#34;sum&#34;,&#34;fastSimNullDistR_work&#34;,&#34;fastSimNullDistRMean&#34;,&#34;eval&#34;,&#34;eval&#34;,&#34;eval.parent&#34;,&#34;local&#34;],&#34;filenum&#34;:[null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null,null,null,null,1,null,null,null,null,null,null,1,null,null,null,null],&#34;linenum&#34;:[null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null,null,null,null,3,null,null,null,null,null,null,3,null,null,null,null],&#34;memalloc&#34;:[30.3009567260742,30.3009567260742,30.3009567260742,30.3009567260742,30.3009567260742,30.3009567260742,30.3009567260742,30.3009567260742,37.7070693969727,37.7070693969727,37.7070693969727,37.7070693969727,37.7070693969727,37.7070693969727,37.7070693969727,37.7070693969727,43.5531539916992,43.5531539916992,43.5531539916992,43.5531539916992,43.5531539916992,43.5531539916992,43.5531539916992,43.5531539916992,50.6177368164062,50.6177368164062,50.6177368164062,50.6177368164062,50.6177368164062,50.6177368164062,50.6177368164062,56.7390975952148,56.7390975952148,56.7390975952148,56.7390975952148,56.7390975952148,56.7390975952148,56.7390975952148,62.6916427612305,62.6916427612305,62.6916427612305,62.6916427612305,62.6916427612305,62.6916427612305,62.6916427612305,62.6916427612305,32.0725326538086,32.0725326538086,32.0725326538086,32.0725326538086,32.0725326538086,32.0725326538086,32.0725326538086,32.0725326538086,39.358024597168,39.358024597168,39.358024597168,39.358024597168,39.358024597168,39.358024597168,39.358024597168,39.358024597168,45.1719436645508,45.1719436645508,45.1719436645508,45.1719436645508,45.1719436645508,45.1719436645508,45.1719436645508,45.1719436645508,54.6248168945312,54.6248168945312,54.6248168945312,54.6248168945312,54.6248168945312,54.6248168945312,54.6248168945312,61.2367401123047,61.2367401123047,61.2367401123047,61.2367401123047,61.2367401123047,61.2367401123047,61.2367401123047,61.2367401123047,29.3435974121094,29.3435974121094,29.3435974121094,29.3435974121094,29.3435974121094,29.3435974121094,29.3435974121094],&#34;meminc&#34;:[0,0,0,0,0,0,0,0,7.40611267089844,0,0,0,0,0,0,0,5.84608459472656,0,0,0,0,0,0,0,7.06458282470703,0,0,0,0,0,0,6.12136077880859,0,0,0,0,0,0,5.95254516601562,0,0,0,0,0,0,0,-30.6191101074219,0,0,0,0,0,0,0,7.28549194335938,0,0,0,0,0,0,0,5.81391906738281,0,0,0,0,0,0,0,9.45287322998047,0,0,0,0,0,0,6.61192321777344,0,0,0,0,0,0,0,-31.8931427001953,0,0,0,0,0,0],&#34;filename&#34;:[null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null,null,null,&#34;&lt;expr&gt;&#34;,null,null,null,null]},&#34;interval&#34;:10,&#34;files&#34;:[{&#34;filename&#34;:&#34;&lt;expr&gt;&#34;,&#34;content&#34;:&#34;set.seed(2009)\nprofvis({\n    NullDistFSNDR_mw &lt;- fastSimNullDistRMean(total_bill ~ time, data=tips)\n})&#34;,&#34;normpath&#34;:&#34;&lt;expr&gt;&#34;}],&#34;prof_output&#34;:&#34;/var/folders/f3/t51slq3x2dlfgk3ksp7vddzm0000gq/T//RtmpyrO71H/file11ae1bf8185c.prof&#34;,&#34;highlight&#34;:{&#34;output&#34;:[&#34;^output\\$&#34;],&#34;gc&#34;:[&#34;^&lt;GC&gt;$&#34;],&#34;stacktrace&#34;:[&#34;^\\.\\.stacktraceo(n|ff)\\.\\.$&#34;]},&#34;split&#34;:&#34;h&#34;}},&#34;evals&#34;:[],&#34;jsHooks&#34;:[]}&lt;/script&gt;
&lt;p&gt;Das mit den beiden Routinen aus FastSimNullDistR die gleichen Ergebnisse zu erwarten sind, sie also ein “(quasi-)drop-in-replacements” der Mosaic Routinen darstellen, kann man an den folgenden QQ-Plots erkennen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.diffprop &amp;lt;- data_frame(diffprop = c(NullDistFSNDR_aw$diffprop,
    NullDistMosaic_aw$diffprop), type = c(rep(&amp;quot;FSNDR&amp;quot;, 10000),
    rep(&amp;quot;mosaic&amp;quot;, 10000)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `data_frame()` was deprecated in tibble 1.1.0.
## Please use `tibble()` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gf_qq(~diffprop, color = ~type, data = df.diffprop)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df.diffmean &amp;lt;- data_frame(diffmean = c(NullDistFSNDR_mw$diffmean,
    NullDistMosaic_mw$diffmean), type = c(rep(&amp;quot;FSNDR&amp;quot;, 10000),
    rep(&amp;quot;mosaic&amp;quot;, 10000)))
gf_qq(~diffmean, color = ~type, data = df.diffmean)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-05-02-ein-wenig-schneller-zur-simulierten-nullverteilung_files/figure-html/unnamed-chunk-15-2.png&#34; width=&#34;672&#34; /&gt;
# qqplot(NullDistFSNDR_aw&lt;span class=&#34;math inline&#34;&gt;\(diffprop, NullDistMosaic_aw\)&lt;/span&gt;diffprop)
gf_qq(FSNDR ~ Mosaic, data=df)
# qqplot(NullDistFSNDR_mw&lt;span class=&#34;math inline&#34;&gt;\(diffmean, NullDistMosaic_mw\)&lt;/span&gt;diffmean)
gf_qq(NullDistFSNDR_mw&lt;span class=&#34;math inline&#34;&gt;\(diffmean ~ NullDistMosaic_mw\)&lt;/span&gt;diffmean)
```&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;woher-kommt-die-geschwindigkeit&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Woher kommt die Geschwindigkeit?&lt;/h2&gt;
&lt;p&gt;Schaut man sich den Quellcode von Mosaic an, wird einem schnell klar, dass es zwar didaktisch sinnvoll ist die unabhängige Variable mit &lt;code&gt;shuffle()&lt;/code&gt; zu bearbeiten, nicht aber programmiertechnisch. Und wenn, dann nicht in dem man die ganze Datenzeile für die Berechnung kopiert. Statt also &lt;span class=&#34;math inline&#34;&gt;\(10\,000\)&lt;/span&gt; mal die ganzen Daten im Speicher zu kopieren wäre es doch sinnvoller mit Hilfe eines Index auf die unveränderten Daten zuzugreifen. Und genau das machen die zwei Routinen. Es wird also nur dieser Zugriffsindex wird &lt;em&gt;geshuffelt&lt;/em&gt; und das spart Speicherplatz und deutlich auch Rechenzeit.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nur ein wenig lineare Regression</title>
      <link>https://sefiroth.net/nab/post/nur-ein-wenig-lineare-regression/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/nur-ein-wenig-lineare-regression/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Der &lt;em&gt;tipping&lt;/em&gt; Datensatz wird oft analysiert. Das Verhältnis von Trinkgeld (&lt;em&gt;tip&lt;/em&gt;) und Rechnungsbetrag (&lt;em&gt;total_bill&lt;/em&gt;) steht dabei im Vordergrund einer lineare Regressionsanalyse.
So auch hier. Wir wollen die einzelnen Angaben von &lt;strong&gt;R&lt;/strong&gt; dabei in den Fokus rücken und einmal Hinterfragen, was wir bei der Ausgabe von &lt;strong&gt;R&lt;/strong&gt; eigentlich genau sehen, woher es kommt und wie man es interpretieren kann.&lt;/p&gt;
&lt;p&gt;Zunächst laden wir dazu die &lt;strong&gt;tipping&lt;/strong&gt; Daten mittels&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mosaic)
download.file(&amp;quot;https://goo.gl/whKjnl&amp;quot;, destfile = &amp;quot;tips.csv&amp;quot;)
tips &amp;lt;- read.csv2(&amp;quot;tips.csv&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in den Arbeitsspeicher.&lt;/p&gt;
&lt;p&gt;Eine lineares Modell wird schnell mit&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linMod &amp;lt;- lm(tip ~ total_bill, data = tips)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;erstellt.
Betrachten wir die Zusammenfassung:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(linMod)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 0.920270   0.159735   5.761 2.53e-08 ***
## total_bill  0.105025   0.007365  14.260  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 
## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Die zentrale Frage bei einer linearen Regression ist, finden wir einen linearen Zusammenhang in unserer Stichprobe, den wir auf die Population (als die Grundgesamtheit) übertragen können.&lt;/p&gt;
&lt;p&gt;Die Spalte &lt;strong&gt;Estimate&lt;/strong&gt; im Abschnitt &lt;strong&gt;Coefficients&lt;/strong&gt; liefert uns in unser Stichprobe einen möglichen linearen Zusammenhang gemäß&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\hat{y}_{\text{tip}} = \hat{\beta}_{\text{0}} + \hat{\beta}_{\text{total_bill}} \cdot x_{\text{total_bill}},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit den &lt;em&gt;Regressionskoeffizienten&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0=0.9202696\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_{\text{total_bill}}=0.1050245\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Graphisch ergibt sich damit das Modell wie folgt:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linMod) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linMod, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;, padding.text = 8,
            lines = list(col = c(&amp;quot;red&amp;quot;), lty = c(2), lwd = 1.2),
            text = list(c(&amp;quot;Regressionsgerade&amp;quot;))
          )
     )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Was hat es mit dem y-Achsenabschnitt &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; auf sich?&lt;/p&gt;
&lt;p&gt;Ist es etwa eine Art &lt;em&gt;Grundtrinkgeld&lt;/em&gt;, mit dem der Kellern rechnen kann, auch wenn der Kunde gar nichts bestellt?&lt;/p&gt;
&lt;p&gt;Nun ja, es so etwas in der Art, aber eben ein rein fiktiver Wert, der durch die Konstruktion der Parameter entsteht.
Eine (affin-)lineare Gerade geht nun einmal irgendwann durch die y-Achse (wenn sie nicht parallel dazu ist) und es kann passieren, dass eine sinnvolle Interpretation nicht so ohne weiteres möglich ist.&lt;/p&gt;
&lt;p&gt;Wir können aber dieses &lt;em&gt;Grundtrinkgeld&lt;/em&gt; heraus nehmen und den y-Achsenabschnitt auf Null setzen. Dazu ziehen wir &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; einfach von alle Trinkgeldern ab. Wir erhalten quasi nur noch den &lt;em&gt;Trinkgeldzuwach&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta_0 &amp;lt;- coef(linMod)[&amp;quot;(Intercept)&amp;quot;]  # Grundtrinkgeld
tips$delta_tip &amp;lt;- tips$tip - beta_0    # wird abgezogen&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Vergleichen wir das alte lineare Modell mit dem neuen Modell (&lt;em&gt;linModDelta&lt;/em&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;linModDelta &amp;lt;- lm(delta_tip ~ total_bill, data = tips)
summary(linModDelta)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = delta_tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) -4.549e-15  1.597e-01    0.00        1    
## total_bill   1.050e-01  7.365e-03   14.26   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  0.4566, Adjusted R-squared:  0.4544 
## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In diesem Modell ist der Wert für den y-Achsenabschnitt numerisch gleich 0. – Ja, da mag zwar &lt;span class=&#34;math inline&#34;&gt;\(-4.5487837\times 10^{-15}\)&lt;/span&gt; stehen, jedoch sind so kleine Werte der jedem Rechner inne wohnenden Ungenauigkeit in der Gleitkomma-Arithmetik geschuldet und ist faktisch gleich 0.&lt;/p&gt;
&lt;p&gt;Der Wert für die Steigung lautet weiterhin &lt;span class=&#34;math inline&#34;&gt;\(0.1050245\)&lt;/span&gt;.
Das war auch zu erwarten, denn wir haben unsere Regressionsgerade eigentlich nur um &lt;span class=&#34;math inline&#34;&gt;\(\hat{\beta}_0\)&lt;/span&gt; nach unten verschoben. (Der Fachmann spricht von einer Translation (Parallelverschiebung)&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; um &lt;span class=&#34;math inline&#34;&gt;\(-\hat{\beta}_0\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linModDelta) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linModDelta, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    delta_tip ~ total_bill, data=tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Delta Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Delta Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space=&amp;quot;bottom&amp;quot;, padding.text=8,
            lines=list(col=c(&amp;quot;red&amp;quot;), lty=c(2), lwd=1.2),
            text=list(c(&amp;quot;Regressionsgerade&amp;quot;)))
     )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Vergleichen wir die beiden Zusammenfassungen, so stellen wir fest das sich mit Ausnahme der &lt;em&gt;[Intercept]&lt;/em&gt; Zeile praktisch nichts geändert hat. Das ist kein Wunder, sondern Absicht!&lt;/p&gt;
&lt;p&gt;Die Regressionsgerade stellt für unsere Stichprobe die Gerade mit dem geringsten Fehler an den Datenpunkten dar. Mathematisch heißt das folgendes:&lt;/p&gt;
&lt;p&gt;An den &lt;span class=&#34;math inline&#34;&gt;\(n=244\)&lt;/span&gt; Datenpunkten unserer Stichprobe &lt;span class=&#34;math inline&#34;&gt;\((x_i, y_i)=(tips\$total\_bill[i], tips\$tip[i])\)&lt;/span&gt; [für &lt;span class=&#34;math inline&#34;&gt;\((i=1, \dots, n)\)&lt;/span&gt;] sind die &lt;em&gt;Residuen&lt;/em&gt;, also die &lt;em&gt;Fehlerterme&lt;/em&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
 \hat{e}_i =\hat{y}_i - y_i = \left[\hat{\beta}_{\text{0}} + \hat{\beta}_{\text{total_bill}} \cdot x_i\right] - y_i
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;durch die verwendete &lt;em&gt;Methode der kleinsten Quadrate&lt;/em&gt;&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; &lt;em&gt;quadratisch minimal&lt;/em&gt;. Kurz:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \sum_{i=1}^n (\hat{e}_i)^2 \text{ ist minimal!}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können diese Fehlerterme graphisch ansehen um die Varianz der Residuen zu sehen.
Dazu ziehen wir von allen Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; den geschätzten Wert &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt; ab und erstellen ein neues lineares Modell:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beta_total_bill &amp;lt;- coef(linModDelta)[&amp;quot;total_bill&amp;quot;]
tips$error_tip &amp;lt;- (tips$tip - beta_0 - beta_total_bill * tips$total_bill)
linModError &amp;lt;- lm(error_tip ~ total_bill, data = tips)
summary(linModError)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = error_tip ~ total_bill, data = tips)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1982 -0.5652 -0.0974  0.4863  3.7434 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&amp;gt;|t|)
## (Intercept)  1.900e-15  1.597e-01       0        1
## total_bill  -8.740e-17  7.365e-03       0        1
## 
## Residual standard error: 1.022 on 242 degrees of freedom
## Multiple R-squared:  6.665e-31,  Adjusted R-squared:  -0.004132 
## F-statistic: 1.613e-28 on 1 and 242 DF,  p-value: 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also Diagramm sieht es dann so aus:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Statt plotModel(linModError) besser:
mypanel &amp;lt;- function(x, y) {
    # Scatterplot:
    panel.xyplot(x, y, col = &amp;quot;darkgreen&amp;quot;) 
    # Regressionsgerade:
    panel.abline(linModError, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    error_tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Residuen&amp;quot;,
    ylab  = &amp;quot;Residuen&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;, rows = 3, padding.text = 8,
            lines = list(col=c(&amp;quot;red&amp;quot;), lty = c(2), lwd = 1.2),
            text = list(c(&amp;quot;Regressionsgerade / x-Achse&amp;quot;))
          )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Wir können die Graphik im wesentlichen auch einfacher über den Befehl&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xyplot(residuals(linMod) ~ fitted(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;erhalten.&lt;/p&gt;
&lt;p&gt;Betrachten wir kurz nur die Residuen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;favstats(~residuals(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        min         Q1      median        Q3      max          mean       sd   n
##  -3.198225 -0.5651615 -0.09744499 0.4863111 3.743435 -2.022281e-17 1.019943 244
##  missing
##        0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wir sehe, dass wir in der Zusammenfassung immer genau diese Werte unter dem Abschnitt &lt;em&gt;Residuals&lt;/em&gt; gefunden haben. Minimum, das 1. Quantil, der Median, das 3. Quantil und das Maximum stimmen überein.&lt;/p&gt;
&lt;p&gt;Der erwartungstreue und unverzerrte Schätzer für den Standardfehler der Residuen, lautet&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
    SE_{\text{Residuen}} &amp;amp;= \sqrt{\frac{1}{n-2} \cdot \sum_{i=1}^n (\hat{e_i})^2} = \sqrt{\frac{n-1}{n-2} \cdot \frac{1}{n-1} \cdot \sum_{i=1}^n (\hat{e_i})^2} \\
                         &amp;amp;= \sqrt{\frac{n-1}{n-2}} \cdot \sqrt{\frac{1}{n-1} \cdot \sum_{i=1}^n (\hat{e_i})^2} \\
                         &amp;amp;= \sqrt{\frac{n-1}{n-2}} \cdot s_{\text{Residuen}}
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Also finden wir den Wert &lt;em&gt;Residual standard error&lt;/em&gt; aus der Zeile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Residual standard error: 1.022 on 242 degrees of freedom&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in dem wir den in den &lt;em&gt;favstats&lt;/em&gt; gefundenen Wert für die Standardabweichung entsprechen korrigieren:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SE_{\text{Residuen}} = \sqrt{\frac{n-1}{n-2}} \cdot s_{\text{Residuen}} = \sqrt{\frac{243}{242}} \cdot 1.0199426 = 1.0220477
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der Median der Residuen ist nicht gleich Null, wie der Mittelwert. (Welcher auch hier als numerisch Null interpretiert werden muss!)
Es könnte also eine linkssteile, rechtsschiefe Verteilung der Residuen vorliegen.
Betrachten wir dazu das Histogramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;histogram(~residuals(linMod), nint = 19)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Schon beim ersten Blick auf das Histogramm kann an eine Normalverteilung der Residuen nicht mehr so ganz geglaubt werden.&lt;/p&gt;
&lt;p&gt;Ein Shapiro-Wilk-Test&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; hat als Nullhypothese die Annahme, dass die Daten normalverteilt sind!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;shapiro.test(residuals(linMod))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Shapiro-Wilk normality test
## 
## data:  residuals(linMod)
## W = 0.96728, p-value = 2.171e-05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Davon ist nach dem Ergebnis eben sowenig auszugehen, wie nach einem Blick auf das QQ-Normal-Diagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqnorm(residuals(linMod), col = &amp;quot;darkgreen&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Ein K.O.-Kriterium für gute Prognosen.&lt;/p&gt;
&lt;p&gt;Wie gut aber beschreibt unsere Regressionsgerade die Daten?&lt;/p&gt;
&lt;p&gt;Als Maß dafür können wir das Bestimmtheitsmaß nehmen.&lt;/p&gt;
&lt;p&gt;Ein kurzer Blick auf die Situation, der Mittelwert der Trinkgelder ist&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \bar{y} =  \frac{1}{n} \cdot \sum_{i=1}^n y_i = 2.9982787.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir erhalten so folgendes Diagramm:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mypanel &amp;lt;- function(x, y) {
    panel.xyplot(x, y)
    panel.abline(h = mean(y), lwd = 1.2, lty = 2, col = &amp;quot;darkgreen&amp;quot;)
    panel.lmline(x, y, col = &amp;quot;red&amp;quot;, lwd = 1.2, lty = 2)
}
xyplot(
    tip ~ total_bill, data = tips, 
    panel = mypanel,
    main  = &amp;quot;Streudiagramm der Trinkgelder&amp;quot;,
    ylab  = &amp;quot;Trinkgeld&amp;quot;,
    xlab  = &amp;quot;Rechnungsbetrag&amp;quot;,
    key = list(
            space = &amp;quot;bottom&amp;quot;,
            padding.text = 8,
            columns = 2,
            just = c(&amp;quot;center&amp;quot;, &amp;quot;bottom&amp;quot;),
            lines = list(col = c(&amp;quot;darkgreen&amp;quot;, &amp;quot;red&amp;quot;), lty = c(2, 2), lwd = 1.2),
            text = list(c(expression(bar(y)), expression(hat(beta)[0]+hat(beta)[total_bill] * x[total_bill]))),
            text = list(c(&amp;quot;Mittelwert Trinkgeld&amp;quot;, &amp;quot;Regressionsgerade&amp;quot;))
    )
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://sefiroth.net/nab/nabpost/2018-01-08-nur-ein-wenig-lineare-regression_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Die Varianz &lt;span class=&#34;math inline&#34;&gt;\(s^2_{y_i}=1.9144546\)&lt;/span&gt; beschreibt die mittlere quadratische Abweichung der Datenpunkte &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; vom Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt;.
Diese Varianz lässt sich Zerlegen in einen Anteil, der durch die Regressionsgerade &lt;em&gt;erklärt&lt;/em&gt; wird und in einen Anteil, der durch die Regressionsgerade &lt;em&gt;nicht erklärt&lt;/em&gt; wird.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    s^2_{y_i} = s^2_{\hat{y}_i} + s^2_{\hat{e}_i}
\]&lt;/span&gt;
Dividiert man beider Seiten durch die Varianz &lt;span class=&#34;math inline&#34;&gt;\(s^2_{y_i}\)&lt;/span&gt;, so normiert man den Ausdruck und kann den Faktor &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n-1}\)&lt;/span&gt; (bzw. &lt;span class=&#34;math inline&#34;&gt;\(\frac{1}{n}\)&lt;/span&gt;) herauskürzen. Es bleibt dann:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    1 = \frac{\sum_{i=1}^n (\bar{y}- \hat{y_i})^2}{\sum_{i=1}^n (\bar{y}-y_i)^2} + \frac{\sum_{i=1}^n (\hat{e_i})^2}{\sum_{i=1}^n (\bar{y}-y_i)^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Multipliziert man beide Seiten mit &lt;span class=&#34;math inline&#34;&gt;\(\sum_{i=1}^n (y_i)^2\)&lt;/span&gt;, so erhält man:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \sum_{i=1}^n (\bar{y}- y_i)^2 = \sum_{i=1}^n (\bar{y}- \hat{y_i})^2+ \sum_{i=1}^n (\hat{e_i})^2 
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Zur Vereinfachung nennt man die einzelnen Summen in dem Ausdruck wie folgt:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der erste Ausdruck heißt &lt;strong&gt;Gesamtvarianz&lt;/strong&gt; oder &lt;strong&gt;total sum of squares&lt;/strong&gt; oder kurz &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt;&lt;/strong&gt;, (oder &lt;strong&gt;TSS&lt;/strong&gt;) er ist die Summe der quadrierten Differenzen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_T = \sum_{i=1}^n (\bar{y}-y_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der zweite Ausdruck heißt &lt;strong&gt;Modellvarianz&lt;/strong&gt; oder &lt;strong&gt;model sum of squares&lt;/strong&gt; oder kurz &lt;strong&gt;&lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt;&lt;/strong&gt; (oder &lt;strong&gt;RSS&lt;/strong&gt;), er ist die Summe der quadrierten Differenzen aus dem Mittelwert &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt; und der Punkte auf der Regressionsgeraden &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_M = \sum_{i=1}^n (\bar{y}-\hat{y}_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Der dritte Ausdruck heißt &lt;strong&gt;Gesamt-Verhersage-Fehler&lt;/strong&gt;, &lt;strong&gt;Fehlersteuung der Regression&lt;/strong&gt; oder &lt;strong&gt;error sum of squares&lt;/strong&gt; oder kurz &lt;span class=&#34;math inline&#34;&gt;\(SS_E\)&lt;/span&gt; (oder &lt;strong&gt;ESS&lt;/strong&gt;), er ist die Summe der quadratischen Differenz aus den Datenpunkten &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; und den Punkten der Regressionsgeraden &lt;span class=&#34;math inline&#34;&gt;\(\hat{y}_i\)&lt;/span&gt;:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_E = \sum_{i=1}^n (\hat{y}_i-y_i)^2 = \sum_{i=1}^n (\hat{e}_i)^2
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wir können daher auch kurz&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_T = SS_M + SS_E
\]&lt;/span&gt;
schreiben und sparen uns die ganzen Summenzeichen.&lt;/p&gt;
&lt;p&gt;Die Güte einer Regression wollen wir durch den Anteil der durch das Model erklärten Varianz (also der &lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt;) ausdrücken und stellen daher nach &lt;span class=&#34;math inline&#34;&gt;\(SS_M\)&lt;/span&gt; um:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    SS_M = SS_T - SS_E
\]&lt;/span&gt;
Teilen wir beide Seiten durch &lt;span class=&#34;math inline&#34;&gt;\(SS_T\)&lt;/span&gt; also der maximalen (weil totalen) Quadratsumme, so erhalten wir:
&lt;span class=&#34;math display&#34;&gt;\[
    \frac{SS_M}{SS_T} = \frac{SS_T}{SS_T} - \frac{SS_E}{SS_T} = 1 - \frac{SS_E}{SS_T}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Den Ausdruck &lt;span class=&#34;math inline&#34;&gt;\(\frac{SS_M}{SS_T}\)&lt;/span&gt; nennen wir &lt;strong&gt;Bestimmtheitsmaß&lt;/strong&gt; und schreiben dafür &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;. Es ist ein Wert zwischen 0 und 1, der den Anteil der durch das Modell beschriebenen Varianz in Bezug auf die Gesamtvarianz angibt. Kraft Definition ist &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; im eindimensionalen Fall tatsächlich das Quadrat des (Pearson-)Korrelationskoeffizienten &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;. (M.a.W.: &lt;span class=&#34;math inline&#34;&gt;\(R^2= r^2\)&lt;/span&gt;.)&lt;/p&gt;
&lt;p&gt;In unserer Zusammenfassung des linearen Models findet sich dieser Wert auch. Und zwar unter dem Begriff:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Multiple R-squared:  0.4566, &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Es gilt ja:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    R^2 = 1 - \frac{SS_E}{SS_T} = 1 - \frac{s^2_{\hat{e}_i}}{s^2_{y_i}} = 1 - \frac{1.0402829}{1.9144546} = 0.4566166
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Der Wert&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## ..., Adjusted R-squared:  0.4544&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;erklärt sich daraus&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, dass das Bestimmheitsmaß um so größer wird je größer die Zahl der unabhängigen Variablen wird.
Und zwar &lt;em&gt;unabhöngig&lt;/em&gt; davon, ob weitere unabhängige Variablen wirklich einen Beitrag zur Erklärungskraft liefern.
Daher nutzt man besser das &lt;strong&gt;korrigierte Bestimmtheitsmaß&lt;/strong&gt; (engl.: &lt;em&gt;adjusted R-squared&lt;/em&gt;) &lt;span class=&#34;math inline&#34;&gt;\(\bar{R}^2\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \begin{align*}
        \bar{R}^2 &amp;amp;= 1- (1-R^2) \cdot \frac{n-1}{n-p-1}\\ 
                  &amp;amp;= R^2 - (1-R^2)  \cdot \frac{p}{n-p-1}
    \end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Wobei &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; die Anzahl der unabhängigen Variablen im Modell darstellt.
In unserem Beispiel gilt daher:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    \begin{align*}
        \bar{R}^2 &amp;amp;= 1 - (1-R^2)  \cdot \frac{n-1}{n-p-1} \\
                  &amp;amp;= 1 - (1- 0.4566166)  \cdot \frac{244-1}{244- 1- 1} \\
                  &amp;amp;= 0.4543712
    \end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vorsicht:&lt;/strong&gt; Das &lt;em&gt;korrigierte Bestimmtheitsmaß&lt;/em&gt; ist nicht mehr an das Intervall &lt;span class=&#34;math inline&#34;&gt;\([0; 1]\)&lt;/span&gt; gebunden!
Es kann negative Werte annehmen, ist in der Regel kleiner als das (unkorrigierte) Bestimmtheitsmaß und erreicht die obere Grenze (&lt;span class=&#34;math inline&#34;&gt;\(\bar{R}^2=1\)&lt;/span&gt;) genau dann, wenn &lt;span class=&#34;math inline&#34;&gt;\(R^2 = 1\)&lt;/span&gt; ist.&lt;/p&gt;
&lt;p&gt;Bei der &lt;strong&gt;Gesamtsignifikanz des Modells&lt;/strong&gt; (auch &lt;strong&gt;Overall-F-Test&lt;/strong&gt; genannt) wird geprüft, ob mindestens eine Variable einen Erklärungsgehalt für das Modell liefert.&lt;/p&gt;
&lt;p&gt;Falls diese Hypothese verworfen wird ist somit das Modell nutzlos.
Dieser Test lässt sich so interpretieren als würde man die gesamte Güte des Modells, also das &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; des Modells, testen.
Aus diesem Grund wird der F-Test der Gesamtsignifikanz des Modells auch als Anpassungsgüte-Test bezeichnet.
Die Nullhypothese des F-Test der Gesamtsignifikanz des Modells sagt aus, dass alle erklärenden Variablen keinen Einfluss auf die abhängige Variable haben.
Sowohl die abhängige Variable als auch die unabhängigen Variablen können binär (kategoriell) oder metrisch sein.
Der &lt;em&gt;Wald-Test&lt;/em&gt; kann dann die Hypothesen testen (ohne Einbezug des Achsenabschnittes):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    H_{0}\colon \beta _{1}=\beta _{2}=\ldots =\beta _{k}\;=\;0\Rightarrow R^{2}=0
\]&lt;/span&gt;
gegen&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    H_{1}:\beta _{j}\;\neq \;0\;\mathrm {f{\ddot {u}}r\;mindestens\;ein} \;j\in \{1,\ldots ,k\}\Rightarrow R^{2}\neq 0
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Die Teststatistik dieses Tests lautet&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
    F\;\;{\stackrel {H_{0}}{=}}{\frac {R^{2}}{1-R^{2}}} \cdot {\frac {n-p-1}{p}}\;\;{\stackrel {H_{0}}{\sim }}\;\;F(p,n-p)
\end{aligned}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;mit &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle (n-p-1)\)&lt;/span&gt; Freiheitsgraden.
Überschreitet der empirische F-Wert einen kritischen F-Wert, der zu einem a priori festgelegten Signifikanzniveau &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, so verwirft man die Nullhypothese &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt;.
Das &lt;span class=&#34;math inline&#34;&gt;\(R^{2}\)&lt;/span&gt; ist dann ausreichend groß und mindestens ein Regressor trägt also vermutlich genügend viel Information zur Erklärung von &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; bei.
Es ist naheliegend bei hohen F-Werten die Nullhypothese zu verwerfen, da ein hohes Bestimmtheitsmaß zu einem hohen F-Wert führt.
Wenn der &lt;em&gt;Wald-Test&lt;/em&gt; für eine oder mehrere unabhängige Variablen die Nullhypothese ablehnt, dann kann man davon ausgehen, dass die zugehörigen Parameter ungleich Null sind, so dass die Variable(n) in das Modell mit einbezogen werden sollten.&lt;/p&gt;
&lt;p&gt;In unserem Beispiel ist&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
    F={\frac {R^{2}}{1-R^{2}}} \cdot {\frac {n-p-1}{p}} = \frac{0.4566166}{1-0.4566166} \cdot \frac{244-1-1}{1} = 203.3577233
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;der Wert in der Zeile&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## F-statistic: 203.4 on 1 and 242 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;mit Parametern &lt;span class=&#34;math inline&#34;&gt;\(p=1\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(n-p-1=242\)&lt;/span&gt; Freiheitsgraden.&lt;/p&gt;
&lt;p&gt;Der p-Wert von (numerisch) 0, liefert also ein hinreichendes Indiz dafür, dass der Rechnungsbetrag einen echten Beitrag liefert.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Parallelverschiebung&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Parallelverschiebung&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Shapiro-Wilk-Test&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Shapiro-Wilk-Test&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;vgl.: &lt;a href=&#34;https://de.wikipedia.org/wiki/Bestimmtheitsmaß#Das_korrigierte_Bestimmtheitsmaß&#34; class=&#34;uri&#34;&gt;https://de.wikipedia.org/wiki/Bestimmtheitsmaß#Das_korrigierte_Bestimmtheitsmaß&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Quartile, Quantile, Perzentile etc.</title>
      <link>https://sefiroth.net/nab/post/quartile-quantile-perzentile-etc/</link>
      <pubDate>Tue, 19 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/post/quartile-quantile-perzentile-etc/</guid>
      <description>
&lt;script src=&#34;https://sefiroth.net/nab/nabrmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;“Was hat das eigentlich mit den Quartilen, Quantilen und so weiter auf sich?”
Diese Frage kommt ab und zu in Vorlesungen zur Statistik vor. Dabei ist die Antwort recht einfach.&lt;/p&gt;
&lt;div id=&#34;quantile&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quantile&lt;/h2&gt;
&lt;div id=&#34;definitorische-antwort&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Definitorische Antwort&lt;/h3&gt;
&lt;p&gt;Für eine gegebene reelle Zufallsvariable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; heißt eine reelle Zahl &lt;span class=&#34;math inline&#34;&gt;\(x_p\)&lt;/span&gt; ein &lt;strong&gt;p-Quantil&lt;/strong&gt; (von &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;), falls gilt:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(X \leq x_p) \leq p \quad \text{ und }\quad P(x_p \leq X) \geq 1-p.\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;was-bedeutet-das-denn-nun-konkret&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Was bedeutet das denn nun konkret?&lt;/h3&gt;
&lt;p&gt;Nun, ein Quantil ist ein Schwellenwert.
Ein bestimmter Anteil der Werte ist kleiner als das Quantil, der Rest ist größer.
Das 25-%-Quantil beispielsweise ist der Wert, für den gilt, dass 25 % aller Werte kleiner sind als dieser Wert.
Quantile formalisieren praktische Aussagen wie „25 % aller Frauen sind kleiner als 1,62 m“ –- wobei 1,62 m hier das 25-%-Quantil ist.&lt;/p&gt;
&lt;p&gt;Spezielle Quantile sind der &lt;em&gt;Median&lt;/em&gt;, die &lt;em&gt;Quartile&lt;/em&gt;, die &lt;em&gt;Quintile&lt;/em&gt;, die &lt;em&gt;Dezile&lt;/em&gt; und die &lt;em&gt;Perzentile&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;Wir betrachten dazu in den Bespielen die Datenreihe &lt;code&gt;dr&lt;/code&gt; an:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Die Zahlen von 0 bis 600 
dr &amp;lt;- 0:600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;median&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Median&lt;/h3&gt;
&lt;p&gt;Der &lt;strong&gt;Median&lt;/strong&gt; (von lat. &lt;em&gt;Medium&lt;/em&gt; für „Mitte, Mittelpunkt“ abgeleiteter Begriff mit der Bedeutung “in der Mitte gelegen”) die das 50-%-Quantil. Der Wert, welcher die Datenreihe (bestenfalls) in zwei (etwa) gleich große Abschnitte trennt. Sehr oft schreibt man &lt;span class=&#34;math inline&#34;&gt;\(x_{med}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{50\%}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{Med}\)&lt;/span&gt; oder &lt;span class=&#34;math inline&#34;&gt;\(Q_2\)&lt;/span&gt; für den Median&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(dr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 300&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;terzile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Terzile&lt;/h3&gt;
&lt;p&gt;Als &lt;strong&gt;Terile&lt;/strong&gt; (von lat. &lt;em&gt;tertius&lt;/em&gt; “der Dritte”) werden die beiden Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=1/3\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=2/3\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in drei Abschnitte.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        0% 33.33333% 66.66667%      100% 
##         0       200       400       600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quartile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quartile&lt;/h3&gt;
&lt;p&gt;Die &lt;strong&gt;Quartile&lt;/strong&gt; (von lat. &lt;em&gt;quartus&lt;/em&gt; „der Vierte“) werden die Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=25\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=50\%\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=75\%\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in vier Abschnitte.
Dabei schreibt man oft: &lt;span class=&#34;math inline&#34;&gt;\(Q_1 = x_{0{,}25}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(x_{Med} = Q_2 = x_{0{,}50}\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(Q_3 = x_{0{,}75}\)&lt;/span&gt; für die drei Quantile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr) # oder auch: quantile(dr, probs=seq(0, 1, 1/4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  25%  50%  75% 100% 
##    0  150  300  450  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;quintile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Quintile&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Quintile&lt;/strong&gt; (von lat. &lt;em&gt;quintus&lt;/em&gt; “der Fünfte”) werden die Quantile mit &lt;span class=&#34;math inline&#34;&gt;\(p=20\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=40\%\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(p=60\%\)&lt;/span&gt; und &lt;span class=&#34;math inline&#34;&gt;\(p=80\%\)&lt;/span&gt; bezeichnet.
Sie teilen die Datenreihe in fünf Abschnitte.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  20%  40%  60%  80% 100% 
##    0  120  240  360  480  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;dezile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dezile&lt;/h3&gt;
&lt;p&gt;Die Quantile für vielfache von &lt;span class=&#34;math inline&#34;&gt;\(0{,}1\)&lt;/span&gt; also für &lt;span class=&#34;math inline&#34;&gt;\(p=0{,}1;0{,}2;\dots ;0{,}9\)&lt;/span&gt; werden &lt;strong&gt;Dezile&lt;/strong&gt; (von mittellateinisch &lt;em&gt;decimalis&lt;/em&gt;, zu lat. &lt;em&gt;decem&lt;/em&gt; „zehn“) genannt.
Dabei heißt das &lt;span class=&#34;math inline&#34;&gt;\(0{,}1\)&lt;/span&gt;-Quantil das erste Dezil, das &lt;span class=&#34;math inline&#34;&gt;\(0{,}2\)&lt;/span&gt;-Quantil das zweite Dezil usw.
Unterhalb des ersten Dezils liegen 10 % der Stichprobe, oberhalb entsprechend 90 % der Stichprobe.
Ebenso liegen 40 % der Stichprobe unterhalb des vierten Dezils und 60 % oberhalb.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/10))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% 
##    0   60  120  180  240  300  360  420  480  540  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;perzentile&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Perzentile&lt;/h3&gt;
&lt;p&gt;Als &lt;strong&gt;Perzentile&lt;/strong&gt; (von lat.-ital. &lt;em&gt;per centum&lt;/em&gt; “von Hundert, Hundertstel”) werden die Quantile von &lt;span class=&#34;math inline&#34;&gt;\(\displaystyle 0{,}01\)&lt;/span&gt; bis $ 0{,}99$ in Schritten von &lt;span class=&#34;math inline&#34;&gt;\(0{,}01\)&lt;/span&gt; bezeichnet.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;quantile(dr, probs = seq(0, 1, 1/100))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   0%   1%   2%   3%   4%   5%   6%   7%   8%   9%  10%  11%  12%  13%  14%  15% 
##    0    6   12   18   24   30   36   42   48   54   60   66   72   78   84   90 
##  16%  17%  18%  19%  20%  21%  22%  23%  24%  25%  26%  27%  28%  29%  30%  31% 
##   96  102  108  114  120  126  132  138  144  150  156  162  168  174  180  186 
##  32%  33%  34%  35%  36%  37%  38%  39%  40%  41%  42%  43%  44%  45%  46%  47% 
##  192  198  204  210  216  222  228  234  240  246  252  258  264  270  276  282 
##  48%  49%  50%  51%  52%  53%  54%  55%  56%  57%  58%  59%  60%  61%  62%  63% 
##  288  294  300  306  312  318  324  330  336  342  348  354  360  366  372  378 
##  64%  65%  66%  67%  68%  69%  70%  71%  72%  73%  74%  75%  76%  77%  78%  79% 
##  384  390  396  402  408  414  420  426  432  438  444  450  456  462  468  474 
##  80%  81%  82%  83%  84%  85%  86%  87%  88%  89%  90%  91%  92%  93%  94%  95% 
##  480  486  492  498  504  510  516  522  528  534  540  546  552  558  564  570 
##  96%  97%  98%  99% 100% 
##  576  582  588  594  600&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Etwas R am Abend</title>
      <link>https://sefiroth.net/nab/project/etwas-r-am-abend/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/project/etwas-r-am-abend/</guid>
      <description></description>
    </item>
    
    <item>
      <title>FastSimNullDistR</title>
      <link>https://sefiroth.net/nab/project/fastsimnulldistr/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/project/fastsimnulldistr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pandoc filter: style.py</title>
      <link>https://sefiroth.net/nab/project/style.py/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/project/style.py/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pandoc filter: typography.py</title>
      <link>https://sefiroth.net/nab/project/typography.py/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/project/typography.py/</guid>
      <description></description>
    </item>
    
    <item>
      <title>RmdStyleChecker</title>
      <link>https://sefiroth.net/nab/project/rmdstylechecker/</link>
      <pubDate>Fri, 10 Feb 2017 00:00:00 +0000</pubDate>
      <guid>https://sefiroth.net/nab/project/rmdstylechecker/</guid>
      <description>&lt;p&gt;Jede Sprache hat Regeln, auch Programmiersprachen und R markdown ist eine Programmiersprache. Wieso also nicht ein Tool schreiben, welches &lt;em&gt;SStilregeln&lt;/em&gt; (engl. &lt;em&gt;style guides&lt;/em&gt;) für R markdown kontrolliert um auch im kolaborativen Einsatz ein einheitliches &amp;ldquo;Schriftbild&amp;rdquo; des Quelltextes zu erhalten.&lt;/p&gt;
&lt;p&gt;&amp;hellip;&lt;/p&gt;
&lt;p&gt;Einen ersten Schritt habe ich mit dem &lt;a href=&#34;auch-rmarkdown-dateien-sollten-sich-regeln-halten&#34;&gt;Blog-Eintrag&lt;/a&gt; gemacht und dazu gleich noch ein Tool in &lt;em&gt;Python&lt;/em&gt; geschrieben um Verstöße dagegen schneller zu finden.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
